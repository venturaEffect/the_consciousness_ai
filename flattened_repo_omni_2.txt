<analysis/plot_annecs.py>
import copy
import gc
import json
import hydra
from omegaconf import DictConfig
import os
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.ticker as ticker
from scipy import stats

from omni_epic.robots import robot_dict
from analysis.visualize_taskgen import read_last_json_entry
from analysis.visualize_dreamer import visualize_ckpt_env
from run_utils import get_task_success_from_folder
from omni_epic.core.fm import FM
from rag_utils import get_similar_codepaths


def check_min_criterion(path, path_index, prev_paths, method_folder, n_prev_paths=-1, embedding_method='openai'):
    # Can the previous ckpts do the new task
    ckpt_successes = []

    # Get the previous paths
    if n_prev_paths > 0:
        prev_paths, prev_paths_indices = get_similar_codepaths(
            path,
            prev_paths,
            num_returns=n_prev_paths,
            embedding_method=embedding_method
        )

    # Evaluate previous ckpts on the new env task
    for j, env_path in zip(prev_paths_indices, prev_paths):
        eval_dir = f'./{method_folder}/eval_env{path_index}_ckpt{j}'
        ckpt_dir = os.path.dirname(env_path)
        if not os.path.exists(eval_dir):
            visualize_ckpt_env(ckpt_dir, path, eval_dir, num_episodes=5)
        task_success = get_task_success_from_folder(eval_dir, voting='any')
        ckpt_successes.append(task_success)
        # Clean up after each evaluation
        gc.collect()

    # Check if ckpt passes the min criterion
    return sum(ckpt_successes) <= len(ckpt_successes) / 2

def check_interesting(fm_moi, config, robot_desc, path, path_index, prev_paths, method_folder):
    json_file = f'./{method_folder}/eval_ckpt{path_index}.json'
    num_examples = config.model_of_interestingness.num_examples

    if not os.path.exists(json_file):
        # Query interestingness
        os.makedirs(os.path.dirname(json_file), exist_ok=True)
        moi_example_paths = copy.copy(prev_paths)
        if num_examples > 0 and len(moi_example_paths) > num_examples:
            moi_example_paths, _ = get_similar_codepaths(
                path,
                moi_example_paths,
                num_returns=num_examples,
                embedding_method=config.embedding_method,
            )
        _, is_interesting = fm_moi.query_interestingness(robot_desc, path, moi_example_paths)

        # Save the interestingness value as json
        json_data = {'is_interesting': is_interesting}
        with open(json_file, 'w') as f:
            json.dump(json_data, f)
    else:
        # Load the interestingness value from json
        with open(json_file, 'r') as f:
            json_data = json.load(f)
            is_interesting = json_data['is_interesting']

    return is_interesting

def change_color(color, factor=0.5):
    """Darken the given color by the given factor."""
    # return tuple([max(0, min(c * factor, 1)) for c in color])
    return tuple([color[2], color[0], color[1]])

def plot_annecs_metrics(metrics_dict, config):
    colors = plt.cm.tab10.colors  # Get a set of colors to use for different methods
    method_color_map = {}  # Dictionary to store the color for each method

    # Find the minimum number of iterations across all methods
    min_iterations = min(len(metrics['median_annecs']) for metrics in metrics_dict.values())
    print(f"Minimum number of iterations: {min_iterations}")

    def apply_plot_customizations(ax, config, title=None):
        if config.remove_titles and title:
            ax.set_title("")
        if config.remove_axes_labels:
            ax.set_xlabel("")
            ax.set_ylabel("")
        if config.remove_legend:
            ax.legend().set_visible(False)
        else:
            ax.legend()

    # Combined plot
    plt.figure(figsize=(10, 6))

    for idx, (method, metrics) in enumerate(metrics_dict.items()):
        iterations = range(1, min_iterations + 1)
        median_annecs = metrics['median_annecs'][:min_iterations]
        lower_annecs = metrics['lower_annecs'][:min_iterations]
        upper_annecs = metrics['upper_annecs'][:min_iterations]
        median_annecs_omni = metrics['median_annecs_omni'][:min_iterations]
        lower_annecs_omni = metrics['lower_annecs_omni'][:min_iterations]
        upper_annecs_omni = metrics['upper_annecs_omni'][:min_iterations]

        if method not in method_color_map:
            method_color_map[method] = colors[idx % len(colors)]  # Assign a color to the method

        color = method_color_map[method]
        dark_color = change_color(color)

        # Plot ANNECS with confidence interval
        plt.plot(iterations, median_annecs, label=f'(ANNECS) {method}', linewidth=2, color=color)
        plt.fill_between(iterations, lower_annecs, upper_annecs, color=color, alpha=0.2)

        # Plot ANNECS-OMNI with dotted line and confidence interval
        plt.plot(iterations, median_annecs_omni, label=f'(ANNECS-OMNI) {method}', linestyle=':', linewidth=2, color=dark_color)
        plt.fill_between(iterations, lower_annecs_omni, upper_annecs_omni, color=dark_color, alpha=0.2)

    plt.xlabel('Completed Archive Size')
    plt.ylabel('Metric Value')
    plt.title('ANNECS and ANNECS-OMNI over Iterations for Different Methods')
    plt.grid(True)

    plt.xticks(range(1, min_iterations + 1, max(1, min_iterations // 10)))  # Set integer tick labels for x-axis
    ax = plt.gca()
    ax.yaxis.set_major_locator(ticker.MaxNLocator(integer=True))  # Set integer tick labels for y-axis

    apply_plot_customizations(ax, config, 'ANNECS and ANNECS-OMNI over Iterations for Different Methods')

    plt.savefig(f'./plot_annecs_combined.{config.file_format}', bbox_inches='tight', transparent=config.remove_background)
    plt.close()

    # New combined plot for ANNECS only
    plt.figure(figsize=(10, 6))

    for idx, (method, metrics) in enumerate(metrics_dict.items()):
        iterations = range(1, min_iterations + 1)
        median_annecs = metrics['median_annecs'][:min_iterations]
        lower_annecs = metrics['lower_annecs'][:min_iterations]
        upper_annecs = metrics['upper_annecs'][:min_iterations]

        color = method_color_map[method]

        # Plot ANNECS with confidence interval
        plt.plot(iterations, median_annecs, label=f'{method}', linewidth=2, color=color)
        plt.fill_between(iterations, lower_annecs, upper_annecs, color=color, alpha=0.2)

    plt.xlabel('Completed Archive Size')
    plt.ylabel('ANNECS Value')
    plt.title('ANNECS over Iterations for Different Methods')
    plt.grid(True)

    plt.xticks(range(1, min_iterations + 1, max(1, min_iterations // 10)))
    ax = plt.gca()
    ax.yaxis.set_major_locator(ticker.MaxNLocator(integer=True))

    apply_plot_customizations(ax, config, 'ANNECS over Iterations for Different Methods')

    plt.savefig(f'./plot_annecs_combined1.{config.file_format}', bbox_inches='tight', transparent=config.remove_background)
    plt.close()

    # New combined plot for ANNECS-OMNI only
    plt.figure(figsize=(10, 6))

    for idx, (method, metrics) in enumerate(metrics_dict.items()):
        iterations = range(1, min_iterations + 1)
        median_annecs_omni = metrics['median_annecs_omni'][:min_iterations]
        lower_annecs_omni = metrics['lower_annecs_omni'][:min_iterations]
        upper_annecs_omni = metrics['upper_annecs_omni'][:min_iterations]

        color = method_color_map[method]

        # Plot ANNECS-OMNI with confidence interval
        plt.plot(iterations, median_annecs_omni, label=f'{method}', linestyle=':', linewidth=2, color=color)
        plt.fill_between(iterations, lower_annecs_omni, upper_annecs_omni, color=color, alpha=0.2)

    plt.xlabel('Completed Archive Size')
    plt.ylabel('ANNECS-OMNI Value')
    plt.title('ANNECS-OMNI over Iterations for Different Methods')
    plt.grid(True)

    plt.xticks(range(1, min_iterations + 1, max(1, min_iterations // 10)))
    ax = plt.gca()
    ax.yaxis.set_major_locator(ticker.MaxNLocator(integer=True))

    apply_plot_customizations(ax, config, 'ANNECS-OMNI over Iterations for Different Methods')

    plt.savefig(f'./plot_annecs_combined2.{config.file_format}', bbox_inches='tight', transparent=config.remove_background)
    plt.close()

    # Individual plots for each method
    for method, metrics in metrics_dict.items():
        plt.figure(figsize=(10, 6))
        iterations = range(1, min_iterations + 1)

        color = method_color_map[method]
        dark_color = change_color(color)

        # Plot ANNECS
        plt.plot(iterations, metrics['median_annecs'][:min_iterations], label='ANNECS', linewidth=2, color=color)
        plt.fill_between(iterations,
                         metrics['lower_annecs'][:min_iterations],
                         metrics['upper_annecs'][:min_iterations],
                         color=color, alpha=0.2)

        # Plot ANNECS-OMNI
        plt.plot(iterations, metrics['median_annecs_omni'][:min_iterations], label='ANNECS-OMNI', linestyle=':', linewidth=2, color=dark_color)
        plt.fill_between(iterations,
                         metrics['lower_annecs_omni'][:min_iterations],
                         metrics['upper_annecs_omni'][:min_iterations],
                         color=dark_color, alpha=0.2)

        plt.xlabel('Completed Archive Size')
        plt.ylabel('Metric Value')
        plt.title(f'ANNECS and ANNECS-OMNI over Iterations for {method}')
        plt.grid(True)

        plt.xticks(range(1, min_iterations + 1, max(1, min_iterations // 10)))  # Set integer tick labels for x-axis
        ax = plt.gca()
        ax.yaxis.set_major_locator(ticker.MaxNLocator(integer=True))  # Set integer tick labels for y-axis

        apply_plot_customizations(ax, config, f'ANNECS and ANNECS-OMNI over Iterations for {method}')

        plt.savefig(f'./plot_annecs_{method.replace("/", "")}.{config.file_format}', bbox_inches='tight', transparent=config.remove_background)
        plt.close()

    # Save numerical data to JSON file
    def serialize_data(data):
        if isinstance(data, np.ndarray):
            return data.tolist()
        elif isinstance(data, list):
            return data
        else:
            return float(data)  # Handle scalar values

    json_data = {
        method: {
            'iterations': list(range(1, min_iterations + 1)),
            **{key: serialize_data(metrics[key][:min_iterations])
            for key in metrics if key != 'iterations'}
        }
        for method, metrics in metrics_dict.items()
    }

    with open('annecs_data.json', 'w') as f:
        json.dump(json_data, f)

def bootstrap_ci(data, num_bootstrap_samples=10000, ci=95):
    bootstrapped_medians = []
    for _ in range(num_bootstrap_samples):
        resampled_data = np.random.choice(data, size=len(data), replace=True)
        bootstrapped_medians.append(np.median(resampled_data))

    lower_percentile = (100 - ci) / 2
    upper_percentile = 100 - lower_percentile

    return (np.percentile(bootstrapped_medians, lower_percentile),
            np.percentile(bootstrapped_medians, upper_percentile))

def calculate_metrics(all_annecs, all_annecs_omni):
    num_iterations = min(len(run) for run in all_annecs)
    all_annecs = [run[:num_iterations] for run in all_annecs]
    all_annecs_omni = [run[:num_iterations] for run in all_annecs_omni]
    median_annecs = np.median(all_annecs, axis=0)
    median_annecs_omni = np.median(all_annecs_omni, axis=0)

    lower_annecs = []
    upper_annecs = []
    lower_annecs_omni = []
    upper_annecs_omni = []

    for i in range(num_iterations):
        annecs_at_i = [run[i] for run in all_annecs]
        annecs_omni_at_i = [run[i] for run in all_annecs_omni]

        lower, upper = bootstrap_ci(annecs_at_i)
        lower_annecs.append(lower)
        upper_annecs.append(upper)

        lower_omni, upper_omni = bootstrap_ci(annecs_omni_at_i)
        lower_annecs_omni.append(lower_omni)
        upper_annecs_omni.append(upper_omni)

    return {
        'median_annecs': median_annecs,
        'lower_annecs': lower_annecs,
        'upper_annecs': upper_annecs,
        'median_annecs_omni': median_annecs_omni,
        'lower_annecs_omni': lower_annecs_omni,
        'upper_annecs_omni': upper_annecs_omni,
    }

def process_method(config, robot_desc, method, method_config):
    all_annecs = []
    all_annecs_omni = []

    config_moi = config.model_of_interestingness
    fm_moi = FM(config_moi)

    codepaths_list = []
    for method_repeat, archive_path in enumerate(method_config.paths):
        data = read_last_json_entry(archive_path)
        codepaths = data['codepaths']
        codepaths_list.append(codepaths)

    # Find the minimum length of codepaths
    min_codepaths_length = min(len(codepaths) for codepaths in codepaths_list)

    for method_repeat, codepaths in enumerate(codepaths_list):
        # Values to plotted
        iterations = []
        annecs = []
        annecs_omni = []

        for i in range(min_codepaths_length):
            env_path = codepaths[i]
            prev_paths = codepaths[:i]

            # Check if the ckpt passes the min criterion and is interesting
            method_folder = f"{method.replace('/', '')}_{method_repeat}"
            if config.train_agent:
                passed_criterion = check_min_criterion(
                    env_path, i, prev_paths, method_folder,
                    n_prev_paths=config.num_prev_eval_envs,
                    embedding_method=config.embedding_method,
                )
            else:
                passed_criterion = True
            is_interesting = check_interesting(fm_moi, config, robot_desc, env_path, i, prev_paths, method_folder)

            # Update ANNECS values
            add_annecs = 1 if passed_criterion else 0
            curr_annecs = annecs[-1] + add_annecs if i > 0 else add_annecs

            # Update ANNECS-OMNI values
            add_annecs_omni = 1 if (passed_criterion and is_interesting) else 0
            curr_annecs_omni = annecs_omni[-1] + add_annecs_omni if i > 0 else add_annecs_omni

            # Append values
            iterations.append(i + 1)
            annecs.append(curr_annecs)
            annecs_omni.append(curr_annecs_omni)

        all_annecs.append(annecs)
        all_annecs_omni.append(annecs_omni)

    # Calculate metrics
    metrics = calculate_metrics(all_annecs, all_annecs_omni)

    return {
        'iterations': iterations,
        **metrics
    }

def significance_testing():
    # Load the annecs_data.json file
    with open('annecs_data.json', 'r') as f:
        data = json.load(f)
    
    # Extract data for comparisons
    methods = list(data.keys())

    # Prepare to store results
    comparison_results = {}

    # Compare each pair of methods
    for i in range(len(methods)):
        for j in range(i + 1, len(methods)):
            method1 = methods[i]
            method2 = methods[j]

            # Extract ANNECS and ANNECS-OMNI data for both methods
            median_annecs1 = data[method1]['median_annecs']
            median_annecs2 = data[method2]['median_annecs']
            median_annecs_omni1 = data[method1]['median_annecs_omni']
            median_annecs_omni2 = data[method2]['median_annecs_omni']

            # Perform t-test
            t_stat, p_val_annecs = stats.ttest_ind(median_annecs1, median_annecs2, equal_var=False)
            t_stat, p_val_annecs_omni = stats.ttest_ind(median_annecs_omni1, median_annecs_omni2, equal_var=False)

            # Perform Mann-Whitney U test
            u_stat, p_val_mannwhitney_annecs = stats.mannwhitneyu(median_annecs1, median_annecs2)
            u_stat, p_val_mannwhitney_annecs_omni = stats.mannwhitneyu(median_annecs_omni1, median_annecs_omni2)

            # Store the results
            comparison_results[f"{method1} vs {method2}"] = {
                't-test_annecs': p_val_annecs,
                't-test_annecs_omni': p_val_annecs_omni,
                'mannwhitney_annecs': p_val_mannwhitney_annecs,
                'mannwhitney_annecs_omni': p_val_mannwhitney_annecs_omni,
            }

    # Save results to a JSON file
    with open('significance_testing_results.json', 'w') as f:
        json.dump(comparison_results, f, indent=4)

@hydra.main(version_base=None, config_path="../configs/", config_name="plot_annecs")
def main(config: DictConfig):
    robot_desc = robot_dict[config.robot]["robot_desc"]

    if not config.metrics_dict_path:
        # Process each method
        metrics_dict = {}
        for method, method_config in config.methods.items():
            print(f"Processing method: {method}")
            metrics_dict[method] = process_method(config, robot_desc, method, method_config)
    else:
        # Load metrics dict from file
        with open(config.metrics_dict_path, 'r') as f:
            metrics_dict = json.load(f)

    # make plots
    plot_annecs_metrics(metrics_dict, config)

    # significance testing
    significance_testing()

if __name__ == "__main__":
    main()

</analysis/plot_annecs.py>

<analysis/plot_diversity.py>
import hydra
from omegaconf import DictConfig
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.colors import ListedColormap, BoundaryNorm
from matplotlib.cm import ScalarMappable
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
import os
import json
from sklearn.decomposition import PCA
from scipy import stats

from analysis.visualize_taskgen import read_last_json_entry
from rag_utils import get_embeddings


class Autoencoder(nn.Module):
    def __init__(self, input_dim, encoding_dim):
        super(Autoencoder, self).__init__()
        self.encoder = nn.Sequential(
            nn.Linear(input_dim, 128),
            nn.ReLU(),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, encoding_dim),
        )
        self.decoder = nn.Sequential(
            nn.Linear(encoding_dim, 64),
            nn.ReLU(),
            nn.Linear(64, 128),
            nn.ReLU(),
            nn.Linear(128, input_dim),
        )
    def forward(self, x):
        encoded = self.encoder(x)
        decoded = self.decoder(encoded)
        return encoded, decoded

def train_autoencoder(model, data, epochs=100, batch_size=32):
    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters())
    dataloader = DataLoader(TensorDataset(data), batch_size=batch_size, shuffle=True)
    
    for epoch in range(epochs):
        total_loss = 0
        for batch in dataloader:
            inputs = batch[0]
            optimizer.zero_grad()
            _, outputs = model(inputs)
            loss = criterion(outputs, inputs)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        
        if (epoch + 1) % 10 == 0:
            print(f'Epoch [{epoch+1}/{epochs}], Loss: {total_loss:.4f}')

def calculate_cell_coverage(codepaths, codepaths_2d_embedding, min_x, max_x, min_y, max_y, grid_size=10):
    embeddings = np.array([codepaths_2d_embedding[codepath] for codepath in codepaths])

    # Create a grid_size x grid_size grid
    grid = np.zeros((grid_size, grid_size), dtype=int)

    # Calculate bin edges
    x_bins = np.linspace(min_x, max_x, grid_size + 1)
    y_bins = np.linspace(min_y, max_y, grid_size + 1)

    # Discretize the embeddings into the grid
    for x, y in embeddings:
        x_index = np.digitize(x, x_bins) - 1
        y_index = np.digitize(y, y_bins) - 1

        # Ensure the indices are within bounds (0 to grid_size-1)
        x_index = min(max(x_index, 0), grid_size - 1)
        y_index = min(max(y_index, 0), grid_size - 1)

        grid[y_index, x_index] += 1  # Increment the cell count

    # Calculate cell coverage
    cell_coverage = (grid > 0).sum() / (grid_size * grid_size)

    return cell_coverage

def plot_archive_diversity(method, codepaths, codepaths_2d_embedding, min_x, max_x, min_y, max_y, grid_size=10, suffix='', file_format='png', remove_titles=False, remove_background=False, remove_axes_labels=False, add_colorbar=True):
    embeddings = np.array([codepaths_2d_embedding[codepath] for codepath in codepaths])
    
    # Create a grid_size x grid_size grid
    grid = np.zeros((grid_size, grid_size), dtype=int)
    
    # Calculate bin edges
    x_bins = np.linspace(min_x, max_x, grid_size + 1)
    y_bins = np.linspace(min_y, max_y, grid_size + 1)
    
    # Discretize the embeddings into the grid
    for x, y in embeddings:
        x_index = np.digitize(x, x_bins) - 1
        y_index = np.digitize(y, y_bins) - 1
        
        # Ensure the indices are within bounds (0 to grid_size-1)
        x_index = min(max(x_index, 0), grid_size - 1)
        y_index = min(max(y_index, 0), grid_size - 1)
        
        grid[y_index, x_index] += 1  # Increment the cell count

    # Create a discrete colormap
    color_palette = plt.cm.inferno
    colors = color_palette(np.linspace(0, 1, 12))
    colors = colors[1:][::-1]  # Reverse the colors, skip black
    colors[0] = [1, 1, 1, 1]  # Set the color of the 0 count cell to white
    cmap = ListedColormap(colors)

    # Create discrete norm
    bounds = np.linspace(0, 10, 11)
    norm = BoundaryNorm(bounds, cmap.N)

    # Plot the grid
    fig, ax = plt.subplots(figsize=(10, 8))
    im = ax.imshow(grid, cmap=cmap, norm=norm, interpolation='nearest', extent=[min_x, max_x, min_y, max_y])

    # Fix aspect ratio
    ax.set_aspect('auto')

    # Add discrete colorbar if required
    if add_colorbar:
        sm = ScalarMappable(cmap=cmap, norm=norm)
        sm.set_array([])
        cbar = plt.colorbar(sm, ax=ax, label='Number of tasks', ticks=np.arange(11))
        cbar.set_ticklabels(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10+'])
        cbar.ax.tick_params(labelsize=12)
        cbar.set_label('Number of tasks', fontsize=14)

    # Add grid lines for all cells
    ax.set_xticks(np.linspace(min_x, max_x, grid_size + 1), minor=True)
    ax.set_yticks(np.linspace(min_y, max_y, grid_size + 1), minor=True)
    ax.grid(which='minor', color='grey', linestyle='-', linewidth=0.5)

    # Set tick labels to appear only 10 times, spaced evenly
    x_ticks = np.linspace(min_x, max_x, 10)
    y_ticks = np.linspace(min_y, max_y, 10)
    ax.set_xticks(x_ticks, minor=False)
    ax.set_yticks(y_ticks, minor=False)
    ax.set_xticklabels([f'{x:.3f}' for x in x_ticks], fontsize=12)
    ax.set_yticklabels([f'{y:.3f}' for y in y_ticks], fontsize=12)

    if not remove_titles:
        ax.set_title(f'Diversity plot for {method}', fontsize=16)
    if not remove_axes_labels:
        ax.set_xlabel('Dimension 1', fontsize=14)
        ax.set_ylabel('Dimension 2', fontsize=14)
    
    method = method.replace('/', '')  # remove '/' from method name
    plt.tight_layout()
    plt.savefig(f'./plot_diversity_{method}_{grid_size}x{grid_size}{suffix}.{file_format}', dpi=300, bbox_inches='tight', transparent=remove_background)
    plt.close()

def plot_coverage(method_cell_coverage, grid_size=10, file_format='png', remove_titles=False, remove_background=False, remove_axes_labels=False, remove_x_labels=True):
    # Create a boxplot of the cell coverage for each method
    plt.figure(figsize=(10, 6))
    methods = list(method_cell_coverage.keys())
    coverages = [method_cell_coverage[method] for method in methods]

    plt.boxplot(coverages, tick_labels=methods, bootstrap=10000)
    if not remove_titles:
        plt.title('Cell Coverage Distribution by Method')
    if not remove_axes_labels:
        plt.ylabel('Cell Coverage')
        plt.xlabel('Method')
    if remove_x_labels:
        plt.gca().xaxis.set_ticklabels(['' for _ in methods])
    plt.tight_layout()
    plt.savefig(f'plot_coverage_{grid_size}.{file_format}', dpi=300, bbox_inches='tight', transparent=remove_background)
    plt.close()

    # Save the cell coverage data
    with open(f'plot_coverage_{grid_size}.json', 'w') as f:
        json.dump(method_cell_coverage, f, indent=4)

def perform_significance_testing(method_cell_coverage, grid_size=10):
    methods = list(method_cell_coverage.keys())
    coverages = [method_cell_coverage[method] for method in methods]

    results = {
        "Kruskal-Wallis H-test": {},
        "Mann-Whitney U tests": []
    }

    # Kruskal-Wallis H-test (non-parametric ANOVA)
    h_stat, p_val = stats.kruskal(*coverages)
    results["Kruskal-Wallis H-test"] = {
        "H-statistic": h_stat,
        "p-value": p_val
    }

    # Pairwise comparisons using Mann-Whitney U test
    for i in range(len(methods)):
        for j in range(i + 1, len(methods)):
            u_stat, p_val = stats.mannwhitneyu(coverages[i], coverages[j])
            results["Mann-Whitney U tests"].append({
                "methods": f"{methods[i]} vs {methods[j]}",
                "U-statistic": u_stat,
                "p-value": p_val
            })

    # Save the results to a JSON file
    with open(f'pvalues_coverage_{grid_size}.json', 'w') as f:
        json.dump(results, f, indent=4)

@hydra.main(version_base=None, config_path="../configs/", config_name="plot_diversity")
def main(config: DictConfig):
    data = {}
    # Read the last entry of each archive
    for method, method_config in config.methods.items():
        archives = []
        for path in method_config.paths:
            archives.append(read_last_json_entry(path))
        data[method] = archives

    # Check if embeddings already exist
    if os.path.exists('./embeddings/embeddings.npy') and os.path.exists('./embeddings/codepaths.json'):
        print("Loading existing embeddings...")
        embeddings = np.load('./embeddings/embeddings.npy')
        with open('./embeddings/codepaths.json', 'r') as f:
            codepaths = json.load(f)
        codepaths_embedding = dict(zip(codepaths, embeddings))
    else:
        print("Generating new embeddings...")
        # Get all the codepaths in all archives
        codepaths_embedding = {}
        for method, archives in data.items():
            for archive in archives:
                codepaths = archive['codepaths']
                for codepath in codepaths:
                    codepaths_embedding[codepath] = get_embeddings(codepath, config.embedding_method)

        # Save original embeddings
        os.makedirs('./embeddings', exist_ok=True)
        np.save('./embeddings/embeddings.npy', np.array(list(codepaths_embedding.values())))
        with open('./embeddings/codepaths.json', 'w') as f:
            json.dump(list(codepaths_embedding.keys()), f)

    embeddings = np.array(list(codepaths_embedding.values()))

    # Check if 2D embeddings already exist
    if os.path.exists('./embeddings/embeddings_2d.npy'):
        print("Loading existing 2D embeddings...")
        embeddings_2d = np.load('./embeddings/embeddings_2d.npy')
    else:
        print(f"Generating new 2D embeddings using {config.downscale_method}...")
        # Downscale embeddings based on the selected method
        if config.downscale_method == "autoenc":
            # Train an autoencoder to downscale embeddings to 2D
            embeddings_tensor = torch.FloatTensor(embeddings)
            input_dim = embeddings.shape[1]
            encoding_dim = 2  # 2D embeddings
            model = Autoencoder(input_dim, encoding_dim)
            train_autoencoder(model, embeddings_tensor)

            # Save the trained model
            torch.save(model.state_dict(), './embeddings/autoencoder_model.pth')

            # Get 2D embeddings of all codepaths
            model.eval()
            with torch.no_grad():
                embeddings_2d, _ = model(embeddings_tensor)
            embeddings_2d = embeddings_2d.numpy()
        elif config.downscale_method == "pca":
            # Use PCA to downscale embeddings to 2D
            pca = PCA(n_components=2)
            embeddings_2d = pca.fit_transform(embeddings)
        else:
            raise ValueError(f"Invalid downscale_method: {config.downscale_method}")

        # Save 2D embeddings
        np.save('./embeddings/embeddings_2d.npy', embeddings_2d)

    codepaths_2d_embedding = dict(zip(codepaths_embedding.keys(), embeddings_2d))

    # Get the min and max values of the 2D embeddings
    min_x, max_x = embeddings_2d[:, 0].min(), embeddings_2d[:, 0].max()
    min_y, max_y = embeddings_2d[:, 1].min(), embeddings_2d[:, 1].max()

    # Calculate the minimum number of codepaths across all methods
    min_n_codepaths = min(len(archive['codepaths']) for archives in data.values() for archive in archives)
    print(f"Minimum number of codepaths: {min_n_codepaths}")

    # Plot the diversity in 2D space for each method and calculate cell coverage
    grid_size = config.grid_size
    method_cell_coverage = {}
    for method, archives in data.items():
        method_coverages = []
        for i, archive in enumerate(archives):
            codepaths = archive['codepaths'][:min_n_codepaths]
            plot_archive_diversity(method, codepaths, codepaths_2d_embedding, min_x, max_x, min_y, max_y, grid_size=grid_size, suffix=f'_{i}', file_format=config.file_format, remove_titles=config.remove_titles, remove_background=config.remove_background, remove_axes_labels=config.remove_axes_labels, add_colorbar=config.add_colorbar)

            # Calculate cell coverage
            cell_coverage = calculate_cell_coverage(codepaths, codepaths_2d_embedding, min_x, max_x, min_y, max_y, grid_size=grid_size)
            method_coverages.append(cell_coverage)

        method_cell_coverage[method] = method_coverages

    # Create boxplot and save data
    plot_coverage(method_cell_coverage, grid_size=grid_size, file_format=config.file_format, remove_titles=config.remove_titles, remove_background=config.remove_background, remove_axes_labels=config.remove_axes_labels, remove_x_labels=config.remove_x_labels)

    # Perform significance testing
    perform_significance_testing(method_cell_coverage, grid_size=grid_size)

if __name__ == "__main__":
    main()

</analysis/plot_diversity.py>

<analysis/plot_envgen_success.py>
import os
import hydra
from omegaconf import DictConfig
import json
import numpy as np
from scipy.stats import bootstrap

from analysis.visualize_taskgen import read_last_json_entry


@hydra.main(version_base=None, config_path="../configs/", config_name="plot_envgen_success")
def main(config: DictConfig):
    # Trackers
    num_gens_totals = []
    num_gens_eventualsucc_totals = []
    num_gens_successfuls = []

    # Go through each run folder
    for run_folder in config.paths:
        archive = read_last_json_entry(os.path.join(run_folder, 'archive.jsonl'))
        eventualsucc_envpaths = archive['codepaths'] + archive['failedint'] + archive['failedtrain']
        num_gens_total = 0
        num_gens_eventualsucc_total = 0
        num_gens_successful = len(eventualsucc_envpaths)

        # Go through all folders in path with the name "task_*"
        for folder in os.listdir(run_folder):
            if not folder.startswith("task_"):
                continue

            # Get the number of env_*.py files in the folder
            env_files = [f for f in os.listdir(os.path.join(run_folder, folder)) if f.startswith("env_") and f.endswith(".py")]
            num_gens_total += len(env_files)

            # if any of the env_files is in eventualsucc_envpaths
            for env_file in env_files:
                if os.path.join(run_folder, folder, env_file) in eventualsucc_envpaths:
                    num_gens_eventualsucc_total += len(env_files)

        # Append trackers
        num_gens_totals.append(num_gens_total)
        num_gens_eventualsucc_totals.append(num_gens_eventualsucc_total)
        num_gens_successfuls.append(num_gens_successful)

    # Calculate metrics
    success_rates = [s / t for s, t in zip(num_gens_successfuls, num_gens_totals)]
    median_success_rate = np.median(success_rates)
    res = bootstrap((np.array(success_rates),), np.median, confidence_level=0.95, n_resamples=10000)
    confidence_interval = res.confidence_interval

    success_rates_eventualsucc = [s / t for s, t in zip(num_gens_successfuls, num_gens_eventualsucc_totals)]
    median_success_rate_eventualsucc = np.median(success_rates_eventualsucc)
    res_eventualsucc = bootstrap((np.array(success_rates_eventualsucc),), np.median, confidence_level=0.95, n_resamples=10000)
    confidence_interval_eventualsucc = res_eventualsucc.confidence_interval

    # Save results to json file
    results = {
        "num_gens_totals": num_gens_totals,
        "num_gens_eventualsucc_totals": num_gens_eventualsucc_totals,
        "num_gens_successfuls": num_gens_successfuls,

        "success_rates": success_rates,
        "median_success_rate": median_success_rate,
        "confidence_interval": [confidence_interval.low, confidence_interval.high],

        "success_rates_eventualsucc": success_rates_eventualsucc,
        "median_success_rate_eventualsucc": median_success_rate_eventualsucc,
        "confidence_interval_eventualsucc": [confidence_interval_eventualsucc.low, confidence_interval_eventualsucc.high],
    }
    with open('output.json', 'w') as f:
        json.dump(results, f, indent=2)
    print("Results saved to output.json")

if __name__ == "__main__":
    main()

</analysis/plot_envgen_success.py>

<analysis/plot_percentlearned.py>
import os
import json
import hydra
import numpy as np
import matplotlib.pyplot as plt
from omegaconf import DictConfig

from analysis.visualize_taskgen import read_last_json_entry

def bootstrap_confidence_interval(data, num_bootstrap_samples=1000, confidence_level=0.95):
    n = len(data)
    bootstrap_samples = np.random.choice(data, (num_bootstrap_samples, n), replace=True)
    bootstrap_means = np.mean(bootstrap_samples, axis=1)
    lower_bound = np.percentile(bootstrap_means, (1 - confidence_level) / 2 * 100)
    upper_bound = np.percentile(bootstrap_means, (1 + confidence_level) / 2 * 100)
    return lower_bound, upper_bound

@hydra.main(version_base=None, config_path="../configs/", config_name="plot_percentlearned")
def main(config: DictConfig):
    total_trainings = []
    total_learned = []

    # Go through each archive path
    for archive_path in config.paths:
        archive = read_last_json_entry(archive_path)
        codepaths = archive['codepaths']
        failedtrain = archive['failedtrain']

        all_paths = codepaths + failedtrain
        all_paths = sorted(all_paths, key=lambda x: os.path.basename(os.path.dirname(x)))

        xs = np.arange(1, len(all_paths) + 1)
        ys = np.array([1 if codepath in codepaths else 0 for codepath in all_paths])
        ys = np.cumsum(ys)

        total_trainings.append(xs)
        total_learned.append(ys)

    # Truncate xss and yss to the minimum length
    min_length = min(len(xs) for xs in total_trainings)
    total_trainings = [xs[:min_length] for xs in total_trainings]
    total_learned = [ys[:min_length] for ys in total_learned]

    # Convert to numpy arrays for easier manipulation
    total_trainings = np.array(total_trainings)
    total_learned = np.array(total_learned)

    # Calculate the mean and bootstrap confidence intervals
    median_learned = np.median(total_learned, axis=0)
    median_percentage_learned = median_learned / total_trainings[0] * 100
    lower_bounds = []
    upper_bounds = []
    for i in range(min_length):
        lower, upper = bootstrap_confidence_interval(total_learned[:, i] / total_trainings[:, i] * 100)
        lower_bounds.append(lower)
        upper_bounds.append(upper)

    # Save the data
    with open('percent_learned.json', 'w') as f:
        json.dump({
            'median_percentage_learned': median_percentage_learned.tolist(),
            'lower_bounds': lower_bounds,
            'upper_bounds': upper_bounds,
            'total_trainings': total_trainings.tolist(),
            'num_learned': total_learned.tolist(),
        }, f)

    # Plot the data with bootstrap confidence intervals
    plt.figure(figsize=(10, 6))
    plt.plot(total_trainings[0], median_percentage_learned, label='Median Percentage Learned')
    plt.fill_between(total_trainings[0], lower_bounds, upper_bounds, color='b', alpha=0.2, label='95% Confidence Interval')
    plt.title('Percentage of Tasks Learned over Training Iterations')
    plt.xlabel('Total Number of Trainings (Successful and Failed)')
    plt.ylabel('Percentage of Tasks Learned')
    plt.legend()
    plt.grid(True)
    plot_path = 'plot_percent_learned.png'
    plt.savefig(plot_path, bbox_inches='tight')
    plt.close()
    print(f"Plot saved to {plot_path}")

if __name__ == "__main__":
    main()

</analysis/plot_percentlearned.py>

<analysis/run_scratch.py>
import os
import hydra
from omegaconf import DictConfig

from analysis.visualize_taskgen import read_last_json_entry
from main_dreamer import main_dreamer


@hydra.main(version_base=None, config_path="../configs/", config_name="run_scratch")
def main(config: DictConfig):
    archive = read_last_json_entry(config.path)
    codepaths = archive['codepaths']
    codepaths = codepaths[:config.num_tasks] if config.num_tasks > 0 else codepaths
    config_dreamer = config.dreamer

    for task_envpath in codepaths:
        task_key = os.path.basename(os.path.dirname(task_envpath))
        task_dir = os.path.join(config.logdir, task_key)

        # Dreamer config
        dreamer_dir = os.path.join(task_dir, 'dreamer/')
        if os.path.exists(dreamer_dir):
            print(f"Skipping {task_key} as it already exists.")
            continue
        config_dreamer.logdir = dreamer_dir
        config_dreamer.env.path = task_envpath

        # Run Dreamer
        main_dreamer(config_dreamer)


if __name__ == "__main__":
    main()

</analysis/run_scratch.py>

<analysis/visualize_blockbuster.py>
from manim import (
    Scene, config, MarkupText, ImageMobject,
    LEFT, RIGHT, UP, DOWN,
)
import argparse
import re
import os
import json
import uuid
import cv2
import tempfile
import numpy as np

from analysis.visualize_taskgen import read_last_json_entry, extract_task_id
from run_utils import get_task_desc_from_env_path, get_task_success_file_from_folder

def write_frames_to_video(frames, video_path, fps=20):
    # Assuming all frames are of the same shape and dtype
    height, width, layers = frames[0].shape
    size = (width, height)
    # Use the mp4v codec for MP4 format
    out = cv2.VideoWriter(video_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, size)
    for frame in frames:
        out.write(frame)  # Write out frame to video
    out.release()  # Release the video writer

def process_recording_file(file_path, output_dir=None):
    """ Read the recorded_actions.jsonl file and save the recorded frames as a video. """
    base_folder = output_dir if output_dir else os.path.dirname(file_path)
    video_folder = os.path.join(base_folder, 'videos')
    os.makedirs(video_folder, exist_ok=True)

    with open(file_path, 'r') as file:
        for line in file:
            try:
                data = json.loads(line)
                env_path = data['env_filepath']
                env_dirname = os.path.basename(os.path.dirname(env_path))
                video_path = os.path.join(video_folder, f"{env_dirname}_{str(uuid.uuid4())[:8]}.mp4")
                recorded_frames = [np.array(d, dtype=np.uint8) for d in data['recorded_frames'] if d is not None]
                write_frames_to_video(recorded_frames, video_path)
                yield env_path, video_path
            except Exception as e:
                print(f"Error processing {file_path}: {e}")

def process_dir(dir_path, recorded_actions=False):
    video_json = {}  # Keep track of the videos generated for each environment
    if recorded_actions:
        """ Process all the recorded_actions.jsonl files in the directory. """
        for root, _, files in os.walk(dir_path):
            print('Processing:', root)
            for file in files:
                if file.endswith('recorded_actions.jsonl'):
                    for env_path, video_path in process_recording_file(os.path.join(root, file), output_dir=dir_path):
                        video_json[env_path] = video_json.get(env_path, []) + [video_path]
                        # if len(video_json[env_path]) > 0:  # for debugging purposes
                        #     return video_json
    else:
        """ Process all the videos in the directory. """
        archive_data = read_last_json_entry(os.path.join(dir_path, 'archive.jsonl'))
        env_paths = archive_data['codepaths'] + archive_data['failedtrain']
        for env_path in env_paths:
            taskname = os.path.basename(os.path.dirname(env_path))
            print('Processing:', taskname)
            video_folder = os.path.join(dir_path, f'{taskname}/dreamer/eval')
            success_path = get_task_success_file_from_folder(video_folder)
            if success_path:  # Get the successful video file
                success_dir, success_file = os.path.split(success_path)
                video_file = success_file.replace('success', 'render').replace('.txt', '.mp4')
                video_path = os.path.join(success_dir, video_file)
                video_json[env_path] = video_json.get(env_path, []) + [video_path]
            else:  # Get the first video file found in the folder
                for file in os.listdir(video_folder):
                    if file.endswith('.mp4') and file.startswith('render_'):
                        video_path = os.path.join(video_folder, file)
                        video_json[env_path] = video_json.get(env_path, []) + [video_path]
                        break
    return video_json

def wrap_text(text, character_length=50, trunc_lines=5):
    """ Dynamically wrap text to fit into the character length. """
    wrapped_text = []
    lines = text.split('\n')
    lines = [lines[0] + '\n', ' '.join(lines[1:])]
    for i, line in enumerate(lines):
        words = line.split(' ')
        line = ""
        for word in words:
            if len(line) + len(word) + 1 <= character_length:
                line += word + " "
            else:
                if len(wrapped_text) >= trunc_lines:
                    break
                wrapped_text.append(line)
                line = word + " "
        if len(wrapped_text) < trunc_lines:
            wrapped_text.append(line)
        if len(wrapped_text) >= trunc_lines:
            wrapped_text[-1] = wrapped_text[-1].rstrip() + "..."
            break
    return '\n'.join(wrapped_text)

class SimpleAnimation(Scene):
    def __init__(self, dirpath, video_json, n_examples=0, **kwargs):
        super().__init__(**kwargs)
        self.dirpath = dirpath
        self.video_json = video_json
        self.n_examples = n_examples

    def construct(self):
        archive_data = read_last_json_entry(os.path.join(self.dirpath, 'archive.jsonl'))
        archive_comments_path = os.path.join(self.dirpath, 'archive_comments.jsonl')
        archive_comments = read_last_json_entry(archive_comments_path) if os.path.exists(archive_comments_path) else {}
        env_paths = archive_data['codepaths'] + archive_data['failedint'] + archive_data['failedtrain']
        env_paths = sorted(env_paths, key=lambda x: int(extract_task_id(x).split('_')[1]))
        example_counter = 0
        task_counter = 0

        for env_path in env_paths:
            video_paths = self.video_json.get(env_path, [])
            # Skip if no video paths are found
            if not video_paths:
                task_counter += 1
                continue
            # Get task information
            task_id = extract_task_id(env_path)
            if example_counter < self.n_examples:
                example_counter += 1
                task_id = f'Seed {example_counter}'
            else:
                task_counter += 1
                task_id = f"Task {task_counter}"
            task_id = f'<span foreground="#FFFF00">{task_id}</span>'
            task_desc = get_task_desc_from_env_path(env_path)
            task_desc = re.split('[.\n]', task_desc)[0]  # Only take the first line of the task description
            task_desc = wrap_text(task_desc, character_length=30, trunc_lines=8)
            task_success = env_path in archive_data['codepaths']
            success_color = '#2FFF2F' if task_success else '#FF4911'
            task_success_text = f'<span foreground="{success_color}" font_size="smaller">{"success detector: true" if task_success else "success detector: false"}</span>'
            task_comments = wrap_text(archive_comments.get(env_path, ''), character_length=35, trunc_lines=5).lower()
            task_comments = f'<span font_size="smaller">{task_comments}</span>'

            # Render task information
            task_info_text = MarkupText(
                f'{task_id}\n\n{task_desc}\n{task_success_text}\n{task_comments}',
                color='white',
                font_size=25,
            )
            task_info_text.to_edge(LEFT)
            self.add(task_info_text)
            self.wait(1.0)

            # Get videos for the task
            for video_file in video_paths:
                cap = cv2.VideoCapture(video_file)
                # tmp_i = 0  # for debugging purposes
                while cap.isOpened():
                    ret, frame = cap.read()
                    # tmp_i += 1
                    if not ret:
                        break
                    # Write frame to a temporary file
                    with tempfile.NamedTemporaryFile(delete=False, suffix='.jpg') as tmpfile:
                        cv2.imwrite(tmpfile.name, frame)
                        img_mobject = ImageMobject(tmpfile.name)
                        img_mobject.width = config['frame_width'] / 2
                        img_mobject.to_edge(RIGHT)
                        self.add(img_mobject)
                        self.wait(0.05)
                        self.remove(img_mobject)
                    # if tmp_i > 1:
                    #     break
                cap.release()

            # Remove current task information rendering
            self.remove(task_info_text)

def main():
    # Setup argparse for command line arguments
    parser = argparse.ArgumentParser(description="Create a blockbuster using Manim")
    parser.add_argument("--dirpath", type=str, required=True, help="Path to the directory")
    parser.add_argument("--recorded_actions", action='store_true', help="Read recorded_actions.jsonl instead of the already rendered videos.")
    parser.add_argument("--high-quality", action='store_true', help="Render the video in high quality.")
    parser.add_argument("--n-examples", "-e", type=int, default=0, help="Number of tasks that are examples.")
    args = parser.parse_args()

    # Process the directory containing multiple recorded_actions.jsonl files
    video_json = process_dir(args.dirpath, recorded_actions=args.recorded_actions)

    # Additional configuration for rendering
    if args.high_quality:
        config.pixel_height = 720
        config.pixel_width = 1280
        config.frame_rate = 60
    else:
        config.pixel_height = 360
        config.pixel_width = 640
        config.frame_rate = 30
    config.media_dir = os.path.join(args.dirpath, 'media')
    config.disable_caching = True

    # Create manim video
    scene = SimpleAnimation(args.dirpath, video_json, n_examples=args.n_examples)
    scene.render()

if __name__ == "__main__":
    main()

</analysis/visualize_blockbuster.py>

<analysis/visualize_dreamer.py>
from pathlib import Path
from omegaconf import OmegaConf
import pickle

import dreamerv3
import embodied
from embodied.run.eval import eval

import mediapy


def visualize_episodes(eval_dir):
	for pickle_path in eval_dir.glob("*.pickle"):
		with open(str(pickle_path), "rb") as f:
			episode = pickle.load(f)
		
		print(pickle_path.stem)
		print(f"\tScore: {episode['score']}")
		print(f"\tLength: {episode['length']}")

		video_path = eval_dir / f"render_{pickle_path.stem}.mp4"
		if not video_path.is_file():
			mediapy.write_video(str(video_path), episode["policy_render"])

		video_path = eval_dir / f"render3p_{pickle_path.stem}.mp4"
		if not video_path.is_file():
			mediapy.write_video(str(video_path), episode["policy_render3p"])

		video_path = eval_dir / f"vision_{pickle_path.stem}.mp4"
		if not video_path.is_file():
			mediapy.write_video(str(video_path), [policy_image[..., :3] for policy_image in episode["policy_image"]])

		success_path = eval_dir / f"success_{pickle_path.stem}.txt"
		if not success_path.is_file():
			with open(str(success_path), "w") as f:
				f.write("\n".join([str(x) for x in episode["success"]]))


def visualize_dreamer(dreamer_dir, num_episodes=5) -> None:
	dreamer_dir = Path(dreamer_dir)
	try:
		config_dreamer = OmegaConf.load(dreamer_dir / ".hydra" / "config.yaml")
	except FileNotFoundError:
		config_dreamer = OmegaConf.load(dreamer_dir / ".." / ".." / ".hydra" / "config.yaml")
		config_dreamer = config_dreamer.dreamer
		if (dreamer_dir / ".." / "env_5.py"). is_file():
			config_dreamer.env.path = str(dreamer_dir / ".." / "env_5.py")
		elif (dreamer_dir / ".." / "env_4.py"). is_file():
			config_dreamer.env.path = str(dreamer_dir / ".." / "env_4.py")
		elif (dreamer_dir / ".." / "env_3.py"). is_file():
			config_dreamer.env.path = str(dreamer_dir / ".." / "env_3.py")
		elif (dreamer_dir / ".." / "env_2.py"). is_file():
			config_dreamer.env.path = str(dreamer_dir / ".." / "env_2.py")
		elif (dreamer_dir / ".." / "env_1.py"). is_file():
			config_dreamer.env.path = str(dreamer_dir / ".." / "env_1.py")
		elif (dreamer_dir / ".." / "env_0.py"). is_file():
			config_dreamer.env.path = str(dreamer_dir / ".." / "env_0.py")
		else:
			raise FileNotFoundError
	config = embodied.Config(OmegaConf.to_container(config_dreamer))
	config = config.update({
		"logdir": str(dreamer_dir),
		"jax.policy_devices": [0],
		"jax.train_devices": [0],
		"run.from_checkpoint": str(dreamer_dir / "checkpoint.ckpt"),
		"run.num_envs": num_episodes,
	})
	config, _ = embodied.Flags(config).parse_known()

	def make_env(env_id=0):
		from embodied.envs.pybullet import PyBullet
		env = PyBullet(config.env.path, vision=config.env.vision, size=config.env.size, fov=config.env.fov)
		env = dreamerv3.wrap_env(env, config)
		return env

	def make_agent():
		env = make_env(config)
		agent = dreamerv3.Agent(env.obs_space, env.act_space, config)
		env.close()
		return agent

	args = embodied.Config(
			**config.run,
			logdir=config.logdir,
			batch_size=config.batch_size,
			batch_length=config.batch_length,
			batch_length_eval=config.batch_length_eval,
			replay_context=config.replay_context,
	)

	# Eval agent
	eval(make_agent, make_env, args, num_episodes=num_episodes)

	# Visualize episodes
	eval_dir = dreamer_dir / 'eval'
	visualize_episodes(eval_dir)


def visualize_ckpt_env(ckpt_dir, env_path, eval_dir, num_episodes=5) -> None:
	dreamer_dir = Path(ckpt_dir) / 'dreamer'
	try:
		config_dreamer = OmegaConf.load(dreamer_dir / ".hydra" / "config.yaml")
	except FileNotFoundError:
		config_dreamer = OmegaConf.load(dreamer_dir / ".." / ".." / ".hydra" / "config.yaml")
		config_dreamer = config_dreamer.dreamer
		if (dreamer_dir / ".." / "env_5.py"). is_file():
			config_dreamer.env.path = str(dreamer_dir / ".." / "env_5.py")
		elif (dreamer_dir / ".." / "env_4.py"). is_file():
			config_dreamer.env.path = str(dreamer_dir / ".." / "env_4.py")
		elif (dreamer_dir / ".." / "env_3.py"). is_file():
			config_dreamer.env.path = str(dreamer_dir / ".." / "env_3.py")
		elif (dreamer_dir / ".." / "env_2.py"). is_file():
			config_dreamer.env.path = str(dreamer_dir / ".." / "env_2.py")
		elif (dreamer_dir / ".." / "env_1.py"). is_file():
			config_dreamer.env.path = str(dreamer_dir / ".." / "env_1.py")
		elif (dreamer_dir / ".." / "env_0.py"). is_file():
			config_dreamer.env.path = str(dreamer_dir / ".." / "env_0.py")
		else:
			raise FileNotFoundError
	config = embodied.Config(OmegaConf.to_container(config_dreamer))
	config = config.update({
		"logdir": str(dreamer_dir),
		"jax.policy_devices": [0],
		"jax.train_devices": [0],
		"run.from_checkpoint": str(dreamer_dir / "checkpoint.ckpt"),
		"run.num_envs": num_episodes,
	})
	config, _ = embodied.Flags(config).parse_known()

	def make_env(env_id=0):
		from embodied.envs.pybullet import PyBullet
		env = PyBullet(env_path, vision=config.env.vision, size=config.env.size, fov=config.env.fov)
		env = dreamerv3.wrap_env(env, config)
		return env

	def make_agent():
		env = make_env(config)
		agent = dreamerv3.Agent(env.obs_space, env.act_space, config)
		env.close()
		return agent

	args = embodied.Config(
			**config.run,
			logdir=config.logdir,
			batch_size=config.batch_size,
			batch_length=config.batch_length,
			batch_length_eval=config.batch_length_eval,
			replay_context=config.replay_context,
	)

	# Eval agent
	eval_dir = Path(eval_dir)
	eval(make_agent, make_env, args, num_episodes=num_episodes, eval_dir=eval_dir)

	# Visualize episodes
	visualize_episodes(eval_dir)


if __name__ == "__main__":
	visualize_dreamer("/workspace/src/output/pipeline/2024-06-18_153134_574615/task_19/dreamer", num_episodes=4)

</analysis/visualize_dreamer.py>

<analysis/visualize_taskgen.py>
import json
import os
import re
from matplotlib import pyplot as plt
import matplotlib.colors as mcolors
from matplotlib.colorbar import ColorbarBase
import networkx as nx
import argparse
import numpy as np
from pyvis.network import Network
from sklearn.manifold import TSNE
from sklearn.preprocessing import MinMaxScaler
import base64
from scipy.spatial.distance import euclidean
from textwrap import dedent

from embodied.envs.pybullet import PyBullet
from run_utils import encode_image
from rag_utils import get_openai_embeddings, read_file


def read_last_json_entry(filepath):
	"""Reads the last JSON entry from a JSONL file."""
	with open(filepath, 'r') as f:
		content = f.read()
		json_str = re.split('(?<=})\n(?={)', content)[-1]
		json_obj = json.loads(json_str)
	return json_obj

def get_from_paths(metadata_path):
	"""Reads the metadata.json file and retrieves the from paths."""
	try:
		with open(metadata_path, 'r') as file:
			metadata = json.load(file)
			from_paths = []
			from_paths = metadata.get('taskgen_example_paths', [])
			# from_paths += metadata.get('taskgen_failed_paths', [])
			from_paths += metadata.get('taskit_from_paths', [])
			return from_paths
	except FileNotFoundError:
		return []

def extract_task_id(path):
	"""Extracts a task identifier from the directory name of the path."""
	return os.path.basename(os.path.dirname(path))

def adjust_positions(pos_dict, min_dist=10):
	"""Adjust positions to ensure a minimum distance between nodes."""
	from scipy.spatial.distance import cdist
	positions = np.array(list(pos_dict.values()))
	dist_matrix = cdist(positions, positions)  # Compute all-pair Euclidean distances

	for i, pos1 in enumerate(positions):
		for j, pos2 in enumerate(positions):
			if i != j and dist_matrix[i, j] < min_dist:
				# Nodes are too close and need to be adjusted
				direction = pos2 - pos1
				norm = np.linalg.norm(direction)
				if norm == 0:
					direction = np.random.randn(2)  # Random direction if exactly the same
					norm = np.linalg.norm(direction)
				shift = (min_dist - norm) / norm * direction
				positions[j] += shift * 0.5  # Move both nodes away from each other
				positions[i] -= shift * 0.5
	return {key: (pos[0], pos[1]) for key, pos in zip(pos_dict.keys(), positions)}

def create_graph(data, num_task_examples=0):
	"""Creates a NetworkX graph from the data dictionary."""
	G = nx.DiGraph()
	G_matchfolder = nx.DiGraph()  # graph that matches the folder name
	codepaths = data.get('codepaths', [])
	failedint = data.get('failedint', [])
	failedtrain = data.get('failedtrain', [])
	example_counter = 0
	task_counter = 0
	all_paths = codepaths + failedint + failedtrain

	# Colormap for the tasks
	colormap = plt.get_cmap('viridis').reversed()

	# Node images based on whether the task succeeded, failed, is boring
	node_images = [
		f"data:image/png;base64,{encode_image(f'./analysis/icons/{xs}.png')}"
		for xs in ['tick', 'sleep', 'cross']
	]
	path_images = {path: node_images[0] for path in codepaths}
	path_images.update({path: node_images[1] for path in failedint})
	path_images.update({path: node_images[2] for path in failedtrain})

	# Task embeddings and t-SNE
	task_embeddings = get_openai_embeddings([read_file(path) for path in all_paths])  # NOTE: this should be the same embedding model used during training
	task_embeddings = np.array(task_embeddings)
	perplexity = max(min(len(all_paths) // 5, 100), 5)
	tsne = TSNE(n_components=2, random_state=42, perplexity=perplexity)
	task_embeddings = tsne.fit_transform(task_embeddings)
	scaler = MinMaxScaler(feature_range=(0, 800))
	task_embeddings = scaler.fit_transform(task_embeddings)
	task_embeddings = {path: emb for path, emb in zip(all_paths, task_embeddings)}

	# Sort the all_paths based on task number
	all_paths = sorted(all_paths, key=lambda x: int(extract_task_id(x).split('_')[1]) if 'task' in extract_task_id(x) else 0)

	for target_path in all_paths:
		# Get task description from the docstring
		try:
			env = PyBullet(env_path=target_path, vision=False)._env
			node_desc = dedent(env.__doc__).strip()
		except:
			node_desc = "Unknown"

		task_id = extract_task_id(target_path)

		if 'task' not in task_id or example_counter < num_task_examples:
			example_counter += 1
			task_id = f"Seed {example_counter}"
			task_id_matchfolder = task_id
			node_color = 'grey'
		else:
			task_counter += 1
			task_number = task_counter
			task_number_matchfolder = int(task_id.split('_')[1])
			rgba_color = colormap(task_number / (len(all_paths) - example_counter))
			node_color = mcolors.to_hex(rgba_color)
			task_id = f"Task {task_number}"
			task_id_matchfolder = f"Task {task_number_matchfolder}"

		G.add_node(
			target_path,
			label=f"{task_id}",
			color=node_color,
			title=node_desc,
			shape='circularImage',
			image=path_images[target_path],
			pos=(float(task_embeddings[target_path][0]),float(task_embeddings[target_path][1])),
		)
		G_matchfolder.add_node(
			target_path,
			label=f"{task_id_matchfolder}",
			color=node_color,
			title=node_desc,
			shape='circularImage',
			image=path_images[target_path],
			pos=(float(task_embeddings[target_path][0]),float(task_embeddings[target_path][1])),
		)
		metadata_path = os.path.join(os.path.dirname(target_path), 'metadata.json')
		from_paths = get_from_paths(metadata_path)

		for from_path in from_paths:
			if from_path in all_paths:
				G.add_edge(from_path, target_path)
				G_matchfolder.add_edge(from_path, target_path)

	return G, G_matchfolder

def create_colorbar(colormap, num_tasks, output_dir, suffix=''):
	"""Create a colorbar image with the given colormap and encode it to a data URL."""
	fig, ax = plt.subplots(figsize=(6, 1))
	fig.subplots_adjust(bottom=0.5)

	# Normalize the color range from 1 to num_tasks
	norm = mcolors.Normalize(vmin=1, vmax=num_tasks)
	cbar = ColorbarBase(ax, cmap=colormap, norm=norm, orientation='horizontal')

	# Set the ticks and labels
	ticks = np.arange(0, num_tasks, max(num_tasks // 50, 1) * 5)
	ticks[0] += 1
	# ticks = np.append(ticks, num_tasks)
	cbar.set_ticks(ticks)
	cbar.set_ticklabels([str(i) for i in ticks])
	cbar.set_label('Generation Number')

	# Save the colorbar to a temporary buffer instead of a file
	from io import BytesIO
	buffer = BytesIO()
	plt.savefig(buffer, format='png', bbox_inches='tight')
	plt.savefig(os.path.join(output_dir, f'colorbar_{suffix}.svg'), format='svg', bbox_inches='tight')  # Save the colorbar to a separate SVG file
	plt.close()
	buffer.seek(0)
	image_png = buffer.getvalue()
	buffer.close()

	# Convert PNG image to data URL
	image_base64 = base64.b64encode(image_png).decode('utf-8')
	return f"data:image/png;base64,{image_base64}"

def visualize_graph(G, output_dir, include_all_edges=True, suffix='', more_points=False):
	"""Converts a NetworkX graph to a pyvis network and saves it as an HTML file."""
	nt = Network("800px", "100%", notebook=True, directed=True, cdn_resources='remote')

	# Disable the physics to ensure nodes stay in given positions
	nt.options.physics.enabled = False

	# Adjust node positions
	pos_dict = {node: (attr['pos'][0], attr['pos'][1]) for node, attr in G.nodes(data=True)}
	for _ in range(10):
		pos_dict = adjust_positions(pos_dict, min_dist=25 if more_points else 60)

	# Set nodes from the NetworkX graph
	max_node_num = 0
	for node, attr in G.nodes(data=True):
		max_node_num = max(int(attr['label'].split(' ')[1]), max_node_num)
		x, y = pos_dict[node]
		nt.add_node(
			node,
			label=attr['label'],
			# label=attr['label'].split(' ')[-1],
			color=attr['color'],
			title=attr['title'],
			x=x, y=y,
			shape='circularImage',
			image=attr['image'],
			size=10 if more_points else 20,
		)

	# Determine closest parent for edge addition
	closest_parents = {}
	for child in G.nodes():
		min_distance = float('inf')
		closest_parent = None
		child_pos = pos_dict[child]
		for parent in G.predecessors(child):
			parent_pos = pos_dict[parent]
			dist = euclidean(child_pos, parent_pos)
			if dist < min_distance:
				min_distance = dist
				closest_parent = parent
		closest_parents[child] = closest_parent

	# Add edges
	for edge in G.edges():
		if include_all_edges:
			nt.add_edge(edge[0], edge[1])
		elif edge[1] in closest_parents and edge[0] == closest_parents[edge[1]]:
			nt.add_edge(edge[0], edge[1])

	# Save the network to an HTML file
	suffix = suffix + ('all_edges' if include_all_edges else 'closest_edges')
	output_path = os.path.join(output_dir, f'archive_viz_{suffix}.html')
	nt.show(output_path)

	# Add colorbar to the HTML
	colorbar_data_url = create_colorbar(plt.get_cmap('viridis').reversed(), max_node_num, output_dir, suffix=suffix)
	with open(output_path, 'a') as f:
		f.write(f'<img src="{colorbar_data_url}" style="position:absolute; top:20; right:20; width:400px;">')

def main():
	parser = argparse.ArgumentParser(description='Process the path to the archive.jsonl file.')
	parser.add_argument('--path', type=str, help='The path to the archive.jsonl file')
	parser.add_argument('--num-task-examples', '-e', type=int, default=0, help='The number of tasks that are actually examples')
	parser.add_argument('--more-points', '-m', action='store_true', help='There are more points in the visualization')
	args = parser.parse_args()

	data = read_last_json_entry(args.path)
	output_dir = os.path.dirname(args.path)
	G, G_matchfolder = create_graph(data, num_task_examples=args.num_task_examples)
	visualize_graph(G, output_dir, include_all_edges=True, more_points=args.more_points)  # Visualize with all edges
	visualize_graph(G, output_dir, include_all_edges=False, more_points=args.more_points)  # Visualize only with closest parent edges
	visualize_graph(G_matchfolder, output_dir, include_all_edges=True, suffix='matchfolder_', more_points=args.more_points)  # Visualize with all edges (match folder)
	visualize_graph(G_matchfolder, output_dir, include_all_edges=False, suffix='matchfolder_', more_points=args.more_points)


if __name__ == "__main__":
	main()

</analysis/visualize_taskgen.py>

<apptainer/10_nvidia.json>
{
	"file_format_version" : "1.0.0",
	"ICD" : {
		"library_path" : "libEGL_nvidia.so.0"
	}
}

</apptainer/10_nvidia.json>

<configs/dreamer/dreamer_xs.yaml>
hydra:
  job:
    chdir: True
  run:
    dir: ./output/dreamer/${now:%Y-%m-%d_%H%M%S_%f}/

seed: 0
method: dreamer
logdir: '.'
eval_dir: ''
filter: 'score|length|fps|ratio|train/.*_loss$|train/rand/.*/mean'
wandb: False
tensorboard_videos: False

replay:
  size: 524288
  online: True
  fracs: {uniform: 1.0, priority: 0.0, recency: 0.0}
  prio: {exponent: 0.8, maxfrac: 0.5, initial: inf, zero_on_sample: True}
  priosignal: model
  recexp: 1.0
  chunksize: 1024
  save_wait: False

jax:
  platform: gpu
  jit: True
  compute_dtype: float32
  param_dtype: float32
  prealloc: True
  checks: False
  logical_cpus: 0
  debug: False
  policy_devices: [0]
  train_devices: [0]
  sync_every: 1
  profiler: False
  transfer_guard: False
  assert_num_devices: -1
  fetch_policy_carry: False
  nvidia_flags: False
  xla_dump: False

run:
  script: train
  steps: 2097152
  duration: 0
  num_envs: 32
  num_envs_eval: 4
  expl_until: 0
  log_every: 120
  save_every: 900
  eval_every: 180
  eval_initial: True
  eval_eps: 10
  train_ratio: 32.0
  train_fill: 0
  eval_fill: 0
  log_zeros: True
  log_keys_video: [image]
  log_keys_sum: '^$'
  log_keys_avg: '^$'
  log_keys_max: '^$'
  log_video_fps: 60
  log_video_streams: 1
  log_episode_timeout: 60
  from_checkpoint: ''
  actor_addr: 'tcp://localhost:{auto}'
  replay_addr: 'tcp://localhost:{auto}'
  logger_addr: 'tcp://localhost:{auto}'
  actor_batch: 8
  actor_threads: 4
  env_replica: -1
  ipv6: False
  usage: {psutil: True, nvsmi: True, gputil: False, malloc: False, gc: False}
  timer: True
  driver_parallel: True
  agent_process: False
  remote_replay: False

env:
  path: /workspace/src/omni_epic/envs/r2d2/go_forward.py
  vision: True
  size: [64, 64]
  use_depth: True
  fov: 90.

wrapper:
  length: 1000
  reset: True
  discretize: 0
  checks: True

# Agent
report: True
report_gradnorms: False
batch_size: 16
batch_length: 65
batch_length_eval: 33
replay_length: 0
replay_length_eval: 0
replay_context: 1
random_agent: False
loss_scales: {dec_cnn: 1.0, dec_mlp: 1.0, reward: 1.0, cont: 1.0, dyn: 1.0, rep: 0.1, actor: 1.0, critic: 1.0, replay_critic: 0.3}
opt: {scaler: rms, lr: 4e-5, eps: 1e-20, momentum: True, wd: 0.0, warmup: 1000, globclip: 0.0, agc: 0.3, beta1: 0.9, beta2: 0.999, details: False, pmin: 1e-3, anneal: 0, schedule: constant}
ac_grads: none
reset_context: 0.0
replay_critic_loss: True
replay_critic_grad: True
replay_critic_bootstrap: imag
reward_grad: True
report_openl_context: 8

# World Model
dyn:
  typ: rssm
  rssm: {deter: 2048, hidden: 256, stoch: 32, classes: 16, act: silu, norm: rms, unimix: 0.01, outscale: 1.0, winit: normal, imglayers: 2, obslayers: 1, dynlayers: 1, absolute: False, cell: blockgru, blocks: 8}
enc:
  spaces: '.*'
  typ: simple
  simple: {depth: 16, mults: [1, 2, 3, 4, 4], layers: 3, units: 256, act: silu, norm: rms, winit: normal, symlog: True, outer: True, kernel: 5, minres: 4}
dec:
  spaces: '.*'
  typ: simple
  simple: {inputs: [deter, stoch], vecdist: symlog_mse, depth: 16, mults: [1, 2, 3, 4, 4], layers: 3, units: 256, act: silu, norm: rms, outscale: 1.0, winit: normal, outer: True, kernel: 5, minres: 4, block_space: 8}
rewhead: {layers: 1, units: 256, act: silu, norm: rms, dist: symexp_twohot, outscale: 0.0, inputs: [deter, stoch], winit: normal, bins: 255}
conhead: {layers: 1, units: 256, act: silu, norm: rms, dist: binary, outscale: 1.0, inputs: [deter, stoch], winit: normal}
contdisc: True
rssm_loss: {free: 1.0}

# Actor Critic
actor: {layers: 3, units: 256, act: silu, norm: rms, minstd: 0.1, maxstd: 1.0, outscale: 0.01, unimix: 0.01, inputs: [deter, stoch], winit: normal}
critic: {layers: 3, units: 256, act: silu, norm: rms, dist: symexp_twohot, outscale: 0.0, inputs: [deter, stoch], winit: normal, bins: 255}
actor_dist_disc: onehot
actor_dist_cont: normal
imag_start: all
imag_repeat: 1
imag_length: 15
imag_unroll: False
horizon: 333
return_lambda: 0.95
return_lambda_replay: 0.95
slow_critic_update: 1
slow_critic_fraction: 0.02
retnorm: {impl: perc, rate: 0.01, limit: 1.0, perclo: 5.0, perchi: 95.0}
valnorm: {impl: off, rate: 0.01, limit: 1e-8}
advnorm: {impl: off, rate: 0.01, limit: 1e-8}
actent: 3e-4
slowreg: 1.0
slowtar: False

</configs/dreamer/dreamer_xs.yaml>

<configs/dreamer/dreamer_xxs.yaml>
hydra:
  job:
    chdir: True
  run:
    dir: ./output/dreamer/${now:%Y-%m-%d_%H%M%S_%f}/

seed: 0
method: dreamer
logdir: '.'
eval_dir: ''
filter: 'score|length|fps|ratio|train/.*_loss$|train/rand/.*/mean'
wandb: False
tensorboard_videos: False

replay:
  size: 524288
  online: True
  fracs: {uniform: 1.0, priority: 0.0, recency: 0.0}
  prio: {exponent: 0.8, maxfrac: 0.5, initial: inf, zero_on_sample: True}
  priosignal: model
  recexp: 1.0
  chunksize: 1024
  save_wait: False

jax:
  platform: gpu
  jit: True
  compute_dtype: float32
  param_dtype: float32
  prealloc: True
  checks: False
  logical_cpus: 0
  debug: False
  policy_devices: [0]
  train_devices: [0]
  sync_every: 1
  profiler: False
  transfer_guard: False
  assert_num_devices: -1
  fetch_policy_carry: False
  nvidia_flags: False
  xla_dump: False

run:
  script: train
  steps: 2097152
  duration: 0
  num_envs: 32
  num_envs_eval: 4
  expl_until: 0
  log_every: 120
  save_every: 900
  eval_every: 180
  eval_initial: True
  eval_eps: 10
  train_ratio: 32.0
  train_fill: 0
  eval_fill: 0
  log_zeros: True
  log_keys_video: [image]
  log_keys_sum: '^$'
  log_keys_avg: '^$'
  log_keys_max: '^$'
  log_video_fps: 60
  log_video_streams: 1
  log_episode_timeout: 60
  from_checkpoint: ''
  actor_addr: 'tcp://localhost:{auto}'
  replay_addr: 'tcp://localhost:{auto}'
  logger_addr: 'tcp://localhost:{auto}'
  actor_batch: 8
  actor_threads: 4
  env_replica: -1
  ipv6: False
  usage: {psutil: True, nvsmi: True, gputil: False, malloc: False, gc: False}
  timer: True
  driver_parallel: True
  agent_process: False
  remote_replay: False

env:
  path: /workspace/src/omni_epic/envs/r2d2/go_forward.py
  vision: True
  size: [32, 32]
  use_depth: True
  fov: 90.

wrapper:
  length: 1000
  reset: True
  discretize: 0
  checks: True

# Agent
report: True
report_gradnorms: False
batch_size: 16
batch_length: 65
batch_length_eval: 33
replay_length: 0
replay_length_eval: 0
replay_context: 1
random_agent: False
loss_scales: {dec_cnn: 1.0, dec_mlp: 1.0, reward: 1.0, cont: 1.0, dyn: 1.0, rep: 0.1, actor: 1.0, critic: 1.0, replay_critic: 0.3}
opt: {scaler: rms, lr: 4e-5, eps: 1e-20, momentum: True, wd: 0.0, warmup: 1000, globclip: 0.0, agc: 0.3, beta1: 0.9, beta2: 0.999, details: False, pmin: 1e-3, anneal: 0, schedule: constant}
ac_grads: none
reset_context: 0.0
replay_critic_loss: True
replay_critic_grad: True
replay_critic_bootstrap: imag
reward_grad: True
report_openl_context: 8

# World Model
dyn:
  typ: rssm
  rssm: {deter: 2048, hidden: 256, stoch: 32, classes: 16, act: silu, norm: rms, unimix: 0.01, outscale: 1.0, winit: normal, imglayers: 2, obslayers: 1, dynlayers: 1, absolute: False, cell: blockgru, blocks: 8}
enc:
  spaces: '.*'
  typ: simple
  simple: {depth: 16, mults: [1, 2, 4], layers: 3, units: 256, act: silu, norm: rms, winit: normal, symlog: True, outer: False, kernel: 5, minres: 4}
dec:
  spaces: '.*'
  typ: simple
  simple: {inputs: [deter, stoch], vecdist: symlog_mse, depth: 16, mults: [1, 2, 4], layers: 3, units: 256, act: silu, norm: rms, outscale: 1.0, winit: normal, outer: False, kernel: 5, minres: 4, block_space: 8}
rewhead: {layers: 1, units: 256, act: silu, norm: rms, dist: symexp_twohot, outscale: 0.0, inputs: [deter, stoch], winit: normal, bins: 255}
conhead: {layers: 1, units: 256, act: silu, norm: rms, dist: binary, outscale: 1.0, inputs: [deter, stoch], winit: normal}
contdisc: True
rssm_loss: {free: 1.0}

# Actor Critic
actor: {layers: 3, units: 256, act: silu, norm: rms, minstd: 0.1, maxstd: 1.0, outscale: 0.01, unimix: 0.01, inputs: [deter, stoch], winit: normal}
critic: {layers: 3, units: 256, act: silu, norm: rms, dist: symexp_twohot, outscale: 0.0, inputs: [deter, stoch], winit: normal, bins: 255}
actor_dist_disc: onehot
actor_dist_cont: normal
imag_start: all
imag_repeat: 1
imag_length: 15
imag_unroll: False
horizon: 333
return_lambda: 0.95
return_lambda_replay: 0.95
slow_critic_update: 1
slow_critic_fraction: 0.02
retnorm: {impl: perc, rate: 0.01, limit: 1.0, perclo: 5.0, perchi: 95.0}
valnorm: {impl: off, rate: 0.01, limit: 1e-8}
advnorm: {impl: off, rate: 0.01, limit: 1e-8}
actent: 3e-4
slowreg: 1.0
slowtar: False

</configs/dreamer/dreamer_xxs.yaml>

<configs/omni_epic.yaml>
hydra:
  job:
    chdir: True
  run:
    dir: ./output/omni_epic/${now:%Y-%m-%d_%H%M%S_%f}/

defaults:
  - _self_
  - dreamer: dreamer_xxs

logdir: '.'
robot: r2d2
iterations: 50
iterate_until_success_gen: False  # (added for the game) only iterate until a successful task is found
error_max_iterations: 5  # maximum number of iterations to solve compilation errors for a task before giving up
enable_moi: True  # whether to evaluate interestingness of generated task
enable_sd: True  # whether to evaluate success on trained task
train_agent: True  # whether to train the agent
train_from_ckpt: True  # whether to train the agent from checkpoint
archive_from_ckpt: ''  # path to the checkpoint to initialize the archive from
embedding_method: openai
add_examples: True  # whether to add handcrafted examples to the prompts
override_vars: {}  # override the variables in the script
num_episodes_to_visualize_dreamer: 4
iterate_same_task: False
use_archive: True  # whether to use the archive when generating tasks

environment_generator:
  # LLM params
  client: openai
  model: gpt-4o-2024-05-13
  max_tokens: 4096
  temperature: 0

task_generator:
  num_examples: 5  # number of examples given in the prompts, -1 means give everything
  num_failed_examples: 5  # number of failed examples given in the prompts, -1 means give everything
  num_add_examples: 0  # number of additional examples to add to the code gen prompts
  enable_moi: True  # whether to include interestingness in task generation
  # LLM params
  client: openai
  model: gpt-4o-2024-05-13
  max_tokens: 4096
  temperature: 0

model_of_interestingness:
  num_examples: 10
  # LLM params
  client: openai
  model: gpt-4o-2024-05-13
  max_tokens: 4096
  temperature: 0

success_detector:
  use_vision: False
  # VLM params, only used if use_vision is True
  client: openai
  model: gpt-4-turbo-2024-04-09
  max_tokens: 4096
  temperature: 0

task_iterator:
  max_iterations: 1
  num_examples: 5
  # LLM params
  client: openai
  model: gpt-4o-2024-05-13
  max_tokens: 4096
  temperature: 0

task_iterator_vision:
  max_iterations: 1
  num_examples: 5
  # VLM params
  client: openai
  model: gpt-4-turbo-2024-04-09
  max_tokens: 4096
  temperature: 0

</configs/omni_epic.yaml>

<configs/plot_annecs.yaml>
hydra:
  job:
    chdir: True
  run:
    dir: ./output/plot_annecs/${now:%Y-%m-%d_%H%M%S_%f}/

methods:
  OMNI-EPIC:
    paths:
      - /workspace/src/output/pipeline/run_0/archive.jsonl
      - /workspace/src/output/pipeline/run_1/archive.jsonl
      - /workspace/src/output/pipeline/run_2/archive.jsonl
  OMNI-EPIC w/o interestingness:
    paths:
      - /workspace/src/output/pipeline/run_0/archive.jsonl
      - /workspace/src/output/pipeline/run_1/archive.jsonl
      - /workspace/src/output/pipeline/run_2/archive.jsonl
  OMNI-EPIC w/o archive:
    paths:
      - /workspace/src/output/pipeline/run_0/archive.jsonl
      - /workspace/src/output/pipeline/run_1/archive.jsonl
      - /workspace/src/output/pipeline/run_2/archive.jsonl

robot: r2d2
num_seed_tasks: 3
train_agent: True
num_prev_eval_envs: 3
embedding_method: openai
metrics_dict_path: ''
file_format: png
remove_titles: False
remove_background: False
remove_axes_labels: False
remove_legend: False

model_of_interestingness:
  num_examples: 10
  # LLM params
  client: openai
  model: gpt-4o-2024-05-13
  max_tokens: 4096
  temperature: 0

</configs/plot_annecs.yaml>

<configs/plot_diversity.yaml>
hydra:
  job:
    chdir: True
  run:
    dir: ./output/plot_diversity/${now:%Y-%m-%d_%H%M%S_%f}/

methods:
  OMNI-EPIC:
    paths:
      - /workspace/src/output/pipeline/run_0/archive.jsonl
      - /workspace/src/output/pipeline/run_1/archive.jsonl
      - /workspace/src/output/pipeline/run_2/archive.jsonl
  OMNI-EPIC w/o interestingness:
    paths:
      - /workspace/src/output/pipeline/run_0/archive.jsonl
      - /workspace/src/output/pipeline/run_1/archive.jsonl
      - /workspace/src/output/pipeline/run_2/archive.jsonl
  OMNI-EPIC w/o archive:
    paths:
      - /workspace/src/output/pipeline/run_0/archive.jsonl
      - /workspace/src/output/pipeline/run_1/archive.jsonl
      - /workspace/src/output/pipeline/run_2/archive.jsonl

embedding_method: openai
downscale_method: pca  # pca or autoenc
grid_size: 20  # diversity grid size
file_format: png
remove_titles: False
remove_background: False
remove_axes_labels: False
add_colorbar: True
remove_x_labels: False

</configs/plot_diversity.yaml>

<dreamerv3/agent.py>
import re
from functools import partial as bind

import embodied
import jax
import jax.numpy as jnp
import numpy as np
import optax
import ruamel.yaml as yaml

from . import jaxagent
from . import jaxutils
from . import nets
from . import ninjax as nj

f32 = jnp.float32
treemap = jax.tree_util.tree_map
sg = lambda x: treemap(jax.lax.stop_gradient, x)
cast = jaxutils.cast_to_compute
sample = lambda dist: {
    k: v.sample(seed=nj.seed()) for k, v in dist.items()}


@jaxagent.Wrapper
class Agent(nj.Module):

  configs = yaml.YAML(typ='safe').load(
      (embodied.Path(__file__).parent / 'configs.yaml').read())

  def __init__(self, obs_space, act_space, config):
    self.obs_space = {
        k: v for k, v in obs_space.items() if not k.startswith('log_')}
    self.act_space = {
        k: v for k, v in act_space.items() if k != 'reset'}
    self.config = config
    enc_space = {
        k: v for k, v in obs_space.items()
        if k not in ('is_first', 'is_last', 'is_terminal', 'reward') and
        not k.startswith('log_') and re.match(config.enc.spaces, k)}
    dec_space = {
        k: v for k, v in obs_space.items()
        if k not in ('is_first', 'is_last', 'is_terminal', 'reward') and
        not k.startswith('log_') and re.match(config.dec.spaces, k)}
    embodied.print('Encoder:', {k: v.shape for k, v in enc_space.items()})
    embodied.print('Decoder:', {k: v.shape for k, v in dec_space.items()})

    # World Model
    self.enc = {
        'simple': bind(nets.SimpleEncoder, **config.enc.simple),
    }[config.enc.typ](enc_space, name='enc')
    self.dec = {
        'simple': bind(nets.SimpleDecoder, **config.dec.simple),
    }[config.dec.typ](dec_space, name='dec')
    self.dyn = {
        'rssm': bind(nets.RSSM, **config.dyn.rssm),
    }[config.dyn.typ](name='dyn')
    self.rew = nets.MLP((), **config.rewhead, name='rew')
    self.con = nets.MLP((), **config.conhead, name='con')

    # Actor
    kwargs = {}
    kwargs['shape'] = {
        k: (*s.shape, s.classes) if s.discrete else s.shape
        for k, s in self.act_space.items()}
    kwargs['dist'] = {
        k: config.actor_dist_disc if v.discrete else config.actor_dist_cont
        for k, v in self.act_space.items()}
    self.actor = nets.MLP(**kwargs, **config.actor, name='actor')
    self.retnorm = jaxutils.Moments(**config.retnorm, name='retnorm')
    self.valnorm = jaxutils.Moments(**config.valnorm, name='valnorm')
    self.advnorm = jaxutils.Moments(**config.advnorm, name='advnorm')

    # Critic
    self.critic = nets.MLP((), name='critic', **self.config.critic)
    self.slowcritic = nets.MLP(
        (), name='slowcritic', **self.config.critic, dtype='float32')
    self.updater = jaxutils.SlowUpdater(
        self.critic, self.slowcritic,
        self.config.slow_critic_fraction,
        self.config.slow_critic_update,
        name='updater')

    # Optimizer
    self.opt = jaxutils.Optimizer(**config.opt, name='opt')
    self.modules = [
        self.enc, self.dyn, self.dec, self.rew, self.con,
        self.actor, self.critic]
    scales = self.config.loss_scales.copy()
    cnn = scales.pop('dec_cnn')
    mlp = scales.pop('dec_mlp')
    scales.update({k: cnn for k in self.dec.imgkeys})
    scales.update({k: mlp for k in self.dec.veckeys})
    self.scales = scales

  @property
  def policy_keys(self):
    return '/(enc|dyn|actor)/'

  @property
  def aux_spaces(self):
    spaces = {}
    spaces['stepid'] = embodied.Space(np.uint8, 20)
    if self.config.replay_context:
      latshape = (self.config.dyn.rssm.stoch, self.config.dyn.rssm.classes)
      latdtype = jaxutils.COMPUTE_DTYPE
      latdtype = np.float32 if latdtype == jnp.bfloat16 else latdtype
      spaces['deter'] = embodied.Space(latdtype, self.config.dyn.rssm.deter)
      spaces['stoch'] = embodied.Space(np.int32, latshape[:-1])
    return spaces

  def init_policy(self, batch_size):
    prevact = {
        k: jnp.zeros((batch_size, *v.shape), v.dtype)
        for k, v in self.act_space.items()}
    return (self.dyn.initial(batch_size), prevact)

  def init_train(self, batch_size):
    prevact = {
        k: jnp.zeros((batch_size, *v.shape), v.dtype)
        for k, v in self.act_space.items()}
    return (self.dyn.initial(batch_size), prevact)

  def init_report(self, batch_size):
    return self.init_train(batch_size)

  def policy(self, obs, carry, mode='train'):
    self.config.jax.jit and embodied.print(
        'Tracing policy function', color='yellow')
    prevlat, prevact = carry
    obs = self.preprocess(obs)
    embed = self.enc(obs, bdims=1)
    prevact = jaxutils.onehot_dict(prevact, self.act_space)
    lat, out = self.dyn.observe(
        prevlat, prevact, embed, obs['is_first'], bdims=1)
    actor = self.actor(out, bdims=1)
    act = sample(actor)

    outs = {}
    if self.config.replay_context:
      outs.update({k: out[k] for k in self.aux_spaces if k != 'stepid'})
      outs['stoch'] = jnp.argmax(outs['stoch'], -1).astype(jnp.int32)

    outs['finite'] = {
        '/'.join(x.key for x in k): (
            jnp.isfinite(v).all(range(1, v.ndim)),
            v.min(range(1, v.ndim)),
            v.max(range(1, v.ndim)))
        for k, v in jax.tree_util.tree_leaves_with_path(dict(
            obs=obs, prevlat=prevlat, prevact=prevact,
            embed=embed, act=act, out=out, lat=lat,
        ))}

    assert all(
        k in outs for k in self.aux_spaces
        if k not in ('stepid', 'finite', 'is_online')), (
              list(outs.keys()), self.aux_spaces)

    act = {
        k: jnp.nanargmax(act[k], -1).astype(jnp.int32)
        if s.discrete else act[k] for k, s in self.act_space.items()}
    return act, outs, (lat, act)

  def train(self, data, carry):
    self.config.jax.jit and embodied.print(
        'Tracing train function', color='yellow')
    data = self.preprocess(data)
    stepid = data.pop('stepid')

    if self.config.replay_context:
      K = self.config.replay_context
      data = data.copy()
      # context = {k: data.pop(k)[:, :K] for k in self.aux_spaces if k in data}
      context = {
          k: data.pop(k)[:, :K] for k in self.aux_spaces if k != 'stepid'}
      context['stoch'] = f32(jax.nn.one_hot(
          context['stoch'], self.config.dyn.rssm.classes))
      prevlat = self.dyn.outs_to_carry(context)
      carry = prevlat, carry[1]
      data = {k: v[:, K:] for k, v in data.items()}
      stepid = stepid[:, K:]

    if self.config.reset_context:
      keep = jax.random.uniform(
          nj.seed(), data['is_first'][:, :1].shape) > self.config.reset_context
      data['is_first'] = jnp.concatenate([
          data['is_first'][:, :1] & keep, data['is_first'][:, 1:]], 1)

    mets, (out, carry, metrics) = self.opt(
        self.modules, self.loss, data, carry, has_aux=True)
    metrics.update(mets)
    self.updater()
    outs = {}

    if self.config.replay_context:
      outs['replay'] = {'stepid': stepid}
      outs['replay'].update({
          k: out['replay_outs'][k] for k in self.aux_spaces if k != 'stepid'})
      outs['replay']['stoch'] = jnp.argmax(
          outs['replay']['stoch'], -1).astype(jnp.int32)

    if self.config.replay.fracs.priority > 0:
      bs = data['is_first'].shape
      if self.config.replay.priosignal == 'td':
        priority = out['critic_loss'][:, 0].reshape(bs)
      elif self.config.replay.priosignal == 'model':
        terms = [out[f'{k}_loss'] for k in (
            'rep', 'dyn', *self.dec.veckeys, *self.dec.imgkeys)]
        priority = jnp.stack(terms, 0).sum(0)
      elif self.config.replay.priosignal == 'all':
        terms = [out[f'{k}_loss'] for k in (
            'rep', 'dyn', *self.dec.veckeys, *self.dec.imgkeys)]
        terms.append(out['actor_loss'][:, 0].reshape(bs))
        terms.append(out['critic_loss'][:, 0].reshape(bs))
        priority = jnp.stack(terms, 0).sum(0)
      else:
        raise NotImplementedError(self.config.replay.priosignal)
      assert stepid.shape[:2] == priority.shape == bs
      outs['replay'] = {'stepid': stepid, 'priority': priority}

    return outs, carry, metrics

  def loss(self, data, carry, update=True):
    metrics = {}
    prevlat, prevact = carry

    # Replay rollout
    prevacts = {
        k: jnp.concatenate([prevact[k][:, None], data[k][:, :-1]], 1)
        for k in self.act_space}
    prevacts = jaxutils.onehot_dict(prevacts, self.act_space)
    embed = self.enc(data)
    newlat, outs = self.dyn.observe(prevlat, prevacts, embed, data['is_first'])
    rew_feat = outs if self.config.reward_grad else sg(outs)
    dists = dict(
        **self.dec(outs),
        reward=self.rew(rew_feat, training=True),
        cont=self.con(outs, training=True))
    losses = {k: -v.log_prob(f32(data[k])) for k, v in dists.items()}
    if self.config.contdisc:
      del losses['cont']
      softlabel = data['cont'] * (1 - 1 / self.config.horizon)
      losses['cont'] = -dists['cont'].log_prob(softlabel)
    dynlosses, mets = self.dyn.loss(outs, **self.config.rssm_loss)
    losses.update(dynlosses)
    metrics.update(mets)
    replay_outs = outs

    # Imagination rollout
    def imgstep(carry, _):
      lat, act = carry
      lat, out = self.dyn.imagine(lat, act, bdims=1)
      out['stoch'] = sg(out['stoch'])
      act = cast(sample(self.actor(out, bdims=1)))
      return (lat, act), (out, act)
    rew = data['reward']
    con = 1 - f32(data['is_terminal'])
    if self.config.imag_start == 'all':
      B, T = data['is_first'].shape
      startlat = self.dyn.outs_to_carry(treemap(
          lambda x: x.reshape((B * T, 1, *x.shape[2:])), replay_outs))
      startout, startrew, startcon = treemap(
          lambda x: x.reshape((B * T, *x.shape[2:])),
          (replay_outs, rew, con))
    elif self.config.imag_start == 'last':
      startlat = newlat
      startout, startrew, startcon = treemap(
          lambda x: x[:, -1], (replay_outs, rew, con))
    if self.config.imag_repeat > 1:
      N = self.config.imag_repeat
      startlat, startout, startrew, startcon = treemap(
          lambda x: x.repeat(N, 0), (startlat, startout, startrew, startcon))
    startact = cast(sample(self.actor(startout, bdims=1)))
    _, (outs, acts) = jaxutils.scan(
        imgstep, sg((startlat, startact)),
        jnp.arange(self.config.imag_length), self.config.imag_unroll)
    outs, acts = treemap(lambda x: x.swapaxes(0, 1), (outs, acts))
    outs, acts = treemap(
        lambda first, seq: jnp.concatenate([first, seq], 1),
        treemap(lambda x: x[:, None], (startout, startact)), (outs, acts))

    # Annotate
    rew = jnp.concatenate([startrew[:, None], self.rew(outs).mean()[:, 1:]], 1)
    con = jnp.concatenate([startcon[:, None], self.con(outs).mean()[:, 1:]], 1)
    acts = sg(acts)
    inp = treemap({
        'none': lambda x: sg(x),
        'first': lambda x: jnp.concatenate([x[:, :1], sg(x[:, 1:])], 1),
        'all': lambda x: x,
    }[self.config.ac_grads], outs)
    actor = self.actor(inp)
    critic = self.critic(inp)
    slowcritic = self.slowcritic(inp)
    voffset, vscale = self.valnorm.stats()
    val = critic.mean() * vscale + voffset
    slowval = slowcritic.mean() * vscale + voffset
    tarval = slowval if self.config.slowtar else val
    discount = 1 if self.config.contdisc else 1 - 1 / self.config.horizon
    weight = jnp.cumprod(discount * con, 1) / discount

    # Return
    rets = [tarval[:, -1]]
    disc = con[:, 1:] * discount
    lam = self.config.return_lambda
    interm = rew[:, 1:] + (1 - lam) * disc * tarval[:, 1:]
    for t in reversed(range(disc.shape[1])):
      rets.append(interm[:, t] + disc[:, t] * lam * rets[-1])
    ret = jnp.stack(list(reversed(rets))[:-1], 1)

    # Actor
    roffset, rscale = self.retnorm(ret, update)
    adv = (ret - tarval[:, :-1]) / rscale
    aoffset, ascale = self.advnorm(adv, update)
    adv_normed = (adv - aoffset) / ascale
    logpi = sum([v.log_prob(sg(acts[k]))[:, :-1] for k, v in actor.items()])
    ents = {k: v.entropy()[:, :-1] for k, v in actor.items()}
    actor_loss = sg(weight[:, :-1]) * -(
        logpi * sg(adv_normed) + self.config.actent * sum(ents.values()))
    losses['actor'] = actor_loss

    # Critic
    voffset, vscale = self.valnorm(ret, update)
    ret_normed = (ret - voffset) / vscale
    ret_padded = jnp.concatenate([ret_normed, 0 * ret_normed[:, -1:]], 1)
    losses['critic'] = sg(weight)[:, :-1] * -(
        critic.log_prob(sg(ret_padded)) +
        self.config.slowreg * critic.log_prob(sg(slowcritic.mean())))[:, :-1]

    if self.config.replay_critic_loss:
      replay_critic = self.critic(
          replay_outs if self.config.replay_critic_grad else sg(replay_outs))
      replay_slowcritic = self.slowcritic(replay_outs)
      boot = dict(
          imag=ret[:, 0].reshape(data['reward'].shape),
          critic=replay_critic.mean(),
      )[self.config.replay_critic_bootstrap]
      rets = [boot[:, -1]]
      live = f32(~data['is_terminal'])[:, 1:] * (1 - 1 / self.config.horizon)
      cont = f32(~data['is_last'])[:, 1:] * self.config.return_lambda_replay
      interm = data['reward'][:, 1:] + (1 - cont) * live * boot[:, 1:]
      for t in reversed(range(live.shape[1])):
        rets.append(interm[:, t] + live[:, t] * cont[:, t] * rets[-1])
      replay_ret = jnp.stack(list(reversed(rets))[:-1], 1)
      voffset, vscale = self.valnorm(replay_ret, update)
      ret_normed = (replay_ret - voffset) / vscale
      ret_padded = jnp.concatenate([ret_normed, 0 * ret_normed[:, -1:]], 1)
      losses['replay_critic'] = sg(f32(~data['is_last']))[:, :-1] * -(
          replay_critic.log_prob(sg(ret_padded)) +
          self.config.slowreg * replay_critic.log_prob(
              sg(replay_slowcritic.mean())))[:, :-1]

    # Metrics
    metrics.update({f'{k}_loss': v.mean() for k, v in losses.items()})
    metrics.update({f'{k}_loss_std': v.std() for k, v in losses.items()})
    metrics.update(jaxutils.tensorstats(adv, 'adv'))
    metrics.update(jaxutils.tensorstats(rew, 'rew'))
    metrics.update(jaxutils.tensorstats(weight, 'weight'))
    metrics.update(jaxutils.tensorstats(val, 'val'))
    metrics.update(jaxutils.tensorstats(ret, 'ret'))
    metrics.update(jaxutils.tensorstats(
        (ret - roffset) / rscale, 'ret_normed'))
    if self.config.replay_critic_loss:
      metrics.update(jaxutils.tensorstats(replay_ret, 'replay_ret'))
    metrics['td_error'] = jnp.abs(ret - val[:, :-1]).mean()
    metrics['ret_rate'] = (jnp.abs(ret) > 1.0).mean()
    for k, space in self.act_space.items():
      act = f32(jnp.argmax(acts[k], -1) if space.discrete else acts[k])
      metrics.update(jaxutils.tensorstats(f32(act), f'act/{k}'))
      if hasattr(actor[k], 'minent'):
        lo, hi = actor[k].minent, actor[k].maxent
        rand = ((ents[k] - lo) / (hi - lo)).mean(
            range(2, len(ents[k].shape)))
        metrics.update(jaxutils.tensorstats(rand, f'rand/{k}'))
      metrics.update(jaxutils.tensorstats(ents[k], f'ent/{k}'))
    metrics['data_rew/max'] = jnp.abs(data['reward']).max()
    metrics['pred_rew/max'] = jnp.abs(rew).max()
    metrics['data_rew/mean'] = data['reward'].mean()
    metrics['pred_rew/mean'] = rew.mean()
    metrics['data_rew/std'] = data['reward'].std()
    metrics['pred_rew/std'] = rew.std()
    if 'reward' in dists:
      stats = jaxutils.balance_stats(dists['reward'], data['reward'], 0.1)
      metrics.update({f'rewstats/{k}': v for k, v in stats.items()})
    if 'cont' in dists:
      stats = jaxutils.balance_stats(dists['cont'], data['cont'], 0.5)
      metrics.update({f'constats/{k}': v for k, v in stats.items()})
    metrics['activation/embed'] = jnp.abs(embed).mean()
    # metrics['activation/deter'] = jnp.abs(replay_outs['deter']).mean()

    # Combine
    losses = {k: v * self.scales[k] for k, v in losses.items()}
    loss = jnp.stack([v.mean() for k, v in losses.items()]).sum()
    newact = {k: data[k][:, -1] for k in self.act_space}
    outs = {'replay_outs': replay_outs, 'prevacts': prevacts, 'embed': embed}
    outs.update({f'{k}_loss': v for k, v in losses.items()})
    carry = (newlat, newact)
    return loss, (outs, carry, metrics)

  def report(self, data, carry):
    self.config.jax.jit and embodied.print(
        'Tracing report function', color='yellow')
    if not self.config.report:
      return {}, carry
    metrics = {}
    data = self.preprocess(data)

    # Train metrics
    _, (outs, carry_out, mets) = self.loss(data, carry, update=False)
    metrics.update(mets)

    # Open loop predictions
    B, T = data['is_first'].shape
    num_obs = min(self.config.report_openl_context, T // 2)
    # Rerun observe to get the correct intermediate state, because
    # outs_to_carry doesn't work with num_obs<context.
    img_start, rec_outs = self.dyn.observe(
        carry[0],
        {k: v[:, :num_obs] for k, v in outs['prevacts'].items()},
        outs['embed'][:, :num_obs],
        data['is_first'][:, :num_obs])
    img_acts = {k: v[:, num_obs:] for k, v in outs['prevacts'].items()}
    img_outs = self.dyn.imagine(img_start, img_acts)[1]
    rec = dict(
        **self.dec(rec_outs), reward=self.rew(rec_outs),
        cont=self.con(rec_outs))
    img = dict(
        **self.dec(img_outs), reward=self.rew(img_outs),
        cont=self.con(img_outs))

    # Prediction losses
    data_img = {k: v[:, num_obs:] for k, v in data.items()}
    losses = {k: -v.log_prob(data_img[k].astype(f32)) for k, v in img.items()}
    metrics.update({f'openl_{k}_loss': v.mean() for k, v in losses.items()})
    stats = jaxutils.balance_stats(img['reward'], data_img['reward'], 0.1)
    metrics.update({f'openl_reward_{k}': v for k, v in stats.items()})
    stats = jaxutils.balance_stats(img['cont'], data_img['cont'], 0.5)
    metrics.update({f'openl_cont_{k}': v for k, v in stats.items()})

    # Video predictions
    for key in self.dec.imgkeys:
      true = f32(data[key][:6])
      pred = jnp.concatenate([rec[key].mode()[:6], img[key].mode()[:6]], 1)
      error = (pred - true + 1) / 2
      video = jnp.concatenate([true, pred, error], 2)
      metrics[f'openloop/{key}'] = jaxutils.video_grid(video)

    # Grad norms per loss term
    if self.config.report_gradnorms:
      for key in self.scales:
        try:
          lossfn = lambda data, carry: self.loss(
              data, carry, update=False)[1][0][f'{key}_loss'].mean()
          grad = nj.grad(lossfn, self.modules)(data, carry)[-1]
          metrics[f'gradnorm/{key}'] = optax.global_norm(grad)
        except KeyError:
          print(f'Skipping gradnorm summary for missing loss: {key}')

    return metrics, carry_out

  def preprocess(self, obs):
    spaces = {**self.obs_space, **self.act_space, **self.aux_spaces}
    result = {}
    for key, value in obs.items():
      if key.startswith('log_') or key in ('reset', 'key', 'id'):
        continue
      space = spaces[key]
      if len(space.shape) >= 3 and space.dtype == jnp.uint8:
        value = cast(value) / 255.0
      result[key] = value
    result['cont'] = 1.0 - f32(result['is_terminal'])
    return result

</dreamerv3/agent.py>

<dreamerv3/configs.yaml>
defaults:

  seed: 0
  method: name
  task: dummy_disc
  logdir: /dev/null
  eval_dir: ''
  filter: 'score|length|fps|ratio|train/.*_loss$|train/rand/.*/mean'
  tensorboard_videos: True

  replay:
    size: 5e6
    online: True
    fracs: {uniform: 1.0, priority: 0.0, recency: 0.0}
    prio: {exponent: 0.8, maxfrac: 0.5, initial: inf, zero_on_sample: True}
    priosignal: model
    recexp: 1.0
    chunksize: 1024
    save_wait: False

  jax:
    platform: gpu
    jit: True
    compute_dtype: bfloat16
    param_dtype: float32
    prealloc: True
    checks: False
    logical_cpus: 0
    debug: False
    policy_devices: [0]
    train_devices: [0]
    sync_every: 1
    profiler: False
    transfer_guard: True
    assert_num_devices: -1
    fetch_policy_carry: False
    nvidia_flags: False
    xla_dump: False

  run:
    script: train
    steps: 1e10
    duration: 0
    num_envs: 16
    num_envs_eval: 4
    expl_until: 0
    log_every: 120
    save_every: 900
    eval_every: 180
    eval_initial: True
    eval_eps: 1
    train_ratio: 32.0
    train_fill: 0
    eval_fill: 0
    log_zeros: True
    log_keys_video: [image]
    log_keys_sum: '^$'
    log_keys_avg: '^$'
    log_keys_max: '^$'
    log_video_fps: 20
    log_video_streams: 4
    log_episode_timeout: 60
    from_checkpoint: ''
    actor_addr: 'tcp://localhost:{auto}'
    replay_addr: 'tcp://localhost:{auto}'
    logger_addr: 'tcp://localhost:{auto}'
    actor_batch: 8
    actor_threads: 4
    env_replica: -1
    ipv6: False
    usage: {psutil: True, nvsmi: True, gputil: False, malloc: False, gc: False}
    timer: True
    driver_parallel: True
    agent_process: False
    remote_replay: False

  wrapper: {length: 0, reset: True, discretize: 0, checks: True}
  env:
    atari: {size: [64, 64], repeat: 4, sticky: True, gray: True, actions: all, lives: unused, noops: 0, autostart: False, pooling: 2, aggregate: max, resize: pillow}
    crafter: {size: [64, 64], logs: False, use_logdir: False}
    atari100k: {size: [64, 64], repeat: 4, sticky: False, gray: False, actions: all, lives: unused, noops: 0, autostart: False, resize: pillow, length: 100000}
    dmlab: {size: [64, 64], repeat: 4, episodic: True, actions: popart, use_seed: False}
    minecraft: {size: [64, 64], break_speed: 100.0, logs: False}
    dmc: {size: [64, 64], repeat: 2, image: True, camera: -1}
    procgen: {size: [64, 64]}
    loconav: {size: [64, 64], repeat: 2, camera: -1}

  # Agent
  report: True
  report_gradnorms: False
  batch_size: 16
  batch_length: 65
  batch_length_eval: 33
  replay_length: 0
  replay_length_eval: 0
  replay_context: 1
  random_agent: False
  loss_scales: {dec_cnn: 1.0, dec_mlp: 1.0, reward: 1.0, cont: 1.0, dyn: 1.0, rep: 0.1, actor: 1.0, critic: 1.0, replay_critic: 0.3}
  opt: {scaler: rms, lr: 4e-5, eps: 1e-20, momentum: True, wd: 0.0, warmup: 1000, globclip: 0.0, agc: 0.3, beta1: 0.9, beta2: 0.999, details: False, pmin: 1e-3, anneal: 0, schedule: constant}
  ac_grads: none
  reset_context: 0.0
  replay_critic_loss: True
  replay_critic_grad: True
  replay_critic_bootstrap: imag
  reward_grad: True
  report_openl_context: 8

  # World Model
  dyn:
    typ: rssm
    rssm: {deter: 8192, hidden: 1024, stoch: 32, classes: 64, act: silu, norm: rms, unimix: 0.01, outscale: 1.0, winit: normal, imglayers: 2, obslayers: 1, dynlayers: 1, absolute: False, cell: blockgru, blocks: 8}
  enc:
    spaces: '.*'
    typ: simple
    simple: {depth: 64, mults: [1, 2, 3, 4, 4], layers: 3, units: 1024, act: silu, norm: rms, winit: normal, symlog: True, outer: True, kernel: 5, minres: 4}
  dec:
    spaces: '.*'
    typ: simple
    simple: {inputs: [deter, stoch], vecdist: symlog_mse, depth: 64, mults: [1, 2, 3, 4, 4], layers: 3, units: 1024, act: silu, norm: rms, outscale: 1.0, winit: normal, outer: True, kernel: 5, minres: 4, block_space: 8}
  rewhead: {layers: 1, units: 1024, act: silu, norm: rms, dist: symexp_twohot, outscale: 0.0, inputs: [deter, stoch], winit: normal, bins: 255}
  conhead: {layers: 1, units: 1024, act: silu, norm: rms, dist: binary, outscale: 1.0, inputs: [deter, stoch], winit: normal}
  contdisc: True
  rssm_loss: {free: 1.0}

  # Actor Critic
  actor: {layers: 3, units: 1024, act: silu, norm: rms, minstd: 0.1, maxstd: 1.0, outscale: 0.01, unimix: 0.01, inputs: [deter, stoch], winit: normal}
  critic: {layers: 3, units: 1024, act: silu, norm: rms, dist: symexp_twohot, outscale: 0.0, inputs: [deter, stoch], winit: normal, bins: 255}
  actor_dist_disc: onehot
  actor_dist_cont: normal
  imag_start: all
  imag_repeat: 1
  imag_length: 15
  imag_unroll: False
  horizon: 333
  return_lambda: 0.95
  return_lambda_replay: 0.95
  slow_critic_update: 1
  slow_critic_fraction: 0.02
  retnorm: {impl: perc, rate: 0.01, limit: 1.0, perclo: 5.0, perchi: 95.0}
  valnorm: {impl: off, rate: 0.01, limit: 1e-8}
  advnorm: {impl: off, rate: 0.01, limit: 1e-8}
  actent: 3e-4
  slowreg: 1.0
  slowtar: False

size12m: &size12m
  dyn.rssm: {deter: 2048, hidden: 256, classes: 16}
  .*\.depth: 16
  .*\.units: 256

size25m: &size25m
  dyn.rssm: {deter: 3072, hidden: 384, classes: 24}
  .*\.depth: 24
  .*\.units: 384

size50m: &size50m
  dyn.rssm: {deter: 4096, hidden: 512, classes: 32}
  .*\.depth: 32
  .*\.units: 512

size100m: &size100m
  dyn.rssm: {deter: 6144, hidden: 768, classes: 48}
  .*\.depth: 48
  .*\.units: 768

size200m: &size200m
  dyn.rssm: {deter: 8192, hidden: 1024, classes: 64}
  .*\.depth: 64
  .*\.units: 1024

size400m: &size400m
  dyn.rssm: {deter: 12288, hidden: 1536, classes: 96}
  .*\.depth: 96
  .*\.units: 1536

minecraft:
  task: minecraft_diamond
  run:
    log_keys_max: '^log_inventory.*'
  enc.spaces: 'image|inventory|inventory_max|equipped|health|hunger|breath'
  dec.spaces: 'image|inventory|inventory_max|equipped|health|hunger|breath'

dmlab:
  task: dmlab_explore_goal_locations_small
  enc.spaces: 'image|instr'
  dec.spaces: 'image|instr'
  run:
    steps: 2.6e7

atari:
  task: atari_pong
  env.atari.size: [96, 96]
  (enc|dec).simple.minres: 6
  run:
    steps: 5.1e7
  enc.spaces: 'image'
  dec.spaces: 'image'

procgen:
  task: procgen_coinrun
  env.procgen.size: [96, 96]
  (enc|dec).simple.minres: 6
  run:
    steps: 1.1e8
    train_ratio: 64
  enc.spaces: 'image'
  dec.spaces: 'image'

atari100k:
  task: atari_pong
  run:
    steps: 1.1e5
    num_envs: 1
    train_ratio: 256
  enc.spaces: 'image'
  dec.spaces: 'image'

crafter:
  task: crafter_reward
  run:
    num_envs: 1
    log_keys_max: '^log_achievement_.*'
    log_keys_sum: '^log_reward$'
    log_video_fps: 10
    train_ratio: 512
    steps: 1.1e6
  enc.spaces: 'image'
  dec.spaces: 'image'

dmc_proprio:
  <<: *size12m
  task: dmc_walker_walk
  run.train_ratio: 512
  run.steps: 3e5
  env.dmc.image: False

dmc_vision:
  <<: *size12m
  task: dmc_walker_walk
  run.train_ratio: 512
  run.steps: 6e5
  enc.spaces: 'image'
  dec.spaces: 'image'

bsuite:
  task: bsuite_mnist/0
  run.num_envs: 1
  run.train_ratio: 1024
  run.save_every: -1

loconav:
  task: loconav_ant_maze_m
  env.loconav.repeat: 1
  run:
    train_ratio: 256
    log_keys_max: '^log_.*'

memmaze:
  task: memmaze_11x11
  enc.spaces: 'image'
  dec.spaces: 'image'

multicpu:
  jax:
    logical_cpus: 8
    policy_devices: [0, 1]
    train_devices: [2, 3, 4, 5, 6, 7]
  run:
    num_envs: 8
    actor_batch: 4
  batch_size: 12

debug:
  jax: {debug: True, jit: True, prealloc: False, platform: cpu, compute_dtype: bfloat16, profiler: False, checks: False}
  wrapper: {length: 100, checks: True}
  run: {num_envs: 4, eval_every: 10, log_every: 5, save_every: 15, train_ratio: 8, actor_batch: 2, driver_parallel: False}
  report_gradnorms: False
  batch_size: 4
  batch_length: 12
  batch_length_eval: 12
  replay.size: 1e4
  (rewhead|critic).bins: 9
  dyn.rssm: {deter: 12, hidden: 8, stoch: 4, classes: 4, blocks: 4}
  .*\.layers: 2
  .*\.units: 8
  .*\.depth: 2

</dreamerv3/configs.yaml>

<dreamerv3/jaxagent.py>
import os
import re
import threading

import chex
import embodied
import jax
import jax.numpy as jnp
import numpy as np

from . import jaxutils
from . import ninjax as nj


def Wrapper(agent_cls):
  class Agent(JAXAgent):
    configs = agent_cls.configs
    inner = agent_cls
    def __init__(self, *args, **kwargs):
      super().__init__(agent_cls, *args, **kwargs)
  return Agent


class JAXAgent(embodied.Agent):

  def __init__(self, agent_cls, obs_space, act_space, config):
    print('Observation space')
    [embodied.print(f'  {k:<16} {v}') for k, v in obs_space.items()]
    print('Action space')
    [embodied.print(f'  {k:<16} {v}') for k, v in act_space.items()]

    self.obs_space = obs_space
    self.act_space = act_space
    self.config = config
    self.jaxcfg = config.jax
    self.logdir = embodied.Path(config.logdir)
    self._setup()
    self.agent = agent_cls(obs_space, act_space, config, name='agent')
    self.rng = np.random.default_rng(config.seed)
    self.spaces = {**obs_space, **act_space, **self.agent.aux_spaces}
    self.keys = [k for k in self.spaces if (
        not k.startswith('_') and not k.startswith('log_') and k != 'reset')]

    available = jax.devices(self.jaxcfg.platform)
    embodied.print(f'JAX devices ({jax.local_device_count()}):', available)
    if self.jaxcfg.assert_num_devices > 0:
      assert len(available) == self.jaxcfg.assert_num_devices, (
          available, len(available), self.jaxcfg.assert_num_devices)

    policy_devices = [available[i] for i in self.jaxcfg.policy_devices]
    train_devices = [available[i] for i in self.jaxcfg.train_devices]
    print('Policy devices:', ', '.join([str(x) for x in policy_devices]))
    print('Train devices: ', ', '.join([str(x) for x in train_devices]))

    self.policy_mesh = jax.sharding.Mesh(policy_devices, 'i')
    self.policy_sharded = jax.sharding.NamedSharding(
        self.policy_mesh, jax.sharding.PartitionSpec('i'))
    self.policy_mirrored = jax.sharding.NamedSharding(
        self.policy_mesh, jax.sharding.PartitionSpec())

    self.train_mesh = jax.sharding.Mesh(train_devices, 'i')
    self.train_sharded = jax.sharding.NamedSharding(
        self.train_mesh, jax.sharding.PartitionSpec('i'))
    self.train_mirrored = jax.sharding.NamedSharding(
        self.train_mesh, jax.sharding.PartitionSpec())

    self.pending_outs = None
    self.pending_mets = None
    self.pending_sync = None

    self._transform()
    self.policy_lock = threading.Lock()
    self.train_lock = threading.Lock()
    self.params = self._init_params(obs_space, act_space)
    self.updates = embodied.Counter()

    pattern = re.compile(self.agent.policy_keys)
    self.policy_keys = [k for k in self.params.keys() if pattern.search(k)]
    assert self.policy_keys, (list(self.params.keys()), self.agent.policy_keys)
    self.should_sync = embodied.when.Every(self.jaxcfg.sync_every)
    self.policy_params = jax.device_put(
        {k: self.params[k].copy() for k in self.policy_keys},
        self.policy_mirrored)

    self._lower_train()
    self._lower_report()
    self._train = self._train.compile()
    self._report = self._report.compile()
    self._stack = jax.jit(lambda xs: jax.tree.map(
        jnp.stack, xs, is_leaf=lambda x: isinstance(x, list)))
    self._split = jax.jit(lambda xs: jax.tree.map(
        lambda x: [y[0] for y in jnp.split(x, len(x))], xs))
    print('Done compiling train and report!')

  def init_policy(self, batch_size):
    seed = self._next_seeds(self.policy_sharded)
    batch_size //= len(self.policy_mesh.devices)
    carry = self._init_policy(self.policy_params, seed, batch_size)
    if self.jaxcfg.fetch_policy_carry:
      carry = self._take_outs(fetch_async(carry))
    else:
      carry = self._split(carry)
    return carry

  def init_train(self, batch_size):
    seed = self._next_seeds(self.train_sharded)
    batch_size //= len(self.train_mesh.devices)
    carry = self._init_train(self.params, seed, batch_size)
    return carry

  def init_report(self, batch_size):
    seed = self._next_seeds(self.train_sharded)
    batch_size //= len(self.train_mesh.devices)
    carry = self._init_report(self.params, seed, batch_size)
    return carry

  @embodied.timer.section('jaxagent_policy')
  def policy(self, obs, carry, mode='train'):
    obs = self._filter_data(obs)

    with embodied.timer.section('prepare_carry'):
      if self.jaxcfg.fetch_policy_carry:
        carry = jax.tree.map(
            np.stack, carry, is_leaf=lambda x: isinstance(x, list))
      else:
        with self.policy_lock:
          carry = self._stack(carry)

    with embodied.timer.section('check_inputs'):
      for key, space in self.obs_space.items():
        if key in self.keys:
          assert np.isfinite(obs[key]).all(), (obs[key], key, space)
      if self.jaxcfg.fetch_policy_carry:
        for keypath, value in jax.tree_util.tree_leaves_with_path(carry):
          assert np.isfinite(value).all(), (value, keypath)

    with embodied.timer.section('upload_inputs'):
      with self.policy_lock:
        obs, carry = jax.device_put((obs, carry), self.policy_sharded)
        seed = self._next_seeds(self.policy_sharded)

    with embodied.timer.section('jit_policy'):
      with self.policy_lock:
        acts, outs, carry = self._policy(
            self.policy_params, obs, carry, seed, mode)

    with embodied.timer.section('swap_params'):
      with self.policy_lock:
        if self.pending_sync:
          old = self.policy_params
          self.policy_params = self.pending_sync
          jax.tree.map(lambda x: x.delete(), old)
          self.pending_sync = None

    with embodied.timer.section('fetch_outputs'):
      if self.jaxcfg.fetch_policy_carry:
        acts, outs, carry = self._take_outs(fetch_async((acts, outs, carry)))
      else:
        carry = self._split(carry)
        acts, outs = self._take_outs(fetch_async((acts, outs)))

    with embodied.timer.section('check_outputs'):
      finite = outs.pop('finite', {})
      for key, (isfinite, _, _) in finite.items():
        assert isfinite.all(), str(finite)
      for key, space in self.act_space.items():
        if key == 'reset':
          continue
        elif space.discrete:
          assert (acts[key] >= 0).all(), (acts[key], key, space)
        else:
          assert np.isfinite(acts[key]).all(), (acts[key], key, space)

    return acts, outs, carry

  @embodied.timer.section('jaxagent_train')
  def train(self, data, carry):
    seed = data['seed']
    data = self._filter_data(data)
    allo = {k: v for k, v in self.params.items() if k in self.policy_keys}
    dona = {k: v for k, v in self.params.items() if k not in self.policy_keys}
    with embodied.timer.section('jit_train'):
      with self.train_lock:
        self.params, outs, carry, mets = self._train(
            allo, dona, data, carry, seed)
    self.updates.increment()

    if self.should_sync(self.updates) and not self.pending_sync:
      self.pending_sync = jax.device_put(
          {k: allo[k] for k in self.policy_keys}, self.policy_mirrored)
    else:
      jax.tree.map(lambda x: x.delete(), allo)

    return_outs = {}
    if self.pending_outs:
      return_outs = self._take_outs(self.pending_outs)
    self.pending_outs = fetch_async(outs)

    return_mets = {}
    if self.pending_mets:
      return_mets = self._take_mets(self.pending_mets)
    self.pending_mets = fetch_async(mets)

    if self.jaxcfg.profiler:
      outdir, copyto = self.logdir, None
      if str(outdir).startswith(('gs://', '/gcs/')):
        copyto = outdir
        outdir = embodied.Path('/tmp/profiler')
        outdir.mkdir()
      if self.updates == 100:
        embodied.print(f'Start JAX profiler: {str(outdir)}', color='yellow')
        jax.profiler.start_trace(str(outdir))
      if self.updates == 120:
        from embodied.core import path as pathlib
        embodied.print('Stop JAX profiler', color='yellow')
        jax.profiler.stop_trace()
        if copyto:
          pathlib.GFilePath(outdir).copy(copyto)
          print(f'Copied profiler result {outdir} to {copyto}')

    return return_outs, carry, return_mets

  @embodied.timer.section('jaxagent_report')
  def report(self, data, carry):
    seed = data['seed']
    data = self._filter_data(data)
    with embodied.timer.section('jit_report'):
      with self.train_lock:
        mets, carry = self._report(self.params, data, carry, seed)
        mets = self._take_mets(fetch_async(mets))
    return mets, carry

  def dataset(self, generator):
    def transform(data):
      return {
          **jax.device_put(data, self.train_sharded),
          'seed': self._next_seeds(self.train_sharded)}
    return embodied.Prefetch(generator, transform)

  @embodied.timer.section('jaxagent_save')
  def save(self):
    with self.train_lock:
      return jax.device_get(self.params)

  @embodied.timer.section('jaxagent_load')
  def load(self, state):
    with self.train_lock:
      with self.policy_lock:
        chex.assert_trees_all_equal_shapes(self.params, state)
        jax.tree.map(lambda x: x.delete(), self.params)
        jax.tree.map(lambda x: x.delete(), self.policy_params)
        self.params = jax.device_put(state, self.train_mirrored)
        self.policy_params = jax.device_put(
            {k: self.params[k].copy() for k in self.policy_keys},
            self.policy_mirrored)

  def _setup(self):
    try:
      import tensorflow as tf
      tf.config.set_visible_devices([], 'GPU')
      tf.config.set_visible_devices([], 'TPU')
    except Exception as e:
      print('Could not disable TensorFlow devices:', e)
    if not self.jaxcfg.prealloc:
      os.environ['XLA_PYTHON_CLIENT_PREALLOCATE'] = 'false'
    xla_flags = []
    if self.jaxcfg.logical_cpus:
      count = self.jaxcfg.logical_cpus
      xla_flags.append(f'--xla_force_host_platform_device_count={count}')
    if self.jaxcfg.nvidia_flags:
      xla_flags.append('--xla_gpu_enable_latency_hiding_scheduler=true')
      xla_flags.append('--xla_gpu_enable_async_all_gather=true')
      xla_flags.append('--xla_gpu_enable_async_reduce_scatter=true')
      xla_flags.append('--xla_gpu_enable_triton_gemm=false')
      os.environ['CUDA_DEVICE_MAX_CONNECTIONS'] = '1'
      os.environ['NCCL_IB_SL'] = '1'
      os.environ['NCCL_NVLS_ENABLE'] = '0'
      os.environ['CUDA_MODULE_LOADING'] = 'EAGER'
    if self.jaxcfg.xla_dump:
      outdir = embodied.Path(self.config.logdir) / 'xla_dump'
      outdir.mkdir()
      xla_flags.append(f'--xla_dump_to={outdir}')
      xla_flags.append('--xla_dump_hlo_as_long_text')
    if xla_flags:
      os.environ['XLA_FLAGS'] = ' '.join(xla_flags)
    jax.config.update('jax_platform_name', self.jaxcfg.platform)
    jax.config.update('jax_disable_jit', not self.jaxcfg.jit)
    if self.jaxcfg.transfer_guard:
      jax.config.update('jax_transfer_guard', 'disallow')
    if self.jaxcfg.platform == 'cpu':
      jax.config.update('jax_disable_most_optimizations', self.jaxcfg.debug)
    jaxutils.COMPUTE_DTYPE = getattr(jnp, self.jaxcfg.compute_dtype)
    jaxutils.PARAM_DTYPE = getattr(jnp, self.jaxcfg.param_dtype)

  def _transform(self):

    def init_policy(params, seed, batch_size):
      pure = nj.pure(self.agent.init_policy)
      return pure(params, batch_size, seed=seed)[1]

    def policy(params, obs, carry, seed, mode):
      pure = nj.pure(self.agent.policy)
      return pure(params, obs, carry, mode, seed=seed)[1]

    def init_train(params, seed, batch_size):
      pure = nj.pure(self.agent.init_train)
      return pure(params, batch_size, seed=seed)[1]

    def train(alloc, donated, data, carry, seed):
      pure = nj.pure(self.agent.train)
      combined = {**alloc, **donated}
      params, (outs, carry, mets) = pure(combined, data, carry, seed=seed)
      mets = {k: v[None] for k, v in mets.items()}
      return params, outs, carry, mets

    def init_report(params, seed, batch_size):
      pure = nj.pure(self.agent.init_report)
      return pure(params, batch_size, seed=seed)[1]

    def report(params, data, carry, seed):
      pure = nj.pure(self.agent.report)
      _, (mets, carry) = pure(params, data, carry, seed=seed)
      mets = {k: v[None] for k, v in mets.items()}
      return mets, carry

    from jax.experimental.shard_map import shard_map
    s = jax.sharding.PartitionSpec('i')  # sharded
    m = jax.sharding.PartitionSpec()     # mirrored
    if len(self.policy_mesh.devices) > 1:
      init_policy = lambda params, seed, batch_size, fn=init_policy: shard_map(
          lambda params, seed: fn(params, seed, batch_size),
          self.policy_mesh, (m, s), s, check_rep=False)(params, seed)
      policy = lambda params, obs, carry, seed, mode, fn=policy: shard_map(
          lambda params, obs, carry, seed: fn(params, obs, carry, seed, mode),
          self.policy_mesh, (m, s, s, s), s, check_rep=False)(
              params, obs, carry, seed)
    if len(self.train_mesh.devices) > 1:
      init_train = lambda params, seed, batch_size, fn=init_train: shard_map(
          lambda params, seed: fn(params, seed, batch_size),
          self.train_mesh, (m, s), s, check_rep=False)(params, seed)
      train = shard_map(
          train, self.train_mesh,
          (m, m, s, s, s), (m, s, s, m), check_rep=False)
      init_report = lambda params, seed, batch_size, fn=init_report: shard_map(
          lambda params, seed: fn(params, seed, batch_size),
          self.train_mesh, (m, s), s, check_rep=False)(params, seed)
      report = shard_map(
          report, self.train_mesh,
          (m, s, s, s), (m, s), check_rep=False)

    ps, pm = self.policy_sharded, self.policy_mirrored
    self._init_policy = jax.jit(
        init_policy, (pm, ps), ps, static_argnames=['batch_size'])
    self._policy = jax.jit(
        policy, (pm, ps, ps, ps), ps, static_argnames=['mode'])

    ts, tm = self.train_sharded, self.train_mirrored
    self._init_train = jax.jit(
        init_train, (tm, ts), ts, static_argnames=['batch_size'])
    self._train = jax.jit(
        train, (tm, tm, ts, ts, ts), (tm, ts, ts, tm), donate_argnums=[1])
    self._init_report = jax.jit(
        init_report, (tm, ts), ts, static_argnames=['batch_size'])
    self._report = jax.jit(
        report, (tm, ts, ts, ts), (tm, ts))

  def _take_mets(self, mets):
    mets = jax.tree.map(lambda x: x.__array__(), mets)
    mets = {k: v[0] for k, v in mets.items()}
    mets = jax.tree.map(
        lambda x: np.float32(x) if x.dtype == jnp.bfloat16 else x, mets)
    return mets

  def _take_outs(self, outs):
    outs = jax.tree.map(lambda x: x.__array__(), outs)
    outs = jax.tree.map(
        lambda x: np.float32(x) if x.dtype == jnp.bfloat16 else x, outs)
    return outs

  def _init_params(self, obs_space, act_space):
    B, T = self.config.batch_size, self.config.batch_length
    seed = jax.device_put(np.array([self.config.seed, 0], np.uint32))
    data = jax.device_put(self._dummy_batch(self.spaces, (B, T)))
    params = nj.init(self.agent.init_train, static_argnums=[1])(
        {}, B, seed=seed)
    _, carry = jax.jit(nj.pure(self.agent.init_train), static_argnums=[1])(
        params, B, seed=seed)
    params = nj.init(self.agent.train)(params, data, carry, seed=seed)
    return jax.device_put(params, self.train_mirrored)

  def _next_seeds(self, sharding):
    shape = [2 * x for x in sharding.mesh.devices.shape]
    seeds = self.rng.integers(0, np.iinfo(np.uint32).max, shape, np.uint32)
    return jax.device_put(seeds, sharding)

  def _filter_data(self, data):
    return {k: v for k, v in data.items() if k in self.keys}

  def _dummy_batch(self, spaces, batch_dims):
    spaces = [(k, v) for k, v in spaces.items()]
    data = {k: np.zeros(v.shape, v.dtype) for k, v in spaces}
    data = self._filter_data(data)
    for dim in reversed(batch_dims):
      data = {k: np.repeat(v[None], dim, axis=0) for k, v in data.items()}
    return data

  def _lower_train(self):
    B = self.config.batch_size
    T = self.config.batch_length
    data = self._dummy_batch(self.spaces, (B, T))
    data = jax.device_put(data, self.train_sharded)
    seed = self._next_seeds(self.train_sharded)
    carry = self.init_train(self.config.batch_size)
    allo = {k: v for k, v in self.params.items() if k in self.policy_keys}
    dona = {k: v for k, v in self.params.items() if k not in self.policy_keys}
    self._train = self._train.lower(allo, dona, data, carry, seed)

  def _lower_report(self):
    B = self.config.batch_size
    T = self.config.batch_length_eval
    data = self._dummy_batch(self.spaces, (B, T))
    data = jax.device_put(data, self.train_sharded)
    seed = self._next_seeds(self.train_sharded)
    carry = self.init_report(self.config.batch_size)
    self._report = self._report.lower(self.params, data, carry, seed)


def fetch_async(value):
  with jax._src.config.explicit_device_get_scope():
    [x.copy_to_host_async() for x in jax.tree_util.tree_leaves(value)]
  return value

</dreamerv3/jaxagent.py>

<dreamerv3/jaxutils.py>
import collections
import re

import jax
import jax.numpy as jnp
import numpy as np
import optax
from jax.experimental import checkify
from tensorflow_probability.substrates import jax as tfp

from . import ninjax as nj

tfd = tfp.distributions
tfb = tfp.bijectors
treemap = jax.tree_util.tree_map
sg = lambda x: treemap(jax.lax.stop_gradient, x)
f32 = jnp.float32
i32 = jnp.int32
COMPUTE_DTYPE = f32
PARAM_DTYPE = f32
ENABLE_CHECKS = False


def cast_to_compute(values):
  return treemap(
      lambda x: x if x.dtype == COMPUTE_DTYPE else x.astype(COMPUTE_DTYPE),
      values)


def get_param_dtype():
  return PARAM_DTYPE


def check(predicate, message, **kwargs):
  if ENABLE_CHECKS:
    checkify.check(predicate, message, **kwargs)


def parallel():
  try:
    jax.lax.axis_index('i')
    return True
  except NameError:
    return False


def scan(fun, carry, xs, unroll=False, axis=0):
  unroll = jax.tree_util.tree_leaves(xs)[0].shape[axis] if unroll else 1
  return nj.scan(fun, carry, xs, False, unroll, axis)


def tensorstats(tensor, prefix=None):
  assert tensor.size > 0, tensor.shape
  assert jnp.issubdtype(tensor.dtype, jnp.floating), tensor.dtype
  tensor = tensor.astype(f32)  # To avoid overflows.
  metrics = {
      'mean': tensor.mean(),
      'std': tensor.std(),
      'mag': jnp.abs(tensor).mean(),
      'min': tensor.min(),
      'max': tensor.max(),
      'dist': subsample(tensor),
  }
  if prefix:
    metrics = {f'{prefix}/{k}': v for k, v in metrics.items()}
  return metrics


def subsample(values, amount=1024):
  values = values.flatten()
  if len(values) > amount:
    values = jax.random.permutation(nj.seed(), values)[:amount]
  return values


def symlog(x):
  return jnp.sign(x) * jnp.log1p(jnp.abs(x))


def symexp(x):
  return jnp.sign(x) * jnp.expm1(jnp.abs(x))


def switch(pred, lhs, rhs):
  def fn(lhs, rhs):
    assert lhs.shape == rhs.shape, (pred.shape, lhs.shape, rhs.shape)
    mask = pred
    while len(mask.shape) < len(lhs.shape):
      mask = mask[..., None]
    return jnp.where(mask, lhs, rhs)
  return treemap(fn, lhs, rhs)


def reset(xs, reset):
  def fn(x):
    mask = reset
    while len(mask.shape) < len(x.shape):
      mask = mask[..., None]
    return x * (1 - mask.astype(x.dtype))
  return treemap(fn, xs)


class OneHotDist(tfd.OneHotCategorical):

  def __init__(self, logits=None, probs=None, dtype=f32):
    super().__init__(logits, probs, dtype)

  @classmethod
  def _parameter_properties(cls, dtype, num_classes=None):
     return super()._parameter_properties(dtype)

  def sample(self, sample_shape=(), seed=None):
    sample = sg(super().sample(sample_shape, seed))
    probs = self._pad(super().probs_parameter(), sample.shape)
    sample = sg(sample) + (probs - sg(probs)).astype(sample.dtype)
    return sample

  def _pad(self, tensor, shape):
    while len(tensor.shape) < len(shape):
      tensor = tensor[None]
    return tensor


class MSEDist:

  def __init__(self, mode, dims, agg='sum'):
    self._mode = mode
    self._dims = tuple([-x for x in range(1, dims + 1)])
    self._agg = agg
    self.batch_shape = mode.shape[:len(mode.shape) - dims]
    self.event_shape = mode.shape[len(mode.shape) - dims:]

  def mode(self):
    return self._mode

  def mean(self):
    return self._mode

  def log_prob(self, value):
    assert self._mode.shape == value.shape, (self._mode.shape, value.shape)
    distance = ((self._mode - value) ** 2)
    if self._agg == 'mean':
      loss = distance.mean(self._dims)
    elif self._agg == 'sum':
      loss = distance.sum(self._dims)
    else:
      raise NotImplementedError(self._agg)
    return -loss


class HuberDist:

  def __init__(self, mode, dims, agg='sum'):
    self._mode = mode
    self._dims = tuple([-x for x in range(1, dims + 1)])
    self._agg = agg
    self.batch_shape = mode.shape[:len(mode.shape) - dims]
    self.event_shape = mode.shape[len(mode.shape) - dims:]

  def mode(self):
    return self._mode

  def mean(self):
    return self._mode

  def log_prob(self, value):
    assert self._mode.shape == value.shape, (self._mode.shape, value.shape)
    distance = ((self._mode - value) ** 2)
    distance = jnp.sqrt(1 + distance) - 1
    if self._agg == 'mean':
      loss = distance.mean(self._dims)
    elif self._agg == 'sum':
      loss = distance.sum(self._dims)
    else:
      raise NotImplementedError(self._agg)
    return -loss


class TransformedMseDist:

  def __init__(self, mode, dims, fwd, bwd, agg='sum', tol=1e-8):
    self._mode = mode
    self._dims = tuple([-x for x in range(1, dims + 1)])
    self._fwd = fwd
    self._bwd = bwd
    self._agg = agg
    self._tol = tol
    self.batch_shape = mode.shape[:len(mode.shape) - dims]
    self.event_shape = mode.shape[len(mode.shape) - dims:]

  def mode(self):
    return self._bwd(self._mode)

  def mean(self):
    return self._bwd(self._mode)

  def log_prob(self, value):
    assert self._mode.shape == value.shape, (self._mode.shape, value.shape)
    distance = (self._mode - self._fwd(value)) ** 2
    distance = jnp.where(distance < self._tol, 0, distance)
    if self._agg == 'mean':
      loss = distance.mean(self._dims)
    elif self._agg == 'sum':
      loss = distance.sum(self._dims)
    else:
      raise NotImplementedError(self._agg)
    return -loss


class TwoHotDist:

  def __init__(
      self, logits, bins, dims=0, transfwd=None, transbwd=None):
    assert logits.shape[-1] == len(bins), (logits.shape, len(bins))
    assert logits.dtype == f32, logits.dtype
    assert bins.dtype == f32, bins.dtype
    self.logits = logits
    self.probs = jax.nn.softmax(logits)
    self.dims = tuple([-x for x in range(1, dims + 1)])
    self.bins = jnp.array(bins)
    self.transfwd = transfwd or (lambda x: x)
    self.transbwd = transbwd or (lambda x: x)
    self.batch_shape = logits.shape[:len(logits.shape) - dims - 1]
    self.event_shape = logits.shape[len(logits.shape) - dims: -1]

  def mean(self):
    # The naive implementation results in a non-zero result even if the bins
    # are symmetric and the probabilities uniform, because the sum operation
    # goes left to right, accumulating numerical errors. Instead, we use a
    # symmetric sum to ensure that the predicted rewards and values are
    # actually zero at initialization.
    # return self.transbwd((self.probs * self.bins).sum(-1))
    n = self.logits.shape[-1]
    if n % 2 == 1:
      m = (n - 1) // 2
      p1 = self.probs[..., :m]
      p2 = self.probs[..., m: m + 1]
      p3 = self.probs[..., m + 1:]
      b1 = self.bins[..., :m]
      b2 = self.bins[..., m: m + 1]
      b3 = self.bins[..., m + 1:]
      wavg = (p2 * b2).sum(-1) + ((p1 * b1)[..., ::-1] + (p3 * b3)).sum(-1)
      return self.transbwd(wavg)
    else:
      p1 = self.probs[..., :n // 2]
      p2 = self.probs[..., n // 2:]
      b1 = self.bins[..., :n // 2]
      b2 = self.bins[..., n // 2:]
      wavg = ((p1 * b1)[..., ::-1] + (p2 * b2)).sum(-1)
      return self.transbwd(wavg)

  def mode(self):
    return self.transbwd((self.probs * self.bins).sum(-1))

  def log_prob(self, x):
    assert x.dtype == f32, x.dtype
    x = self.transfwd(x)
    below = (self.bins <= x[..., None]).astype(i32).sum(-1) - 1
    above = len(self.bins) - (
        self.bins > x[..., None]).astype(i32).sum(-1)
    below = jnp.clip(below, 0, len(self.bins) - 1)
    above = jnp.clip(above, 0, len(self.bins) - 1)
    equal = (below == above)
    dist_to_below = jnp.where(equal, 1, jnp.abs(self.bins[below] - x))
    dist_to_above = jnp.where(equal, 1, jnp.abs(self.bins[above] - x))
    total = dist_to_below + dist_to_above
    weight_below = dist_to_above / total
    weight_above = dist_to_below / total
    target = (
        jax.nn.one_hot(below, len(self.bins)) * weight_below[..., None] +
        jax.nn.one_hot(above, len(self.bins)) * weight_above[..., None])
    log_pred = self.logits - jax.scipy.special.logsumexp(
        self.logits, -1, keepdims=True)
    return (target * log_pred).sum(-1).sum(self.dims)


def video_grid(video):
  B, T, H, W, C = video.shape
  return video.transpose((1, 2, 0, 3, 4)).reshape((T, H, B * W, C))


def balance_stats(dist, target, thres):
  # Values are NaN when there are no positives or negatives in the current
  # batch, which means they will be ignored when aggregating metrics via
  # np.nanmean() later, as they should.
  pos = (target.astype(f32) > thres).astype(f32)
  neg = (target.astype(f32) <= thres).astype(f32)
  pred = (dist.mean().astype(f32) > thres).astype(f32)
  loss = -dist.log_prob(target)
  return dict(
      pos_loss=(loss * pos).sum() / pos.sum(),
      neg_loss=(loss * neg).sum() / neg.sum(),
      pos_acc=(pred * pos).sum() / pos.sum(),
      neg_acc=((1 - pred) * neg).sum() / neg.sum(),
      rate=pos.mean(),
      avg=target.astype(f32).mean(),
      pred=dist.mean().astype(f32).mean(),
  )


class Moments(nj.Module):

  rate: float = 0.01
  limit: float = 1e-8
  perclo: float = 5.0
  perchi: float = 95.0

  def __init__(self, impl='mean_std'):
    self.impl = impl
    if self.impl == False:
      pass
    elif self.impl == 'mean_std':
      self.mean = nj.Variable(jnp.zeros, (), f32, name='mean')
      self.sqrs = nj.Variable(jnp.zeros, (), f32, name='sqrs')
      self.corr = nj.Variable(jnp.zeros, (), f32, name='corr')
    elif self.impl == 'min_max':
      self.low = nj.Variable(jnp.zeros, (), f32, name='low')
      self.high = nj.Variable(jnp.zeros, (), f32, name='high')
    elif self.impl == 'perc':
      self.low = nj.Variable(jnp.zeros, (), f32, name='low')
      self.high = nj.Variable(jnp.zeros, (), f32, name='high')
    elif self.impl == 'perc_corr':
      self.low = nj.Variable(jnp.zeros, (), f32, name='low')
      self.high = nj.Variable(jnp.zeros, (), f32, name='high')
      self.corr = nj.Variable(jnp.zeros, (), f32, name='corr')
    else:
      raise NotImplementedError(self.impl)

  def __call__(self, x, update=True):
    update and self.update(x)
    return self.stats()

  def update(self, x):
    if parallel():
      mean = lambda x: jax.lax.pmean(x.mean(), 'i')
      min_ = lambda x: jax.lax.pmin(x.min(), 'i')
      max_ = lambda x: jax.lax.pmax(x.max(), 'i')
      per = lambda x, q: jnp.percentile(jax.lax.all_gather(x, 'i'), q)
    else:
      mean = jnp.mean
      min_ = jnp.min
      max_ = jnp.max
      per = jnp.percentile
    x = sg(x.astype(f32))
    m = self.rate
    if self.impl == False:
      pass
    elif self.impl == 'mean_std':
      self.mean.write((1 - m) * self.mean.read() + m * mean(x))
      self.sqrs.write((1 - m) * self.sqrs.read() + m * mean(x * x))
      self.corr.write((1 - m) * self.corr.read() + m * 1.0)
    elif self.impl == 'min_max':
      low, high = min_(x), max_(x)
      self.low.write((1 - m) * jnp.minimum(self.low.read(), low) + m * low)
      self.high.write((1 - m) * jnp.maximum(self.high.read(), high) + m * high)
    elif self.impl == 'perc':
      low, high = per(x, self.perclo), per(x, self.perchi)
      self.low.write((1 - m) * self.low.read() + m * low)
      self.high.write((1 - m) * self.high.read() + m * high)
    elif self.impl == 'perc_corr':
      low, high = per(x, self.perclo), per(x, self.perchi)
      self.low.write((1 - m) * self.low.read() + m * low)
      self.high.write((1 - m) * self.high.read() + m * high)
      self.corr.write((1 - m) * self.corr.read() + m * 1.0)
    else:
      raise NotImplementedError(self.impl)

  def stats(self):
    if self.impl == False:
      return 0.0, 1.0
    elif self.impl == 'mean_std':
      corr = jnp.maximum(self.rate, self.corr.read())
      mean = self.mean.read() / corr
      std = jnp.sqrt(jax.nn.relu(self.sqrs.read() / corr - mean ** 2))
      std = jnp.maximum(self.limit, std)
      return sg(mean), sg(std)
    elif self.impl == 'min_max':
      offset = self.low.read()
      span = self.high.read() - self.low.read()
      span = jnp.maximum(self.limit, span)
      return sg(offset), sg(span)
    elif self.impl == 'perc':
      offset = self.low.read()
      span = self.high.read() - self.low.read()
      span = jnp.maximum(self.limit, span)
      return sg(offset), sg(span)
    elif self.impl == 'perc_corr':
      corr = jnp.maximum(self.rate, self.corr.read())
      lo = self.low.read() / corr
      hi = self.high.read() / corr
      span = hi - lo
      span = jnp.maximum(self.limit, span)
      return sg(lo), sg(span)
    else:
      raise NotImplementedError(self.impl)


class Optimizer(nj.Module):

  # Normalization
  scaler: str = 'adam'
  eps: float = 1e-7
  beta1: float = 0.9
  beta2: float = 0.999

  # Learning rate
  warmup: int = 1000
  anneal: int = 0
  schedule: str = 'constant'

  # Regularization
  wd: float = 0.0
  wd_pattern: str = r'/kernel$'

  # Clipping
  pmin: float = 1e-3
  globclip: float = 0.0
  agc: float = 0.0

  # Smoothing
  momentum: bool = False
  nesterov: bool = False

  # Metrics
  details: bool = False

  def __init__(self, lr):
    self.lr = lr
    chain = []

    if self.globclip:
      chain.append(optax.clip_by_global_norm(self.globclip))
    if self.agc:
      chain.append(scale_by_agc(self.agc, self.pmin))

    if self.scaler == 'adam':
      chain.append(optax.scale_by_adam(self.beta1, self.beta2, self.eps))
    elif self.scaler == 'rms':
      chain.append(scale_by_rms(self.beta2, self.eps))
    else:
      raise NotImplementedError(self.scaler)

    if self.momentum:
      chain.append(scale_by_momentum(self.beta1, self.nesterov))

    if self.wd:
      assert not self.wd_pattern[0].isnumeric(), self.wd_pattern
      pattern = re.compile(self.wd_pattern)
      wdmaskfn = lambda params: {k: bool(pattern.search(k)) for k in params}
      chain.append(optax.add_decayed_weights(self.wd, wdmaskfn))

    chain.append(optax.scale(-self.lr))

    self.chain = optax.chain(*chain)
    self.step = nj.Variable(jnp.array, 0, i32, name='step')
    self.scaling = (COMPUTE_DTYPE == jnp.float16)
    if self.scaling:
      self.chain = optax.apply_if_finite(
          self.chain, max_consecutive_errors=1000)
      self.grad_scale = nj.Variable(jnp.array, 1e4, f32, name='grad_scale')
      self.good_steps = nj.Variable(jnp.array, 0, i32, name='good_steps')
    self.once = True

  def __call__(self, modules, lossfn, *args, has_aux=False, **kwargs):
    def wrapped(*args, **kwargs):
      outs = lossfn(*args, **kwargs)
      loss, aux = outs if has_aux else (outs, None)
      assert loss.dtype == f32, (self.name, loss.dtype)
      assert loss.shape == (), (self.name, loss.shape)
      if self.scaling:
        loss *= sg(self.grad_scale.read())
      return loss, aux

    metrics = {}
    loss, params, grads, aux = nj.grad(
        wrapped, modules, has_aux=True)(*args, **kwargs)
    if self.scaling:
      loss /= self.grad_scale.read()
    if not isinstance(modules, (list, tuple)):
      modules = [modules]
    counts = {k: int(np.prod(v.shape)) for k, v in params.items()}
    if self.once:
      self.once = False
      prefs = []
      for key in counts:
        parts = key.split('/')
        prefs += ['/'.join(parts[: i + 1]) for i in range(min(len(parts), 2))]
      subcounts = {
          prefix: sum(v for k, v in counts.items() if k.startswith(prefix))
          for prefix in set(prefs)}
      print(f'Optimizer {self.name} has {sum(counts.values()):,} variables:')
      for prefix, count in sorted(subcounts.items(), key=lambda x: -x[1]):
        print(f'{count:>14,} {prefix}')

    if parallel():
      grads = treemap(lambda x: jax.lax.pmean(x, 'i'), grads)
    if self.scaling:
      invscale = 1.0 / self.grad_scale.read()
      grads = treemap(lambda x: x * invscale, grads)
    optstate = self.get('state', self.chain.init, params)
    updates, optstate = self.chain.update(grads, optstate, params)
    self.put('state', optstate)

    if self.details:
      metrics.update(self._detailed_stats(optstate, params, updates, grads))

    scale = 1
    step = self.step.read().astype(f32)
    if self.warmup > 0:
      scale *= jnp.clip(step / self.warmup, 0, 1)
    assert self.schedule == 'constant' or self.anneal > self.warmup
    prog = jnp.clip((step - self.warmup) / (self.anneal - self.warmup), 0, 1)
    if self.schedule == 'constant':
      pass
    elif self.schedule == 'linear':
      scale *= 1 - prog
    elif self.schedule == 'cosine':
      scale *= 0.5 * (1 + jnp.cos(jnp.pi * prog))
    else:
      raise NotImplementedError(self.schedule)
    updates = treemap(lambda x: x * scale, updates)

    nj.context().update(optax.apply_updates(params, updates))
    grad_norm = optax.global_norm(grads)
    update_norm = optax.global_norm(updates)
    param_norm = optax.global_norm([x.find() for x in modules])
    isfin = jnp.isfinite
    if self.scaling:
      self._update_scale(grads, jnp.isfinite(grad_norm))
      metrics['grad_scale'] = self.grad_scale.read()
      metrics['grad_overflow'] = (~jnp.isfinite(grad_norm)).astype(f32)
      grad_norm = jnp.where(jnp.isfinite(grad_norm), grad_norm, jnp.nan)
      self.step.write(self.step.read() + isfin(grad_norm).astype(i32))
    else:
      check(isfin(grad_norm), f'{self.path} grad norm: {{x}}', x=grad_norm)
      self.step.write(self.step.read() + 1)
    check(isfin(update_norm), f'{self.path} updates: {{x}}', x=update_norm)
    check(isfin(param_norm), f'{self.path} params: {{x}}', x=param_norm)

    metrics['loss'] = loss.mean()
    metrics['grad_norm'] = grad_norm
    metrics['update_norm'] = update_norm
    metrics['param_norm'] = param_norm
    metrics['grad_steps'] = self.step.read()
    metrics['param_count'] = jnp.array(sum(counts.values()))
    metrics = {f'{self.name}_{k}': v for k, v in metrics.items()}
    return (metrics, aux) if has_aux else metrics

  def _update_scale(self, grads, finite):
    keep = (finite & (self.good_steps.read() < 1000))
    incr = (finite & (self.good_steps.read() >= 1000))
    decr = ~finite
    self.good_steps.write(
        keep.astype(i32) * (self.good_steps.read() + 1))
    self.grad_scale.write(jnp.clip(
        keep.astype(f32) * self.grad_scale.read() +
        incr.astype(f32) * self.grad_scale.read() * 2 +
        decr.astype(f32) * self.grad_scale.read() / 2,
        1e-4, 1e5))
    return finite

  def _detailed_stats(self, optstate, params, updates, grads):
    groups = {
        'all': r'.*',
        'enc': r'/enc/.*',
        'dec': r'/dec/.*',
        'dyn': r'/dyn/.*',
        'con': r'/con/.*',
        'rew': r'/rew/.*',
        'actor': r'/actor/.*',
        'critic': r'/critic/.*',
        'out': r'/out/kernel$',
        'repr': r'/repr_logit/kernel$',
        'prior': r'/prior_logit/kernel$',
        'offset': r'/offset$',
        'scale': r'/scale$',
    }
    metrics = {}
    stddev = None
    for state in getattr(optstate, 'inner_state', optstate):
      if isinstance(state, optax.ScaleByAdamState):
        corr = 1 / (1 - 0.999 ** state.count)
        stddev = treemap(lambda x: jnp.sqrt(x * corr), state.nu)
    for name, pattern in groups.items():
      keys = [k for k in params if re.search(pattern, k)]
      ps = [params[k] for k in keys]
      us = [updates[k] for k in keys]
      gs = [grads[k] for k in keys]
      if not ps:
        continue
      metrics.update({f'{k}/{name}': v for k, v in dict(
          param_count=jnp.array(np.sum([np.prod(x.shape) for x in ps])),
          param_abs_max=jnp.stack([jnp.abs(x).max() for x in ps]).max(),
          param_abs_mean=jnp.stack([jnp.abs(x).mean() for x in ps]).mean(),
          param_norm=optax.global_norm(ps),
          update_abs_max=jnp.stack([jnp.abs(x).max() for x in us]).max(),
          update_abs_mean=jnp.stack([jnp.abs(x).mean() for x in us]).mean(),
          update_norm=optax.global_norm(us),
          grad_norm=optax.global_norm(gs),
      ).items()})
      if stddev is not None:
        sc = [stddev[k] for k in keys]
        pr = [
            jnp.abs(x) / jnp.maximum(1e-3, jnp.abs(y)) for x, y in zip(us, ps)]
        metrics.update({f'{k}/{name}': v for k, v in dict(
            scale_abs_max=jnp.stack([jnp.abs(x).max() for x in sc]).max(),
            scale_abs_min=jnp.stack([jnp.abs(x).min() for x in sc]).min(),
            scale_abs_mean=jnp.stack([jnp.abs(x).mean() for x in sc]).mean(),
            prop_max=jnp.stack([x.max() for x in pr]).max(),
            prop_min=jnp.stack([x.min() for x in pr]).min(),
            prop_mean=jnp.stack([x.mean() for x in pr]).mean(),
        ).items()})
    return metrics


def scale_by_agc(clip=0.03, pmin=1e-3):

  def init_fn(params):
    return ()

  def update_fn(updates, state, params=None):
    def fn(param, update):
      unorm = jnp.linalg.norm(update.flatten(), 2)
      pnorm = jnp.linalg.norm(param.flatten(), 2)
      upper = clip * jnp.maximum(pmin, pnorm)
      return update * (1 / jnp.maximum(1.0, unorm / upper))
    updates = treemap(fn, params, updates)
    return updates, ()

  return optax.GradientTransformation(init_fn, update_fn)


def scale_by_rms(beta=0.999, eps=1e-8):

  def init_fn(params):
    nu = treemap(lambda t: jnp.zeros_like(t, f32), params)
    step = jnp.zeros((), i32)
    return (step, nu)

  def update_fn(updates, state, params=None):
    step, nu = state
    step = optax.safe_int32_increment(step)
    nu = treemap(lambda v, u: beta * v + (1 - beta) * (u * u), nu, updates)
    nu_hat = optax.bias_correction(nu, beta, step)
    updates = treemap(lambda u, v: u / (jnp.sqrt(v) + eps), updates, nu_hat)
    return updates, (step, nu)

  return optax.GradientTransformation(init_fn, update_fn)


def scale_by_momentum(beta=0.9, nesterov=False):

  def init_fn(params):
    mu = treemap(lambda t: jnp.zeros_like(t, f32), params)
    step = jnp.zeros((), i32)
    return (step, mu)

  def update_fn(updates, state, params=None):
    step, mu = state
    step = optax.safe_int32_increment(step)
    mu = optax.update_moment(updates, mu, beta, 1)
    if nesterov:
      mu_nesterov = optax.update_moment(updates, mu, beta, 1)
      mu_hat = optax.bias_correction(mu_nesterov, beta, step)
    else:
      mu_hat = optax.bias_correction(mu, beta, step)
    return mu_hat, (step, mu)

  return optax.GradientTransformation(init_fn, update_fn)


def concat_dict(mapping, batch_shape=None):
  tensors = [v for _, v in sorted(mapping.items(), key=lambda x: x[0])]
  if batch_shape is not None:
    tensors = [x.reshape((*batch_shape, -1)) for x in tensors]
  return jnp.concatenate(tensors, -1)


def onehot_dict(mapping, spaces):
  result = {}
  for key, value in mapping.items():
    space = spaces[key]
    if space.discrete:
      value = jax.nn.one_hot(value, space.classes)
    result[key] = value
  return result


class SlowUpdater(nj.Module):

  def __init__(self, src, dst, fraction=1.0, period=1):
    self.src = src
    self.dst = dst
    self.fraction = fraction
    self.period = period
    self.updates = nj.Variable(jnp.zeros, (), i32, name='updates')

  def __call__(self):
    assert self.src.find()
    updates = self.updates.read()
    need_init = (updates == 0).astype(f32)
    need_update = (updates % self.period == 0).astype(f32)
    mix = jnp.clip(1.0 * need_init + self.fraction * need_update, 0, 1)
    params = {
        k.replace(f'/{self.src.name}/', f'/{self.dst.name}/'): v
        for k, v in self.src.find().items()}
    ema = treemap(
        lambda s, d: mix * s + (1 - mix) * d,
        params, self.dst.find())
    for name, param in ema.items():
      assert param.dtype == jnp.float32, (
          f'EMA of {name} should be float32 not {param.dtype}')
    self.dst.put(ema)
    self.updates.write(updates + 1)

</dreamerv3/jaxutils.py>

<dreamerv3/main.py>
import importlib
import os
import pathlib
import sys
import warnings
from functools import partial as bind

directory = pathlib.Path(__file__).resolve().parent
sys.path.insert(0, str(directory.parent))
sys.path.insert(0, str(directory.parent.parent))
__package__ = directory.name

warnings.filterwarnings('ignore', '.*box bound precision lowered.*')
warnings.filterwarnings('ignore', '.*using stateful random seeds*')
warnings.filterwarnings('ignore', '.*is a deprecated alias for.*')
warnings.filterwarnings('ignore', '.*truncated to dtype int32.*')

import embodied
from embodied import wrappers


def main(argv=None):

  embodied.print(r"---  ___                           __   ______ ---")
  embodied.print(r"--- |   \ _ _ ___ __ _ _ __  ___ _ \ \ / /__ / ---")
  embodied.print(r"--- | |) | '_/ -_) _` | '  \/ -_) '/\ V / |_ \ ---")
  embodied.print(r"--- |___/|_| \___\__,_|_|_|_\___|_|  \_/ |___/ ---")

  from . import agent as agt
  parsed, other = embodied.Flags(configs=['defaults']).parse_known(argv)
  config = embodied.Config(agt.Agent.configs['defaults'])
  for name in parsed.configs:
    config = config.update(agt.Agent.configs[name])
  config = embodied.Flags(config).parse(other)
  config = config.update(
      logdir=config.logdir.format(timestamp=embodied.timestamp()),
      replay_length=config.replay_length or config.batch_length,
      replay_length_eval=config.replay_length_eval or config.batch_length_eval)
  args = embodied.Config(
      **config.run,
      logdir=config.logdir,
      batch_size=config.batch_size,
      batch_length=config.batch_length,
      batch_length_eval=config.batch_length_eval,
      replay_length=config.replay_length,
      replay_length_eval=config.replay_length_eval,
      replay_context=config.replay_context)
  print('Run script:', args.script)
  print('Logdir:', args.logdir)

  logdir = embodied.Path(args.logdir)
  if not args.script.endswith(('_env', '_replay')):
    logdir.mkdir()
    config.save(logdir / 'config.yaml')

  def init():
    embodied.timer.global_timer.enabled = args.timer
  embodied.distr.Process.initializers.append(init)
  init()

  if args.script == 'train':
    embodied.run.train(
        bind(make_agent, config),
        bind(make_replay, config, 'replay'),
        bind(make_env, config),
        bind(make_logger, config), args)

  elif args.script == 'train_eval':
    embodied.run.train_eval(
        bind(make_agent, config),
        bind(make_replay, config, 'replay'),
        bind(make_replay, config, 'eval_replay', is_eval=True),
        bind(make_env, config),
        bind(make_env, config),
        bind(make_logger, config), args)

  elif args.script == 'train_holdout':
    assert config.eval_dir
    embodied.run.train_holdout(
        bind(make_agent, config),
        bind(make_replay, config, 'replay'),
        bind(make_replay, config, config.eval_dir),
        bind(make_env, config),
        bind(make_logger, config), args)

  elif args.script == 'eval_only':
    embodied.run.eval_only(
        bind(make_agent, config),
        bind(make_env, config),
        bind(make_logger, config), args)

  elif args.script == 'parallel':
    embodied.run.parallel.combined(
        bind(make_agent, config),
        bind(make_replay, config, 'replay', rate_limit=True),
        bind(make_env, config),
        bind(make_logger, config), args)

  elif args.script == 'parallel_env':
    envid = args.env_replica
    if envid < 0:
      envid = int(os.environ['JOB_COMPLETION_INDEX'])
    embodied.run.parallel.env(
        bind(make_env, config), envid, args, False)

  elif args.script == 'parallel_replay':
    embodied.run.parallel.replay(
        bind(make_replay, config, 'replay', rate_limit=True), args)

  elif args.script == 'parallel_with_eval':
    embodied.run.parallel_with_eval.combined(
        bind(make_agent, config),
        bind(make_replay, config, 'replay', rate_limit=True),
        bind(make_replay, config, 'replay_eval', is_eval=True),
        bind(make_env, config),
        bind(make_env, config),
        bind(make_logger, config), args)

  elif args.script == 'parallel_with_eval_env':
    envid = args.env_replica
    if envid < 0:
      envid = int(os.environ['JOB_COMPLETION_INDEX'])
    is_eval = envid >= args.num_envs
    embodied.run.parallel_with_eval.parallel_env(
        bind(make_env, config), envid, args, True, is_eval)

  elif args.script == 'parallel_with_eval_replay':
    embodied.run.parallel_with_eval.parallel_replay(
        bind(make_replay, config, 'replay', rate_limit=True),
        bind(make_replay, config, 'replay_eval', is_eval=True), args)

  else:
    raise NotImplementedError(args.script)


def make_agent(config):
  from . import agent as agt
  env = make_env(config, 0)
  if config.random_agent:
    agent = embodied.RandomAgent(env.obs_space, env.act_space)
  else:
    agent = agt.Agent(env.obs_space, env.act_space, config)
  env.close()
  return agent


def make_logger(config):
  step = embodied.Counter()
  logdir = config.logdir
  multiplier = config.env.get(config.task.split('_')[0], {}).get('repeat', 1)
  logger = embodied.Logger(step, [
      embodied.logger.TerminalOutput(config.filter, 'Agent'),
      embodied.logger.JSONLOutput(logdir, 'metrics.jsonl'),
      embodied.logger.JSONLOutput(logdir, 'scores.jsonl', 'episode/score'),
      embodied.logger.TensorBoardOutput(
          logdir, config.run.log_video_fps, config.tensorboard_videos),
      # embodied.logger.WandbOutput(logdir.name, ...),
  ], multiplier)
  return logger


def make_replay(config, directory=None, is_eval=False, rate_limit=False):
  directory = directory and embodied.Path(config.logdir) / directory
  size = int(config.replay.size / 10 if is_eval else config.replay.size)
  length = config.replay_length_eval if is_eval else config.replay_length
  kwargs = {}
  kwargs['online'] = config.replay.online
  if rate_limit and config.run.train_ratio > 0:
    kwargs['samples_per_insert'] = config.run.train_ratio / (
        length - config.replay_context)
    kwargs['tolerance'] = 5 * config.batch_size
    kwargs['min_size'] = min(
        max(config.batch_size, config.run.train_fill), size)
  selectors = embodied.replay.selectors
  if config.replay.fracs.uniform < 1 and not is_eval:
    assert config.jax.compute_dtype in ('bfloat16', 'float32'), (
        'Gradient scaling for low-precision training can produce invalid loss '
        'outputs that are incompatible with prioritized replay.')
    import numpy as np
    recency = 1.0 / np.arange(1, size + 1) ** config.replay.recexp
    kwargs['selector'] = selectors.Mixture(dict(
        uniform=selectors.Uniform(),
        priority=selectors.Prioritized(**config.replay.prio),
        recency=selectors.Recency(recency),
    ), config.replay.fracs)
  kwargs['chunksize'] = config.replay.chunksize
  replay = embodied.replay.Replay(length, size, directory, **kwargs)
  return replay


def make_env(config, index, **overrides):
  suite, task = config.task.split('_', 1)
  if suite == 'memmaze':
    from embodied.envs import from_gym
    import memory_maze  # noqa
  ctor = {
      'dummy': 'embodied.envs.dummy:Dummy',
      'gym': 'embodied.envs.from_gym:FromGym',
      'dm': 'embodied.envs.from_dmenv:FromDM',
      'crafter': 'embodied.envs.crafter:Crafter',
      'dmc': 'embodied.envs.dmc:DMC',
      'atari': 'embodied.envs.atari:Atari',
      'atari100k': 'embodied.envs.atari:Atari',
      'dmlab': 'embodied.envs.dmlab:DMLab',
      'minecraft': 'embodied.envs.minecraft:Minecraft',
      'loconav': 'embodied.envs.loconav:LocoNav',
      'pinpad': 'embodied.envs.pinpad:PinPad',
      'langroom': 'embodied.envs.langroom:LangRoom',
      'procgen': 'embodied.envs.procgen:ProcGen',
      'bsuite': 'embodied.envs.bsuite:BSuite',
      'memmaze': lambda task, **kw: from_gym.FromGym(
          f'MemoryMaze-{task}-ExtraObs-v0', **kw),
  }[suite]
  if isinstance(ctor, str):
    module, cls = ctor.split(':')
    module = importlib.import_module(module)
    ctor = getattr(module, cls)
  kwargs = config.env.get(suite, {})
  kwargs.update(overrides)
  if kwargs.pop('use_seed', False):
    kwargs['seed'] = hash((config.seed, index)) % (2 ** 32 - 1)
  if kwargs.pop('use_logdir', False):
    kwargs['logdir'] = embodied.Path(config.logdir) / f'env{index}'
  env = ctor(task, **kwargs)
  return wrap_env(env, config)


def wrap_env(env, config):
  args = config.wrapper
  for name, space in env.act_space.items():
    if name == 'reset':
      continue
    elif not space.discrete:
      env = wrappers.NormalizeAction(env, name)
      if args.discretize:
        env = wrappers.DiscretizeAction(env, name, args.discretize)
  env = wrappers.ExpandScalars(env)
  if args.length:
    env = wrappers.TimeLimit(env, args.length, args.reset)
  if args.checks:
    env = wrappers.CheckSpaces(env)
  for name, space in env.act_space.items():
    if not space.discrete:
      env = wrappers.ClipAction(env, name)
  return env


if __name__ == '__main__':
  main()

</dreamerv3/main.py>

<dreamerv3/nets.py>
import einops
import jax
import jax.numpy as jnp
import numpy as np
from tensorflow_probability.substrates import jax as tfp

from . import jaxutils
from . import ninjax as nj

f32 = jnp.float32
tfd = tfp.distributions
sg = lambda x: jax.tree_util.tree_map(jax.lax.stop_gradient, x)
cast = jaxutils.cast_to_compute


class RSSM(nj.Module):

  deter: int = 4096
  hidden: int = 2048
  stoch: int = 32
  classes: int = 32
  norm: str = 'rms'
  act: str = 'gelu'
  unroll: bool = False
  unimix: float = 0.01
  outscale: float = 1.0
  imglayers: int = 2
  obslayers: int = 1
  dynlayers: int = 1
  absolute: bool = False
  cell: str = 'gru'
  blocks: int = 8

  def __init__(self, **kw):
    self.kw = kw

  def initial(self, bsize):
    carry = dict(
        deter=jnp.zeros([bsize, self.deter], f32),
        stoch=jnp.zeros([bsize, self.stoch, self.classes], f32))
    if self.cell == 'stack':
      carry['feat'] = jnp.zeros([bsize, self.hidden], f32)
    return cast(carry)

  def outs_to_carry(self, outs):
    keys = ('deter', 'stoch')
    if self.cell == 'stack':
      keys += ('feat',)
    return {k: outs[k][:, -1] for k in keys}

  def observe(self, carry, action, embed, reset, bdims=2):
    kw = dict(**self.kw, norm=self.norm, act=self.act)
    assert bdims in (1, 2)
    if isinstance(action, dict):
      action = jaxutils.concat_dict(action)
    carry, action, embed = cast((carry, action, embed))
    if bdims == 2:
      return jaxutils.scan(
          lambda carry, inputs: self.observe(carry, *inputs, bdims=1),
          carry, (action, embed, reset), self.unroll, axis=1)
    deter, stoch, action = jaxutils.reset(
        (carry['deter'], carry['stoch'], action), reset)
    deter, feat = self._gru(deter, stoch, action)
    x = embed if self.absolute else jnp.concatenate([feat, embed], -1)
    for i in range(self.obslayers):
      x = self.get(f'obs{i}', Linear, self.hidden, **kw)(x)
    logit = self._logit('obslogit', x)
    stoch = cast(self._dist(logit).sample(seed=nj.seed()))
    carry = dict(deter=deter, stoch=stoch)
    outs = dict(deter=deter, stoch=stoch, logit=logit)
    if self.cell == 'stack':
      carry['feat'] = feat
      outs['feat'] = feat
    return cast(carry), cast(outs)

  def imagine(self, carry, action, bdims=2):
    assert bdims in (1, 2)
    if isinstance(action, dict):
      action = jaxutils.concat_dict(action)
    carry, action = cast((carry, action))
    if bdims == 2:
      return jaxutils.scan(
          lambda carry, action: self.imagine(carry, action, bdims=1),
          cast(carry), cast(action), self.unroll, axis=1)
    deter, feat = self._gru(carry['deter'], carry['stoch'], action)
    logit = self._prior(feat)
    stoch = cast(self._dist(logit).sample(seed=nj.seed()))
    carry = dict(deter=deter, stoch=stoch)
    outs = dict(deter=deter, stoch=stoch, logit=logit)
    if self.cell == 'stack':
      carry['feat'] = feat
      outs['feat'] = feat
    return cast(carry), cast(outs)

  def loss(self, outs, free=1.0):
    metrics = {}
    prior = self._prior(outs.get('feat', outs['deter']))
    post = outs['logit']
    dyn = self._dist(sg(post)).kl_divergence(self._dist(prior))
    rep = self._dist(post).kl_divergence(self._dist(sg(prior)))
    if free:
      dyn = jnp.maximum(dyn, free)
      rep = jnp.maximum(rep, free)
    metrics.update(jaxutils.tensorstats(
        self._dist(prior).entropy(), 'prior_ent'))
    metrics.update(jaxutils.tensorstats(
        self._dist(post).entropy(), 'post_ent'))
    return {'dyn': dyn, 'rep': rep}, metrics

  def _prior(self, feat):
    kw = dict(**self.kw, norm=self.norm, act=self.act)
    x = feat
    for i in range(self.imglayers):
      x = self.get(f'img{i}', Linear, self.hidden, **kw)(x)
    return self._logit('imglogit', x)

  def _gru(self, deter, stoch, action):
    kw = dict(**self.kw, norm=self.norm, act=self.act)
    inkw = {**self.kw, 'norm': self.norm, 'binit': False}
    stoch = stoch.reshape((stoch.shape[0], -1))
    action /= sg(jnp.maximum(1, jnp.abs(action)))
    if self.cell == 'gru':
      x0 = self.get('dynnorm', Norm, self.norm)(deter)
      x1 = self.get('dynin1', Linear, self.hidden, **inkw)(stoch)
      x2 = self.get('dynin2', Linear, self.hidden, **inkw)(action)
      x = jnp.concatenate([x0, x1, x2], -1)
      for i in range(self.dynlayers):
        x = self.get(f'dyn{i}', Linear, self.hidden, **kw)(x)
      x = self.get('dyncore', Linear, 3 * self.deter, **self.kw)(x)
      reset, cand, update = jnp.split(x, 3, -1)
      reset = jax.nn.sigmoid(reset)
      cand = jnp.tanh(reset * cand)
      update = jax.nn.sigmoid(update - 1)
      deter = update * cand + (1 - update) * deter
      out = deter
    elif self.cell == 'mgu':
      x0 = self.get('dynnorm', Norm, self.norm)(deter)
      x1 = self.get('dynin1', Linear, self.hidden, **inkw)(stoch)
      x2 = self.get('dynin2', Linear, self.hidden, **inkw)(action)
      x = jnp.concatenate([x0, x1, x2], -1)
      for i in range(self.dynlayers):
        x = self.get(f'dyn{i}', Linear, self.hidden, **kw)(x)
      x = self.get('dyncore', Linear, 2 * self.deter, **self.kw)(x)
      cand, update = jnp.split(x, 2, -1)
      update = jax.nn.sigmoid(update - 1)
      cand = jnp.tanh((1 - update) * cand)
      deter = update * cand + (1 - update) * deter
      out = deter
    elif self.cell == 'blockgru':
      g = self.blocks
      flat2group = lambda x: einops.rearrange(x, '... (g h) -> ... g h', g=g)
      group2flat = lambda x: einops.rearrange(x, '... g h -> ... (g h)', g=g)
      x0 = self.get('dynin0', Linear, self.hidden, **kw)(deter)
      x1 = self.get('dynin1', Linear, self.hidden, **kw)(stoch)
      x2 = self.get('dynin2', Linear, self.hidden, **kw)(action)
      x = jnp.concatenate([x0, x1, x2], -1)[..., None, :].repeat(g, -2)
      x = group2flat(jnp.concatenate([flat2group(deter), x], -1))
      for i in range(self.dynlayers):
        x = self.get(f'dyn{i}', BlockLinear, self.deter, g, **kw)(x)
      x = self.get('dyncore', BlockLinear, 3 * self.deter, g, **self.kw)(x)
      gates = jnp.split(flat2group(x), 3, -1)
      reset, cand, update = [group2flat(x) for x in gates]
      reset = jax.nn.sigmoid(reset)
      cand = jnp.tanh(reset * cand)
      update = jax.nn.sigmoid(update - 1)
      deter = update * cand + (1 - update) * deter
      out = deter
    elif self.cell == 'stack':
      result = []
      deters = jnp.split(deter, self.dynlayers, -1)
      x = jnp.concatenate([stoch, action], -1)
      x = self.get('in', Linear, self.hidden, **kw)(x)
      for i in range(self.dynlayers):
        skip = x
        x = get_act(self.act)(jnp.concatenate([
            self.get(f'dyngru{i}norm1', Norm, self.norm)(deters[i]),
            self.get(f'dyngru{i}norm2', Norm, self.norm)(x)], -1))
        x = self.get(
            f'dyngru{i}core', Linear, 3 * deters[i].shape[-1], **self.kw)(x)
        reset, cand, update = jnp.split(x, 3, -1)
        reset = jax.nn.sigmoid(reset)
        cand = jnp.tanh(reset * cand)
        update = jax.nn.sigmoid(update - 1)
        deter = update * cand + (1 - update) * deters[i]
        result.append(deter)
        x = self.get(f'dyngru{i}proj', Linear, self.hidden, **self.kw)(x)
        x += skip
        skip = x
        x = self.get(f'dynmlp{i}norm', Norm, self.norm)(x)
        x = self.get(
            f'dynmlp{i}up', Linear, deters[i].shape[-1], **self.kw)(x)
        x = get_act(self.act)(x)
        x = self.get(f'dynmlp{i}down', Linear, self.hidden, **self.kw)(x)
        x += skip
      out = self.get('outnorm', Norm, self.norm)(x)
      deter = jnp.concatenate(result, -1)
    else:
      raise NotImplementedError(self.cell)
    return deter, out

  def _logit(self, name, x):
    kw = dict(**self.kw, outscale=self.outscale)
    kw['binit'] = False
    x = self.get(name, Linear, self.stoch * self.classes, **kw)(x)
    logit = x.reshape(x.shape[:-1] + (self.stoch, self.classes))
    if self.unimix:
      probs = jax.nn.softmax(logit, -1)
      uniform = jnp.ones_like(probs) / probs.shape[-1]
      probs = (1 - self.unimix) * probs + self.unimix * uniform
      logit = jnp.log(probs)
    return logit

  def _dist(self, logit):
    return tfd.Independent(jaxutils.OneHotDist(logit.astype(f32)), 1)


class SimpleEncoder(nj.Module):

  depth: int = 128
  mults: tuple = (1, 2, 4, 2)
  layers: int = 5
  units: int = 1024
  symlog: bool = True
  norm: str = 'rms'
  act: str = 'gelu'
  kernel: int = 4
  outer: bool = False
  minres: int = 4

  def __init__(self, spaces, **kw):
    assert all(len(s.shape) <= 3 for s in spaces.values()), spaces
    self.veckeys = [k for k, s in spaces.items() if len(s.shape) <= 2]
    self.imgkeys = [k for k, s in spaces.items() if len(s.shape) == 3]
    self.vecinp = Input(self.veckeys, featdims=1)
    self.imginp = Input(self.imgkeys, featdims=3)
    self.depths = tuple(self.depth * mult for mult in self.mults)
    self.kw = kw

  def __call__(self, data, bdims=2):
    kw = dict(**self.kw, norm=self.norm, act=self.act)
    outs = []

    if self.veckeys:
      x = self.vecinp(data, bdims, f32)
      x = x.reshape((-1, *x.shape[bdims:]))
      x = jaxutils.symlog(x) if self.symlog else x
      x = jaxutils.cast_to_compute(x)
      for i in range(self.layers):
        x = self.get(f'mlp{i}', Linear, self.units, **kw)(x)
      outs.append(x)

    if self.imgkeys:
      print('ENC')
      x = self.imginp(data, bdims, jaxutils.COMPUTE_DTYPE) - 0.5
      x = x.reshape((-1, *x.shape[bdims:]))
      for i, depth in enumerate(self.depths):
        stride = 1 if self.outer and i == 0 else 2
        x = self.get(f'conv{i}', Conv2D, depth, self.kernel, stride, **kw)(x)
      assert x.shape[-3] == x.shape[-2] == self.minres, x.shape
      x = x.reshape((x.shape[0], -1))
      print(x.shape, 'out')
      outs.append(x)

    x = jnp.concatenate(outs, -1)
    x = x.reshape((*data['is_first'].shape, *x.shape[1:]))
    return x


class SimpleDecoder(nj.Module):

  inputs: tuple = ('deter', 'stoch')
  depth: int = 128
  mults: tuple = (1, 2, 4, 3)
  sigmoid: bool = True
  layers: int = 5
  units: int = 1024
  norm: str = 'rms'
  act: str = 'gelu'
  outscale: float = 1.0
  vecdist: str = 'symlog_mse'
  kernel: int = 4
  outer: bool = False
  block_space: int = 0
  minres: int = 4

  def __init__(self, spaces, **kw):
    assert all(len(s.shape) <= 3 for s in spaces.values()), spaces
    self.inp = Input(self.inputs, featdims=1)
    self.veckeys = [k for k, s in spaces.items() if len(s.shape) <= 2]
    self.imgkeys = [k for k, s in spaces.items() if len(s.shape) == 3]
    self.spaces = spaces
    self.depths = tuple([self.depth * mult for mult in self.mults])
    self.imgdep = sum(self.spaces[k].shape[-1] for k in self.imgkeys)
    self.kw = kw

  def __call__(self, lat, bdims=2):
    kw = dict(**self.kw, norm=self.norm, act=self.act)
    outs = {}

    if self.veckeys:
      inp = self.inp(lat, bdims, jaxutils.COMPUTE_DTYPE)
      x = inp.reshape((-1, inp.shape[-1]))
      for i in range(self.layers):
        x = self.get(f'mlp{i}', Linear, self.units, **kw)(x)
      x = x.reshape((*inp.shape[:bdims], *x.shape[1:]))
      for k in self.veckeys:
        dist = (
            dict(dist='softmax', bins=self.spaces[k].classes)
            if self.spaces[k].discrete else dict(dist=self.vecdist))
        k = k.replace('/', '_')
        outs[k] = self.get(f'out_{k}', Dist, self.spaces[k].shape, **dist)(x)

    if self.imgkeys:
      inp = self.inp(lat, bdims, jaxutils.COMPUTE_DTYPE)
      print('DEC')
      shape = (self.minres, self.minres, self.depths[-1])
      x = inp.reshape((-1, inp.shape[-1]))

      if self.block_space:
        g = self.block_space
        x0 = einops.rearrange(cast(lat['deter']), 'b t ... -> (b t) ...')
        x1 = einops.rearrange(cast(lat['stoch']), 'b t l c -> (b t) (l c)')
        x0 = self.get(
            'space0', BlockLinear, int(np.prod(shape)), g, **self.kw)(x0)
        x0 = einops.rearrange(
            x0, '... (g h w c) -> ... h w (g c)',
            h=self.minres, w=self.minres, g=g)
        x1 = self.get('space1', Linear, 2 * self.units, **kw)(x1)
        x1 = self.get('space2', Linear, shape, **self.kw)(x1)
        x = self.get('spacenorm', Norm, self.norm, act=self.act)(x0 + x1)
      else:
        x = self.get('space', Linear, shape, **kw)(x)

      print(x.shape, 'in')
      for i, depth in reversed(list(enumerate(self.depths[:-1]))):
        x = self.get(
            f'conv{i}', Conv2D, depth, self.kernel, 2, **kw, transp=True)(x)
      outkw = dict(**self.kw, outscale=self.outscale, transp=True)
      stride = 1 if self.outer else 2
      x = self.get(
          'imgout', Conv2D, self.imgdep, self.kernel, stride, **outkw)(x)
      x = jax.nn.sigmoid(x) if self.sigmoid else x + 0.5
      print(x.shape, 'out')
      x = x.reshape((*inp.shape[:bdims], *x.shape[1:]))
      split = np.cumsum([self.spaces[k].shape[-1] for k in self.imgkeys][:-1])
      for k, out in zip(self.imgkeys, jnp.split(x, split, -1)):
        outs[k] = jaxutils.MSEDist(f32(out), 3, 'sum')

    return outs


class MLP(nj.Module):

  layers: int = None
  units: int = None

  def __init__(self, shape, dist='mse', inputs=['tensor'], **kw):
    shape = (shape,) if isinstance(shape, (int, np.integer)) else shape
    assert isinstance(shape, (tuple, dict, type(None))), shape
    assert isinstance(dist, (str, dict)), dist
    assert isinstance(dist, dict) == isinstance(shape, dict), (dist, shape)
    self.shape = shape
    self.dist = dist
    self.inputs = Input(inputs, featdims=1)
    distonly = ('outscale', 'minstd', 'maxstd', 'unimix', 'bins')
    self.lkw = {k: v for k, v in kw.items() if k not in distonly}
    forbidden = ('binit', 'norm', 'act')
    self.dkw = {k: v for k, v in kw.items() if k not in forbidden}

  def __call__(self, inputs, bdims=2, training=False):
    feat = self.inputs(inputs, bdims, jaxutils.COMPUTE_DTYPE)
    x = feat.reshape([-1, feat.shape[-1]])
    for i in range(self.layers):
      x = self.get(f'h{i}', Linear, self.units, **self.lkw)(x)
    x = x.reshape((*feat.shape[:bdims], -1))
    if self.shape is None:
      return x
    elif isinstance(self.shape, dict):
      return {
          k: self._out(k, v, self.dist[k], x) for k, v in self.shape.items()}
    else:
      return self._out('dist', self.shape, self.dist, x)

  def _out(self, name, shape, dist, x):
    name = name.replace('/', '_').replace('.', '_')
    return self.get(name, Dist, shape, dist, **self.dkw)(x)


class Dist(nj.Module):

  outscale: float = 0.1
  minstd: float = 1.0
  maxstd: float = 1.0
  unimix: float = 0.0
  bins: int = 255

  def __init__(self, shape, dist='mse', **kw):
    assert all(isinstance(dim, (int, np.integer)) for dim in shape), shape
    forbidden = ('binit', 'norm', 'act')
    assert all(k not in kw for k in forbidden), (forbidden, kw)
    self.shape = shape
    self.dist = dist
    self.kw = dict(**kw, outscale=self.outscale)

  def __call__(self, inputs):
    dist = self.inner(inputs)
    assert tuple(dist.batch_shape) == tuple(inputs.shape[:-1]), (
        dist.batch_shape, dist.event_shape, inputs.shape)
    return dist

  def inner(self, inputs):
    shape = self.shape
    padding = 0

    if 'twohot' in self.dist or self.dist == 'softmax':
      padding = int(self.bins % 2)
      shape = (*self.shape, self.bins + padding)

    out = self.get('out', Linear, int(np.prod(shape)), **self.kw)(inputs)
    out = out.reshape(inputs.shape[:-1] + shape).astype(f32)
    out = out[..., :-padding] if padding else out

    if 'normal' in self.dist:
      units = int(np.prod(self.shape))
      std = self.get('std', Linear, units, **self.kw)(inputs)
      std = std.reshape(inputs.shape[:-1] + self.shape).astype(f32)

    if self.dist == 'symlog_mse':
      fwd, bwd = jaxutils.symlog, jaxutils.symexp
      return jaxutils.TransformedMseDist(out, len(self.shape), fwd, bwd)

    if self.dist == 'hyperbolic_mse':
      fwd = lambda x, eps=1e-3: (
          jnp.sign(x) * (jnp.sqrt(jnp.abs(x) + 1) - 1) + eps * x)
      bwd = lambda x, eps=1e-3: jnp.sign(x) * (jnp.square(
          jnp.sqrt(1 + 4 * eps * (eps + 1 + jnp.abs(x))) / 2 / eps -
          1 / 2 / eps) - 1)
      return jaxutils.TransformedMseDist(out, len(self.shape), fwd, bwd)

    if self.dist == 'symlog_and_twohot':
      bins = np.linspace(-20, 20, out.shape[-1])
      return jaxutils.TwoHotDist(
          out, bins, len(self.shape), jaxutils.symlog, jaxutils.symexp)

    if self.dist == 'symexp_twohot':
      if out.shape[-1] % 2 == 1:
        half = jnp.linspace(-20, 0, (out.shape[-1] - 1) // 2 + 1, dtype=f32)
        half = jaxutils.symexp(half)
        bins = jnp.concatenate([half, -half[:-1][::-1]], 0)
      else:
        half = jnp.linspace(-20, 0, out.shape[-1] // 2, dtype=f32)
        half = jaxutils.symexp(half)
        bins = jnp.concatenate([half, -half[::-1]], 0)
      return jaxutils.TwoHotDist(out, bins, len(self.shape))

    if self.dist == 'hyperbolic_twohot':
      eps = 0.001
      f = lambda x: np.sign(x) * (np.square(np.sqrt(
          1 + 4 * eps * (eps + 1 + np.abs(x))) / 2 / eps - 1 / 2 / eps) - 1)
      bins = f(np.linspace(-300, 300, out.shape[-1]))
      return jaxutils.TwoHotDist(out, bins, len(self.shape))

    if self.dist == 'mse':
      return jaxutils.MSEDist(out, len(self.shape), 'sum')

    if self.dist == 'huber':
      return jaxutils.HuberDist(out, len(self.shape), 'sum')

    if self.dist == 'normal':
      lo, hi = self.minstd, self.maxstd
      std = (hi - lo) * jax.nn.sigmoid(std + 2.0) + lo
      dist = tfd.Normal(jnp.tanh(out), std)
      dist = tfd.Independent(dist, len(self.shape))
      dist.minent = np.prod(self.shape) * tfd.Normal(0.0, lo).entropy()
      dist.maxent = np.prod(self.shape) * tfd.Normal(0.0, hi).entropy()
      return dist

    if self.dist == 'trunc_normal':
      lo, hi = self.minstd, self.maxstd
      std = (hi - lo) * jax.nn.sigmoid(std + 2.0) + lo
      dist = tfd.TruncatedNormal(jnp.tanh(out), std, -1, 1)
      dist = tfd.Independent(dist, len(self.shape))
      dist.minent = np.prod(self.shape) * (
          tfd.TruncatedNormal(1.0, lo, -1, 1).entropy())
      dist.maxent = np.prod(self.shape) * (
          tfd.TruncatedNormal(0.0, hi, -1, 1).entropy())
      return dist

    if self.dist == 'binary':
      dist = tfd.Bernoulli(out)
      if self.shape:
        dist = tfd.Independent(dist, len(self.shape))
      return dist

    if self.dist == 'softmax':
      dist = tfd.Categorical(out)
      if len(self.shape) > 1:
        dist = tfd.Independent(dist, len(self.shape) - 1)
      return dist

    if self.dist == 'onehot':
      if self.unimix:
        probs = jax.nn.softmax(out, -1)
        uniform = jnp.ones_like(probs) / probs.shape[-1]
        probs = (1 - self.unimix) * probs + self.unimix * uniform
        out = jnp.log(probs)
      dist = jaxutils.OneHotDist(out)
      if len(self.shape) > 1:
        dist = tfd.Independent(dist, len(self.shape) - 1)
      dist.minent = 0.0
      dist.maxent = np.prod(self.shape[:-1]) * np.log(self.shape[-1])
      return dist

    raise NotImplementedError(self.dist)


class Conv2D(nj.Module):

  groups: int = 1
  transp: bool = False
  act: str = 'none'
  norm: str = 'none'
  pad: str = 'same'
  bias: bool = True
  outscale: float = 1.0
  winit: str = 'normal'
  binit: bool = False
  fan: str = 'in'
  dtype: str = 'default'

  def __init__(self, depth, kernel, stride=1):
    self.depth = depth
    self.kernel = kernel
    self.stride = stride
    self._winit = Initializer(self.winit, self.outscale, self.fan, self.dtype)
    self._binit = Initializer('zeros', 1.0, self.fan, self.dtype)
    self._norm = Norm(self.norm, name='norm')

  def __call__(self, x):
    assert x.dtype == jaxutils.COMPUTE_DTYPE, (x.dtype, x.shape)
    x = self._layer(x)
    x = self._norm(x)
    x = get_act(self.act)(x)
    return x

  def _layer(self, x):
    if self.transp:
      assert self.groups == 1, self.groups
      shape = (self.kernel, self.kernel, x.shape[-1], self.depth)
      kernel = self.get('kernel', self._winit, shape)
      kernel = jaxutils.cast_to_compute(kernel)
      flops = int(np.prod(shape)) * x.shape[-3] * x.shape[-2]
      x = jax.lax.conv_transpose(
          x, kernel, (self.stride, self.stride), self.pad.upper(),
          dimension_numbers=('NHWC', 'HWIO', 'NHWC'))
    else:
      G = self.groups
      shape = (self.kernel, self.kernel, x.shape[-1] // G, self.depth)
      kernel = self.get('kernel', self._winit, shape)
      kernel = jaxutils.cast_to_compute(kernel)
      x = jax.lax.conv_general_dilated(
          x, kernel, (self.stride, self.stride), self.pad.upper(),
          feature_group_count=self.groups,
          dimension_numbers=('NHWC', 'HWIO', 'NHWC'))
      flops = int(np.prod(shape)) * x.shape[-3] * x.shape[-2]
    if self.bias:
      if self.binit:
        args = (self._winit, self.depth, shape)
      else:
        args = (self._binit, self.depth)
      x += self.get('bias', *args).astype(x.dtype)
      flops += int(np.prod(x.shape[-3:]))
    assert x.dtype == jaxutils.COMPUTE_DTYPE, (x.dtype, x.shape)
    return x


class Linear(nj.Module):

  act: str = 'none'
  norm: str = 'none'
  bias: bool = True
  outscale: float = 1.0
  winit: str = 'normal'
  binit: bool = False
  fan: str = 'in'
  dtype: str = 'default'
  fanin: int = 0

  def __init__(self, units):
    self.units = (units,) if isinstance(units, int) else tuple(units)
    self._winit = Initializer(
        self.winit, self.outscale, self.fan, self.dtype)
    self._binit = Initializer('zeros', 1.0, self.fan, self.dtype)
    self._norm = Norm(self.norm, name='norm')

  def __call__(self, x):
    assert x.dtype == jaxutils.COMPUTE_DTYPE, (x.dtype, x.shape)
    x = self._layer(x)
    x = self._norm(x)
    x = get_act(self.act)(x)
    return x

  def _layer(self, x):
    shape = (x.shape[-1], int(np.prod(self.units)))
    fan_shape = (self.fanin, shape[1]) if self.fanin else None
    x = x @ self.get('kernel', self._winit, shape, fan_shape).astype(x.dtype)
    flops = int(np.prod(shape))
    if self.bias:
      if self.binit:
        args = (self._winit, np.prod(self.units), shape)
      else:
        args = (self._binit, np.prod(self.units))
      x += self.get('bias', *args).astype(x.dtype)
      flops += int(np.prod(self.units))
    assert x.dtype == jaxutils.COMPUTE_DTYPE, (x.dtype, x.shape)
    if len(self.units) > 1:
      x = x.reshape(x.shape[:-1] + self.units)
    return x


class BlockLinear(nj.Module):

  act: str = 'none'
  norm: str = 'none'
  bias: bool = True
  outscale: float = 1.0
  winit: str = 'normal'
  binit: bool = False
  fan: str = 'in'
  dtype: str = 'default'

  def __init__(self, units, groups):
    self.units = (units,) if isinstance(units, int) else tuple(units)
    assert groups <= np.prod(units), (groups, units)
    self.groups = groups
    self._winit = Initializer(self.winit, self.outscale, self.fan, self.dtype)
    self._binit = Initializer('zeros', 1.0, self.fan, self.dtype)
    self._norm = Norm(self.norm, name='norm')

  def __call__(self, x):
    assert x.dtype == jaxutils.COMPUTE_DTYPE, (x.dtype, x.shape)
    x = self._layer(x)
    x = self._norm(x)
    x = get_act(self.act)(x)
    return x

  def _layer(self, x):
    bdims, indim, outdim = x.shape[:-1], x.shape[-1], np.prod(self.units)
    if indim % self.groups != 0:
      pad = int(np.ceil(indim / self.groups)) * self.groups - indim
      x = jnp.concatenate([x, jnp.zeros((*x.shape[:-1], pad), x.dtype)], -1)
      indim = x.shape[-1]
    assert indim % self.groups == outdim % self.groups == 0, (
        indim, outdim, self.groups, self.units)
    shape = (self.groups, indim // self.groups, outdim // self.groups)
    kernel = self.get('kernel', self._winit, shape, shape).astype(x.dtype)
    flops = int(np.prod(shape))
    x = x.reshape((*bdims, self.groups, indim // self.groups))
    x = jnp.einsum('...ki,kio->...ko', x, kernel)
    x = x.reshape((*bdims, outdim))
    if self.bias:
      if self.binit:
        args = (self._winit, np.prod(self.units), shape)
      else:
        args = (self._binit, np.prod(self.units))
      bias = self.get('bias', *args)
      x += bias.astype(x.dtype)
      flops += int(np.prod(self.units))
    if len(self.units) > 1:
      x = x.reshape(x.shape[:-1] + self.units)
    assert x.dtype == jaxutils.COMPUTE_DTYPE, (x.dtype, x.shape)
    return x


class Embed(nj.Module):

  outscale: float = 1.0
  winit: str = 'normal'
  fan: str = 'in'
  dtype: str = 'default'

  def __init__(self, count, units):
    self.count = count
    self.units = units
    self._winit = Initializer(self.winit, self.outscale, self.fan, self.dtype)

  def __call__(self, x):
    assert x.dtype in (jnp.uint32, jnp.int32), x.dtype
    shape = (self.count, self.units)
    fan_shape = (1, self.units)
    w = self.get('embed', self._winit, shape, fan_shape).astype(x.dtype)
    return jnp.take(w, x, axis=0)


class Norm(nj.Module):

  act: str = 'none'

  def __init__(self, impl, eps=1e-4):
    if '1em' in impl:
      impl, exponent = impl.split('1em')
      eps = 10 ** -int(exponent)
    self._impl = impl
    self._eps = eps

  def __call__(self, x):
    x = self._norm(x)
    x = get_act(self.act)(x)
    return x

  def _norm(self, x):
    if self._impl == 'none':
      return x
    elif self._impl == 'layer':
      x = x.astype(f32)
      mean = x.mean(-1)[..., None]
      mean2 = jnp.square(x).mean(-1)[..., None]
      var = jnp.maximum(0, mean2 - jnp.square(mean))
      scale = self.get('scale', jnp.ones, x.shape[-1], f32)
      offset = self.get('offset', jnp.zeros, x.shape[-1], f32)
      mult = scale * jax.lax.rsqrt(var + self._eps)
      x = (x - mean) * mult + offset
      return cast(x)
    elif self._impl == 'rms':
      dtype = x.dtype
      x = f32(x) if x.dtype == jnp.float16 else x
      scale = self.get('scale', jnp.ones, x.shape[-1], f32).astype(x.dtype)
      mult = jax.lax.rsqrt((x * x).mean(-1)[..., None] + self._eps) * scale
      return (x * mult).astype(dtype)
    elif self._impl == 'rms_instance':
      x = x.astype(f32)
      scale = self.get('scale', jnp.ones, x.shape[-1], f32)
      mult = jax.lax.rsqrt((x * x).mean((-3, -2), keepdims=True) + self._eps)
      mult = mult * scale
      return cast(x * mult)
    elif self._impl == 'grn':
      assert len(x.shape) >= 4, x.shape
      x = x.astype(f32)
      norm = jnp.linalg.norm(x, 2, (-3, -2), keepdims=True)
      norm /= (norm.mean(-1, keepdims=True) + self._eps)
      scale = self.get('scale', jnp.ones, x.shape[-1], f32)
      offset = self.get('offset', jnp.zeros, x.shape[-1], f32)
      x = (norm * scale + 1) * x + offset
      return cast(x)
    elif self._impl == 'instance':
      x = x.astype(f32)
      mean = x.mean(axis=(-3, -2), keepdims=True)
      var = x.var(axis=(-3, -2), keepdims=True)
      scale = self.get('scale', jnp.ones, x.shape[-1], f32)
      offset = self.get('offset', jnp.zeros, x.shape[-1], f32)
      x = (scale * jax.lax.rsqrt(var + self._eps)) * (x - mean) + offset
      return cast(x)
    else:
      raise NotImplementedError(self._impl)


class Input:

  def __init__(self, keys=['tensor'], featdims=1):
    self.keys = tuple(keys)
    self.featdims = featdims

  def __call__(self, inputs, bdims=2, dtype=None):
    if not isinstance(inputs, dict):
      inputs = {'tensor': inputs}
    try:
      xs = []
      for key in self.keys:
        x = inputs[key]
        if jnp.issubdtype(x.dtype, jnp.complexfloating):
          x = jnp.concatenate([x.real, x.imag], -1)
        x = x.astype(dtype or inputs[self.keys[0]].dtype)
        x = x.reshape((*x.shape[:bdims + self.featdims - 1], -1))
        msg = f'Invalid input ({nj.SCOPE}, {key}, {x.shape}, {x.dtype}): {{x}}'
        jaxutils.check(jnp.isfinite(x).all(), msg, x=x)
        xs.append(x)
      xs = jnp.concatenate(xs, -1)
    except (KeyError, ValueError, TypeError) as e:
      shapes = {k: v.shape for k, v in inputs.items()}
      raise ValueError(
          f'Error: {e}\n'
          f'Input shapes: {shapes}\n' +
          f'Requested keys: {self.keys}')
    return xs


class Initializer:

  VARIANCE_FACTOR = 1.0

  def __init__(
      self, dist='normal', scale=1.0, fan='in', dtype='default',
      block_fans=False):
    self.dist = dist
    self.scale = scale
    self.fan = fan
    self.dtype = dtype
    self.block_fans = block_fans

  def __call__(self, shape, fan_shape=None):
    shape = (shape,) if isinstance(shape, (int, np.integer)) else tuple(shape)
    assert all(x > 0 for x in shape), shape
    dtype = jaxutils.PARAM_DTYPE if self.dtype == 'default' else self.dtype
    dtype = getattr(jnp, dtype) if isinstance(dtype, str) else dtype
    fanin, fanout = self._fans(fan_shape or shape)
    fan = {'avg': (fanin + fanout) / 2, 'in': fanin, 'out': fanout}[self.fan]
    if self.dist == 'zeros':
      value = jnp.zeros(shape, dtype)
    elif self.dist == 'uniform':
      limit = np.sqrt(self.VARIANCE_FACTOR / fan)
      value = jax.random.uniform(nj.seed(), shape, dtype, -limit, limit)
    elif self.dist == 'normal':
      value = jax.random.truncated_normal(nj.seed(), -2, 2, shape)
      value *= 1.1368 * np.sqrt(self.VARIANCE_FACTOR / fan)
      value = value.astype(dtype)
    elif self.dist == 'normed':
      value = jax.random.uniform(nj.seed(), shape, dtype, -1, 1)
      value /= jnp.linalg.norm(value.reshape((-1, shape[-1])), 2, 0)
    elif self.dist == 'complex':
      assert jnp.issubdtype(dtype, jnp.complexfloating), dtype
      realdt = jnp.finfo(dtype).dtype
      value = jax.random.truncated_normal(
          nj.seed(), -2, 2, (2, *shape), realdt)
      value = value[0] + 1j * value[1]
      value *= jax.lax.convert_element_type(1.137 * np.sqrt(1 / fan), realdt)
    elif self.dist == 'ortho':
      nrows, ncols = shape[-1], np.prod(shape) // shape[-1]
      matshape = (nrows, ncols) if nrows > ncols else (ncols, nrows)
      mat = jax.random.normal(nj.seed(), matshape, dtype)
      qmat, rmat = jnp.linalg.qr(mat)
      qmat *= jnp.sign(jnp.diag(rmat))
      qmat = qmat.T if nrows < ncols else qmat
      qmat = qmat.reshape(nrows, *shape[:-1])
      value = jnp.moveaxis(qmat, 0, -1)
    else:
      raise NotImplementedError(self.dist)
    value *= self.scale
    return value

  def _fans(self, shape):
    if len(shape) == 0:
      return (1, 1)
    elif len(shape) == 1:
      return (1, shape[0])
    elif len(shape) == 2:
      return shape
    elif len(shape) == 3 and self.block_fans:
      return shape[1:]
    else:
      space = int(np.prod(shape[:-2]))
      return (shape[-2] * space, shape[-1] * space)


def get_act(name):
  if callable(name):
    return name
  elif name == 'none':
    return lambda x: x
  elif name == 'cswiglu':
    def fn(x):
      x, y = jnp.split(x, 2, -1)
      y1, y2 = jnp.split(y, 2, -1)
      pad = jnp.ones_like(y1)
      x = jax.nn.swish(jnp.concatenate([x, -x], -1))
      y = jnp.concatenate([y1, pad, y2, pad], -1)
      return x * y
    return fn
  elif name == 'mish':
    return lambda x: x * jnp.tanh(jax.nn.softplus(x))
  elif hasattr(jax.nn, name):
    return getattr(jax.nn, name)
  else:
    raise NotImplementedError(name)

</dreamerv3/nets.py>

<dreamerv3/ninjax.py>
import contextlib
import functools
import inspect
import re
import threading

import jax
import jax.numpy as jnp

__version__ = '2.3.1'


###############################################################################
# State
###############################################################################


# When running an impure function that accesses state, it will find the state
# in this global variable. The pure() wrapper populates this global variable
# with the provided state, calls the inner function, and then the takes the
# resulting state out of the global variable to return it back to the user.
# To allow multi-threaded programs to use impure functions in parallel, the
# context is a dictionary with a slot for each thread identifier.
CONTEXT = {}


class Context(dict):

  def __init__(
      self, entries, seed, create, modify, ignore, reserve, name):
    super().__init__(entries)
    self.create = create   # Allow creating new state entries.
    self.modify = modify   # Allow modifying existing state entries.
    self.ignore = ignore   # Ignore modifications to existing state entries.
    self.seed = seed
    self.reserve = reserve
    self.name = name
    self.accessed = set()  # Keys accessed for reading.
    self.created = set()   # Keys accessed for creating.
    self.modified = set()  # Keys accessed for modifying (even if ignored).

  def update(self, entries):
    for key, value in dict(entries).items():
      self[key] = value

  def __getitem__(self, key):
    self.accessed.add(key)
    try:
      return super().__getitem__(key)
    except KeyError:
      raise KeyError(
          f"Trying to access state key '{key}' that does not exist in context "
          f'create={self.create} modify={self.modify} ignore={self.ignore}.')

  def __setitem__(self, key, value):
    if key in self:
      self.modified.add(key)
    else:
      self.created.add(key)
    if self.ignore and key in self:
      return  # Do not overwrite existing entries.
    if not self.create and key not in self:
      raise RuntimeError(
          'Pass create=True to pure functions to allow them to create new '
          f'state entries or use nj.init(). You were trying to set {key} to '
          f'shape {value.shape}.')
    if not self.modify:
      existing = self[key]
      raise RuntimeError(
          'Cannot modify state entries here. (If you want to modify '
          'state inside of scan() pass modify=True.) ' +
          f'You were trying to change {key} from shape {existing.shape} '
          f'and dtype {existing.dtype} to shape {value.shape} and ' +
          f'dtype {value.dtype}.')
    super().__setitem__(key, value)


def pure(fun, nested=False):
  """Wrap an impure function that uses global state to explicitly pass the
  state in and out. The result is a pure function that is composable with JAX
  transformation. The pure function can be used as follows:
  ```
  state, out = fun(state, *args, **kwargs)
  ```
  Additional keyword arguments can be provided:
  - `seed`: Provide an integer or array of two integers to be able to use
    `nj.seed()` inside the impure function.
  - `create=False`: Boolean indicating whether the impure function will be
    allowed to create new state entries.
  - `modify=True`: Boolean indicating whether the impure function will be
    allowed to modify existing state entries.
  - `ignore=False`: Boolean indicating whether state modifications by the
    impure function will be ignored silently; useful for initialization.
  - `track=False`: Boolean indicating whether to return the sets of state
    keys that the impure function attempted to read, modify, and create.
  """
  def purified(
      state, *args, seed=None, create=None, modify=None, ignore=None,
      track=False, **kwargs):
    if isinstance(seed, int) or (hasattr(seed, 'shape') and seed.shape == ()):
      seed = jnp.array([seed, seed], jnp.uint32)
    context = CONTEXT.get(threading.get_ident(), None)
    if context is not None:
      create = create if create is not None else context.create
      modify = modify if modify is not None else context.modify
      ignore = ignore if ignore is not None else context.ignore
      assert context.create or not create, 'Parent context disabled create.'
      assert context.modify or not modify, 'Parent context disabled modify.'
      assert not context.ignore or ignore, 'Parent context enabled ignore.'
    else:
      create = create if create is not None else False
      modify = modify if modify is not None else True
      ignore = ignore if ignore is not None else False
    if not isinstance(state, dict):
      raise ValueError('Must provide a dict as state.')
    name = getattr(fun, '__name__', str(fun))
    if context and (not nested):
      raise RuntimeError(
          f'You are trying to call pure {name}() inside pure '
          f'{context.name}(). Is that intentional? If you want to nest pure '
          f'functions, use pure(..., nested=True) for the inner function.')
    before = context
    try:
      context = Context(
          state.copy(), seed, create, modify, ignore, [], name)
      CONTEXT[threading.get_ident()] = context
      out = fun(*args, **kwargs)
      state = dict(context)
      if before:
        before.accessed |= context.accessed
        before.modified |= context.modified
        before.created |= context.created
      if track:
        return state, out, context.accessed, context.modified, context.created
      return state, out
    finally:
      CONTEXT[threading.get_ident()] = before
  purified._is_pure = True
  return purified


def context():
  """Access and modify the global context from within an impure function. For
  advanced users only. Prefer to use module methods to access and modify state
  and seed() to get the next random seed."""
  context = CONTEXT.get(threading.get_ident(), None)
  if context is None:
    raise RuntimeError('Wrap impure functions in pure() before running them.')
  return context


def init(fun, **jit_kwargs):
  """Creates an initializer for a pure or impure function, which when called
  with example inputs , quickly populates the initial state without performing
  the actual computation of the function."""
  if not getattr(fun, '_is_pure', False):
    fun = pure(fun)
  def wrapper(*args, **kwargs):
    state, out = fun(*args, create=True, modify=True, ignore=True, **kwargs)
    del out
    return state
  return jax.jit(wrapper, **jit_kwargs)


@jax.named_scope('seed')
def seed(amount=None, optional=False, reserve=16):
  """Split the global random seed and return a new local seed."""
  ctx = context()
  if ctx.seed is None:
    if optional:
      return None if amount is None else [None] * amount
    raise ValueError(
        'You must provide a seed to the pure function to use nj.seed() '
        'inside the impure function.')
  if amount:
    keys = jax.random.split(ctx.seed, amount + 1)
    ctx.seed = keys[0]
    return keys[1:]
  else:
    if not ctx.reserve:
      keys = jax.random.split(ctx.seed, reserve)
      ctx.seed = keys[0]
      ctx.reserve = list(keys[1:])
    return ctx.reserve.pop(0)


def creating():
  """Indicates whether the program is currently allowed to create state
  entries. Can use used for initialization logic that should be excluded from
  compiled functions."""
  return context().create


###############################################################################
# Transformations
###############################################################################


@jax.named_scope('grad')
def grad(fun, keys, has_aux=False):
  """Compute the gradient of an impure function with respect to the specified
  state entries or modules. The transformed function returns a tuple containing
  the computed value, selected state entries, their gradients, and if
  applicable auxiliary outputs of the function."""
  keys = keys if hasattr(keys, '__len__') else (keys,)
  if not has_aux:
    fun = lambda *args, _fun=fun, **kwargs: (_fun(*args, *kwargs), {})
  fun = pure(fun, nested=True)

  def wrapper(*args, **kwargs):
    accessed, modified = _prerun(fun, *args, **kwargs)

    strs = []
    for key in keys:
      if isinstance(key, Module):
        matches = key.find()
      if isinstance(key, str):
        pattern = re.compile(f'^{key}(/.*|$)')
        matches = [k for k in context() if pattern.match(k)]
      if not matches:
        raise KeyError(
            f"Gradient key '{key}' did not match any state entries. "
            'List existing entries using print(nj.context().keys()).')
      strs += matches
    existing = context().keys()
    assert all(key in existing for key in strs), (strs, existing)
    x1 = {k: v for k, v in context().items() if k in strs}
    x2 = {k: v for k, v in context().items() if k not in strs}
    assert x1

    for key in x1.keys():
      if key not in accessed:
        raise RuntimeError(
            f"Trying to compute gradient with respect to key '{key}' "
            'but the differentiated function does not access it.\n'
            f'Accessed keys: {list(accessed)}\n'
            f'Gradient keys: {list(strs)}')
    x1 = {k: v for k, v in x1.items() if k in accessed}
    x2 = {k: v for k, v in x2.items() if k in accessed}

    def forward(x1, x2, *args, **kwargs):
      before = {**x1, **x2}
      state, (y, aux) = fun(before, *args, create=False, **kwargs)
      changes = {k: v for k, v in state.items() if k in modified}
      return y, (changes, aux)
    backward = jax.value_and_grad(forward, has_aux=True)

    (y, (changes, aux)), dx = backward(
        x1, x2, *args, seed=seed(None, True), **kwargs)
    if context().modify:
      context().update(changes)
    return (y, x1, dx, aux) if has_aux else (y, x1, dx)
  return wrapper


@jax.named_scope('cond')
def cond(pred, true_fun, false_fun, *operands):
  true_fun = pure(true_fun, nested=True)
  false_fun = pure(false_fun, nested=True)

  accessed1, modified1 = _prerun(true_fun, *operands)
  accessed2, modified2 = _prerun(false_fun, *operands)
  accessed = accessed1 | accessed2
  modified = modified1 | modified2

  def true_fun_wrapper(state, seed1, seed2, *args):
    state, outs = true_fun(state, *args, seed=seed1)
    changes = {k: v for k, v in state.items() if k in modified}
    return changes, outs

  def false_fun_wrapper(state, seed1, seed2, *args):
    state, outs = false_fun(state, *args, seed=seed2)
    changes = {k: v for k, v in state.items() if k in modified}
    return changes, outs

  needed = {k: v for k, v in context().items() if k in accessed}
  changes, out = jax.lax.cond(
      pred, true_fun_wrapper, false_fun_wrapper,
      needed, *seed(2, True), *operands)
  if context().modify:
    context().update(changes)
  return out


@jax.named_scope('scan')
def scan(fun, carry, xs, reverse=False, unroll=1, axis=0):
  if axis:
    xs = jax.tree_util.tree_map(lambda x: x.swapaxes(0, axis), xs)

  fun = pure(fun, nested=True)
  accessed, modified = _prerun(
      fun, carry, jax.tree_util.tree_map(lambda x: x[0], xs))

  changing = {k: v for k, v in context().items() if k in modified}
  unchanging = {
      k: v for k, v in context().items()
      if k in accessed and k not in modified}

  def inner(carry, x):
    carry, changing = carry
    x, seed = x
    state = {**unchanging, **changing}
    state, (carry, y) = fun(state, carry, x, create=False, seed=seed)
    changing = {k: v for k, v in state.items() if k in modified}
    return (carry, changing), y

  length = len(jax.tree_util.tree_leaves(xs)[0])
  seeds = seed(length, True)
  (carry, changes), ys = jax.lax.scan(
      inner, (carry, changing), (xs, seeds), length, reverse, unroll)

  if context().modify:
    context().update(changes)

  if axis:
    ys = jax.tree_util.tree_map(lambda y: y.swapaxes(0, axis), ys)
  return carry, ys


def checkpoint(fun, **cp_kwargs):
  static = cp_kwargs.get('static_argnums', tuple())
  static = static if isinstance(static, tuple) else (static,)
  static = tuple(x + 1 for x in static)
  cp_kwargs['static_argnums'] = static

  accessed, modified = [None], [None]
  fun = pure(fun, nested=True)

  @functools.partial(jax.checkpoint, **cp_kwargs)
  def inner(*args, **kwargs):
    state, output = fun(*args, **kwargs)
    changes = {k: v for k, v in state.items() if k in modified[0]}
    return changes, output

  @jax.named_scope('checkpoint')
  def outer(*args, **kwargs):
    accessed[0], modified[0] = _prerun(fun, *args, **kwargs)
    needed = {k: v for k, v in context().items() if k in accessed[0]}
    changes, output = inner(needed, *args, seed=seed(None, True), **kwargs)
    if context().modify:
      context().update(changes)
    return output

  return outer


@jax.named_scope('prerun')
def _prerun(fun, *args, **kwargs):
  if not context().modify and not context().create:
    return set()
  state, output, accessed, modified, created = fun(
      dict(context()), *args, ignore=True, track=True,
      seed=seed(None, True), **kwargs)
  del output
  creations = {k: v for k, v in state.items() if k in created}
  context().update(creations)
  return accessed, modified


###############################################################################
# Modules
###############################################################################


SCOPE = ''


@contextlib.contextmanager
def scope(name, absolute=False):
  """Enter a relative or absolute name scope. Name scopes are used to make
  names of state entries unique."""
  global SCOPE
  if SCOPE is None:
    raise RuntimeError(
        'Purify stateful functions with fn = pure(fn) before running them.')
  outside = SCOPE
  if absolute:
    SCOPE = name
  elif SCOPE == '':
    SCOPE = name
  else:
    SCOPE = outside + '/' + name
  try:
    yield SCOPE
  except Exception as e:
    if not hasattr(e, '_njscope'):
      e._njscope = SCOPE
      if hasattr(e, 'add_note'):
        e.add_note(f"This happened inside Ninjax scope '{SCOPE}'.")
      else:
        print(f"Exception happened inside Ninjax scope '{SCOPE}'.")
    raise
  finally:
    SCOPE = outside


class ModuleMeta(type):
  """Meta class that creates a unique path for each module instance and wraps
  the methods and properties of the module to enter the name scope."""

  def __new__(mcs, name, bases, clsdict):
    """This runs once per user module class definition. It wraps the methods of
    the module class to automatically enter the name scope of the module."""
    method_names = []
    for key, value in clsdict.items():
      if key.startswith('__') and key != '__call__':
        continue
      elif isinstance(value, property):
        clsdict[key] = property(
            value.fget if not value.fget else _scope_method(value.fget),
            value.fset if not value.fset else _scope_method(value.fset),
            value.fdel if not value.fdel else _scope_method(value.fdel),
            doc=value.__doc__)
      elif inspect.isfunction(value):
        method_names.append(key)
    cls = super(ModuleMeta, mcs).__new__(mcs, name, bases, clsdict)
    cls.__field_defaults = {
        k: getattr(cls, k) for k, v in cls.__annotations__.items()
        if hasattr(cls, k)}
    for key, value in cls.__annotations__.items():
      setattr(cls, key, property(lambda self, key=key: self.__fields[key]))
    for method_name in method_names:
      method = getattr(cls, method_name)
      method = _scope_method(method)
      setattr(cls, method_name, method)
    return cls

  def __call__(cls, *args, name=None, **kwargs):
    """This runs once per use module instance creation. It derives a unique
    name and path for the module instance."""
    if not isinstance(name, str):
      raise TypeError(
          "Please provide a module name via Module(..., name='example').")
    if not re.match(r'^[A-Za-z0-9_]+$', name):
      raise ValueError(
          'Only letters, numbers, and underscores are allowed in scope names; '
          f'got: {name}')
    fields = {}
    for key, typ in cls.__annotations__.items():
      if key in kwargs:
        value = kwargs.pop(key)
      elif key in cls.__field_defaults:
        value = cls.__field_defaults[key]
      else:
        raise TypeError(
            f"Pass a keyword argument for field '{key}' or define a default.")
      if typ is not None and not isinstance(value, typ):
        raise TypeError(
            f"Value '{value}' for field '{key}' is not of type "
            f"'{typ.__name__}'.")
      fields[key] = value
    obj = cls.__new__(cls)
    obj.__fields = fields
    with scope(name) as path:
      obj._path = path
    obj._submodules = {}
    init = _scope_method(cls.__init__)
    init(obj, *args, **kwargs)
    return obj


def _scope_method(method):
  @functools.wraps(method)
  def wrapper(self, *args, **kwargs):
    with scope(self._path, absolute=True):
      with jax.named_scope(self._path.split('/')[-1]):
        return method(self, *args, **kwargs)
  return wrapper


class Module(object, metaclass=ModuleMeta):
  """Base class for users to inherit their modules from. Provides automatic
  name scoping via the meta class and helper functions for accessing state."""

  def __repr__(self):
    return f'{self.__class__.__name__}({self.path})'

  @property
  def path(self):
    """The unique name scope of this module instance as a string."""
    return self._path

  @property
  def name(self):
    """The name of this module instance as a string."""
    return self._path.split('/')[-1]

  def get(self, name, *args, **kwargs):
    """Retrieve or create a state entry that belongs to this module."""
    assert '{' not in name, 'Did you forget to format a string?'
    path = self.path + '/' + name
    if name in self._submodules:
      return self._submodules[name]
    if path in context():
      return context()[path]
    ctor, *args = args
    if 'name' in inspect.signature(ctor).parameters:
      kwargs['name'] = name
    value = ctor(*args, **kwargs)
    # We support trees of arrays for easier integration with other libraries.
    flat = jax.tree_util.tree_leaves(value)
    if all(isinstance(x, jnp.ndarray) for x in flat):
      context()[path] = value
      # Look up the value again to make sure we are registering it as an
      # accessed key in the context.
      return context()[path]
    else:
      self._submodules[name] = value
      return value

  def put(self, *args):
    """Update or create state entries that belong to this module. The arguments
    are either string name and value of a single state entry or a dict holding
    multiple state entries."""
    if len(args) == 2:
      name, value = args
      self.put({self.path + '/' + name: value})
      return value
    assert len(args) == 1 and isinstance(args[0], dict)
    mapping = args[0]
    prefix = self.path + '/'
    for key in mapping:
      if not key.startswith(prefix):
        raise KeyError(f'Key {key} does not belong to module {self.path}.')
    context().update(mapping)

  def find(self, pattern=r'.*', empty_ok=False):
    """Find the state entries of this module, optionally filtered by regex."""
    pattern = re.compile(pattern)
    prefix = self.path + '/'
    results = {}
    for key, value in context().items():
      if not key.startswith(prefix):
        continue
      if pattern.match(key[len(prefix):]):
        results[key] = value
    if not empty_ok and not results:
      raise KeyError(f'Pattern {pattern} matched no state keys.')
    return results


class Variable(Module):

  def __init__(self, ctor, *args, **kwargs):
    self.ctor = ctor
    self.args = args
    self.kwargs = kwargs

  def read(self):
    return self.get('value', self.ctor, *self.args, **self.kwargs)

  def write(self, value):
    return self.put('value', value)


###############################################################################
# Integrations
###############################################################################


def FromFlax(ctor):
  class FlaxModule(Module):
    def __init__(self, *args, **kwargs):
      self.module = ctor(*args, **kwargs)
    def __call__(self, *args, **kwargs):
      seed_ = seed() if creating() else None
      state = self.get('flax', self.module.init, seed_, *args, **kwargs)
      return self.module.apply(state, *args, **kwargs)
  return FlaxModule


def FromHaiku(ctor):
  class HaikuModule(Module):
    def __init__(self, *args, **kwargs):
      import haiku as hk
      def net(*args_, **kwargs_):
        return ctor(*args, **kwargs)(*args_, **kwargs_)
      self.transformed = hk.transform(net)
    def __call__(self, *args, **kwargs):
      seed_ = seed() if creating() else None
      state = self.get('haiku', self.transformed.init, seed_, *args, **kwargs)
      return self.transformed.apply(state, seed_, *args, **kwargs)
  return HaikuModule


def FromOptax(ctor):
  class OptaxModule(Module):
    def __init__(self, *args, **kwargs):
      self.opt = ctor(*args, **kwargs)
    def __call__(self, loss, keys, *args, **kwargs):
      import optax
      loss, params, grads = grad(loss, keys)(*args, **kwargs)
      optstate = self.get('state', self.opt.init, params)
      updates, optstate = self.opt.update(grads, optstate)
      self.put('state', optstate)
      context().update(optax.apply_updates(params, updates))
      return loss, params, grads
  return OptaxModule

</dreamerv3/ninjax.py>

<dreamerv3/requirements.txt>
chex
einops
jax[cuda12_pip]
jaxlib
optax
tensorflow_probability

</dreamerv3/requirements.txt>

<dreamerv3/__init__.py>
from .agent import Agent
from .main import wrap_env

</dreamerv3/__init__.py>

<embodied/core/agg.py>
import math
import operator
from collections import defaultdict
from functools import partial as bind

import numpy as np


class Agg:

  def __init__(self, maxlen=1e6):
    self.reducers = defaultdict(list)
    self.names = {}
    self.maxlen = int(maxlen)

  def add(self, key_or_dict, value=None, agg='default', prefix=None):
    if value is not None:
      self._add_single(key_or_dict, value, agg, prefix)
      return
    for key, value in key_or_dict.items():
      self._add_single(key, value, agg, prefix)

  def result(self, reset=True, prefix=None):
    metrics = {}
    for key, reducers in self.reducers.items():
      if len(reducers) == 1:
        metrics[key] = reducers[0].current()
      else:
        for name, reducer in zip(self.names[key], reducers):
          metrics[f'{key}/{name}'] = reducer.current()
    if prefix:
      metrics = {f'{prefix}/{k}': v for k, v in metrics.items()}
    reset and self.reset()
    return metrics

  def reset(self):
    self.reducers.clear()

  def _add_single(self, key, value, agg, prefix):
    key = f'{prefix}/{key}' if prefix else key
    reducers = self.reducers[key]
    if reducers:
      for reducer in reducers:
        reducer.update(value)
      return
    if agg == 'default':
      agg = 'avg' if np.asarray(value).ndim <= 1 else 'last'
    if isinstance(agg, str):
      aggs = (agg,)
      self.names[key] = None
    else:
      aggs = agg
      self.names[key] = aggs
    for agg in aggs:
      if agg == 'avg':
        reducer = Mean(value)
      elif agg == 'sum':
        reducer = Sum(value)
      elif agg == 'min':
        reducer = Min(value)
      elif agg == 'max':
        reducer = Max(value)
      elif agg == 'stack':
        reducer = Stack(value, self.maxlen)
      elif agg == 'last':
        reducer = Last(value)
      else:
        raise ValueError(agg)
      reducers.append(reducer)


class Reducer:

  def __init__(self, scalar_fn, array_fn, initial):
    self.is_scalar = isinstance(initial, (int, float))
    self.fn = scalar_fn if self.is_scalar else array_fn
    self.interm = self._input(initial)
    self.count = 1

  def update(self, value):
    value = self._input(value)
    if self._isnan(value):
      return
    if self._isnan(self.interm):
      self.interm = value
      return
    self.interm = self.fn(self.interm, value)
    self.count += 1

  def current(self):
    return np.array(self.interm)

  def _input(self, value):
    if self.is_scalar:
      return value
    else:
      return np.asarray(value, np.float64)

  def _isnan(self, value):
    if self.is_scalar:
      return math.isnan(value)
    else:
      return np.isnan(value).any()


class Mean:

  def __init__(self, initial):
    self.reducer = Sum(initial)

  def update(self, value):
    self.reducer.update(value)

  def current(self):
    return self.reducer.current() / self.reducer.count


class Stack:

  def __init__(self, initial, maxlen=1e5):
    self.stack = [initial]
    self.maxlen = int(maxlen)

  def update(self, value):
    if len(self.stack) < self.maxlen:
      self.stack.append(value)

  def current(self):
    return np.stack(self.stack)


class Last:

  def __init__(self, initial):
    self.value = initial

  def update(self, value):
    self.value = value

  def current(self):
    return self.value


Sum = bind(
    Reducer, operator.add, lambda x, y: np.add(x, y, out=x, dtype=np.float64))
Min = bind(
    Reducer, min, lambda x, y: np.minimum(x, y, out=x, dtype=np.float64))
Max = bind(
    Reducer, max, lambda x, y: np.maximum(x, y, out=x, dtype=np.float64))

</embodied/core/agg.py>

<embodied/core/base.py>
class Agent:

  configs = {}  # Dict of dicts, must contain 'defaults' key.

  def __init__(self, obs_space, act_space, config):
    pass

  def init_policy(self, batch_size):
    raise NotImplementedError(
        "init_policy(batch_size) -> carry")

  def init_train(self, batch_size):
    raise NotImplementedError(
        "init_train(batch_size) -> carry")

  def init_report(self, batch_size):
    raise NotImplementedError(
        "init_report(batch_size) -> carry")

  def policy(self, obs, carry=None, mode='train'):
    raise NotImplementedError(
        "policy(obs, carry=None, mode='train') -> act, out, carry")

  def train(self, data, carry=None):
    raise NotImplementedError(
        'train(data, carry=None) -> outs, carry, metrics')

  def report(self, data, carry=None):
    raise NotImplementedError(
        'report(data, carry=None) -> metrics, carry')

  def dataset(self, generator_fn):
    raise NotImplementedError(
        'dataset(generator_fn) -> generator_fn')

  def save(self):
    raise NotImplementedError('save() -> data')

  def load(self, data):
    raise NotImplementedError('load(data) -> None')

  @property
  def aux_spaces(self):
    return {}


class Env:

  def __len__(self):
    return 0  # Return positive integer for batched envs.

  def __bool__(self):
    return True  # Env is always truthy, despite length zero.

  def __repr__(self):
    return (
        f'{self.__class__.__name__}('
        f'len={len(self)}, '
        f'obs_space={self.obs_space}, '
        f'act_space={self.act_space})')

  @property
  def obs_space(self):
    # The observation space must contain the keys is_first, is_last, and
    # is_terminal. Commonly, it also contains the keys reward and image. By
    # convention, keys starting with log_ are not consumed by the agent.
    raise NotImplementedError('Returns: dict of spaces')

  @property
  def act_space(self):
    # The observation space must contain the keys action and reset. This
    # restriction may be lifted in the future.
    raise NotImplementedError('Returns: dict of spaces')

  def step(self, action):
    raise NotImplementedError('Returns: dict')

  def render(self):
    raise NotImplementedError('Returns: array')

  def close(self):
    pass


class Wrapper:

  def __init__(self, env):
    self.env = env

  def __len__(self):
    return len(self.env)

  def __bool__(self):
    return bool(self.env)

  def __getattr__(self, name):
    if name.startswith('__'):
      raise AttributeError(name)
    try:
      return getattr(self.env, name)
    except AttributeError:
      raise ValueError(name)


class Replay:

  def __len__(self):
    raise NotImplementedError('Returns: total number of steps')

  @property
  def stats(self):
    raise NotImplementedError('Returns: metrics')

  def add(self, transition, worker=0):
    raise NotImplementedError('Returns: None')

  def add_traj(self, trajectory):
    raise NotImplementedError('Returns: None')

  def dataset(self):
    raise NotImplementedError('Yields: trajectory')

  def prioritize(self, keys, priorities):
    pass

  def save(self):
    pass

  def load(self, data):
    pass

</embodied/core/base.py>

<embodied/core/checkpoint.py>
import concurrent.futures
import pickle
import time

from . import path
from . import printing
from . import timer


class Checkpoint:

  def __init__(self, filename=None, parallel=True):
    self._filename = filename and path.Path(filename)
    self._values = {}
    self._parallel = parallel
    if self._parallel:
      self._worker = concurrent.futures.ThreadPoolExecutor(1, 'checkpoint')
      self._promise = None

  def __setattr__(self, name, value):
    if name in ('exists', 'save', 'load'):
      return super().__setattr__(name, value)
    if name.startswith('_'):
      return super().__setattr__(name, value)
    has_load = hasattr(value, 'load') and callable(value.load)
    has_save = hasattr(value, 'save') and callable(value.save)
    if not (has_load and has_save):
      message = f"Checkpoint entry '{name}' must implement save() and load()."
      raise ValueError(message)
    self._values[name] = value

  def __getattr__(self, name):
    if name.startswith('_'):
      raise AttributeError(name)
    try:
      return self._values[name]
    except AttributeError:
      raise ValueError(name)

  def exists(self, filename=None):
    assert self._filename or filename
    filename = path.Path(filename or self._filename)
    exists = self._filename.exists()
    if exists:
      print('Found existing checkpoint.')
    else:
      print('Did not find any checkpoint.')
    return exists

  def save(self, filename=None, keys=None):
    assert self._filename or filename
    filename = path.Path(filename or self._filename)
    printing.print_(f'Writing checkpoint: {filename}')
    if self._parallel:
      self._promise and self._promise.result()
      self._promise = self._worker.submit(self._save, filename, keys)
    else:
      self._save(filename, keys)

  @timer.section('checkpoint_save')
  def _save(self, filename, keys):
    keys = tuple(self._values.keys() if keys is None else keys)
    assert all([not k.startswith('_') for k in keys]), keys
    data = {k: self._values[k].save() for k in keys}
    data['_timestamp'] = time.time()
    filename.parent.mkdir()
    content = pickle.dumps(data)
    if str(filename).startswith('gs://'):
      filename.write(content, mode='wb')
    else:
      # Write to a temporary file and then atomically rename, so that the file
      # either contains a complete write or not update at all if writing was
      # interrupted.
      tmp = filename.parent / (filename.name + '.tmp')
      tmp.write(content, mode='wb')
      tmp.move(filename)
    print('Wrote checkpoint.')

  @timer.section('checkpoint_load')
  def load(self, filename=None, keys=None):
    assert self._filename or filename
    self._promise and self._promise.result()  # Wait for last save.
    filename = path.Path(filename or self._filename)
    printing.print_(f'Loading checkpoint: {filename}')
    data = pickle.loads(filename.read('rb'))
    keys = tuple(data.keys() if keys is None else keys)
    for key in keys:
      if key.startswith('_'):
        continue
      try:
        self._values[key].load(data[key])
      except Exception:
        print(f"Error loading '{key}' from checkpoint.")
        raise
    age = time.time() - data['_timestamp']
    printing.print_(f'Loaded checkpoint from {age:.0f} seconds ago.')

  def load_or_save(self):
    if self.exists():
      self.load()
    else:
      self.save()

</embodied/core/checkpoint.py>

<embodied/core/config.py>
import io
import json
import re

from . import path


class Config(dict):

  SEP = '.'
  IS_PATTERN = re.compile(r'.*[^A-Za-z0-9_.-].*')

  def __init__(self, *args, **kwargs):
    mapping = dict(*args, **kwargs)
    mapping = self._flatten(mapping)
    mapping = self._ensure_keys(mapping)
    mapping = self._ensure_values(mapping)
    self._flat = mapping
    self._nested = self._nest(mapping)
    # Need to assign the values to the base class dictionary so that
    # conversion to dict does not lose the content.
    super().__init__(self._nested)

  @property
  def flat(self):
    return self._flat.copy()

  def save(self, filename):
    filename = path.Path(filename)
    if filename.suffix == '.json':
      filename.write(json.dumps(dict(self)))
    elif filename.suffix in ('.yml', '.yaml'):
      from ruamel.yaml import YAML
      yaml = YAML(typ='safe')
      with io.StringIO() as stream:
        yaml.dump(dict(self), stream)
        filename.write(stream.getvalue())
    else:
      raise NotImplementedError(filename.suffix)

  @classmethod
  def load(cls, filename):
    filename = path.Path(filename)
    if filename.suffix == '.json':
      return cls(json.loads(filename.read_text()))
    elif filename.suffix in ('.yml', '.yaml'):
      from ruamel.yaml import YAML
      yaml = YAML(typ='safe')
      return cls(yaml.load(filename.read_text()))
    else:
      raise NotImplementedError(filename.suffix)

  def __contains__(self, name):
    try:
      self[name]
      return True
    except KeyError:
      return False

  def __getattr__(self, name):
    if name.startswith('_'):
      return super().__getattr__(name)
    try:
      return self[name]
    except KeyError:
      raise AttributeError(name)

  def __getitem__(self, name):
    result = self._nested
    for part in name.split(self.SEP):
      try:
        result = result[part]
      except TypeError:
        raise KeyError
    if isinstance(result, dict):
      result = type(self)(result)
    return result

  def __setattr__(self, key, value):
    if key.startswith('_'):
      return super().__setattr__(key, value)
    message = f"Tried to set key '{key}' on immutable config. Use update()."
    raise AttributeError(message)

  def __setitem__(self, key, value):
    if key.startswith('_'):
      return super().__setitem__(key, value)
    message = f"Tried to set key '{key}' on immutable config. Use update()."
    raise AttributeError(message)

  def __reduce__(self):
    return (type(self), (dict(self),))

  def __str__(self):
    lines = ['\nConfig:']
    keys, vals, typs = [], [], []
    for key, val in self.flat.items():
      keys.append(key + ':')
      vals.append(self._format_value(val))
      typs.append(self._format_type(val))
    max_key = max(len(k) for k in keys) if keys else 0
    max_val = max(len(v) for v in vals) if vals else 0
    for key, val, typ in zip(keys, vals, typs):
      key = key.ljust(max_key)
      val = val.ljust(max_val)
      lines.append(f'{key}  {val}  ({typ})')
    return '\n'.join(lines)

  def update(self, *args, **kwargs):
    result = self._flat.copy()
    inputs = self._flatten(dict(*args, **kwargs))
    for key, new in inputs.items():
      if self.IS_PATTERN.match(key):
        pattern = re.compile(key)
        keys = {k for k in result if pattern.match(k)}
      else:
        keys = [key]
      if not keys:
        raise KeyError(f'Unknown key or pattern {key}.')
      for key in keys:
        old = result[key]
        try:
          if isinstance(old, int) and isinstance(new, float):
            if float(int(new)) != new:
              message = f"Cannot convert fractional float {new} to int."
              raise ValueError(message)
          result[key] = type(old)(new)
        except (ValueError, TypeError):
          raise TypeError(
              f"Cannot convert '{new}' to type '{type(old).__name__}' " +
              f"for key '{key}' with previous value '{old}'.")
    return type(self)(result)

  def _flatten(self, mapping):
    result = {}
    for key, value in mapping.items():
      if isinstance(value, dict):
        for k, v in self._flatten(value).items():
          if self.IS_PATTERN.match(key) or self.IS_PATTERN.match(k):
            combined = f'{key}\\{self.SEP}{k}'
          else:
            combined = f'{key}{self.SEP}{k}'
          result[combined] = v
      else:
        result[key] = value
    return result

  def _nest(self, mapping):
    result = {}
    for key, value in mapping.items():
      parts = key.split(self.SEP)
      node = result
      for part in parts[:-1]:
        if part not in node:
          node[part] = {}
        node = node[part]
      node[parts[-1]] = value
    return result

  def _ensure_keys(self, mapping):
    for key in mapping:
      assert not self.IS_PATTERN.match(key), key
    return mapping

  def _ensure_values(self, mapping):
    result = json.loads(json.dumps(mapping))
    for key, value in result.items():
      if isinstance(value, list):
        value = tuple(value)
      if isinstance(value, tuple):
        if len(value) == 0:
          message = 'Empty lists are disallowed because their type is unclear.'
          raise TypeError(message)
        if not isinstance(value[0], (str, float, int, bool)):
          message = 'Lists can only contain strings, floats, ints, bools'
          message += f' but not {type(value[0])}'
          raise TypeError(message)
        if not all(isinstance(x, type(value[0])) for x in value[1:]):
          message = 'Elements of a list must all be of the same type.'
          raise TypeError(message)
      result[key] = value
    return result

  def _format_value(self, value):
    if isinstance(value, (list, tuple)):
      return '[' + ', '.join(self._format_value(x) for x in value) + ']'
    return str(value)

  def _format_type(self, value):
    if isinstance(value, (list, tuple)):
      assert len(value) > 0, value
      return self._format_type(value[0]) + 's'
    return str(type(value).__name__)

</embodied/core/config.py>

<embodied/core/counter.py>
import functools
import threading


@functools.total_ordering
class Counter:

  def __init__(self, initial=0):
    self.value = initial
    self.lock = threading.Lock()

  def __repr__(self):
    return f'Counter({self.value})'

  def __int__(self):
    return int(self.value)

  def __eq__(self, other):
    return int(self) == other

  def __ne__(self, other):
    return int(self) != other

  def __lt__(self, other):
    return int(self) < other

  def __add__(self, other):
    return int(self) + other

  def __radd__(self, other):
    return other - int(self)

  def __sub__(self, other):
    return int(self) - other

  def __rsub__(self, other):
    return other - int(self)

  def increment(self, amount=1):
    with self.lock:
      self.value += amount

  def reset(self):
    with self.lock:
      self.value = 0

  def save(self):
    return self.value

  def load(self, value):
    self.value = value

</embodied/core/counter.py>

<embodied/core/driver.py>
import time

import cloudpickle
import numpy as np

from .. import distr


class Driver:

  def __init__(self, make_env_fns, parallel=True, **kwargs):
    assert len(make_env_fns) >= 1
    self.parallel = parallel
    self.kwargs = kwargs
    self.length = len(make_env_fns)
    if parallel:
      import multiprocessing as mp
      context = mp.get_context()
      self.pipes, pipes = zip(*[context.Pipe() for _ in range(self.length)])
      fns = [cloudpickle.dumps(fn) for fn in make_env_fns]
      self.procs = [
          distr.StoppableProcess(self._env_server, i, pipe, fn, start=True)
          for i, (fn, pipe) in enumerate(zip(fns, pipes))]
      self.pipes[0].send(('act_space',))
      self.act_space = self._receive(self.pipes[0])
    else:
      self.envs = [fn() for fn in make_env_fns]
      self.act_space = self.envs[0].act_space
    self.callbacks = []
    self.acts = None
    self.carry = None
    self.reset()

  def reset(self, init_policy=None):
    self.acts = {
        k: np.zeros((self.length,) + v.shape, v.dtype)
        for k, v in self.act_space.items()}
    self.acts['reset'] = np.ones(self.length, bool)
    self.carry = init_policy and init_policy(self.length)

  def close(self):
    if self.parallel:
      [proc.stop() for proc in self.procs]
    else:
      [env.close() for env in self.envs]

  def on_step(self, callback):
    self.callbacks.append(callback)

  def __call__(self, policy, steps=0, episodes=0):
    step, episode = 0, 0
    while step < steps or episode < episodes:
      step, episode = self._step(policy, step, episode)

  def _step(self, policy, step, episode):
    acts = self.acts
    assert all(len(x) == self.length for x in acts.values())
    assert all(isinstance(v, np.ndarray) for v in acts.values())
    acts = [{k: v[i] for k, v in acts.items()} for i in range(self.length)]
    if self.parallel:
      [pipe.send(('step', act)) for pipe, act in zip(self.pipes, acts)]
      obs = [self._receive(pipe) for pipe in self.pipes]
    else:
      obs = [env.step(act) for env, act in zip(self.envs, acts)]
    obs = {k: np.stack([x[k] for x in obs]) for k in obs[0].keys()}
    assert all(len(x) == self.length for x in obs.values()), obs
    acts, outs, self.carry = policy(obs, self.carry, **self.kwargs)
    assert all(k not in acts for k in outs), (
        list(outs.keys()), list(acts.keys()))
    if obs['is_last'].any():
      mask = ~obs['is_last']
      acts = {k: self._mask(v, mask) for k, v in acts.items()}
    acts['reset'] = obs['is_last'].copy()
    self.acts = acts
    trans = {**obs, **acts, **outs}
    for i in range(self.length):
      trn = {k: v[i] for k, v in trans.items()}
      [fn(trn, i, **self.kwargs) for fn in self.callbacks]
    step += len(obs['is_first'])
    episode += obs['is_last'].sum()
    return step, episode

  def _mask(self, value, mask):
    while mask.ndim < value.ndim:
      mask = mask[..., None]
    return value * mask.astype(value.dtype)

  def _receive(self, pipe):
    try:
      msg, arg = pipe.recv()
      if msg == 'error':
        raise RuntimeError(arg)
      assert msg == 'result'
      return arg
    except Exception:
      print('Terminating workers due to an exception.')
      [proc.kill() for proc in self.procs]
      raise

  @staticmethod
  def _env_server(context, envid, pipe, ctor):
    try:
      ctor = cloudpickle.loads(ctor)
      env = ctor()
      while context.running:
        if not pipe.poll(0.1):
          time.sleep(0.1)
          continue
        try:
          msg, *args = pipe.recv()
        except EOFError:
          return
        if msg == 'step':
          assert len(args) == 1
          act = args[0]
          obs = env.step(act)
          pipe.send(('result', obs))
        elif msg == 'obs_space':
          assert len(args) == 0
          pipe.send(('result', env.obs_space))
        elif msg == 'act_space':
          assert len(args) == 0
          pipe.send(('result', env.act_space))
        else:
          raise ValueError(f'Invalid message {msg}')
    except Exception as e:
      distr.warn_remote_error(e, f'Env{envid}')
      pipe.send(('error', e))
    finally:
      print(f'Closing env {envid}')
      env.close()
      pipe.close()

</embodied/core/driver.py>

<embodied/core/flags.py>
import re
import sys

from . import config


class Flags:

  def __init__(self, *args, **kwargs):
    self._config = config.Config(*args, **kwargs)

  def parse(self, argv=None, help_exits=True):
    parsed, remaining = self.parse_known(argv)
    for flag in remaining:
      if flag.startswith('--') and flag[2:] not in self._config.flat:
        raise KeyError(f"Flag '{flag}' did not match any config keys.")
    if remaining:
      raise ValueError(
          f'Could not parse all arguments. Remaining: {remaining}')
    return parsed

  def parse_known(self, argv=None, help_exits=False):
    if argv is None:
      argv = sys.argv[1:]
    if '--help' in argv:
      print('\nHelp:')
      lines = str(self._config).split('\n')[2:]
      print('\n'.join('--' + re.sub(r'[:,\[\]]', '', x) for x in lines))
      help_exits and sys.exit()
    parsed = {}
    remaining = []
    key = None
    vals = None
    for arg in argv:
      if arg.startswith('--'):
        if key:
          self._submit_entry(key, vals, parsed, remaining)
        if '=' in arg:
          key, val = arg.split('=', 1)
          vals = [val]
        else:
          key, vals = arg, []
      else:
        if key:
          vals.append(arg)
        else:
          remaining.append(arg)
    self._submit_entry(key, vals, parsed, remaining)
    parsed = self._config.update(parsed)
    return parsed, remaining

  def _submit_entry(self, key, vals, parsed, remaining):
    if not key and not vals:
      return
    if not key:
      vals = ', '.join(f"'{x}'" for x in vals)
      remaining.extend(vals)
      return
      # raise ValueError(f"Values {vals} were not preceded by any flag.")
    name = key[len('--'):]
    if '=' in name:
      remaining.extend([key] + vals)
      return
    if not vals:
      remaining.extend([key])
      return
      # raise ValueError(f"Flag '{key}' was not followed by any values.")
    if name.endswith('+') and name[:-1] in self._config:
      key = name[:-1]
      default = self._config[key]
      if not isinstance(default, tuple):
        raise TypeError(
            f"Cannot append to key '{key}' which is of type "
            f"'{type(default).__name__}' instead of tuple.")
      if key not in parsed:
        parsed[key] = default
      parsed[key] += self._parse_flag_value(default, vals, key)
    elif self._config.IS_PATTERN.fullmatch(name):
      pattern = re.compile(name)
      keys = [k for k in self._config.flat if pattern.fullmatch(k)]
      if keys:
        for key in keys:
          parsed[key] = self._parse_flag_value(self._config[key], vals, key)
      else:
        remaining.extend([key] + vals)
    elif name in self._config:
      key = name
      parsed[key] = self._parse_flag_value(self._config[key], vals, key)
    else:
      remaining.extend([key] + vals)

  def _parse_flag_value(self, default, value, key):
    value = value if isinstance(value, (tuple, list)) else (value,)
    if isinstance(default, (tuple, list)):
      if len(value) == 1 and ',' in value[0]:
        value = value[0].split(',')
      return tuple(self._parse_flag_value(default[0], [x], key) for x in value)
    if len(value) != 1:
      raise TypeError(
          f"Expected a single value for key '{key}' but got: {value}")
    value = str(value[0])
    if default is None:
      return value
    if isinstance(default, bool):
      try:
        return bool(['False', 'True'].index(value))
      except ValueError:
        message = f"Expected bool but got '{value}' for key '{key}'."
        raise TypeError(message)
    if isinstance(default, int):
      try:
        value = float(value)  # Allow scientific notation for integers.
        assert float(int(value)) == value
      except (ValueError, TypeError, AssertionError):
        message = f"Expected int but got '{value}' for key '{key}'."
        raise TypeError(message)
      return int(value)
    if isinstance(default, dict):
      raise KeyError(
          f"Key '{key}' refers to a whole dict. Please speicfy a subkey.")
    try:
      return type(default)(value)
    except ValueError:
      raise TypeError(
          f"Cannot convert '{value}' to type '{type(default).__name__}' for "
          f"key '{key}'.")

</embodied/core/flags.py>

<embodied/core/fps.py>
import time


class FPS:

  def __init__(self):
    self.start = time.time()
    self.count = 0

  def step(self, amount=1):
    self.count += amount

  def result(self, reset=True):
    now = time.time()
    fps = self.count / (now - self.start)
    if reset:
      self.start = now
      self.count = 0
    return fps

</embodied/core/fps.py>

<embodied/core/logger.py>
import collections
import concurrent.futures
import json
import os
import re

import numpy as np

from . import path
from . import printing
from . import timer


class Logger:

  def __init__(self, step, outputs, multiplier=1):
    assert outputs, 'Provide a list of logger outputs.'
    self.step = step
    self.outputs = outputs
    self.multiplier = multiplier
    self._last_step = None
    self._last_time = None
    self._metrics = []

  @timer.section('logger_add')
  def add(self, mapping, prefix=None):
    mapping = dict(mapping)
    # print('logger add:', len(mapping))
    assert len(mapping) <= 1000, list(mapping.keys())
    for key in mapping.keys():
      assert len(key) <= 200, (len(key), key[:200] + '...')
    step = int(self.step) * self.multiplier
    for name, value in mapping.items():
      name = f'{prefix}/{name}' if prefix else name
      if isinstance(value, np.ndarray) and np.issubdtype(value.dtype, str):
        value = str(value)
      if not isinstance(value, str):
        value = np.asarray(value)
        if len(value.shape) not in (0, 1, 2, 3, 4):
          raise ValueError(
              f"Shape {value.shape} for name '{name}' cannot be "
              "interpreted as scalar, vector, image, or video.")
      self._metrics.append((step, name, value))

  def scalar(self, name, value):
    value = np.asarray(value)
    assert len(value.shape) == 0, value.shape
    self.add({name: value})

  def vector(self, name, value):
    value = np.asarray(value)
    assert len(value.shape) == 1, value.shape
    self.add({name: value})

  def image(self, name, value):
    value = np.asarray(value)
    assert len(value.shape) in (2, 3), value.shape
    self.add({name: value})

  def video(self, name, value):
    value = np.asarray(value)
    assert len(value.shape) == 4, value.shape
    self.add({name: value})

  def text(self, name, value):
    assert isinstance(value, str), (type(value), str(value)[:100])
    self.add({name: value})

  @timer.section('logger_write')
  def write(self):
    if not self._metrics:
      return
    for output in self.outputs:
      output(tuple(self._metrics))
    self._metrics.clear()

  def close(self):
    self.write()
    for output in self.outputs:
      if hasattr(output, 'wait'):
        try:
          output.wait()
        except Exception as e:
          print(f'Error waiting on output: {e}')

  def __del__(self):
    self.close()
    for output in self.outputs:
      if hasattr(output, 'cleanup'):
        output.cleanup()


class AsyncOutput:

  def __init__(self, callback, parallel=True):
    self._callback = callback
    self._parallel = parallel
    if parallel:
      name = type(self).__name__
      self._worker = concurrent.futures.ThreadPoolExecutor(
          1, f'logger_{name}_async')
      self._future = None

  def wait(self):
    if self._parallel and self._future:
      concurrent.futures.wait([self._future])

  def __call__(self, summaries):
    if self._parallel:
      self._future and self._future.result()
      self._future = self._worker.submit(self._callback, summaries)
    else:
      self._callback(summaries)

  def cleanup(self):
    if self._parallel:
      self._worker.shutdown(wait=True)


class TerminalOutput:

  def __init__(self, pattern=r'.*', name=None, limit=50):
    self._pattern = (pattern != r'.*') and re.compile(pattern)
    self._name = name
    self._limit = limit

  @timer.section('terminal')
  def __call__(self, summaries):
    step = max(s for s, _, _, in summaries)
    scalars = {
        k: float(v) for _, k, v in summaries
        if isinstance(v, np.ndarray) and len(v.shape) == 0}
    if self._pattern:
      scalars = {k: v for k, v in scalars.items() if self._pattern.search(k)}
    else:
      truncated = 0
      if len(scalars) > self._limit:
        truncated = len(scalars) - self._limit
        scalars = dict(list(scalars.items())[:self._limit])
    formatted = {k: self._format_value(v) for k, v in scalars.items()}
    if self._name:
      header = f'{"-" * 20}[{self._name} Step {step}]{"-" * 20}'
    else:
      header = f'{"-" * 20}[Step {step}]{"-" * 20}'
    content = ''
    if self._pattern:
      content += f"Metrics filtered by: '{self._pattern.pattern}'"
    elif truncated:
      content += f'{truncated} metrics truncated, filter to see specific keys.'
    content += '\n'
    if formatted:
      content += ' / '.join(f'{k} {v}' for k, v in formatted.items())
    else:
      content += 'No metrics.'
    printing.print_(f'\n{header}\n{content}\n', flush=True)

  def _format_value(self, value):
    value = float(value)
    if value == 0:
      return '0'
    elif 0.01 < abs(value) < 10000:
      value = f'{value:.2f}'
      value = value.rstrip('0')
      value = value.rstrip('0')
      value = value.rstrip('.')
      return value
    else:
      value = f'{value:.1e}'
      value = value.replace('.0e', 'e')
      value = value.replace('+0', '')
      value = value.replace('+', '')
      value = value.replace('-0', '-')
    return value

  def cleanup(self):
    pass


class JSONLOutput(AsyncOutput):

  def __init__(
      self, logdir, filename='metrics.jsonl', pattern=r'.*',
      strings=False, parallel=True):
    super().__init__(self._write, parallel)
    self._pattern = re.compile(pattern)
    self._strings = strings
    logdir = path.Path(logdir)
    logdir.mkdir()
    self._filename = logdir / filename

  @timer.section('jsonl')
  def _write(self, summaries):
    bystep = collections.defaultdict(dict)
    for step, name, value in summaries:
      if not self._pattern.search(name):
        continue
      if isinstance(value, str) and self._strings:
        bystep[step][name] = value
      if isinstance(value, np.ndarray) and len(value.shape) == 0:
        bystep[step][name] = float(value)
    lines = ''.join([
        json.dumps({'step': step, **scalars}) + '\n'
        for step, scalars in bystep.items()])
    printing.print_(f'Writing metrics: {self._filename}')
    with self._filename.open('a') as f:
      f.write(lines)


class TensorBoardOutput(AsyncOutput):

  def __init__(
      self, logdir, fps=20, videos=True, maxsize=1e9, parallel=True):
    super().__init__(self._write, parallel)
    self._logdir = str(logdir)
    if self._logdir.startswith('/gcs/'):
      self._logdir = self._logdir.replace('/gcs/', 'gs://')
    self._fps = fps
    self._writer = None
    self._maxsize = self._logdir.startswith('gs://') and maxsize
    self._videos = videos
    if self._maxsize:
      self._checker = concurrent.futures.ThreadPoolExecutor(max_workers=1)
      self._promise = None
    import tensorflow as tf
    tf.config.set_visible_devices([], 'GPU')
    tf.config.set_visible_devices([], 'TPU')

  @timer.section('tensorboard_write')
  def _write(self, summaries):
    import tensorflow as tf
    reset = False
    if self._maxsize:
      result = self._promise and self._promise.result()
      # print('Current TensorBoard event file size:', result)
      reset = (self._promise and result >= self._maxsize)
      self._promise = self._checker.submit(self._check)
    if not self._writer or reset:
      print('Creating new TensorBoard event file writer.')
      self._writer = tf.summary.create_file_writer(
          self._logdir, flush_millis=1000, max_queue=10000)
    self._writer.set_as_default()
    for step, name, value in summaries:
      try:
        if isinstance(value, str):
          tf.summary.text(name, value, step)
        elif len(value.shape) == 0:
          tf.summary.scalar(name, value, step)
        elif len(value.shape) == 1:
          if len(value) > 1024:
            value = value.copy()
            np.random.shuffle(value)
            value = value[:1024]
          tf.summary.histogram(name, value, step)
        elif len(value.shape) == 2:
          tf.summary.image(name, value[None, ..., None], step)
        elif len(value.shape) == 3:
          tf.summary.image(name, value[None], step)
        elif len(value.shape) == 4 and self._videos:
          self._video_summary(name, value, step)
      except Exception:
        print('Error writing summary:', name)
        raise
    self._writer.flush()

  @timer.section('tensorboard_check')
  def _check(self):
    import tensorflow as tf
    events = tf.io.gfile.glob(self._logdir.rstrip('/') + '/events.out.*')
    return tf.io.gfile.stat(sorted(events)[-1]).length if events else 0

  @timer.section('tensorboard_video')
  def _video_summary(self, name, video, step):
    import tensorflow as tf
    import tensorflow.compat.v1 as tf1
    name = name if isinstance(name, str) else name.decode('utf-8')
    assert video.dtype in (np.float32, np.uint8), (video.shape, video.dtype)
    if np.issubdtype(video.dtype, np.floating):
      video = np.clip(255 * video, 0, 255).astype(np.uint8)
    try:
      T, H, W, C = video.shape
      summary = tf1.Summary()
      image = tf1.Summary.Image(height=H, width=W, colorspace=C)
      image.encoded_image_string = _encode_gif(video, self._fps)
      summary.value.add(tag=name, image=image)
      tf.summary.experimental.write_raw_pb(summary.SerializeToString(), step)
    except (IOError, OSError) as e:
      print('GIF summaries require ffmpeg in $PATH.', e)
      tf.summary.image(name, video, step)


class WandBOutput:

  def __init__(self, logdir, config, pattern=r'.*', **kwargs):
    self._pattern = re.compile(pattern)
    import wandb
    wandb.init(
        dir=logdir.name,
        config=dict(config),
        project="omni_epic",
        entity="airl-lab",
        **kwargs,
    )
    self._wandb = wandb

  def __call__(self, summaries):
    bystep = collections.defaultdict(dict)
    wandb = self._wandb
    for step, name, value in summaries:
      if not self._pattern.search(name):
        continue
      if isinstance(value, str):
        bystep[step][name] = value
      elif len(value.shape) == 0:
        bystep[step][name] = float(value)
      elif len(value.shape) == 1:
        bystep[step][name] = wandb.Histogram(value)
      elif len(value.shape) in (2, 3):
        value = value[..., None] if len(value.shape) == 2 else value
        assert value.shape[3] in [1, 3, 4], value.shape
        if value.dtype != np.uint8:
          value = (255 * np.clip(value, 0, 1)).astype(np.uint8)
        value = np.transpose(value, [2, 0, 1])
        bystep[step][name] = wandb.Image(value)
      elif len(value.shape) == 4:
        assert value.shape[3] in [1, 3, 4], value.shape
        value = np.transpose(value, [0, 3, 1, 2])
        if value.dtype != np.uint8:
          value = (255 * np.clip(value, 0, 1)).astype(np.uint8)
        bystep[step][name] = wandb.Video(value)

    for step, metrics in bystep.items():
      self._wandb.log(metrics, step=step)

  def cleanup(self):
    self._wandb.finish()


class MLFlowOutput:

  def __init__(self, run_name=None, resume_id=None, config=None, prefix=None):
    import mlflow
    self._mlflow = mlflow
    self._prefix = prefix
    self._setup(run_name, resume_id, config)

  def __call__(self, summaries):
    bystep = collections.defaultdict(dict)
    for step, name, value in summaries:
      if len(value.shape) == 0 and self._pattern.search(name):
        name = f'{self._prefix}/{name}' if self._prefix else name
        bystep[step][name] = float(value)
    for step, metrics in bystep.items():
      self._mlflow.log_metrics(metrics, step=step)

  def _setup(self, run_name, resume_id, config):
    tracking_uri = os.environ.get('MLFLOW_TRACKING_URI', 'local')
    run_name = run_name or os.environ.get('MLFLOW_RUN_NAME')
    resume_id = resume_id or os.environ.get('MLFLOW_RESUME_ID')
    print('MLFlow Tracking URI:', tracking_uri)
    print('MLFlow Run Name:    ', run_name)
    print('MLFlow Resume ID:   ', resume_id)
    if resume_id:
      runs = self._mlflow.search_runs(None, f'tags.resume_id="{resume_id}"')
      assert len(runs), ('No runs to resume found.', resume_id)
      self._mlflow.start_run(run_name=run_name, run_id=runs['run_id'].iloc[0])
      for key, value in config.items():
        self._mlflow.log_param(key, value)
    else:
      tags = {'resume_id': resume_id or ''}
      self._mlflow.start_run(run_name=run_name, tags=tags)

  def cleanup(self):
    self._mlflow.end_run()


class ExpaOutput:

  def __init__(self, exp, run, project, user, config=None):
    try:
      import expa
      print(f'Expa: {exp}/{run} ({project})')
      self._expa = expa.Logger(
          exp, run, project, user, api_url='pubsub://expa-dev/ingest')
      if config:
        self._expa.log_params(dict(config))
    except Exception as e:
      print(f'Error exporting Expa: {e}')
      self._expa = None
      return

  def __call__(self, summaries):
    if not self._expa:
      return
    bystep = collections.defaultdict(dict)
    for step, name, value in summaries:
      bystep[step][name] = value
    for step, metrics in bystep.items():
      self._expa.log(metrics, step)

  def cleanup(self):
    if self._expa:
      self._expa.close()


@timer.section('gif')
def _encode_gif(frames, fps):
  from subprocess import Popen, PIPE
  h, w, c = frames[0].shape
  pxfmt = {1: 'gray', 3: 'rgb24'}[c]
  cmd = ' '.join([
      'ffmpeg -y -f rawvideo -vcodec rawvideo',
      f'-r {fps:.02f} -s {w}x{h} -pix_fmt {pxfmt} -i - -filter_complex',
      '[0:v]split[x][z];[z]palettegen[y];[x]fifo[x];[x][y]paletteuse',
      f'-r {fps:.02f} -f gif -'])
  proc = Popen(cmd.split(' '), stdin=PIPE, stdout=PIPE, stderr=PIPE)
  for image in frames:
    proc.stdin.write(image.tobytes())
  out, err = proc.communicate()
  if proc.returncode:
    raise IOError('\n'.join([' '.join(cmd), err.decode('utf8')]))
  del proc
  return out

</embodied/core/logger.py>

<embodied/core/path.py>
import contextlib
import glob as globlib
import os
import re
import shutil


class Path:

  __slots__ = ('_path',)

  filesystems = []

  def __new__(cls, path):
    if cls is not Path:
      return super().__new__(cls)
    path = str(path)
    for impl, pred in cls.filesystems:
      if pred(path):
        obj = super().__new__(impl)
        obj.__init__(path)
        return obj
    raise NotImplementedError(f'No filesystem supports: {path}')

  def __getnewargs__(self):
    return (self._path,)

  def __init__(self, path):
    assert isinstance(path, str)
    path = re.sub(r'^\./*', '', path)  # Remove leading dot or dot slashes.
    path = re.sub(r'(?<=[^/])/$', '', path)  # Remove single trailing slash.
    path = path or '.'  # Empty path is represented by a dot.
    self._path = path

  def __truediv__(self, part):
    sep = '' if self._path.endswith('/') else '/'
    return type(self)(f'{self._path}{sep}{str(part)}')

  def __repr__(self):
    return f'Path({str(self)})'

  def __fspath__(self):
    return str(self)

  def __eq__(self, other):
    return self._path == other._path

  def __lt__(self, other):
    return self._path < other._path

  def __str__(self):
    return self._path

  @property
  def parent(self):
    if '/' not in self._path:
      return type(self)('.')
    parent = self._path.rsplit('/', 1)[0]
    parent = parent or ('/' if self._path.startswith('/') else '.')
    return type(self)(parent)

  @property
  def name(self):
    if '/' not in self._path:
      return self._path
    return self._path.rsplit('/', 1)[1]

  @property
  def stem(self):
    return self.name.split('.', 1)[0] if '.' in self.name else self.name

  @property
  def suffix(self):
    return ('.' + self.name.split('.', 1)[1]) if '.' in self.name else ''

  def read(self, mode='r'):
    assert mode in 'r rb'.split(), mode
    with self.open(mode) as f:
      return f.read()

  def write(self, content, mode='w'):
    assert mode in 'w a wb ab'.split(), mode
    with self.open(mode) as f:
      f.write(content)

  @contextlib.contextmanager
  def open(self, mode='r'):
    raise NotImplementedError

  def absolute(self):
    raise NotImplementedError

  def glob(self, pattern):
    raise NotImplementedError

  def exists(self):
    raise NotImplementedError

  def isfile(self):
    raise NotImplementedError

  def isdir(self):
    raise NotImplementedError

  def mkdir(self):
    raise NotImplementedError

  def remove(self):
    raise NotImplementedError

  def rmtree(self):
    raise NotImplementedError

  def copy(self, dest):
    raise NotImplementedError

  def move(self, dest):
    self.copy(dest)
    self.remove()


class LocalPath(Path):

  __slots__ = ('_path',)

  def __init__(self, path):
    super().__init__(os.path.expanduser(str(path)))

  @contextlib.contextmanager
  def open(self, mode='r'):
    with open(str(self), mode=mode) as f:
      yield f

  def absolute(self):
    return type(self)(os.path.absolute(str(self)))

  def glob(self, pattern):
    for path in globlib.glob(f'{str(self)}/{pattern}'):
      yield type(self)(path)

  def exists(self):
    return os.path.exists(str(self))

  def isfile(self):
    return os.path.isfile(str(self))

  def isdir(self):
    return os.path.isdir(str(self))

  def mkdir(self):
    os.makedirs(str(self), exist_ok=True)

  def remove(self):
    os.rmdir(str(self)) if self.isdir() else os.remove(str(self))

  def rmtree(self):
    shutil.rmtree(self)

  def copy(self, dest):
    if self.isfile():
      shutil.copy(self, type(self)(dest))
    else:
      shutil.copytree(self, type(self)(dest), dirs_exist_ok=True)

  def move(self, dest):
    shutil.move(self, dest)


class GFilePath(Path):

  __slots__ = ('_path',)

  gfile = None

  def __init__(self, path):
    path = str(path)
    if not (path.startswith('/') or '://' in path):
      path = os.path.abspath(os.path.expanduser(path))
    super().__init__(path)
    if not type(self).gfile:
      import tensorflow as tf
      tf.config.set_visible_devices([], 'GPU')
      tf.config.set_visible_devices([], 'TPU')
      type(self).gfile = tf.io.gfile

  @contextlib.contextmanager
  def open(self, mode='r'):
    path = str(self)
    if 'a' in mode and path.startswith('/cns/'):
      path += '%r=3.2'
    if mode.startswith('x') and self.exists():
      raise FileExistsError(path)
      mode = mode.replace('x', 'w')
    with self.gfile.GFile(path, mode) as f:
      yield f

  def absolute(self):
    return self

  def glob(self, pattern):
    for path in self.gfile.glob(f'{str(self)}/{pattern}'):
      yield type(self)(path)

  def exists(self):
    return self.gfile.exists(str(self))

  def isfile(self):
    return self.exists() and not self.isdir()

  def isdir(self):
    return self.gfile.isdir(str(self))

  def mkdir(self):
    self.gfile.makedirs(str(self))

  def remove(self):
    self.gfile.remove(str(self))

  def rmtree(self):
    self.gfile.rmtree(str(self))

  def copy(self, dest):
    dest = type(self)(dest)
    if self.isfile():
      self.gfile.copy(str(self), str(dest), overwrite=True)
    else:
      for folder, subdirs, files in self.gfile.walk(str(self)):
        target = type(self)(folder.replace(str(self), str(dest)))
        target.exists() or target.mkdir()
        for file in files:
          (type(self)(folder) / file).copy(target / file)

  def move(self, dest):
    dest = Path(dest)
    if dest.isdir():
      dest.rmtree()
    self.gfile.rename(self, str(dest), overwrite=True)


Path.filesystems = [
    (GFilePath, lambda path: path.startswith('gs://')),
    (LocalPath, lambda path: True),
]

</embodied/core/path.py>

<embodied/core/prefetch.py>
import queue as queuelib

import numpy as np

from . import timer
from .. import distr


class Prefetch:

  def __init__(self, source, transform=None, amount=1):
    self.source = source
    self.transform = transform
    self.queue = queuelib.Queue(amount)
    self.worker = distr.StoppableThread(self._worker, start=True)

  def close(self):
    self.worker.stop()

  def check(self):
    self.worker.check()

  def __iter__(self):
    return self

  def __call__(self):
    return self.__iter__()

  def __next__(self):
    return self.queue.get()

  def _worker(self, context):
    # it = iter(self.source)
    it = self.source()
    while context.running:
      with timer.section('prefetch_source'):
        data = next(it)
      if self.transform:
        with timer.section('prefetch_transform'):
          data = self.transform(data)
      self.queue.put(data)


class Batch:

  def __init__(self, sources, amount=1):
    self.sources = sources
    self.queue = queuelib.Queue(amount)
    self.worker = distr.StoppableThread(self._worker, start=True)

  def close(self):
    self.worker.stop()

  def __iter__(self):
    return self

  def __call__(self):
    return self.__iter__()

  def __next__(self):
    return self.queue.get()

  def _worker(self, context):
    its = [source() for source in self.sources]
    while context.running:
      with timer.section('batch_source'):
        data = [next(it) for it in its]
      with timer.section('batch_stack'):
        data = {k: np.stack([x[k] for x in data]) for k in data[0]}
      self.queue.put(data)

</embodied/core/prefetch.py>

<embodied/core/printing.py>
import re

try:
  import colored
except ImportError:
  print('For colored outputs: pip install colored')
  colored = None


REGEX_TOKEN = re.compile(
    r"([^a-zA-Z0-9-_./'\"\[\]]|['\"][^\s]*['\"])", re.MULTILINE)
REGEX_NUMBER = re.compile(
    r'([-+]?[0-9]+[0-9.,]*(e[-+]?[0-9])?|nan|-?inf)')
KEYWORDS = (
    'True', 'False', 'None', 'bool', 'int', 'str', 'float',
    'uint8', 'float16', 'float32', 'int32', 'int64')


def print_(*values, color=True, **kwargs):
  value = kwargs.get('sep', ' ').join(str(x) for x in values)
  assert not color or isinstance(color, (bool, str)), color
  if isinstance(color, str) and colored:
    value = colored.stylize(value, colored.fg(color))
  elif color is True and colored:
    result = []
    prev = [None, None, None]  # Color, highlighted, bold
    tokens = REGEX_TOKEN.split(value) + [None]
    for i, token in enumerate(tokens[:-1]):
      new = prev.copy()
      word = token.strip()
      new[2] = None
      if not word:
        new[0] = None
      elif word in '/-+':
        new[0] = 'green'
        new[2] = True
      elif word in '{}()<>,:':
        new[0] = 'white'
      elif token == '=':
        new[0] = 'white'
      elif word[0].isalpha() and tokens[i + 1] == '=':
        new[0] = 'magenta'
      elif word in KEYWORDS:
        new[0] = 'blue'
      elif word.startswith('---'):
        new[1] = True
      elif REGEX_NUMBER.match(word):
        new[0] = 'blue'
      elif word[0] == word[-1] == "'":
        new[0] = 'red'
      elif word[0] == word[-1] == '"':
        new[0] = 'red'
      elif word[0] == '[' and word[-1] == ']':
        new[0] = 'cyan'
      elif any(word.startswith(x) for x in ('/', '~', './')):
        new[0] = 'yellow'
      elif len(word) >= 3 and word[0] == word[-1] and word[0] in ("'", '"'):
        new[0] = 'green'
      elif word[0] == word[0].upper():
        new[0] = None
      else:
        new[0] = None
      if new[1]:
        new[0] = 'cyan'
        new[2] = True
      if new != prev:
        result.append(colored.attr('reset'))
        new[0] and result.append(colored.fg(new[0]))
        new[2] and result.append(colored.attr('bold'))
      result.append(token)
      prev = new
      if '\n' in token:
        prev[1] = None
        prev[2] = None
    result.append(colored.attr('reset'))
    value = ''.join(result)
  print(value, **kwargs)


def format_(value):
  if isinstance(value, dict):
    items = [f'{format_(k)}: {format_(v)}' for k, v in value.items()]
    return '{' + ', '.join(items) + '}'
  if isinstance(value, list):
    return '[' + ', '.join(f'{format_(x)}' for x in value) + ']'
  if isinstance(value, tuple):
    return '(' + ', '.join(f'{format_(x)}' for x in value) + ')'
  if hasattr(value, 'shape') and hasattr(value, 'dtype'):
    shape = ','.join(str(x) for x in value.shape)
    dtype = value.dtype.name
    for long, short in {'float': 'f', 'uint': 'u', 'int': 'i'}.items():
      dtype = dtype.replace(long, short)
    return f'{dtype}<{shape}>'
  if isinstance(value, bytes):
    value = '0x' + value.hex() if r'\x' in str(value) else str(value)
    if len(value) > 32:
      value = value[:32 - 3] + '...'
  return str(value)

</embodied/core/printing.py>

<embodied/core/random_agent.py>
import numpy as np


class RandomAgent:

  def __init__(self, obs_space, act_space):
    self.obs_space = obs_space
    self.act_space = act_space

  def init_policy(self, batch_size):
    return ()

  def init_train(self, batch_size):
    return ()

  def init_report(self, batch_size):
    return ()

  def policy(self, obs, carry=(), mode='train'):
    batch_size = len(obs['is_first'])
    act = {
        k: np.stack([v.sample() for _ in range(batch_size)])
        for k, v in self.act_space.items() if k != 'reset'}
    outs = {}
    return act, outs, carry

  def train(self, data, carry=()):
    outs = {}
    metrics = {}
    return outs, carry, metrics

  def report(self, data, carry=()):
    report = {}
    return report, carry

  def dataset(self, generator):
    return generator()

  def save(self):
    return None

  def load(self, data=None):
    pass

</embodied/core/random_agent.py>

<embodied/core/rwlock.py>
import contextlib
import threading


class RWLock:

  def __init__(self):
    self.lock = threading.Lock()
    self.active_writer_lock = threading.Lock()
    self.writer_count = 0
    self.waiting_reader_count = 0
    self.active_reader_count = 0
    self.readers_finished_cond = threading.Condition(self.lock)
    self.writers_finished_cond = threading.Condition(self.lock)

  @property
  @contextlib.contextmanager
  def reading(self):
    try:
      self.acquire_read()
      yield
    finally:
      self.release_read()

  @property
  @contextlib.contextmanager
  def writing(self):
    try:
      self.acquire_write()
      yield
    finally:
      self.release_write()

  def acquire_read(self):
    with self.lock:
      if self.writer_count:
        self.waiting_reader_count += 1
        while self.writer_count:
          self.writers_finished_cond.wait()
        self.waiting_reader_count -= 1
      self.active_reader_count += 1

  def release_read(self):
    with self.lock:
      assert self.active_reader_count > 0
      self.active_reader_count -= 1
      if not self.active_reader_count and self.writer_count:
        self.readers_finished_cond.notify_all()

  def acquire_write(self):
    with self.lock:
      self.writer_count += 1
      while self.active_reader_count:
        self.readers_finished_cond.wait()
    self.active_writer_lock.acquire()

  def release_write(self):
    self.active_writer_lock.release()
    with self.lock:
      assert self.writer_count > 0
      self.writer_count -= 1
      if not self.writer_count and self.waiting_reader_count:
        self.writers_finished_cond.notify_all()

</embodied/core/rwlock.py>

<embodied/core/space.py>
import numpy as np


class Space:

  def __init__(self, dtype, shape=(), low=None, high=None):
    # For integer types, high is one above the highest allowed value.
    shape = (shape,) if isinstance(shape, int) else shape
    self._dtype = np.dtype(dtype)
    assert self._dtype is not object, self._dtype
    assert isinstance(shape, tuple), shape
    self._low = self._infer_low(dtype, shape, low, high)
    self._high = self._infer_high(dtype, shape, low, high)
    self._shape = self._infer_shape(dtype, shape, self._low, self._high)
    self._discrete = (
        np.issubdtype(self.dtype, np.integer) or self.dtype == bool)
    self._random = np.random.RandomState()

  @property
  def dtype(self):
    return self._dtype

  @property
  def shape(self):
    return self._shape

  @property
  def low(self):
    return self._low

  @property
  def high(self):
    return self._high

  @property
  def discrete(self):
    return self._discrete

  @property
  def classes(self):
    assert self.discrete
    classes = self._high - self._low
    if not classes.ndim:
      classes = int(classes.item())
    return classes

  def __repr__(self):
    low = None if self.low is None else self.low.min()
    high = None if self.high is None else self.high.min()
    return (
        f'Space(dtype={self.dtype.name}, '
        f'shape={self.shape}, '
        f'low={low}, '
        f'high={high})')

  def __contains__(self, value):
    value = np.asarray(value)
    if np.issubdtype(self.dtype, str):
      return np.issubdtype(value.dtype, str)
    if value.shape != self.shape:
      return False
    if (value > self.high).any():
      return False
    if (value < self.low).any():
      return False
    if value.dtype != self.dtype:
      return False
    return True

  def sample(self):
    low, high = self.low, self.high
    if np.issubdtype(self.dtype, np.floating):
      low = np.maximum(np.ones(self.shape) * np.finfo(self.dtype).min, low)
      high = np.minimum(np.ones(self.shape) * np.finfo(self.dtype).max, high)
    return self._random.uniform(low, high, self.shape).astype(self.dtype)

  def _infer_low(self, dtype, shape, low, high):
    if np.issubdtype(dtype, str):
      assert low is None, low
      return None
    if low is not None:
      try:
        return np.broadcast_to(low, shape)
      except ValueError:
        raise ValueError(f'Cannot broadcast {low} to shape {shape}')
    elif np.issubdtype(dtype, np.floating):
      return -np.inf * np.ones(shape)
    elif np.issubdtype(dtype, np.integer):
      return np.iinfo(dtype).min * np.ones(shape, dtype)
    elif np.issubdtype(dtype, bool):
      return np.zeros(shape, bool)
    else:
      raise ValueError('Cannot infer low bound from shape and dtype.')

  def _infer_high(self, dtype, shape, low, high):
    if np.issubdtype(dtype, str):
      assert high is None, high
      return None
    if high is not None:
      try:
        return np.broadcast_to(high, shape)
      except ValueError:
        raise ValueError(f'Cannot broadcast {high} to shape {shape}')
    elif np.issubdtype(dtype, np.floating):
      return np.inf * np.ones(shape)
    elif np.issubdtype(dtype, np.integer):
      return np.iinfo(dtype).max * np.ones(shape, dtype)
    elif np.issubdtype(dtype, bool):
      return np.ones(shape, bool)
    else:
      raise ValueError('Cannot infer high bound from shape and dtype.')

  def _infer_shape(self, dtype, shape, low, high):
    if shape is None and low is not None:
      shape = low.shape
    if shape is None and high is not None:
      shape = high.shape
    if not hasattr(shape, '__len__'):
      shape = (shape,)
    assert all(dim and dim > 0 for dim in shape), shape
    return tuple(shape)

</embodied/core/space.py>

<embodied/core/timer.py>
import contextlib
import threading
import time
from collections import defaultdict

import numpy as np


class Timer:

  def __init__(self, enabled=True):
    self.enabled = enabled
    self.stack = defaultdict(list)
    self.paths = set()
    self.mins = defaultdict(lambda: np.inf)
    self.maxs = defaultdict(lambda: 0)
    self.sums = defaultdict(lambda: 0)
    self.counts = defaultdict(lambda: 0)
    self.start = time.perf_counter_ns()
    self.writing = False
    self.extensions = []

  @contextlib.contextmanager
  def section(self, name):
    if not self.enabled:
      yield
      return
    stack = self.stack[threading.get_ident()]
    if name in stack:
      raise RuntimeError(
          f"Tried to recursively enter timer section {name} " +
          f"from {'/'.join(stack)}.")
    stack.append(name)
    path = '/'.join(stack)
    start = time.perf_counter_ns()
    try:
      if self.extensions:
        with contextlib.ExitStack() as es:
          [es.enter_context(ext(path)) for ext in self.extensions]
          yield
      else:
        yield
    finally:
      dur = time.perf_counter_ns() - start
      stack.pop()
      if not self.writing:
        self.paths.add(path)
        self.sums[path] += dur
        self.mins[path] = min(self.mins[path], dur)
        self.maxs[path] = max(self.maxs[path], dur)
        self.counts[path] += 1

  def wrap(self, name, obj, methods):
    for method in methods:
      decorator = self.section(f'{name}.{method}')
      setattr(obj, method, decorator(getattr(obj, method)))

  def stats(self, reset=True):
    if not self.enabled:
      return {}
    self.writing = True
    time.sleep(0.001)
    now = time.perf_counter_ns()
    passed = now - self.start
    self.start = now
    metrics = {}
    div = lambda x, y: x and x / y
    for key in self.paths:
      metrics.update({
          f'{key}/sum': self.sums[key] / 1e9,
          f'{key}/min': self.mins[key] / 1e9,
          f'{key}/max': self.maxs[key] / 1e9,
          f'{key}/avg': div(self.sums[key], self.counts[key]) / 1e9,
          f'{key}/frac': self.sums[key] / passed,
          f'{key}/count': self.counts[key],
      })
    self.writing = False
    fracs = {k: metrics[f'{k}/frac'] for k in self.paths}
    fracs = sorted(fracs.items(), key=lambda x: -x[1])
    metrics['summary'] = '\n'.join(f'- {100*v:.0f}% {k}' for k, v in fracs)
    reset and self.reset()
    return metrics

  def reset(self):
    if not self.enabled:
      return
    self.writing = True
    time.sleep(0.001)
    self.sums.clear()
    self.mins.clear()
    self.maxs.clear()
    self.counts.clear()
    self.start = time.perf_counter_ns()
    self.writing = False


global_timer = Timer()
section = global_timer.section
wrap = global_timer.wrap
stats = global_timer.stats
reset = global_timer.reset
extensions = global_timer.extensions

</embodied/core/timer.py>

<embodied/core/tree.py>
from . import printing


def map_(fn, *trees, isleaf=None):
  assert trees, 'Provide one or more nested Python structures'
  kw = dict(isleaf=isleaf)
  first = trees[0]
  assert all(isinstance(x, type(first)) for x in trees)
  if isleaf and isleaf(first):
    return fn(*trees)
  if isinstance(first, list):
    assert all(len(x) == len(first) for x in trees), printing.format_(trees)
    return [map_(
        fn, *[t[i] for t in trees], **kw) for i in range(len(first))]
  if isinstance(first, tuple):
    assert all(len(x) == len(first) for x in trees), printing.format_(trees)
    return tuple([map_(
        fn, *[t[i] for t in trees], **kw) for i in range(len(first))])
  if isinstance(first, dict):
    assert all(set(x.keys()) == set(first.keys()) for x in trees), (
        printing.format_(trees))
    return {k: map_(fn, *[t[k] for t in trees], **kw) for k in first}
  if hasattr(first, 'keys') and hasattr(first, 'get'):
    assert all(set(x.keys()) == set(first.keys()) for x in trees), (
        printing.format_(trees))
    return type(first)(
        {k: map_(fn, *[t[k] for t in trees], **kw) for k in first})
  return fn(*trees)


map = map_

</embodied/core/tree.py>

<embodied/core/usage.py>
import gc
import inspect
import os
import re
import threading
import time
import tracemalloc
from collections import defaultdict

from . import agg
from . import timer


class Usage:

  def __init__(self, **kwargs):
    available = {
        'psutil': PsutilStats,  # per process and global
        'nvsmi': NvsmiStats,    # gloal
        'gputil': GputilStats,  # per process
        'malloc': MallocStats,  # per process
        'gc': GcStats,          # per process
    }
    self.tools = {}
    for name, enabled in kwargs.items():
      assert isinstance(enabled, bool), (name, type(enabled))
      if enabled:
        self.tools[name] = available[name]()

  def stats(self):
    stats = {}
    for name, tool in self.tools.items():
      stats.update({f'{name}/{k}': v for k, v in tool().items()})
    return stats

  def __del__(self):
    for tool in self.tools.values():
      if hasattr(tool, 'cleanup'):
        tool.cleanup()


class NvsmiStats:

  PATTERNS = {
      'compute_min': (r'GPU Utilization Samples(.|\n)+?Min.*?: (\d+) %', 1),
      'compute_avg': (r'GPU Utilization Samples(.|\n)+?Avg.*?: (\d+) %', 1),
      'compute_max': (r'GPU Utilization Samples(.|\n)+?Max.*?: (\d+) %', 1),
      'memory_min': (r'Memory Utilization Samples(.|\n)+?Min.*?: (\d+) %', 1),
      'memory_avg': (r'Memory Utilization Samples(.|\n)+?Avg.*?: (\d+) %', 1),
      'memory_max': (r'Memory Utilization Samples(.|\n)+?Max.*?: (\d+) %', 1),
  }

  def __init__(self):
    pass

  @timer.section('nvsmi_stats')
  def __call__(self):
    output = os.popen('nvidia-smi --query -d UTILIZATION 2>&1').read()
    if not output:
      print('To log GPU stats, make sure nvidia-smi is working.')
      return {}
    metrics = {'output': output}
    for name, (pattern, group) in self.PATTERNS.items():
      numbers = [x[group] for x in re.findall(pattern, output)]
      for i, number in enumerate(numbers):
        metrics[f'{name}/gpu{i}'] = float(numbers[i]) / 100
    return metrics

  def cleanup(self):
    pass


class PsutilStats:

  def __init__(self):
    import psutil
    self.proc = psutil.Process()

  @timer.section('psutil_stats')
  def __call__(self):
    import psutil
    gb = 1024 ** 3
    cpus = psutil.cpu_count()
    memory = psutil.virtual_memory()
    stats = {
        'proc_cpu_usage': self.proc.cpu_percent() / 100,
        'proc_ram_frac': self.proc.memory_info().rss / memory.total,
        'proc_ram_gb': self.proc.memory_info().rss / gb,
        'total_cpu_count': cpus,
        'total_cpu_frac': psutil.cpu_percent() / 100,
        'total_ram_frac': memory.percent / 100,
        'total_ram_total_gb': memory.total / gb,
        'total_ram_used_gb': memory.used / gb,
        'total_ram_avail_gb': memory.available / gb,
    }
    return stats

  def cleanup(self):
    del self.proc


class GputilStats:

  def __init__(self):
    import GPUtil
    self.gpus = GPUtil.getGPUs()
    print(f'GPUtil found {len(self.gpus)} GPUs')
    self.error = None
    self.aggs = defaultdict(agg.Agg)
    self.once = True
    self.worker = threading.Thread(target=self._worker, daemon=True)
    self.worker.start()

  @timer.section('gputil_stats')
  def __call__(self):
    if self.error:
      raise self.error
    stats = {}
    for i, agg_ in self.aggs.items():
      stats.update(agg_.result(prefix=f'gpu{i}'))
    if self.once:
      self.once = False
      lines = [f'GPU {i}: {gpu.name}' for i, gpu in enumerate(self.gpus)]
      stats['summary'] = '\n'.join(lines)
    return stats

  def _worker(self):
    try:
      while True:
        for i, gpu in enumerate(self.gpus):
          agg = self.aggs[i]
          agg.add('load', gpu.load, 'avg')
          agg.add('mem_free_gb', gpu.memoryFree / 1024, 'min')
          agg.add('mem_used_gb', gpu.memoryFree / 1024, 'max')
          agg.add('mem_total_gb', gpu.memoryTotal / 1024)
          agg.add('memory_util', gpu.memoryUtil, ('min', 'avg', 'max'))
          agg.add('temperature', gpu.temperature, 'max')
        time.sleep(0.5)
    except Exception as e:
      print(f'Exception in Gputil worker: {e}')
      self.error = e

  def cleanup(self):
    self.stop_event.set()
    self.worker.join()


class GcStats:

  def __init__(self):
    gc.callbacks.append(self._callback)
    self.stats = agg.Agg()
    self.keys = set()
    self.counts = [{}, {}, {}]
    self.start = None

  @timer.section('gc_stats')
  # def __call__(self, log=False):
  def __call__(self, log=True):
    stats = {k: 0 for k in self.keys}
    stats.update(self.stats.result())
    stats['objcounts'] = self._summary()
    log and print(stats['objcounts'])
    self.keys |= set(stats.keys())
    return stats

  def _summary(self):
    lines = ['GC Most Common Types']
    for gen in range(3):

      objs = {
          id(obj): obj for obj in gc.get_objects(gen)
          if not inspect.isframe(obj)}
      for obj in list(objs.values()):
        for obj in gc.get_referents(obj):
          if not gc.is_tracked(obj):
            objs[id(obj)] = obj

      counts = defaultdict(int)
      for obj in objs.values():
        counts[type(obj).__name__] += 1

      deltas = {k: v - self.counts[gen].get(k, 0) for k, v in counts.items()}
      self.counts[gen] = counts

      deltas = dict(sorted(deltas.items(), key=lambda x: -abs(x[1]))[:10])
      lines.append(f'\nGeneration {gen}\n')
      for name, delta in deltas.items():
        lines.append(f'- {name}: {delta:+d} ({counts[name]})')

    return '\n'.join(lines)

  def _callback(self, phase, info):
    # We cannot wrap this function into a timer section, because it would get
    # nested into an arbitrary scope that was active before the garbage
    # collector got triggered.
    now = time.perf_counter_ns()
    if phase == 'start':
      self.start = now
    if phase == 'stop' and self.start:
      gen = info['generation']
      agg = ('avg', 'max', 'sum')
      self.stats.add(f'gen{gen}/calls', 1, agg='sum')
      self.stats.add(f'gen{gen}/collected', info['collected'], agg)
      self.stats.add(f'gen{gen}/uncollectable', info['collected'], agg)
      self.stats.add(f'gen{gen}/duration', (now - self.start) / 1e9, agg)

  def cleanup(self):
    if self in gc.callbacks:
      gc.callbacks.remove(self._callback)


class MallocStats:

  def __init__(self):
    tracemalloc.start()
    self.previous = None

  @timer.section('malloc_stats')
  def __call__(self, log=True):
    stats = {}
    snapshot = tracemalloc.take_snapshot()
    stats['full'] = self._summary(snapshot)
    stats['diff'] = self._summary(snapshot, self.previous)
    self.previous = snapshot
    log and print(stats['full'])
    return stats

  def _summary(self, snapshot, relative=None, top=50, root='embodied'):
    if relative:
      statistics = snapshot.compare_to(relative, 'traceback')
    else:
      statistics = snapshot.statistics('traceback')
    agg = defaultdict(lambda: [0, 0])
    for stat in statistics:
      filename = stat.traceback[-1].filename
      lineno = stat.traceback[-1].lineno
      for frame in reversed(stat.traceback):
        if f'/{root}/' in frame.filename:
          filename = f'{root}/' + frame.filename.split(f'/{root}/')[-1]
          lineno = frame.lineno
          break
      agg[(filename, lineno)][0] += stat.size_diff if relative else stat.size
      agg[(filename, lineno)][1] += stat.count_diff if relative else stat.count
    lines = []
    lines.append('\nMemory Allocation' + (' Changes' if relative else ''))
    lines.append(f'\nTop {top} by size:\n')
    entries = sorted(agg.items(), key=lambda x: -abs(x[1][0]))
    for (filename, lineno), (size, count) in entries[:top]:
      size = size / (1024 ** 2)
      lines.append(f'- {size:.2f}Mb ({count}) {filename}:{lineno}')
    lines.append(f'\nTop {top} by count:\n')
    entries = sorted(agg.items(), key=lambda x: -abs(x[1][1]))
    for (filename, lineno), (size, count) in entries[:top]:
      size = size / (1024 ** 2)
      lines.append(f'- {size:.2f}Mb ({count}) {filename}:{lineno}')
    return '\n'.join(lines)

  def cleanup(self):
    tracemalloc.stop()

</embodied/core/usage.py>

<embodied/core/utils.py>
from datetime import datetime


def timestamp(now=None, millis=False):
  now = datetime.now() if now is None else now
  string = now.strftime("%Y%m%dT%H%M%S")
  if millis:
    string += f'F{now.microsecond:06d}'
  return string

</embodied/core/utils.py>

<embodied/core/uuid.py>
import string
import uuid as uuidlib

import numpy as np


class uuid:
  """UUID that is stored as 16 byte string and can be converted to and from
  int, string, and array types."""

  __slots__ = ('value', '_hash')

  DEBUG_ID = None
  BASE62 = string.digits + string.ascii_letters
  BASE62REV = {x: i for i, x in enumerate(BASE62)}

  # def __new__(cls, val=None):
  #   return val or np.random.randint(1, 2 ** 63)

  @classmethod
  def reset(cls, *, debug):
    cls.DEBUG_ID = 0 if debug else None

  def __init__(self, value=None):
    if value is None:
      if self.DEBUG_ID is None:
        self.value = uuidlib.uuid4().bytes
      else:
        type(self).DEBUG_ID += 1
        self.value = self.DEBUG_ID.to_bytes(16, 'big')
    elif isinstance(value, uuid):
      self.value = value.value
    elif isinstance(value, int):
      self.value = value.to_bytes(16, 'big')
    elif isinstance(value, bytes):
      assert len(value) == 16, value
      self.value = value
    elif isinstance(value, str):
      if self.DEBUG_ID is None:
        integer = 0
        for index, char in enumerate(value[::-1]):
          integer += (62 ** index) * self.BASE62REV[char]
        self.value = integer.to_bytes(16, 'big')
      else:
        self.value = int(value).to_bytes(16, 'big')
    elif isinstance(value, np.ndarray):
      self.value = value.tobytes()
    else:
      raise ValueError(value)
    assert type(self.value) == bytes, type(self.value)  # noqa
    assert len(self.value) == 16, len(self.value)
    self._hash = hash(self.value)

  def __int__(self):
    return int.from_bytes(self.value, 'big')

  def __str__(self):
    if self.DEBUG_ID is not None:
      return str(int(self))
    chars = []
    integer = int(self)
    while integer != 0:
      chars.append(self.BASE62[integer % 62])
      integer //= 62
    while len(chars) < 22:
      chars.append('0')
    return ''.join(chars[::-1])

  def __array__(self):
    return np.frombuffer(self.value, np.uint8)

  def __getitem__(self, index):
    return self.__array__()[index]

  def __repr__(self):
    return str(self)

  def __eq__(self, other):
    return self.value == other.value

  def __hash__(self):
    return self._hash

</embodied/core/uuid.py>

<embodied/core/when.py>
import time


class Every:

  def __init__(self, every, initial=True):
    self._every = every
    self._initial = initial
    self._prev = None

  def __call__(self, step):
    step = int(step)
    if self._every < 0:
      return True
    if self._every == 0:
      return False
    if self._prev is None:
      self._prev = (step // self._every) * self._every
      return self._initial
    if step >= self._prev + self._every:
      self._prev += self._every
      return True
    return False


class Ratio:

  def __init__(self, ratio):
    assert ratio >= 0, ratio
    self._ratio = ratio
    self._prev = None

  def __call__(self, step):
    step = int(step)
    if self._ratio == 0:
      return 0
    if self._prev is None:
      self._prev = step
      return 1
    repeats = int((step - self._prev) * self._ratio)
    self._prev += repeats / self._ratio
    return repeats


class Once:

  def __init__(self):
    self._once = True

  def __call__(self):
    if self._once:
      self._once = False
      return True
    return False


class Until:

  def __init__(self, until):
    self._until = until

  def __call__(self, step):
    step = int(step)
    if not self._until:
      return True
    return step < self._until


class Clock:

  def __init__(self, every, first=True):
    self._every = every
    self._prev = None
    self._first = first

  def __call__(self, step=None):
    if self._every < 0:
      return False
    if self._every == 0:
      return True
    now = time.time()
    if self._prev is None:
      self._prev = now
      return self._first
    if now >= self._prev + self._every:
      # self._prev += self._every
      self._prev = now
      return True
    return False

</embodied/core/when.py>

<embodied/core/wrappers.py>
import functools
import time

import numpy as np

from . import base
from . import space as spacelib


class TimeLimit(base.Wrapper):

  def __init__(self, env, duration, reset=True):
    super().__init__(env)
    self._duration = duration
    self._reset = reset
    self._step = 0
    self._done = False

  def step(self, action):
    if action['reset'] or self._done:
      self._step = 0
      self._done = False
      if self._reset:
        action.update(reset=True)
        return self.env.step(action)
      else:
        action.update(reset=False)
        obs = self.env.step(action)
        obs['is_first'] = True
        return obs
    self._step += 1
    obs = self.env.step(action)
    if self._duration and self._step >= self._duration:
      obs['is_last'] = True
    self._done = obs['is_last']
    return obs


class ActionRepeat(base.Wrapper):

  def __init__(self, env, repeat):
    super().__init__(env)
    self._repeat = repeat

  def step(self, action):
    if action['reset']:
      return self.env.step(action)
    reward = 0.0
    for _ in range(self._repeat):
      obs = self.env.step(action)
      reward += obs['reward']
      if obs['is_last'] or obs['is_terminal']:
        break
    obs['reward'] = np.float32(reward)
    return obs


class ClipAction(base.Wrapper):

  def __init__(self, env, key='action', low=-1, high=1):
    super().__init__(env)
    self._key = key
    self._low = low
    self._high = high

  def step(self, action):
    clipped = np.clip(action[self._key], self._low, self._high)
    return self.env.step({**action, self._key: clipped})


class NormalizeAction(base.Wrapper):

  def __init__(self, env, key='action'):
    super().__init__(env)
    self._key = key
    self._space = env.act_space[key]
    self._mask = np.isfinite(self._space.low) & np.isfinite(self._space.high)
    self._low = np.where(self._mask, self._space.low, -1)
    self._high = np.where(self._mask, self._space.high, 1)

  @functools.cached_property
  def act_space(self):
    low = np.where(self._mask, -np.ones_like(self._low), self._low)
    high = np.where(self._mask, np.ones_like(self._low), self._high)
    space = spacelib.Space(np.float32, self._space.shape, low, high)
    return {**self.env.act_space, self._key: space}

  def step(self, action):
    orig = (action[self._key] + 1) / 2 * (self._high - self._low) + self._low
    orig = np.where(self._mask, orig, action[self._key])
    return self.env.step({**action, self._key: orig})


class ExpandScalars(base.Wrapper):

  def __init__(self, env):
    super().__init__(env)
    self._obs_expanded = []
    self._obs_space = {}
    for key, space in self.env.obs_space.items():
      if space.shape == () and key != 'reward' and not space.discrete:
        space = spacelib.Space(space.dtype, (1,), space.low, space.high)
        self._obs_expanded.append(key)
      self._obs_space[key] = space
    self._act_expanded = []
    self._act_space = {}
    for key, space in self.env.act_space.items():
      if space.shape == () and not space.discrete:
        space = spacelib.Space(space.dtype, (1,), space.low, space.high)
        self._act_expanded.append(key)
      self._act_space[key] = space

  @functools.cached_property
  def obs_space(self):
    return self._obs_space

  @functools.cached_property
  def act_space(self):
    return self._act_space

  def step(self, action):
    action = {
        key: np.squeeze(value, 0) if key in self._act_expanded else value
        for key, value in action.items()}
    obs = self.env.step(action)
    obs = {
        key: np.expand_dims(value, 0) if key in self._obs_expanded else value
        for key, value in obs.items()}
    return obs


class FlattenTwoDimObs(base.Wrapper):

  def __init__(self, env):
    super().__init__(env)
    self._keys = []
    self._obs_space = {}
    for key, space in self.env.obs_space.items():
      if len(space.shape) == 2:
        space = spacelib.Space(
            space.dtype,
            (int(np.prod(space.shape)),),
            space.low.flatten(),
            space.high.flatten())
        self._keys.append(key)
      self._obs_space[key] = space

  @functools.cached_property
  def obs_space(self):
    return self._obs_space

  def step(self, action):
    obs = self.env.step(action).copy()
    for key in self._keys:
      obs[key] = obs[key].flatten()
    return obs


class FlattenTwoDimActions(base.Wrapper):

  def __init__(self, env):
    super().__init__(env)
    self._origs = {}
    self._act_space = {}
    for key, space in self.env.act_space.items():
      if len(space.shape) == 2:
        space = spacelib.Space(
            space.dtype,
            (int(np.prod(space.shape)),),
            space.low.flatten(),
            space.high.flatten())
        self._origs[key] = space.shape
      self._act_space[key] = space

  @functools.cached_property
  def act_space(self):
    return self._act_space

  def step(self, action):
    action = action.copy()
    for key, shape in self._origs.items():
      action[key] = action[key].reshape(shape)
    return self.env.step(action)


class ForceDtypes(base.Wrapper):

  def __init__(self, env):
    super().__init__(env)
    self._obs_space, _, self._obs_outer = self._convert(env.obs_space)
    self._act_space, self._act_inner, _ = self._convert(env.act_space)

  @property
  def obs_space(self):
    return self._obs_space

  @property
  def act_space(self):
    return self._act_space

  def step(self, action):
    action = action.copy()
    for key, dtype in self._act_inner.items():
      action[key] = np.asarray(action[key], dtype)
    obs = self.env.step(action)
    for key, dtype in self._obs_outer.items():
      obs[key] = np.asarray(obs[key], dtype)
    return obs

  def _convert(self, spaces):
    results, befores, afters = {}, {}, {}
    for key, space in spaces.items():
      before = after = space.dtype
      if np.issubdtype(before, np.floating):
        after = np.float32
      elif np.issubdtype(before, np.uint8):
        after = np.uint8
      elif np.issubdtype(before, np.integer):
        after = np.int32
      befores[key] = before
      afters[key] = after
      results[key] = spacelib.Space(after, space.shape, space.low, space.high)
    return results, befores, afters


class CheckSpaces(base.Wrapper):

  def __init__(self, env):
    super().__init__(env)

  def step(self, action):
    for key, value in action.items():
      self._check(value, self.env.act_space[key], key)
    obs = self.env.step(action)
    for key, value in obs.items():
      self._check(value, self.env.obs_space[key], key)
    return obs

  def _check(self, value, space, key):
    if not isinstance(value, (
        np.ndarray, np.generic, list, tuple, int, float, bool)):
      raise TypeError(f'Invalid type {type(value)} for key {key}.')
    if value in space:
      return
    dtype = np.array(value).dtype
    shape = np.array(value).shape
    lowest, highest = np.min(value), np.max(value)
    raise ValueError(
        f"Value for '{key}' with dtype {dtype}, shape {shape}, "
        f"lowest {lowest}, highest {highest} is not in {space}.")


class DiscretizeAction(base.Wrapper):

  def __init__(self, env, key='action', bins=5):
    super().__init__(env)
    self._dims = np.squeeze(env.act_space[key].shape, 0).item()
    self._values = np.linspace(-1, 1, bins)
    self._key = key

  @functools.cached_property
  def act_space(self):
    space = spacelib.Space(np.int32, self._dims, 0, len(self._values))
    return {**self.env.act_space, self._key: space}

  def step(self, action):
    continuous = np.take(self._values, action[self._key])
    return self.env.step({**action, self._key: continuous})


class ResizeImage(base.Wrapper):

  def __init__(self, env, size=(64, 64)):
    super().__init__(env)
    self._size = size
    self._keys = [
        k for k, v in env.obs_space.items()
        if len(v.shape) > 1 and v.shape[:2] != size]
    print(f'Resizing keys {",".join(self._keys)} to {self._size}.')
    if self._keys:
      from PIL import Image
      self._Image = Image

  @functools.cached_property
  def obs_space(self):
    spaces = self.env.obs_space
    for key in self._keys:
      shape = self._size + spaces[key].shape[2:]
      spaces[key] = spacelib.Space(np.uint8, shape)
    return spaces

  def step(self, action):
    obs = self.env.step(action)
    for key in self._keys:
      obs[key] = self._resize(obs[key])
    return obs

  def _resize(self, image):
    image = self._Image.fromarray(image)
    image = image.resize(self._size, self._Image.NEAREST)
    image = np.array(image)
    return image


class RenderImage(base.Wrapper):

  def __init__(self, env, key='image'):
    super().__init__(env)
    self._key = key
    self._shape = self.env.render().shape

  @functools.cached_property
  def obs_space(self):
    spaces = self.env.obs_space
    spaces[self._key] = spacelib.Space(np.uint8, self._shape)
    return spaces

  def step(self, action):
    obs = self.env.step(action)
    obs[self._key] = self.env.render()
    return obs


class BackwardReturn(base.Wrapper):

  def __init__(self, env, horizon):
    super().__init__(env)
    self._discount = 1 - 1 / horizon
    self._bwreturn = 0.0

  @functools.cached_property
  def obs_space(self):
    return {
        **self.env.obs_space,
        'bwreturn': spacelib.Space(np.float32),
    }

  def step(self, action):
    obs = self.env.step(action)
    self._bwreturn *= (1 - obs['is_first']) * self._discount
    self._bwreturn += obs['reward']
    obs['bwreturn'] = np.float32(self._bwreturn)
    return obs


class RestartOnException(base.Wrapper):

  def __init__(
      self, ctor, exceptions=(Exception,), window=300, maxfails=2, wait=20):
    if not isinstance(exceptions, (tuple, list)):
        exceptions = [exceptions]
    self._ctor = ctor
    self._exceptions = tuple(exceptions)
    self._window = window
    self._maxfails = maxfails
    self._wait = wait
    self._last = time.time()
    self._fails = 0
    super().__init__(self._ctor())

  def step(self, action):
    try:
      return self.env.step(action)
    except self._exceptions as e:
      if time.time() > self._last + self._window:
        self._last = time.time()
        self._fails = 1
      else:
        self._fails += 1
      if self._fails > self._maxfails:
        raise RuntimeError('The env crashed too many times.')
      message = f'Restarting env after crash with {type(e).__name__}: {e}'
      print(message, flush=True)
      time.sleep(self._wait)
      self.env = self._ctor()
      action['reset'] = np.ones_like(action['reset'])
      return self.env.step(action)

</embodied/core/wrappers.py>

<embodied/core/__init__.py>
from .base import Agent, Env, Wrapper, Replay

from .printing import print_ as print
from .printing import format_ as format
from .utils import timestamp

from .space import Space
from .path import Path
from .checkpoint import Checkpoint
from .config import Config
from .counter import Counter
from .driver import Driver
from .flags import Flags
from .logger import Logger
from .timer import Timer
from .prefetch import Prefetch
from .prefetch import Batch
from .agg import Agg
from .usage import Usage
from .rwlock import RWLock
from .fps import FPS
from .random_agent import RandomAgent
from .uuid import uuid

from . import logger
from . import when
from . import wrappers
from . import timer
from . import tree



</embodied/core/__init__.py>

<embodied/distr/client.py>
import time
import weakref
from functools import partial as bind
from collections import deque

import numpy as np

from ..core import fps
from ..core import printing
from ..core import timer
from . import sockets


class Client:

  RESOLVERS = []

  def __init__(
      self, address, name='Client', ipv6=False, identity=None,
      pings=10, maxage=300, maxinflight=16, errors=True,
      connect=False):
    if identity is None:
      identity = int(np.random.randint(2 ** 32))
    self.address = address
    self.identity = identity
    self.name = name
    self.maxinflight = maxinflight
    self.errors = errors
    self.resolved = None
    self.socket = sockets.ClientSocket(identity, ipv6, pings, maxage)
    self.futures = weakref.WeakValueDictionary()
    self.queue = deque()
    self.conn_per_sec = fps.FPS()
    self.send_per_sec = fps.FPS()
    self.recv_per_sec = fps.FPS()
    connect and self.connect()

  def __getattr__(self, name):
    if name.startswith('__'):
      raise AttributeError(name)
    try:
      return bind(self.call, name)
    except AttributeError:
      raise ValueError(name)

  def stats(self):
    return {
        'futures': len(self.futures),
        'inflight': len(self.queue),
        'conn_per_sec': self.conn_per_sec.result(),
        'send_per_sec': self.send_per_sec.result(),
        'recv_per_sec': self.recv_per_sec.result(),
    }

  @timer.section('client_connect')
  def connect(self, retry=True, timeout=10):
    while True:
      self.resolved = self._resolve(self.address)
      self._print(f'Connecting to {self.resolved}')
      try:
        self.socket.connect(self.resolved, timeout)
        self._print('Connection established')
        self.conn_per_sec.step(1)
        return
      except sockets.ProtocolError as e:
        self._print(f'Ignoring unexpected message: {e}')
      except sockets.ConnectError:
        pass
      if retry:
        continue
      else:
        raise sockets.ConnectError

  @timer.section('client_call')
  def call(self, method, data):
    assert len(self.futures) < 1000, (
        f'Too many unresolved requests in client {self.name}.\n' +
        f'Futures: {len(self.futures)}\n' +
        f'Resolved: {sum([x.done() for x in self.futures.values()])}')
    if self.maxinflight:
      with timer.section('inflight_wait'):
        while sum(not x.done() for x in self.queue) >= self.maxinflight:
          self.queue[0].check()
          time.sleep(0.001)
    if self.errors:
      try:
        while self.queue[0].done():
          self.queue.popleft().result()
      except IndexError:
        pass
    assert isinstance(data, dict)
    data = {k: np.asarray(v) for k, v in data.items()}
    data = sockets.pack(data)
    rid = self.socket.send_call(method, data)
    self.send_per_sec.step(1)
    future = Future(self._receive, rid)
    self.futures[rid] = future
    if self.errors or self.maxinflight:
      self.queue.append(future)
    return future

  def close(self):
    return self.socket.close()

  @timer.section('client_receive')
  def _receive(self, rid, retry):
    while rid in self.futures and not self.futures[rid].done():
      result = self._listen()
      if result is None and not retry:
        return
      time.sleep(0.0001)

  @timer.section('client_listen')
  def _listen(self):
    try:
      result = self.socket.receive()
      if result is not None:
        other, payload = result
        if other in self.futures:
          self.futures[other].set_result(sockets.unpack(payload))
        self.recv_per_sec.step(1)
      return result
    except sockets.NotAliveError:
      self._print('Server is not responding')
      raise
    except sockets.RemoteError as e:
      self._print(f'Received error response: {e.args[1]}')
      other = e.args[0]
      if other in self.futures:
        self.futures[other].set_error(sockets.RemoteError(e.args[1]))
    except sockets.ProtocolError as e:
      self._print(f'Ignoring unexpected message: {e}')

  @timer.section('client_resolve')
  def _resolve(self, address):
    for check, resolve in self.RESOLVERS:
      if check(address):
        return resolve(address)
    return address

  def _print(self, text):
    printing.print_(f'[{self.name}] {text}')


class Future:

  def __init__(self, waitfn, *args):
    self._waitfn = waitfn
    self._args = args
    self._status = 0
    self._result = None
    self._error = None

  def check(self):
    if self._status == 0:
      self._waitfn(*self._args, retry=False)

  def done(self):
    return self._status > 0

  def result(self):
    if self._status == 0:
      self._waitfn(*self._args, retry=True)
    if self._status == 1:
      return self._result
    elif self._status == 2:
      raise self._error
    else:
      assert False

  def set_result(self, result):
    self._status = 1
    self._result = result

  def set_error(self, error):
    self._status = 2
    self._error = error

</embodied/distr/client.py>

<embodied/distr/pool.py>
import concurrent.futures


class ThreadPool:

  def __init__(self, workers, name):
    self.pool = concurrent.futures.ThreadPoolExecutor(workers, name)

  def submit(self, fn, *args, **kwargs):
    future = self.pool.submit(fn, *args, **kwargs)
    # Prevent deamon threads from hanging due to exit handlers registered by
    # the concurrent.futures modules.
    concurrent.futures.thread._threads_queues.clear()
    return future

  def close(self, wait=False):
    self.pool.shutdown(wait=wait)

</embodied/distr/pool.py>

<embodied/distr/process.py>
import multiprocessing as mp
import os
import queue
import signal
import sys

import cloudpickle

from . import utils


class Process:

  initializers = []
  current_name = None

  def __init__(self, fn, *args, name=None, start=False, pass_running=False):
    name = name or fn.__name__
    fn = cloudpickle.dumps(fn)
    inits = cloudpickle.dumps(self.initializers)
    context = mp.get_context()
    self.errqueue = context.Queue()
    self.exception = None
    self.process = context.Process(target=self._wrapper, name=name, args=(
        fn, name, args, utils.get_print_lock(), self.errqueue, inits))
    self.started = False
    start and self.start()

  @property
  def name(self):
    return self.process.name

  @property
  def pid(self):
    return self.process.pid

  @property
  def running(self):
    running = self.process.is_alive()
    if running:
      assert self.exitcode is None, (self.name, self.exitcode)
    return running

  @property
  def exitcode(self):
    return self.process.exitcode

  def start(self):
    assert not self.started
    self.started = True
    self.process.start()

  def check(self):
    if self.process.exitcode not in (None, 0):
      if self.exception is None:
        try:
          self.exception = self.errqueue.get(timeout=0.1)
        except queue.Empty:
          if self.exitcode in (-15, 15):
            msg = 'Process was terminated.'
          else:
            msg = f'Process excited with code {self.exitcode}'
          self.exception = RuntimeError(msg)
      self.kill()
      raise self.exception

  def join(self, timeout=None):
    if self.exitcode in (-15, 15):
      assert not self.running
      return
    self.check()
    if self.running:
      self.process.join(timeout)

  def kill(self):
    utils.kill_subprocs(self.pid)
    if self.running:
      self.process.terminate()
      self.process.join(timeout=0.1)
    if self.running:
      try:
        os.kill(self.pid, signal.SIGKILL)
        self.process.join(timeout=0.1)
      except ProcessLookupError:
        pass
    if self.running:
      print(f'Process {self.name} did not shut down yet.')

  def __repr__(self):
    attrs = ('name', 'pid', 'running', 'exitcode')
    attrs = [f'{k}={getattr(self, k)}' for k in attrs]
    return f'{type(self).__name__}(' + ', '.join(attrs) + ')'

  @staticmethod
  def _wrapper(fn, name, args, lock, errqueue, inits):
    Process.current_name = name
    try:
      for init in cloudpickle.loads(inits):
        init()
      fn = cloudpickle.loads(fn)
      fn(*args)
      sys.exit(0)
    except Exception as e:
      utils.warn_remote_error(e, name, lock)
      errqueue.put(e)
      sys.exit(1)
    finally:
      pid = mp.current_process().pid
      utils.kill_subprocs(pid)


class StoppableProcess(Process):

  def __init__(self, fn, *args, name=None, start=False):
    self.runflag = mp.get_context().Event()
    def fn2(runflag, *args):
      assert runflag is not None
      context = utils.Context(runflag.is_set)
      fn(context, *args)
    super().__init__(fn2, self.runflag, *args, name=name, start=start)

  def start(self):
    self.runflag.set()
    super().start()

  def stop(self, wait=1):
    self.check()
    if not self.running:
      return
    self.runflag.clear()
    if wait is True:
      self.join()
    elif wait:
      self.join(wait)
      self.kill()

</embodied/distr/process.py>

<embodied/distr/proc_server.py>
import collections
import time

import numpy as np

from ..core import printing

from . import process
from . import server
from . import sockets


class ProcServer:

  def __init__(
      self, address, name='Server', ipv6=False, workers=1, errors=True):
    self.address = address
    self.inner = f'ipc:///tmp/inner{np.random.randint(2 ** 32)}'
    self.name = name
    self.ipv6 = ipv6
    self.server = server.Server(self.inner, name, ipv6, workers, errors)
    self.batches = {}
    self.batcher = None

  def bind(self, name, workfn, logfn=None, workers=0, batch=0):
    self.batches[name] = batch
    self.server.bind(name, workfn, logfn, workers, batch=0)

  def start(self):
    self.batcher = process.StoppableProcess(
        self._batcher, self.address, self.inner,
        self.batches, self.name, self.ipv6, name='batcher', start=True)
    self.server.start()

  def check(self):
    self.batcher.check()
    self.server.check()

  def close(self):
    self.server.close()
    self.batcher.stop()
    assert not self.batcher.running

  def run(self):
    try:
      self.start()
      while True:
        self.check()
        time.sleep(1)
    finally:
      self.close()

  def stats(self):
    return self.server.stats()

  def __enter__(self):
    self.start()
    return self

  def __exit__(self, type, value, traceback):
    self.close()

  @staticmethod
  def _batcher(context, address, inner, batches, name, ipv6):

    socket = sockets.ServerSocket(address, ipv6)
    inbound = sockets.ClientSocket(identity=0, pings=0, maxage=0)
    inbound.connect(inner, timeout=120)
    queues = collections.defaultdict(list)
    buffers = collections.defaultdict(dict)
    pending = {}
    printing.print_(f'[{name}] Listening at {address}')

    while context.running:

      result = socket.receive()
      if result:
        addr, rid, name, payload = result
        batch = batches.get(name, None)
        if batch is not None:
          if batch:
            queue = queues[name]
            queue.append((addr, rid, payload))
            if len(queue) == batch:
              addrs, rids, payloads = zip(*queue)
              queue.clear()
              datas = [sockets.unpack(x) for x in payloads]
              idx = range(batch)
              bufs = buffers[name]
              for key, value in datas[0].items():
                bufs[key] = np.stack(
                    [datas[i][key] for i in idx], out=bufs.get(key, None))
              payload = sockets.pack(bufs)
              rid = inbound.send_call(name, payload)
              pending[rid] = (name, addrs, rids)
          else:
            inner_rid = inbound.send_call(name, payload)
            pending[inner_rid] = (name, addr, rid)
        else:
          socket.send_error(addr, rid, f'Unknown method {name}.')

      try:
        result = inbound.receive()
        if result:
          inner_rid, payload = result
          name, addr, rid = pending.pop(inner_rid)
          if batches[name]:
            addrs, rids = addr, rid
            result = sockets.unpack(payload)
            results = [
                {k: v[i] for k, v in result.items()}
                for i in range(batches[name])]
            payloads = [sockets.pack(x) for x in results]
            for addr, rid, payload in zip(addrs, rids, payloads):
              socket.send_result(addr, rid, payload)
          else:
            socket.send_result(addr, rid, payload)
      except sockets.RemoteError as e:
        inner_rid, msg = e.args[:2]
        name, addr, rid = pending.pop(inner_rid)
        if batches[name]:
          addrs, rids = addr, rid
          for addr, rid in zip(addrs, rids):
            socket.send_error(addr, rid, msg)
        else:
          socket.send_error(addr, rid, msg)

    socket.close()
    inbound.close()

</embodied/distr/proc_server.py>

<embodied/distr/server.py>
import concurrent.futures
import time
import traceback
from collections import deque, namedtuple

import numpy as np

from ..core import agg
from ..core import printing
from . import sockets
from . import pool as poollib
from . import thread


Method = namedtuple('Method', (
    'name,workfn,donefn,pool,workers,batched,insize,inqueue,inprog'))


class Server:

  def __init__(
      self, address, name='Server', ipv6=False, workers=1, errors=True):
    self.address = address
    self.workers = workers
    self.name = name
    self.errors = errors
    self.ipv6 = ipv6
    self.methods = {}
    self.default_pool = poollib.ThreadPool(workers, 'work')
    self.other_pools = []
    self.done_pool = poollib.ThreadPool(1, 'log')
    self.result_set = set()
    self.done_queue = deque()
    self.done_proms = deque()
    self.agg = agg.Agg()
    self.loop = thread.StoppableThread(self._loop, name=f'{name}_loop')
    self.exception = None

  def bind(self, name, workfn, donefn=None, workers=0, batch=0):
    if workers:
      pool = poollib.ThreadPool(workers, name)
      self.other_pools.append(pool)
    else:
      workers = self.workers
      pool = self.default_pool
    batched = (batch > 0)
    insize = max(1, batch)
    self.methods[name] = Method(
        name, workfn, donefn, pool, workers, batched, insize, deque(), [0])

  def start(self):
    self.loop.start()

  def check(self):
    self.loop.check()
    [not x.done() or x.result() for x in self.result_set.copy()]
    [not x.done() or x.result() for x in self.done_proms.copy()]
    if self.exception:
      exception = self.exception
      self.exception = None
      raise exception

  def close(self):
    self._print('Shutting down')
    self.loop.stop()
    self.default_pool.close()
    self.done_pool.close()
    for pool in self.other_pools:
      pool.close()

  def run(self):
    try:
      self.start()
      while True:
        self.check()
        time.sleep(1)
    finally:
      self.close()

  def __enter__(self):
    self.start()
    return self

  def __exit__(self, type, value, traceback):
    self.close()

  def stats(self):
    return {
        **self.agg.result(),
        'result_set': len(self.result_set),
        'done_queue': len(self.done_queue),
        'done_proms': len(self.done_proms),
    }

  def _loop(self, context):
    socket = sockets.ServerSocket(self.address, self.ipv6)
    self._print(f'Listening at {self.address}')
    while context.running:
      now = time.time()
      result = socket.receive()
      self._handle_request(socket, result, now)
      for method in self.methods.values():
        self._handle_input(method, now)
      self._handle_results(socket, now)
      self._handle_dones()
      time.sleep(0.0001)
    socket.close()

  def _handle_request(self, socket, result, now):
    if result is None:
      return
    addr, rid, name, payload = result
    method = self.methods.get(name, None)
    if not method:
      socket.send_error(addr, rid, f'Unknown method {name}.')
      return
    method.inqueue.append((addr, rid, payload, now))
    self._handle_input(method, now)

  def _handle_input(self, method, now):
    if len(method.inqueue) < method.insize:
      return
    if method.inprog[0] >= 2 * method.workers:
      return
    method.inprog[0] += 1
    if method.batched:
      inputs = [method.inqueue.popleft() for _ in range(method.insize)]
      addr, rid, payload, recvd = zip(*inputs)
    else:
      addr, rid, payload, recvd = method.inqueue.popleft()
    future = method.pool.submit(self._work, method, addr, rid, payload, recvd)
    future.method = method
    future.addr = addr
    future.rid = rid
    self.result_set.add(future)
    if method.donefn:
      self.done_queue.append(future)

  def _handle_results(self, socket, now):
    completed, self.result_set = concurrent.futures.wait(
        self.result_set, 0, concurrent.futures.FIRST_COMPLETED)
    for future in completed:
      method = future.method
      try:
        result = future.result()
        addr, rid, payload, logs, recvd = result
        if method.batched:
          for addr, rid, payload in zip(addr, rid, payload):
            socket.send_result(addr, rid, payload)
          for recvd in recvd:
            self.agg.add(method.name, now - recvd, ('min', 'avg', 'max'))
        else:
          socket.send_result(addr, rid, payload)
          self.agg.add(method.name, now - recvd, ('min', 'avg', 'max'))
      except Exception as e:
        print(f'Exception in server {self.name}:')
        typ, tb = type(e), e.__traceback__
        full = ''.join(traceback.format_exception(typ, e, tb)).strip('\n')
        print(full)
        if method.batched:
          for addr, rid in zip(future.addr, future.rid):
            socket.send_error(addr, rid, repr(e))
        else:
          socket.send_error(future.addr, future.rid, repr(e))
        if self.errors:
          self.exception = e
      finally:
        if not method.donefn:
          method.inprog[0] -= 1

  def _handle_dones(self):
    while self.done_queue and self.done_queue[0].done():
      future = self.done_queue.popleft()
      if future.exception():
        continue
      addr, rid, payload, logs, recvd = future.result()
      future2 = self.done_pool.submit(future.method.donefn, logs)
      future2.method = future.method
      self.done_proms.append(future2)
    while self.done_proms and self.done_proms[0].done():
      future = self.done_proms.popleft()
      future.result()
      future.method.inprog[0] -= 1

  def _work(self, method, addr, rid, payload, recvd):
    if method.batched:
      data = [sockets.unpack(x) for x in payload]
      data = {
          k: np.stack([data[i][k] for i in range(method.insize)])
          for k, v in data[0].items()}
    else:
      data = sockets.unpack(payload)
    if method.donefn:
      result, logs = method.workfn(data)
    else:
      result = method.workfn(data)
      result = result or {}
      logs = None
    if method.batched:
      results = [
          {k: v[i] for k, v in result.items()} for i in range(method.insize)]
      payload = [sockets.pack(x) for x in results]
    else:
      payload = sockets.pack(result)
    return addr, rid, payload, logs, recvd

  def _print(self, text):
    printing.print_(f'[{self.name}] {text}')

</embodied/distr/server.py>

<embodied/distr/sockets.py>
import enum
import itertools
import msgpack
import threading
import time

import numpy as np
import zmq

DEBUG = False
# DEBUG = True

class Type(enum.Enum):
  PING   = int(1).to_bytes(1, 'big')  # rid
  PONG   = int(2).to_bytes(1, 'big')  # rid
  CALL   = int(3).to_bytes(1, 'big')  # rid, text, payload
  RESULT = int(4).to_bytes(1, 'big')  # rid, payload
  ERROR  = int(5).to_bytes(1, 'big')  # rid, text

class ConnectError(RuntimeError): pass
class NotAliveError(RuntimeError): pass
class RemoteError(RuntimeError): pass
class ProtocolError(RuntimeError): pass


class ClientSocket:

  def __init__(self, identity, ipv6=False, pings=10, maxage=60):
    self.socket = zmq.Context.instance().socket(zmq.DEALER)
    self.socket.setsockopt(zmq.IDENTITY, identity.to_bytes(16, 'big'))
    self.socket.setsockopt(zmq.IPV6, int(ipv6))
    self.socket.setsockopt(zmq.LINGER, 0)
    self.socket.set_hwm(0)
    self.pings = pings
    self.maxage = maxage
    self.connected = False
    self.last_call = float('-inf')
    self.last_response = float('-inf')
    self.last_pinged = float('-inf')
    self.addr = None
    self.rid = iter(itertools.count(0))
    self.running = True
    self.lock = threading.RLock()

  def connect(self, addr, timeout=10.0):
    self.disconnect()
    with self.lock:
      self.socket.connect(addr)
      self.addr = addr
      rid = next(self.rid).to_bytes(8, 'big')
      self.socket.send_multipart([Type.PING.value, rid])
      start = time.time()
      while True:
        try:
          parts = self.socket.recv_multipart(zmq.NOBLOCK, copy=False)
          typ, rid2, *args = [x.buffer for x in parts]
          if typ == Type.PONG.value and rid == rid2:
            self.connected = True
            return
          else:
            raise ProtocolError(Type(typ).name)
        except zmq.Again:
          pass
        if timeout and time.time() - start >= timeout:
          raise ConnectError()
        time.sleep(0.01)

  def disconnect(self):
    if self.addr:
      with self.lock:
        self.socket.disconnect(self.addr)
        self.connected = False

  def receive(self):
    assert self.connected
    now = time.time()
    try:
      with self.lock:
        parts = self.socket.recv_multipart(zmq.NOBLOCK, copy=False)
      self.last_response = now
    except zmq.Again:
      parts = None
    if parts is None:

      # This is the time since the last response or if the server is not
      # responding, since the last ping so that we can try again.
      last_ping_or_resp = max(self.last_response, self.last_pinged)
      if self.pings and now - last_ping_or_resp >= self.pings:
        self.last_pinged = now
        self.send_ping()

      # This is the time since the last call, unless the server sent back
      # anything in the meantime to keep the connection alive.
      last_call_or_resp = max(self.last_call, self.last_response)
      if self.maxage and now - last_call_or_resp >= self.maxage:
        raise NotAliveError(
            f'\nlast call:     {now - self.last_call:.3f}s ago'
            f'\nlast response: {now - self.last_response:.3f}s ago'
            f'\nlast pinged:   {now - self.last_pinged:.3f}s ago'
        )
      return None

    typ, rid, *args = [x.buffer for x in parts]
    rid = bytes(rid)
    DEBUG and print(
        f'Client received {Type(bytes(typ)).name} ' +
        f'with rid {int.from_bytes(rid, "big")}')
    if typ == Type.PING.value:
      assert not args
      with self.lock:
        self.socket.send_multipart([Type.PONG.value, rid])
      return None
    elif typ == Type.PONG.value:
      assert not args
      return None
    elif typ == Type.RESULT.value:
      payload = args
      return rid, payload
    elif typ == Type.ERROR.value:
      msgs = [str(x, 'utf-8') for x in args]
      raise RemoteError(rid, *msgs)
    else:
      raise ProtocolError(Type(bytes(typ)).name)

  def send_call(self, name, payload):
    assert self.connected
    rid = next(self.rid)
    DEBUG and print(f"Client calling '{name}' with rid {rid}")
    rid = rid.to_bytes(8, 'big')
    name = name.encode('utf-8')
    with self.lock:
      self.socket.send_multipart([Type.CALL.value, rid, name, *payload])
    self.last_call = time.time()
    return rid

  def send_ping(self):
    assert self.connected
    rid = next(self.rid)
    DEBUG and print(f'Client ping with rid {rid}')
    rid = rid.to_bytes(8, 'big')
    with self.lock:
      self.socket.send_multipart([Type.PING.value, rid])
    return rid

  def close(self):
    with self.lock:
      self.socket.close()


class ServerSocket:

  def __init__(self, addr, ipv6=False):
    assert any(addr.startswith(x) for x in ('tcp://', 'ipc://')), addr
    if addr.startswith('tcp://'):
      port = addr.split(':')[-1]
      addr = f'tcp://*:{port}'
    self.socket = zmq.Context.instance().socket(zmq.ROUTER)
    self.socket.setsockopt(zmq.IPV6, ipv6)
    self.socket.setsockopt(zmq.LINGER, 0)
    self.socket.set_hwm(0)
    print(f'Starting server at {addr}')
    self.socket.bind(addr)
    self.alive = {}
    self.rid = iter(itertools.count(0))
    self.lock = threading.RLock()

  def clients(self, maxage=float('inf')):
    now = time.time()
    with self.lock:
      return tuple(k for k, v in self.alive.items() if now - v <= maxage)

  def receive(self):
    now = time.time()
    try:
      with self.lock:
        parts = self.socket.recv_multipart(zmq.NOBLOCK, copy=False)
    except zmq.Again:
      return None
    addr, typ, rid, *args = [x.buffer for x in parts]
    addr = bytes(addr)
    self.alive[addr] = now
    if typ == Type.PING.value:
      assert not args
      with self.lock:
        self.socket.send_multipart([addr, Type.PONG.value, bytes(rid)])
      return None
    elif typ == Type.PONG.value:
      assert not args
      return None
    elif typ == Type.CALL.value:
      method, *payload = args
      method = str(method, 'utf-8')
      return addr, rid, method, payload
    else:
      msg = f'Server received unexpected message of type {typ}'
      self.send_error(addr, rid, msg)
      return None

  def send_ping(self, addr):
    rid = next(self.rid).to_bytes(8, 'big')
    with self.lock:
      self.socket.send_multipart([addr, Type.PING.value, rid])
    return rid

  def send_result(self, addr, rid, payload):
    with self.lock:
      self.socket.send_multipart(
          [addr, Type.RESULT.value, rid, *payload], copy=False, track=True)

  def send_error(self, addr, rid, text):
    text = text.encode('utf-8')
    with self.lock:
      self.socket.send_multipart([addr, Type.ERROR.value, rid, text])

  def close(self):
    with self.lock:
      self.socket.close()


def pack(data):
  data = {k: np.asarray(v) for k, v in data.items()}
  for key, value in data.items():
    assert value.data.c_contiguous, (
        f'Value for key {key} is not contiguous in memory. Call arr.copy() ' +
        'before passing the data into pack().')
  dtypes, shapes, buffers = [], [], []
  items = sorted(data.items(), key=lambda x: x[0])
  keys, vals = zip(*items) if items else ((), ())
  dtypes = [v.dtype.str for v in vals]
  shapes = [v.shape for v in vals]
  buffers = [v.data for v in vals]
  meta = (keys, dtypes, shapes)
  payload = [msgpack.packb(meta), *buffers]
  return payload


def unpack(payload):
  meta, *buffers = payload
  keys, dtypes, shapes = msgpack.unpackb(meta)
  vals = [
      np.frombuffer(b, d).reshape(s)
      for i, (d, s, b) in enumerate(zip(dtypes, shapes, buffers))]
  data = dict(zip(keys, vals))
  return data

</embodied/distr/sockets.py>

<embodied/distr/thread.py>
import threading

from . import utils


class Thread:

  def __init__(self, fn, *args, name=None, start=False):
    self.fn = fn
    self._exitcode = None
    self.exception = None
    name = name or fn.__name__
    self.old_name = name[:]
    self.thread = threading.Thread(
        target=self._wrapper, args=args, name=name, daemon=True)
    self.started = False
    start and self.start()

  @property
  def name(self):
    return self.thread.name

  @property
  def ident(self):
    return self.thread.ident

  @property
  def running(self):
    running = self.thread.is_alive()
    if running:
      assert self.exitcode is None, (self.name, self.exitcode)
    return running

  @property
  def exitcode(self):
    return self._exitcode

  def start(self):
    assert not self.started
    self.started = True
    self.thread.start()

  def check(self):
    assert self.started
    if self.exception is not None:
      raise self.exception

  def join(self, timeout=None):
    self.check()
    self.thread.join(timeout)

  def kill(self):
    if not self.running:
      return
    utils.kill_thread(self.thread)
    self.thread.join(0.1)
    if self.running:
      print(f'Thread {self.name} did not shut down yet.')

  def __repr__(self):
    attrs = ('name', 'ident', 'running', 'exitcode')
    attrs = [f'{k}={getattr(self, k)}' for k in attrs]
    return f'{type(self).__name__}(' + ', '.join(attrs) + ')'

  def _wrapper(self, *args):
    try:
      self.fn(*args)
    except SystemExit:
      return
    except Exception as e:
      utils.warn_remote_error(e, self.name)
      self._exitcode = 1
      self.exception = e
    finally:
      if self._exitcode is None:
        self._exitcode = 0


class StoppableThread(Thread):

  def __init__(self, fn, *args, name=None, start=False):
    self.runflag = None
    def fn2(*args):
      assert self.runflag is not None
      context = utils.Context(lambda: self.runflag)
      fn(context, *args)
    super().__init__(fn2, *args, name=name, start=start)

  def start(self):
    self.runflag = True
    super().start()

  def stop(self, wait=1):
    self.runflag = False
    self.check()
    if not self.running:
      return
    if wait is True:
      self.join()
    elif wait:
      self.join(wait)
      self.kill()

</embodied/distr/thread.py>

<embodied/distr/utils.py>
import ctypes
import multiprocessing as mp
import os
import socket
import threading
import time
import traceback

import embodied
import numpy as np
import psutil


_PRINT_LOCK = None
def get_print_lock():
  global _PRINT_LOCK
  if not _PRINT_LOCK:
    _PRINT_LOCK = mp.get_context().Lock()
  return _PRINT_LOCK


def get_free_port():
  rng = np.random.default_rng()
  while True:
    port = int(rng.integers(5000, 8000))
    if port_free(port):
      return port


def port_free(port):
  with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
    return s.connect_ex(('localhost', int(port)))


def run(workers, duration=None, exit_after=False):
  try:

    for worker in workers:
      if not worker.started:
        try:
          worker.start()
        except Exception:
          print(f'Failed to start worker {worker.name}')
          raise

    start = time.time()
    while True:
      if duration and time.time() - start >= duration:
        print(f'Shutting down workers after {duration} seconds.')
        [x.kill() for x in workers]
        return
      if all(x.exitcode == 0 for x in workers):
        print('All workers terminated successfully.')
        return
      for worker in workers:
        if worker.exitcode not in (None, 0):
          time.sleep(0.1)  # Wait for workers to print their error messages.
          msg = f'Shutting down workers due to crash in {worker.name}.'
          print(msg)
          if exit_after:
            for worker in workers:
              if hasattr(worker, 'pid'):
                kill_subprocs(worker.pid)
          worker.check()  # Raise the forwarded exception.
          raise RuntimeError(msg)  # In case exception was not forwarded.
      time.sleep(0.1)

  finally:
    # Make sure all workers get stopped on shutdown. If some worker processes
    # survive program shutdown after an exception then ports may not be freeed
    # up. Even worse, clients of the new program execution could connect to
    # servers of the previous program execution that did not get cleaned up.
    [x.kill() for x in workers]


def assert_no_children(parent=None):
  procs = list(psutil.Process(parent).children(recursive=True))
  threads = list(threading.enumerate())
  print(
      f'Process {os.getpid()} should have no children.\n' +
      f'Threads: {threads}\n'
      f'Subprocs: {procs}')
  kill_subprocs(parent)


def kill_subprocs(parent=None):
  try:
    procs = list(psutil.Process(parent).children(recursive=True))
  except psutil.NoSuchProcess:
    return
  for proc in procs:
    try:
      proc.terminate()
    except psutil.NoSuchProcess:
      pass
  for proc in procs:
    try:
      proc.wait(timeout=0.1)
    except (psutil.NoSuchProcess, psutil.TimeoutExpired):
      pass
  for proc in procs:
    try:
      proc.kill()
    except psutil.NoSuchProcess:
      pass
  for proc in procs:
    try:
      proc.wait(timeout=0.1)
    except (psutil.NoSuchProcess, psutil.TimeoutExpired):
      pass
  for proc in procs:
    assert not proc_alive(proc.pid)


def kill_proc(pid):
  try:
    proc = psutil.Process(pid)
    proc.terminate()
    try:
      proc.wait(timeout=0.1)
    except psutil.TimeoutExpired:
      proc.kill()
      proc.wait(timeout=0.1)
  except psutil.NoSuchProcess:
    pass


def proc_alive(pid):
  try:
    return psutil.Process(pid).status() != psutil.STATUS_ZOMBIE
  except psutil.NoSuchProcess:
    return False


def kill_thread(thread):
  if isinstance(thread, int):
    thread_id = int(thread)
  elif hasattr(thread, '_thread_id'):
    thread_id = thread._thread_id
  else:
    thread_id = [k for k, v in threading._active.items() if v is thread][0]
  result = ctypes.pythonapi.PyThreadState_SetAsyncExc(
      ctypes.c_long(thread_id), ctypes.py_object(SystemExit))
  if result > 1:
    ctypes.pythonapi.PyThreadState_SetAsyncExc(
        ctypes.c_long(thread_id), None)


def warn_remote_error(e, name, lock=get_print_lock):
  lock = lock() if callable(lock) else lock
  typ, tb = type(e), e.__traceback__
  summary = list(traceback.format_exception_only(typ, e))[0].strip('\n')
  full = ''.join(traceback.format_exception(typ, e, tb)).strip('\n')
  msg = f"Exception in worker '{name}' ({summary}). "
  msg += 'Call check() to reraise in main process. '
  msg += f'Worker stack trace:\n{full}'
  with lock:
    embodied.print(msg, color='red')
  if hasattr(e, 'add_note'):
    e.add_note(f'\nWorker stack trace:\n\n{full}')


class Context:

  def __init__(self, predicate):
    self._predicate = predicate

  @property
  def running(self):
    return self._predicate()

  def __bool__(self):
    raise TypeError('Cannot convert Context to boolean.')

</embodied/distr/utils.py>

<embodied/distr/__init__.py>
import multiprocessing as mp
try:
  mp.set_start_method('spawn')
except RuntimeError:
  pass

from .client import Client
from .thread import Thread, StoppableThread
from .process import Process, StoppableProcess
from .utils import run
from .utils import port_free
from .utils import get_free_port
from .utils import warn_remote_error
from .utils import kill_proc
from .utils import kill_subprocs
from .utils import proc_alive
from .server import Server
from .proc_server import ProcServer
from .sockets import NotAliveError, RemoteError, ProtocolError

</embodied/distr/__init__.py>

<embodied/envs/atari.py>
import os
import threading
from collections import deque

import embodied
import numpy as np


class Atari(embodied.Env):

  LOCK = threading.Lock()
  WEIGHTS = np.array([0.299, 0.587, 1 - (0.299 + 0.587)])
  ACTION_MEANING = (
      'NOOP', 'FIRE', 'UP', 'RIGHT', 'LEFT', 'DOWN', 'UPRIGHT', 'UPLEFT',
      'DOWNRIGHT', 'DOWNLEFT', 'UPFIRE', 'RIGHTFIRE', 'LEFTFIRE', 'DOWNFIRE',
      'UPRIGHTFIRE', 'UPLEFTFIRE', 'DOWNRIGHTFIRE', 'DOWNLEFTFIRE')

  def __init__(
      self, name, repeat=4, size=(84, 84), gray=True, noops=0, lives='unused',
      sticky=True, actions='all', length=108000, pooling=2, aggregate='max',
      resize='pillow', autostart=False, clip_reward=False, seed=None):
    import ale_py
    import ale_py.roms as roms

    assert lives in ('unused', 'discount', 'reset'), lives
    assert actions in ('all', 'needed'), actions
    assert resize in ('opencv', 'pillow'), resize
    assert aggregate in ('max', 'mean'), aggregate
    assert pooling >= 1, pooling
    assert repeat >= 1, repeat
    if name == 'james_bond':
      name = 'jamesbond'

    self.repeat = repeat
    self.size = size
    self.gray = gray
    self.noops = noops
    self.lives = lives
    self.sticky = sticky
    self.length = length
    self.pooling = pooling
    self.aggregate = aggregate
    self.resize = resize
    self.autostart = autostart
    self.clip_reward = clip_reward
    self.rng = np.random.default_rng(seed)

    with self.LOCK:
      self.ale = ale_py.ALEInterface()
      self.ale.setLoggerMode(ale_py.LoggerMode.Error)
      self.ale.setInt(b'random_seed', self.rng.integers(0, 2 ** 31))
      path = os.environ.get('ALE_ROM_PATH', None)
      if path:
        self.ale.loadROM(os.path.join(path, f'{name}.bin'))
      else:
        import ale_py.roms.utils as rom_utils
        self.ale.loadROM(getattr(roms, rom_utils.rom_id_to_name(name)))

    self.ale.setFloat('repeat_action_probability', 0.25 if sticky else 0.0)
    self.actionset = {
        'all': self.ale.getLegalActionSet,
        'needed': self.ale.getMinimalActionSet,
    }[actions]()

    W, H = self.ale.getScreenDims()
    self.buffers = deque(
        [np.zeros((W, H, 3), np.uint8) for _ in range(self.pooling)],
        maxlen=self.pooling)
    self.prevlives = None
    self.duration = None
    self.done = True

  @property
  def obs_space(self):
    return {
        'image': embodied.Space(np.uint8, (*self.size, 1 if self.gray else 3)),
        'reward': embodied.Space(np.float32),
        'is_first': embodied.Space(bool),
        'is_last': embodied.Space(bool),
        'is_terminal': embodied.Space(bool),
    }

  @property
  def act_space(self):
    return {
        'action': embodied.Space(np.int32, (), 0, len(self.actionset)),
        'reset': embodied.Space(bool),
    }

  def step(self, action):
    if action['reset'] or self.done:
      self._reset()
      self.prevlives = self.ale.lives()
      self.duration = 0
      self.done = False
      return self._obs(0.0, is_first=True)
    reward = 0.0
    terminal = False
    last = False
    assert 0 <= action['action'] < len(self.actionset), action['action']
    act = self.actionset[action['action']]
    for repeat in range(self.repeat):
      reward += self.ale.act(act)
      self.duration += 1
      if repeat >= self.repeat - self.pooling:
        self._render()
      if self.ale.game_over():
        terminal = True
        last = True
      if self.duration >= self.length:
        last = True
      lives = self.ale.lives()
      if self.lives == 'discount' and 0 < lives < self.prevlives:
        terminal = True
      if self.lives == 'reset' and 0 < lives < self.prevlives:
        terminal = True
        last = True
      self.prevlives = lives
      if terminal or last:
        break
    self.done = last
    obs = self._obs(reward, is_last=last, is_terminal=terminal)
    return obs

  def _reset(self):
    with self.LOCK:
      self.ale.reset_game()
    for _ in range(self.rng.integers(self.noops + 1)):
      self.ale.act(self.ACTION_MEANING.index('NOOP'))
      if self.ale.game_over():
        with self.LOCK:
          self.ale.reset_game()
    if self.autostart and self.ACTION_MEANING.index('FIRE') in self.actionset:
      self.ale.act(self.ACTION_MEANING.index('FIRE'))
      if self.ale.game_over():
        with self.LOCK:
          self.ale.reset_game()
      self.ale.act(self.ACTION_MEANING.index('UP'))
      if self.ale.game_over():
        with self.LOCK:
          self.ale.reset_game()
    self._render()
    for i, dst in enumerate(self.buffers):
      if i > 0:
        np.copyto(self.buffers[0], dst)

  def _render(self, reset=False):
    self.buffers.appendleft(self.buffers.pop())
    self.ale.getScreenRGB(self.buffers[0])

  def _obs(self, reward, is_first=False, is_last=False, is_terminal=False):
    if self.clip_reward:
      reward = np.sign(reward)
    if self.aggregate == 'max':
      image = np.amax(self.buffers, 0)
    elif self.aggregate == 'mean':
      image = np.mean(self.buffers, 0).astype(np.uint8)
    if self.resize == 'opencv':
      import cv2
      image = cv2.resize(image, self.size, interpolation=cv2.INTER_AREA)
    elif self.resize == 'pillow':
      from PIL import Image
      image = Image.fromarray(image)
      image = image.resize(self.size, Image.BILINEAR)
      image = np.array(image)
    if self.gray:
      image = (image * self.WEIGHTS).sum(-1).astype(image.dtype)[:, :, None]
    return dict(
        image=image,
        reward=np.float32(reward),
        is_first=is_first,
        is_last=is_last,
        is_terminal=is_last,
    )

</embodied/envs/atari.py>

<embodied/envs/bsuite.py>
import time

import embodied
import numpy as np


class BSuite(embodied.Env):

  def __init__(self, task):
    print(
        'Warning: BSuite result logging is stateful and therefore training ' +
        'runs cannot be interrupted or restarted.')
    np.int = int  # Patch deprecated Numpy alias used inside BSuite.
    import bsuite
    from . import from_dm
    if '/' not in task:
      task = f'{task}/0'
    env = bsuite.load_from_id(task)
    self.num_episodes = 0
    self.max_episodes = env.bsuite_num_episodes
    self.exit_after = None
    env = from_dm.FromDM(env)
    env = embodied.wrappers.ForceDtypes(env)
    env = embodied.wrappers.FlattenTwoDimObs(env)
    self.env = env

  @property
  def obs_space(self):
    return self.env.obs_space

  @property
  def act_space(self):
    return self.env.act_space

  def step(self, action):
    obs = self.env.step(action)
    if obs['is_last']:
      self.num_episodes += 1
    if self.num_episodes >= self.max_episodes:
      # After reaching the target number of episodes, continue running for 10
      # minutes to make sure logs are flushed and then raise an exception to
      # terminate the program.
      if not self.exit_after:
        self.exit_after = time.time() + 600
      if time.time() > self.exit_after:
        raise RuntimeError('BSuite run complete')
    return obs

</embodied/envs/bsuite.py>

<embodied/envs/crafter.py>
import json

import embodied
import numpy as np


class Crafter(embodied.Env):

  def __init__(self, task, size=(64, 64), logs=False, logdir=None, seed=None):
    assert task in ('reward', 'noreward')
    import crafter
    self._env = crafter.Env(size=size, reward=(task == 'reward'), seed=seed)
    self._logs = logs
    self._logdir = logdir and embodied.Path(logdir)
    self._logdir and self._logdir.mkdir()
    self._episode = 0
    self._length = None
    self._reward = None
    self._achievements = crafter.constants.achievements.copy()
    self._done = True

  @property
  def obs_space(self):
    spaces = {
        'image': embodied.Space(np.uint8, self._env.observation_space.shape),
        'reward': embodied.Space(np.float32),
        'is_first': embodied.Space(bool),
        'is_last': embodied.Space(bool),
        'is_terminal': embodied.Space(bool),
        'log_reward': embodied.Space(np.float32),
    }
    if self._logs:
      spaces.update({
          f'log_achievement_{k}': embodied.Space(np.int32)
          for k in self._achievements})
    return spaces

  @property
  def act_space(self):
    return {
        'action': embodied.Space(np.int32, (), 0, self._env.action_space.n),
        'reset': embodied.Space(bool),
    }

  def step(self, action):
    if action['reset'] or self._done:
      self._episode += 1
      self._length = 0
      self._reward = 0
      self._done = False
      image = self._env.reset()
      return self._obs(image, 0.0, {}, is_first=True)
    image, reward, self._done, info = self._env.step(action['action'])
    self._reward += reward
    self._length += 1
    if self._done and self._logdir:
      self._write_stats(self._length, self._reward, info)
    return self._obs(
        image, reward, info,
        is_last=self._done,
        is_terminal=info['discount'] == 0)

  def _obs(
      self, image, reward, info,
      is_first=False, is_last=False, is_terminal=False):
    obs = dict(
        image=image,
        reward=np.float32(reward),
        is_first=is_first,
        is_last=is_last,
        is_terminal=is_terminal,
        log_reward=np.float32(info['reward'] if info else 0.0),
    )
    if self._logs:
      log_achievements = {
          f'log_achievement_{k}': info['achievements'][k] if info else 0
          for k in self._achievements}
      obs.update({k: np.int32(v) for k, v in log_achievements.items()})
    return obs

  def _write_stats(self, length, reward, info):
    stats = {
        'episode': self._episode,
        'length': length,
        'reward': round(reward, 1),
        **{f'achievement_{k}': v for k, v in info['achievements'].items()},
    }
    filename = self._logdir / 'stats.jsonl'
    lines = filename.read() if filename.exists() else ''
    lines += json.dumps(stats) + '\n'
    filename.write(lines)
    print(f'Wrote stats: {filename}')

  def render(self):
    return self._env.render()

</embodied/envs/crafter.py>

<embodied/envs/dmc.py>
import functools
import os

import embodied
import numpy as np


class DMC(embodied.Env):

  DEFAULT_CAMERAS = dict(
      quadruped=2,
      locom_rodent=4,
  )

  def __init__(
      self, env, repeat=1, size=(64, 64), image=True, camera=-1):
    if 'MUJOCO_GL' not in os.environ:
      os.environ['MUJOCO_GL'] = 'egl'
    if isinstance(env, str):
      domain, task = env.split('_', 1)
      if camera == -1:
        camera = self.DEFAULT_CAMERAS.get(domain, 0)
      if domain == 'cup':  # Only domain with multiple words.
        domain = 'ball_in_cup'
      if domain == 'manip':
        from dm_control import manipulation
        env = manipulation.load(task + '_vision')
      elif domain == 'locom':
        # camera 0: topdown map
        # camera 2: shoulder
        # camera 4: topdown tracking
        # camera 5: eyes
        from dm_control.locomotion.examples import basic_rodent_2020
        env = getattr(basic_rodent_2020, task)()
      else:
        from dm_control import suite
        env = suite.load(domain, task)
    self._dmenv = env
    from . import from_dm
    self._env = from_dm.FromDM(self._dmenv)
    self._env = embodied.wrappers.ExpandScalars(self._env)
    self._env = embodied.wrappers.ActionRepeat(self._env, repeat)
    self._size = size
    self._image = image
    self._camera = camera

  @functools.cached_property
  def obs_space(self):
    spaces = self._env.obs_space.copy()
    key = 'image' if self._image else 'log_image'
    spaces[key] = embodied.Space(np.uint8, self._size + (3,))
    return spaces

  @functools.cached_property
  def act_space(self):
    return self._env.act_space

  def step(self, action):
    for key, space in self.act_space.items():
      if not space.discrete:
        assert np.isfinite(action[key]).all(), (key, action[key])
    obs = self._env.step(action)
    key = 'image' if self._image else 'log_image'
    obs[key] = self._dmenv.physics.render(*self._size, camera_id=self._camera)
    for key, space in self.obs_space.items():
      if np.issubdtype(space.dtype, np.floating):
        assert np.isfinite(obs[key]).all(), (key, obs[key])
    return obs

</embodied/envs/dmc.py>

<embodied/envs/dmlab.py>
import functools
import re
import zlib

import embodied
import numpy as np


class DMLab(embodied.Env):

  TOKENIZER = re.compile(r'([A-Za-z_]+|[^A-Za-z_ ]+)')

  def __init__(
      self, level, repeat=4, size=(64, 64), mode='train',
      actions='popart', episodic=True, text=None, seed=None):
    import deepmind_lab
    cache = None
    # path = os.environ.get('DMLAB_CACHE', None)
    # if path:
    #   cache = Cache(path)
    self._size = size
    self._repeat = repeat
    self._actions = {
        'impala': IMPALA_ACTION_SET,
        'popart': POPART_ACTION_SET,
    }[actions]
    if text is None:
      text = bool(level.startswith('language'))
    self._episodic = episodic
    self._text = text
    self._random = np.random.RandomState(seed)
    config = dict(height=size[0], width=size[1], logLevel='WARN')
    if mode == 'train':
      if level.endswith('_test'):
        level = level.replace('_test', '_train')
    elif mode == 'eval':
      config.update(allowHoldOutLevels='true', mixerSeed=0x600D5EED)
    else:
      raise NotImplementedError(mode)
    config = {k: str(v) for k, v in config.items()}
    obs = ['RGB_INTERLEAVED', 'INSTR'] if text else ['RGB_INTERLEAVED']
    self._env = deepmind_lab.Lab(
        level='contributed/dmlab30/' + level,
        observations=obs, level_cache=cache, config=config)
    self._current_image = None
    if self._text:
      self._current_instr = None
      self._instr_length = 32
      self._embed_size = 32
      self._vocab_buckets = 64 * 1024
      self._embeddings = np.random.default_rng(seed=0).normal(
          0.0, 1.0, (self._vocab_buckets, self._embed_size)).astype(np.float32)
    self._done = True

  @property
  def obs_space(self):
    spaces = {
        'image': embodied.Space(np.uint8, self._size + (3,)),
        'reward': embodied.Space(np.float32),
        'is_first': embodied.Space(bool),
        'is_last': embodied.Space(bool),
        'is_terminal': embodied.Space(bool),
    }
    if self._text:
      spaces['instr'] = embodied.Space(
          np.float32, self._instr_length * self._embed_size)
    return spaces

  @property
  def act_space(self):
    return {
        'action': embodied.Space(np.int32, (), 0, len(self._actions)),
        'reset': embodied.Space(bool),
    }

  def step(self, action):
    if action['reset'] or self._done:
      self._env.reset(seed=self._random.randint(0, 2 ** 31 - 1))
      self._done = False
      return self._obs(0.0, is_first=True)
    raw_action = np.array(self._actions[action['action']], np.intc)
    reward = self._env.step(raw_action, num_steps=self._repeat)
    self._done = not self._env.is_running()
    return self._obs(reward, is_last=self._done)

  def _obs(self, reward, is_first=False, is_last=False):
    if not self._done:
      self._current_image = self._env.observations()['RGB_INTERLEAVED']
      if self._text:
        self._current_instr = self._embed(self._env.observations()['INSTR'])
    obs = dict(
        image=self._current_image,
        reward=np.float32(reward),
        is_first=is_first,
        is_last=is_last,
        is_terminal=is_last if self._episodic else False,
    )
    if self._text:
      obs['instr'] = self._current_instr
    return obs

  def _embed(self, text):
    tokens = self.TOKENIZER.findall(text.lower())
    indices = [self._hash(token) for token in tokens]
    # print('EMBED', text, '->', tokens, '->', indices)
    indices = indices + [0] * (self._instr_length - len(indices))
    embeddings = [self._embeddings[i] for i in indices]
    return np.concatenate(embeddings)

  @functools.cache
  def _hash(self, token):
    return zlib.crc32(token.encode('utf-8')) % self._vocab_buckets

  def close(self):
    self._env.close()


class Cache:

  def __init__(self, cache_dir):
    self._cache_dir = cache_dir
    import tensorflow as tf
    tf.config.set_visible_devices([], 'GPU')
    tf.config.set_visible_devices([], 'TPU')

  def get_path(self, key):
    import hashlib
    import os
    key = hashlib.md5(key.encode('utf-8')).hexdigest()
    dir_, filename = key[:3], key[3:]
    return os.path.join(self._cache_dir, dir_, filename)

  def fetch(self, key, pk3_path):
    import tensorflow as tf
    path = self.get_path(key)
    try:
      tf.io.gfile.copy(path, pk3_path, overwrite=True)
      return True
    except tf.errors.OpError:
      return False

  def write(self, key, pk3_path):
    import os
    import tensorflow as tf
    path = self.get_path(key)
    try:
      if not tf.io.gfile.exists(path):
        tf.io.gfile.makedirs(os.path.dirname(path))
        tf.io.gfile.copy(pk3_path, path)
    except Exception as e:
      print(f'Could to store level: {e}')


# Small action set used by IMPALA.
IMPALA_ACTION_SET = (
    (  0, 0,  0,  1, 0, 0, 0),  # Forward
    (  0, 0,  0, -1, 0, 0, 0),  # Backward
    (  0, 0, -1,  0, 0, 0, 0),  # Strafe Left
    (  0, 0,  1,  0, 0, 0, 0),  # Strafe Right
    (-20, 0,  0,  0, 0, 0, 0),  # Look Left
    ( 20, 0,  0,  0, 0, 0, 0),  # Look Right
    (-20, 0,  0,  1, 0, 0, 0),  # Look Left + Forward
    ( 20, 0,  0,  1, 0, 0, 0),  # Look Right + Forward
    (  0, 0,  0,  0, 1, 0, 0),  # Fire
)

# Large action set used by PopArt and R2D2.
POPART_ACTION_SET = [
    (  0,   0,  0,  1, 0, 0, 0),  # FW
    (  0,   0,  0, -1, 0, 0, 0),  # BW
    (  0,   0, -1,  0, 0, 0, 0),  # Strafe Left
    (  0,   0,  1,  0, 0, 0, 0),  # Strafe Right
    (-10,   0,  0,  0, 0, 0, 0),  # Small LL
    ( 10,   0,  0,  0, 0, 0, 0),  # Small LR
    (-60,   0,  0,  0, 0, 0, 0),  # Large LL
    ( 60,   0,  0,  0, 0, 0, 0),  # Large LR
    (  0,  10,  0,  0, 0, 0, 0),  # Look Down
    (  0, -10,  0,  0, 0, 0, 0),  # Look Up
    (-10,   0,  0,  1, 0, 0, 0),  # FW + Small LL
    ( 10,   0,  0,  1, 0, 0, 0),  # FW + Small LR
    (-60,   0,  0,  1, 0, 0, 0),  # FW + Large LL
    ( 60,   0,  0,  1, 0, 0, 0),  # FW + Large LR
    (  0,   0,  0,  0, 1, 0, 0),  # Fire
]

</embodied/envs/dmlab.py>

<embodied/envs/dummy.py>
import embodied
import numpy as np


class Dummy(embodied.Env):

  def __init__(self, task, size=(64, 64), length=100):
    assert task in ('cont', 'disc')
    self._task = task
    self._size = size
    self._length = length
    self._step = 0
    self._done = False

  @property
  def obs_space(self):
    return {
        'image': embodied.Space(np.uint8, self._size + (3,)),
        'vector': embodied.Space(np.float32, (7,)),
        # 'token': embodied.Space(np.int32, (), 0, 256),
        'step': embodied.Space(np.int32, (), 0, self._length),
        'reward': embodied.Space(np.float32),
        'is_first': embodied.Space(bool),
        'is_last': embodied.Space(bool),
        'is_terminal': embodied.Space(bool),
    }

  @property
  def act_space(self):

    # if self._task == 'cont':
    #   space = embodied.Space(np.float32, (6,))
    # else:
    #   space = embodied.Space(np.int32, (), 0, 5)
    # return {'action': space, 'reset': embodied.Space(bool)}

    return {
        'action': embodied.Space(np.int32, (), 0, 5),
        'other': embodied.Space(np.float32, (6,)),
        'reset': embodied.Space(bool),
    }

  def step(self, action):
    if action['reset'] or self._done:
      self._step = 0
      self._done = False
      return self._obs(0, is_first=True)
    action = action['action']
    self._step += 1
    self._done = (self._step >= self._length)
    return self._obs(1, is_last=self._done, is_terminal=self._done)

  def _obs(self, reward, is_first=False, is_last=False, is_terminal=False):
    return dict(
        image=np.zeros(self._size + (3,), np.uint8),
        vector=np.zeros(7, np.float32),
        # token=np.zeros((), np.int32),
        step=np.int32(self._step),
        reward=np.float32(reward),
        is_first=is_first,
        is_last=is_last,
        is_terminal=is_terminal,
    )

</embodied/envs/dummy.py>

<embodied/envs/from_dm.py>
import functools

import embodied
import numpy as np


class FromDM(embodied.Env):

  def __init__(self, env, obs_key='observation', act_key='action'):
    self._env = env
    obs_spec = self._env.observation_spec()
    act_spec = self._env.action_spec()
    self._obs_dict = isinstance(obs_spec, dict)
    self._act_dict = isinstance(act_spec, dict)
    self._obs_key = not self._obs_dict and obs_key
    self._act_key = not self._act_dict and act_key
    self._obs_empty = []
    self._done = True

  @functools.cached_property
  def obs_space(self):
    spec = self._env.observation_spec()
    spec = spec if self._obs_dict else {self._obs_key: spec}
    if 'reward' in spec:
      spec['obs_reward'] = spec.pop('reward')
    for key, value in spec.copy().items():
      if int(np.prod(value.shape)) == 0:
        self._obs_empty.append(key)
        del spec[key]
    spaces = {
        'reward': embodied.Space(np.float32),
        'is_first': embodied.Space(bool),
        'is_last': embodied.Space(bool),
        'is_terminal': embodied.Space(bool),
    }
    for key, value in spec.items():
      key = key.replace('/', '_')
      spaces[key] = self._convert(value)
    return spaces

  @functools.cached_property
  def act_space(self):
    spec = self._env.action_spec()
    spec = spec if self._act_dict else {self._act_key: spec}
    return {
        'reset': embodied.Space(bool),
        **{k or self._act_key: self._convert(v) for k, v in spec.items()},
    }

  def step(self, action):
    action = action.copy()
    reset = action.pop('reset')
    if reset or self._done:
      time_step = self._env.reset()
    else:
      action = action if self._act_dict else action[self._act_key]
      time_step = self._env.step(action)
    self._done = time_step.last()
    return self._obs(time_step)

  def _obs(self, time_step):
    if not time_step.first():
      assert time_step.discount in (0, 1), time_step.discount
    obs = time_step.observation
    obs = dict(obs) if self._obs_dict else {self._obs_key: obs}
    if 'reward' in obs:
      obs['obs_reward'] = obs.pop('reward')
    for key in self._obs_empty:
      del obs[key]
    obs = {k.replace('/', '_'): v for k, v in obs.items()}
    return dict(
        reward=np.float32(0.0 if time_step.first() else time_step.reward),
        is_first=time_step.first(),
        is_last=time_step.last(),
        is_terminal=False if time_step.first() else time_step.discount == 0,
        **obs,
    )

  def _convert(self, space):
    if hasattr(space, 'num_values'):
      return embodied.Space(space.dtype, (), 0, space.num_values)
    elif hasattr(space, 'minimum'):
      assert np.isfinite(space.minimum).all(), space.minimum
      assert np.isfinite(space.maximum).all(), space.maximum
      return embodied.Space(
          space.dtype, space.shape, space.minimum, space.maximum)
    else:
      return embodied.Space(space.dtype, space.shape, None, None)

</embodied/envs/from_dm.py>

<embodied/envs/from_gym.py>
import functools

import embodied
import gym
import numpy as np


class FromGym(embodied.Env):

  def __init__(self, env, obs_key='image', act_key='action', **kwargs):
    if isinstance(env, str):
      self._env = gym.make(env, **kwargs)
    else:
      assert not kwargs, kwargs
      self._env = env
    self._obs_dict = hasattr(self._env.observation_space, 'spaces')
    self._act_dict = hasattr(self._env.action_space, 'spaces')
    self._obs_key = obs_key
    self._act_key = act_key
    self._done = True
    self._info = None

  @property
  def env(self):
    return self._env

  @property
  def info(self):
    return self._info

  @functools.cached_property
  def obs_space(self):
    if self._obs_dict:
      spaces = self._flatten(self._env.observation_space.spaces)
    else:
      spaces = {self._obs_key: self._env.observation_space}
    spaces = {k: self._convert(v) for k, v in spaces.items()}
    return {
        **spaces,
        'reward': embodied.Space(np.float32),
        'is_first': embodied.Space(bool),
        'is_last': embodied.Space(bool),
        'is_terminal': embodied.Space(bool),
    }

  @functools.cached_property
  def act_space(self):
    if self._act_dict:
      spaces = self._flatten(self._env.action_space.spaces)
    else:
      spaces = {self._act_key: self._env.action_space}
    spaces = {k: self._convert(v) for k, v in spaces.items()}
    spaces['reset'] = embodied.Space(bool)
    return spaces

  def step(self, action):
    if action['reset'] or self._done:
      self._done = False
      obs = self._env.reset()
      return self._obs(obs, 0.0, is_first=True)
    if self._act_dict:
      action = self._unflatten(action)
    else:
      action = action[self._act_key]
    obs, reward, self._done, self._info = self._env.step(action)
    return self._obs(
        obs, reward,
        is_last=bool(self._done),
        is_terminal=bool(self._info.get('is_terminal', self._done)))

  def _obs(
      self, obs, reward, is_first=False, is_last=False, is_terminal=False):
    if not self._obs_dict:
      obs = {self._obs_key: obs}
    obs = self._flatten(obs)
    obs = {k: np.asarray(v) for k, v in obs.items()}
    obs.update(
        reward=np.float32(reward),
        is_first=is_first,
        is_last=is_last,
        is_terminal=is_terminal)
    return obs

  def render(self):
    image = self._env.render('rgb_array')
    assert image is not None
    return image

  def close(self):
    try:
      self._env.close()
    except Exception:
      pass

  def _flatten(self, nest, prefix=None):
    result = {}
    for key, value in nest.items():
      key = prefix + '/' + key if prefix else key
      if isinstance(value, gym.spaces.Dict):
        value = value.spaces
      if isinstance(value, dict):
        result.update(self._flatten(value, key))
      else:
        result[key] = value
    return result

  def _unflatten(self, flat):
    result = {}
    for key, value in flat.items():
      parts = key.split('/')
      node = result
      for part in parts[:-1]:
        if part not in node:
          node[part] = {}
        node = node[part]
      node[parts[-1]] = value
    return result

  def _convert(self, space):
    if hasattr(space, 'n'):
      return embodied.Space(np.int32, (), 0, space.n)
    return embodied.Space(space.dtype, space.shape, space.low, space.high)

</embodied/envs/from_gym.py>

<embodied/envs/loconav.py>
import functools
import os
import warnings

import embodied
import numpy as np


class LocoNav(embodied.Env):

  DEFAULT_CAMERAS = dict(
      ant=4,
      quadruped=5,
  )

  def __init__(
      self, name, repeat=1, size=(64, 64), camera=-1, again=False,
      termination=False, weaker=1.0):
    if name.endswith('hz'):
      name, freq = name.rsplit('_', 1)
      freq = int(freq.strip('hz'))
    else:
      freq = 50
    if 'MUJOCO_GL' not in os.environ:
      os.environ['MUJOCO_GL'] = 'egl'
    from dm_control import composer
    from dm_control.locomotion.props import target_sphere
    from dm_control.locomotion.tasks import random_goal_maze
    walker, arena = name.split('_', 1)
    if camera == -1:
      camera = self.DEFAULT_CAMERAS.get(walker, 0)
    self._walker = self._make_walker(walker)
    arena = self._make_arena(arena)
    target = target_sphere.TargetSphere(radius=1.2, height_above_ground=0.0)
    task = random_goal_maze.RepeatSingleGoalMaze(
        walker=self._walker, maze_arena=arena, target=target,
        max_repeats=1000 if again else 1,
        randomize_spawn_rotation=True,
        target_reward_scale=1.0,
        aliveness_threshold=-0.5 if termination else -1.0,
        contact_termination=False,
        physics_timestep=min(1 / freq / 4, 0.02),
        control_timestep=1 / freq)
    if not again:
      def after_step(self, physics, random_state):
        super(random_goal_maze.RepeatSingleGoalMaze, self).after_step(
            physics, random_state)
        self._rewarded_this_step = self._target.activated
        self._targets_obtained = int(self._target.activated)
      task.after_step = functools.partial(after_step, task)
    env = composer.Environment(
        time_limit=60, task=task, random_state=None,
        strip_singleton_obs_buffer_dim=True)
    from . import dmc
    self._env = dmc.DMC(env, repeat, size=size, camera=camera, image=False)
    self._visited = None
    self._weaker = weaker

  @property
  def obs_space(self):
    spaces = self._env.obs_space.copy()
    spaces['log_coverage'] = embodied.Space(np.int32, low=-1)
    return spaces

  @property
  def act_space(self):
    return self._env.act_space

  def step(self, action):
    with warnings.catch_warnings():
      warnings.filterwarnings('ignore', '.*is a deprecated alias for.*')
      action = action.copy()
      action['action'] *= self._weaker
      obs = self._env.step(action)
    if obs['is_first']:
      self._visited = set()
    global_pos = self._walker.get_pose(
        self._env._dmenv._physics)[0].reshape(-1)
    self._visited.add(tuple(np.round(global_pos[:2]).astype(int).tolist()))
    obs['log_coverage'] = np.int32(len(self._visited))
    return obs

  def _make_walker(self, name):
    if name == 'ant':
      from dm_control.locomotion.walkers import ant
      return ant.Ant()
    elif name == 'quadruped':
      from . import loconav_quadruped
      return loconav_quadruped.Quadruped()
    else:
      raise NotImplementedError(name)

  def _make_arena(self, name):
    import labmaze
    from dm_control import mjcf
    from dm_control.locomotion.arenas import labmaze_textures
    from dm_control.locomotion.arenas import mazes
    import matplotlib.pyplot as plt
    class WallTexture(labmaze_textures.WallTextures):
      def _build(self, color=[0.8, 0.8, 0.8], model='labmaze_style_01'):
        self._mjcf_root = mjcf.RootElement(model=model)
        self._textures = [self._mjcf_root.asset.add(
            'texture', type='2d', name='wall', builtin='flat',
            rgb1=color, width=100, height=100)]
    wall_textures = {'*': WallTexture([0.8, 0.8, 0.8])}
    cmap = plt.get_cmap('tab10')
    for index in range(9):
      wall_textures[str(index + 1)] = WallTexture(cmap(index)[:3])
    layout = ''.join([
        line[::2].replace('.', ' ') + '\n' for line in MAPS[name]])
    maze = labmaze.FixedMazeWithRandomGoals(
        entity_layer=layout,
        num_spawns=1, num_objects=1, random_state=None)
    arena = mazes.MazeWithTargets(
        maze, xy_scale=1.2, z_height=2.0, aesthetic='default',
        wall_textures=wall_textures, name='maze')
    return arena


MAPS = {

    'maze_s': (
        '            6 6 6 6 6',
        '            6 . . . 6',
        '            6 . G . 6',
        '            6 . . . 6',
        '            5 . . . 4',
        '            5 . . . 4',
        '1 1 1 1 5 5 5 . . . 4',
        '1 . . . . . . . . . 3',
        '1 . P . . . . . . . 3',
        '1 . . . . . . . . . 3',
        '1 1 1 1 2 2 2 3 3 3 3',
    ),

    'maze_m': (
        '6 6 6 6 8 8 8 7 7 7 7',
        '6 . . . . . . . . . 7',
        '6 . G . . . . . . . 7',
        '6 . . . . . . . . . 7',
        '6 6 6 5 5 5 5 . . . 4',
        '            5 . . . 4',
        '1 1 1 1 5 5 5 . . . 4',
        '1 . . . . . . . . . 3',
        '1 . P . . . . . . . 3',
        '1 . . . . . . . . . 3',
        '1 1 1 1 2 2 2 3 3 3 3',
    ),

    'maze_l': (
        '8 8 8 8 7 7 7 6 6 6 6 . . .',
        '8 . . . . . . . . . 6 . . .',
        '8 . G . . . . . . . 6 . . .',
        '8 . . . . . . . . . 6 5 5 5',
        '8 8 8 8 7 7 7 . . . . . . 5',
        '. . . . . . 7 . . . . . . 5',
        '1 1 1 1 1 . 7 . . . . . . 5',
        '1 . . . 1 . 7 9 9 9 . . . 5',
        '1 . . . 1 . . . . 9 . . . 5',
        '1 . . . 1 1 1 9 9 9 . . . 5',
        '2 . . . . . . . . . . . . 4',
        '2 . . . . P . . . . . . . 4',
        '2 . . . . . . . . . . . . 4',
        '2 2 2 2 3 3 3 3 3 3 4 4 4 4',
    ),

    'maze_xl': (
        '9 9 9 9 9 9 9 8 8 8 8 . 4 4 4 4 4',
        '9 . . . . . . . . . 8 . 4 . . . 4',
        '9 . . . . . . . G . 8 . 4 . . . 4',
        '9 . . . . . . . . . 8 . 4 . . . 4',
        '6 . . . 7 7 7 8 8 8 8 . 5 . . . 3',
        '6 . . . 7 . . . . . . . 5 . . . 3',
        '6 . . . 7 7 7 5 5 5 5 5 5 . . . 3',
        '5 . . . . . . . . . . . . . . . 3',
        '5 . . . . . . . . . . . . . . . 3',
        '5 . . . . . . . . . . . . . . . 3',
        '5 5 5 5 4 4 4 . . . 6 6 6 . . . 3',
        '. . . . . . 4 . . . 6 . 6 . . . 3',
        '1 1 1 1 4 4 4 . . . 6 . 6 . . . 3',
        '1 . . . . . . . . . 2 . 1 . . . 1',
        '1 . P . . . . . . . 2 . 1 . . . 1',
        '1 . . . . . . . . . 2 . 1 . . . 1',
        '1 1 1 1 1 1 1 2 2 2 2 . 1 1 1 1 1',
    ),

    'maze_xxl': (
        '7 7 7 7 * * * 6 6 6 * * * 9 9 9 9',
        '7 . . . . . . . . . . . . . . . 9',
        '7 . . . . . . . . . . . . . G . 9',
        '7 . . . . . . . . . . . . . . . 9',
        '* . . . 5 5 5 * * * * * * 9 9 9 9',
        '* . . . 5 . . . . . . . . . . . .',
        '* . . . 5 5 5 * * * * * * 3 3 3 3',
        '8 . . . . . . . . . . . . . . . 3',
        '8 . . . . . . . . . . . . . . . 3',
        '8 . . . . . . . . . . . . . . . 3',
        '8 8 8 8 * * * * * * 4 4 4 . . . *',
        '. . . . . . . . . . . . 4 . . . *',
        '1 1 1 1 * * * * * * 4 4 4 . . . *',
        '1 . . . . . . . . . . . . . . . 2',
        '1 . P . . . . . . . . . . . . . 2',
        '1 . . . . . . . . . . . . . . . 2',
        '1 1 1 1 * * * 6 6 6 * * * 2 2 2 2',
    ),

    'empty': (
        '. . . . . . . . . . . . . . . . .',
        '. . . . . . . . . . . . . . . . .',
        '. . . . . . . . . . . . . . . . .',
        '. . . . . . . . . . . . . . . . .',
        '. . . . . . . . . . . . . . . . .',
        '. . . . . . . . . . . . . . . . .',
        '. . . . . . . . . . . . . . . . .',
        '. . . . . . . . . . . . . . . . .',
        '. . . . . . . . . . . . . . . . .',
        '. . . . . . . . . . . . . . . . .',
        '. . . . . . . . . . . . . . . . .',
        '. . . . . . . . . . . . . . . . .',
        '. . . . . . . . . . . . . . . . .',
        '. . . . . . . . . . . . . . . . .',
        '. . . . . . . . . . . . . . . . .',
        '. . . . . . . . . . . . . . . . .',
        '. . . . . . . . . . . . . . . . .',
    ),

}

</embodied/envs/loconav.py>

<embodied/envs/loconav_quadruped.py>
import os

from dm_control import composer
from dm_control import mjcf
from dm_control.composer.observation import observable
from dm_control.locomotion.walkers import base
from dm_control.locomotion.walkers import legacy_base
from dm_control.mujoco.wrapper import mjbindings
import numpy as np

enums = mjbindings.enums
mjlib = mjbindings.mjlib


class Quadruped(legacy_base.Walker):

  def _build(self, name='walker', initializer=None):
    super()._build(initializer=initializer)
    self._mjcf_root = mjcf.from_path(
        os.path.join(os.path.dirname(__file__), 'loconav_quadruped.xml'))
    if name:
      self._mjcf_root.model = name
    self._prev_action = np.zeros(
        self.action_spec.shape, self.action_spec.dtype)

  def initialize_episode(self, physics, random_state):
    self._prev_action = np.zeros_like(self._prev_action)

  def apply_action(self, physics, action, random_state):
    super().apply_action(physics, action, random_state)
    self._prev_action[:] = action

  def _build_observables(self):
    return QuadrupedObservables(self)

  @property
  def mjcf_model(self):
    return self._mjcf_root

  @property
  def upright_pose(self):
    return base.WalkerPose()

  @composer.cached_property
  def actuators(self):
    return self._mjcf_root.find_all('actuator')

  @composer.cached_property
  def root_body(self):
    return self._mjcf_root.find('body', 'torso')

  @composer.cached_property
  def bodies(self):
    return tuple(self.mjcf_model.find_all('body'))

  @composer.cached_property
  def mocap_tracking_bodies(self):
    return tuple(self.mjcf_model.find_all('body'))

  @property
  def mocap_joints(self):
    return self.mjcf_model.find_all('joint')

  @property
  def _foot_bodies(self):
    return (
        self._mjcf_root.find('body', 'toe_front_left'),
        self._mjcf_root.find('body', 'toe_front_right'),
        self._mjcf_root.find('body', 'toe_back_right'),
        self._mjcf_root.find('body', 'toe_back_left'),
    )

  @composer.cached_property
  def end_effectors(self):
    return self._foot_bodies

  @composer.cached_property
  def observable_joints(self):
    return self._mjcf_root.find_all('joint')

  @composer.cached_property
  def egocentric_camera(self):
    return self._mjcf_root.find('camera', 'egocentric')

  def aliveness(self, physics):
    return (physics.bind(self.root_body).xmat[-1] - 1.) / 2.

  @composer.cached_property
  def ground_contact_geoms(self):
    foot_geoms = []
    for foot in self._foot_bodies:
      foot_geoms.extend(foot.find_all('geom'))
    return tuple(foot_geoms)

  @property
  def prev_action(self):
    return self._prev_action


class QuadrupedObservables(legacy_base.WalkerObservables):

  @composer.observable
  def actuator_activations(self):
    def actuator_activations_in_egocentric_frame(physics):
      return physics.data.act
    return observable.Generic(actuator_activations_in_egocentric_frame)

  @composer.observable
  def root_global_pos(self):
    def root_pos(physics):
      root_xpos, _ = self._entity.get_pose(physics)
      return np.reshape(root_xpos, -1)
    return observable.Generic(root_pos)

  @composer.observable
  def torso_global_pos(self):
    def torso_pos(physics):
      root_body = self._entity.root_body
      root_body_xpos = physics.bind(root_body).xpos
      return np.reshape(root_body_xpos, -1)
    return observable.Generic(torso_pos)

  @property
  def proprioception(self):
    return ([
        self.joints_pos, self.joints_vel, self.actuator_activations,
        self.sensors_accelerometer, self.sensors_gyro,
        self.sensors_velocimeter,
        self.sensors_force, self.sensors_torque,
        self.world_zaxis,
        self.root_global_pos, self.torso_global_pos,
    ] + self._collect_from_attachments('proprioception'))

</embodied/envs/loconav_quadruped.py>

<embodied/envs/loconav_quadruped.xml>
<mujoco model="quadruped">

  <visual>
    <quality shadowsize="2048"/>
    <rgba rangefinder="1 1 0.1 0.1"/>
  </visual>

  <asset>
    <texture name="grid" type="2d" builtin="checker" rgb1=".1 .2 .3" rgb2=".2 .3 .4" width="300" height="300" mark="edge" markrgb=".2 .3 .4"/>
    <material name="grid" texture="grid" texrepeat="1 1" texuniform="true" reflectance=".2"/>
    <material name="self" rgba=".7 .5 .3 1"/>
    <material name="self_default" rgba=".7 .5 .3 1"/>
    <material name="self_highlight" rgba="0 .5 .3 1"/>
    <material name="effector" rgba=".7 .4 .2 1"/>
    <material name="effector_default" rgba=".7 .4 .2 1"/>
    <material name="effector_highlight" rgba="0 .5 .3 1"/>
    <material name="decoration" rgba=".3 .5 .7 1"/>
    <material name="eye" rgba="0 .2 1 1"/>
    <material name="target" rgba=".6 .3 .3 1"/>
    <material name="target_default" rgba=".6 .3 .3 1"/>
    <material name="target_highlight" rgba=".6 .3 .3 .4"/>
    <material name="site" rgba=".5 .5 .5 .3"/>

    <hfield name="terrain" ncol="201" nrow="201" size="30 30 5 .1"/>
  </asset>

  <option timestep=".005"/>

  <default>
    <geom solimp=".9 .99 .003" solref=".01 1"/>
    <default class="body">
      <geom  type="capsule" size=".08" condim="1" material="self" density="500"/>
      <joint type="hinge" damping="30" armature=".01"
             limited="true" solimplimit="0 .99 .01"/>
      <default class="hip">
        <default class="yaw">
          <joint axis="0 0 1" range="-50 50"/>
        </default>
        <default class="pitch">
          <joint axis="0 1 0" range="-20 60"/>
        </default>
        <geom fromto="0 0 0 .3 0 .11"/>
      </default>
      <default class="knee">
        <joint axis="0 1 0" range="-60 50"/>
        <geom size=".065" fromto="0 0 0 .25 0 -.25"/>
      </default>
      <default class="ankle">
        <joint axis="0 1 0" range="-45 55"/>
        <geom size=".055" fromto="0 0 0 0 0 -.25"/>
      </default>
      <default class="toe">
        <geom type="sphere" size=".08" material="effector" friction="1.5"/>
        <site type="sphere" size=".084" material="site"  group="4"/>
      </default>
    </default>
    <default class="rangefinder">
      <site type="capsule" size=".005 .1" material="site" group="4"/>
    </default>

    <default class="coupling">
      <equality solimp="0.95 0.99 0.01" solref=".005 .5"/>
    </default>

    <general ctrllimited="true" gainprm="1000" biasprm="0 -1000" biastype="affine" dyntype="filter" dynprm=".1"/>
    <default class="yaw_act">
      <general ctrlrange="-1 1"/>
    </default>
    <default class="lift_act">
      <general ctrlrange="-1 1.1"/>
    </default>
    <default class="extend_act">
      <general ctrlrange="-.8 .8"/>
    </default>
  </default>

  <worldbody>
    <camera name="sideon" pos="0 -10 5" fovy="45" mode="targetbody" target="torso" />
    <camera name="float_far"  pos="-4 0 2" xyaxes="0 -1 0 .5 0 1" mode="trackcom" fovy="90"/>
    <body name="torso" childclass="body" pos="0 0 .57">

      <camera name="x"  pos="-1.7 0 1" xyaxes="0 -1 0 .75 0 1" mode="trackcom"/>
      <camera name="y"  pos="0 4 2" xyaxes="-1 0 0 0 -.5 1" mode="trackcom"/>
      <camera name="egocentric"  pos=".3 0 .11" xyaxes="0 -1 0 .4 0 1" fovy="60"/>
      <light name="light" pos="0 0 4" mode="trackcom"/>

      <geom name="eye_r" type="cylinder" size=".05"  fromto=".1 -.07 .12 .31 -.07 .08" mass="0"/>
      <site name="pupil_r" type="sphere" size=".033"  pos=".3 -.07 .08" zaxis="1 0 0" material="eye"/>
      <geom name="eye_l" type="cylinder" size=".05"  fromto=".1 .07 .12 .31 .07 .08" mass="0"/>
      <site name="pupil_l" type="sphere" size=".033"  pos=".3 .07 .08" zaxis="1 0 0" material="eye"/>
      <site name="workspace" type="sphere" size=".3 .3 .3"  material="site" pos=".8 0 -.2" group="3"/>

      <site name="rf_00" class="rangefinder" fromto=".41 -.02  .11 .34 0 .115"/>
      <site name="rf_01" class="rangefinder" fromto=".41 -.01  .11 .34 0 .115"/>
      <site name="rf_02" class="rangefinder" fromto=".41   0   .11 .34 0 .115"/>
      <site name="rf_03" class="rangefinder" fromto=".41  .01  .11 .34 0 .115"/>
      <site name="rf_04" class="rangefinder" fromto=".41  .02  .11 .34 0 .115"/>
      <site name="rf_10" class="rangefinder" fromto=".41 -.02  .1  .36 0 .11"/>
      <site name="rf_11" class="rangefinder" fromto=".41 -.02  .1  .36 0 .11"/>
      <site name="rf_12" class="rangefinder" fromto=".41   0   .1  .36 0 .11"/>
      <site name="rf_13" class="rangefinder" fromto=".41  .01  .1  .36 0 .11"/>
      <site name="rf_14" class="rangefinder" fromto=".41  .02  .1  .36 0 .11"/>
      <site name="rf_20" class="rangefinder" fromto=".41 -.02  .09 .38 0 .105"/>
      <site name="rf_21" class="rangefinder" fromto=".41 -.01  .09 .38 0 .105"/>
      <site name="rf_22" class="rangefinder" fromto=".41   0   .09 .38 0 .105"/>
      <site name="rf_23" class="rangefinder" fromto=".41  .01  .09 .38 0 .105"/>
      <site name="rf_24" class="rangefinder" fromto=".41  .02  .09 .38 0 .105"/>
      <site name="rf_30" class="rangefinder" fromto=".41 -.02  .08 .4  0 .1"/>
      <site name="rf_31" class="rangefinder" fromto=".41 -.01  .08 .4  0 .1"/>
      <site name="rf_32" class="rangefinder" fromto=".41   0   .08 .4  0 .1"/>
      <site name="rf_33" class="rangefinder" fromto=".41  .01  .08 .4  0 .1"/>
      <site name="rf_34" class="rangefinder" fromto=".41  .02  .08 .4  0 .1"/>

      <geom name="torso" type="ellipsoid" size=".3 .27 .2" density="1000"/>
      <site name="torso_touch" type="box" size=".26 .26 .26" rgba="0 0 1 0"/>
      <site name="torso" size=".05" rgba="1 0 0 1" />

      <body name="hip_front_left" pos=".2 .2 0" euler="0 0 45" childclass="hip">
        <joint name="yaw_front_left" class="yaw"/>
        <joint name="pitch_front_left" class="pitch"/>
        <geom name="thigh_front_left"/>
        <body name="knee_front_left" pos=".3 0 .11" childclass="knee">
          <joint name="knee_front_left"/>
          <geom name="shin_front_left"/>
          <body name="ankle_front_left" pos=".25 0 -.25" childclass="ankle">
            <joint name="ankle_front_left"/>
            <geom name="foot_front_left"/>
            <body name="toe_front_left" pos="0 0 -.3" childclass="toe">
              <geom name="toe_front_left"/>
              <site name="toe_front_left"/>
            </body>
          </body>
        </body>
      </body>

      <body name="hip_front_right" pos=".2 -.2 0" euler="0 0 -45" childclass="hip">
        <joint name="yaw_front_right" class="yaw"/>
        <joint name="pitch_front_right" class="pitch"/>
        <geom name="thigh_front_right"/>
        <body name="knee_front_right" pos=".3 0 .11" childclass="knee">
          <joint name="knee_front_right"/>
          <geom name="shin_front_right"/>
          <body name="ankle_front_right" pos=".25 0 -.25" childclass="ankle">
            <joint name="ankle_front_right"/>
            <geom name="foot_front_right"/>
            <body name="toe_front_right" pos="0 0 -.3" childclass="toe">
              <geom name="toe_front_right"/>
              <site name="toe_front_right"/>
            </body>
          </body>
        </body>
      </body>

      <body name="hip_back_right" pos="-.2 -.2 0" euler="0 0 -135" childclass="hip">
        <joint name="yaw_back_right" class="yaw"/>
        <joint name="pitch_back_right" class="pitch"/>
        <geom name="thigh_back_right"/>
        <body name="knee_back_right" pos=".3 0 .11" childclass="knee">
          <joint name="knee_back_right"/>
          <geom name="shin_back_right"/>
          <body name="ankle_back_right" pos=".25 0 -.25" childclass="ankle">
            <joint name="ankle_back_right"/>
            <geom name="foot_back_right"/>
            <body name="toe_back_right" pos="0 0 -.3" childclass="toe">
              <geom name="toe_back_right"/>
              <site name="toe_back_right"/>
            </body>
          </body>
        </body>
      </body>

      <body name="hip_back_left" pos="-.2 .2 0" euler="0 0 135" childclass="hip">
        <joint name="yaw_back_left" class="yaw"/>
        <joint name="pitch_back_left" class="pitch"/>
        <geom name="thigh_back_left"/>
        <body name="knee_back_left" pos=".3 0 .11" childclass="knee">
          <joint name="knee_back_left"/>
          <geom name="shin_back_left"/>
          <body name="ankle_back_left" pos=".25 0 -.25" childclass="ankle">
            <joint name="ankle_back_left"/>
            <geom name="foot_back_left"/>
            <body name="toe_back_left" pos="0 0 -.3" childclass="toe">
              <geom name="toe_back_left"/>
              <site name="toe_back_left"/>
            </body>
          </body>
        </body>
      </body>
    </body>
  </worldbody>

  <tendon>
    <fixed name="coupling_front_left">
      <joint joint="pitch_front_left"      coef=".333"/>
      <joint joint="knee_front_left"       coef=".333"/>
      <joint joint="ankle_front_left"      coef=".333"/>
    </fixed>
    <fixed name="coupling_front_right">
      <joint joint="pitch_front_right"      coef=".333"/>
      <joint joint="knee_front_right"       coef=".333"/>
      <joint joint="ankle_front_right"      coef=".333"/>
    </fixed>
    <fixed name="coupling_back_right">
      <joint joint="pitch_back_right"      coef=".333"/>
      <joint joint="knee_back_right"       coef=".333"/>
      <joint joint="ankle_back_right"      coef=".333"/>
    </fixed>
    <fixed name="coupling_back_left">
      <joint joint="pitch_back_left"      coef=".333"/>
      <joint joint="knee_back_left"       coef=".333"/>
      <joint joint="ankle_back_left"      coef=".333"/>
    </fixed>

    <fixed name="extend_front_left">
      <joint joint="pitch_front_left"      coef=".25"/>
      <joint joint="knee_front_left"       coef="-.5"/>
      <joint joint="ankle_front_left"      coef=".25"/>
    </fixed>
    <fixed name="lift_front_left">
      <joint joint="pitch_front_left"      coef=".5"/>
      <joint joint="ankle_front_left"      coef="-.5"/>
    </fixed>

    <fixed name="extend_front_right">
      <joint joint="pitch_front_right"     coef=".25"/>
      <joint joint="knee_front_right"      coef="-.5"/>
      <joint joint="ankle_front_right"     coef=".25"/>
    </fixed>
    <fixed name="lift_front_right">
      <joint joint="pitch_front_right"     coef=".5"/>
      <joint joint="ankle_front_right"     coef="-.5"/>
    </fixed>

    <fixed name="extend_back_right">
      <joint joint="pitch_back_right"     coef=".25"/>
      <joint joint="knee_back_right"      coef="-.5"/>
      <joint joint="ankle_back_right"     coef=".25"/>
    </fixed>
    <fixed name="lift_back_right">
      <joint joint="pitch_back_right"     coef=".5"/>
      <joint joint="ankle_back_right"     coef="-.5"/>
    </fixed>

    <fixed name="extend_back_left">
      <joint joint="pitch_back_left"      coef=".25"/>
      <joint joint="knee_back_left"       coef="-.5"/>
      <joint joint="ankle_back_left"      coef=".25"/>
    </fixed>
    <fixed name="lift_back_left">
      <joint joint="pitch_back_left"     coef=".5"/>
      <joint joint="ankle_back_left"     coef="-.5"/>
    </fixed>
  </tendon>

  <equality>
    <tendon name="coupling_front_left" tendon1="coupling_front_left" class="coupling"/>
    <tendon name="coupling_front_right" tendon1="coupling_front_right" class="coupling"/>
    <tendon name="coupling_back_right" tendon1="coupling_back_right" class="coupling"/>
    <tendon name="coupling_back_left" tendon1="coupling_back_left" class="coupling"/>
  </equality>

  <actuator>
    <general name="yaw_front_left" class="yaw_act" joint="yaw_front_left"/>
    <general name="lift_front_left" class="lift_act" tendon="lift_front_left"/>
    <general name="extend_front_left" class="extend_act" tendon="extend_front_left"/>
    <general name="yaw_front_right" class="yaw_act" joint="yaw_front_right"/>
    <general name="lift_front_right" class="lift_act" tendon="lift_front_right"/>
    <general name="extend_front_right" class="extend_act" tendon="extend_front_right"/>
    <general name="yaw_back_right" class="yaw_act" joint="yaw_back_right"/>
    <general name="lift_back_right" class="lift_act" tendon="lift_back_right"/>
    <general name="extend_back_right" class="extend_act" tendon="extend_back_right"/>
    <general name="yaw_back_left" class="yaw_act" joint="yaw_back_left"/>
    <general name="lift_back_left" class="lift_act" tendon="lift_back_left"/>
    <general name="extend_back_left" class="extend_act" tendon="extend_back_left"/>
  </actuator>

  <sensor>
    <accelerometer name="imu_accel" site="torso"/>
    <gyro name="imu_gyro" site="torso"/>
    <velocimeter name="velocimeter" site="torso"/>
    <force name="force_toe_front_left" site="toe_front_left"/>
    <force name="force_toe_front_right" site="toe_front_right"/>
    <force name="force_toe_back_right" site="toe_back_right"/>
    <force name="force_toe_back_left" site="toe_back_left"/>
    <torque name="torque_toe_front_left" site="toe_front_left"/>
    <torque name="torque_toe_front_right" site="toe_front_right"/>
    <torque name="torque_toe_back_right" site="toe_back_right"/>
    <torque name="torque_toe_back_left" site="toe_back_left"/>
    <subtreecom name="center_of_mass" body="torso"/>
    <rangefinder name="rf_00" site="rf_00"/>
    <rangefinder name="rf_01" site="rf_01"/>
    <rangefinder name="rf_02" site="rf_02"/>
    <rangefinder name="rf_03" site="rf_03"/>
    <rangefinder name="rf_04" site="rf_04"/>
    <rangefinder name="rf_10" site="rf_10"/>
    <rangefinder name="rf_11" site="rf_11"/>
    <rangefinder name="rf_12" site="rf_12"/>
    <rangefinder name="rf_13" site="rf_13"/>
    <rangefinder name="rf_14" site="rf_14"/>
    <rangefinder name="rf_20" site="rf_20"/>
    <rangefinder name="rf_21" site="rf_21"/>
    <rangefinder name="rf_22" site="rf_22"/>
    <rangefinder name="rf_23" site="rf_23"/>
    <rangefinder name="rf_24" site="rf_24"/>
    <rangefinder name="rf_30" site="rf_30"/>
    <rangefinder name="rf_31" site="rf_31"/>
    <rangefinder name="rf_32" site="rf_32"/>
    <rangefinder name="rf_33" site="rf_33"/>
    <rangefinder name="rf_34" site="rf_34"/>
  </sensor>
</mujoco>

</embodied/envs/loconav_quadruped.xml>

<embodied/envs/minecraft.py>
import embodied
import numpy as np

from . import minecraft_base


class Minecraft(embodied.Wrapper):

  def __init__(self, task, *args, **kwargs):
    super().__init__({
        'wood': MinecraftWood,
        'climb': MinecraftClimb,
        'diamond': MinecraftDiamond,
    }[task](*args, **kwargs))


class MinecraftWood(embodied.Wrapper):

  def __init__(self, *args, **kwargs):
    actions = BASIC_ACTIONS
    self.rewards = [
        CollectReward('log', repeated=1),
        HealthReward(),
    ]
    length = kwargs.pop('length', 36000)
    env = minecraft_base.MinecraftBase(actions, *args, **kwargs)
    env = embodied.wrappers.TimeLimit(env, length)
    super().__init__(env)

  def step(self, action):
    obs = self.env.step(action)
    reward = sum([fn(obs, self.env.inventory) for fn in self.rewards])
    obs['reward'] = np.float32(reward)
    return obs


class MinecraftClimb(embodied.Wrapper):

  def __init__(self, *args, **kwargs):
    actions = BASIC_ACTIONS
    length = kwargs.pop('length', 36000)
    env = minecraft_base.MinecraftBase(actions, *args, **kwargs)
    env = embodied.wrappers.TimeLimit(env, length)
    super().__init__(env)
    self._previous = None
    self._health_reward = HealthReward()

  def step(self, action):
    obs = self.env.step(action)
    x, y, z = obs['log_player_pos']
    height = np.float32(y)
    if obs['is_first']:
      self._previous = height
    reward = (height - self._previous) + self._health_reward(obs)
    obs['reward'] = np.float32(reward)
    self._previous = height
    return obs


class MinecraftDiamond(embodied.Wrapper):

  def __init__(self, *args, **kwargs):
    actions = {
        **BASIC_ACTIONS,
        'craft_planks': dict(craft='planks'),
        'craft_stick': dict(craft='stick'),
        'craft_crafting_table': dict(craft='crafting_table'),
        'place_crafting_table': dict(place='crafting_table'),
        'craft_wooden_pickaxe': dict(nearbyCraft='wooden_pickaxe'),
        'craft_stone_pickaxe': dict(nearbyCraft='stone_pickaxe'),
        'craft_iron_pickaxe': dict(nearbyCraft='iron_pickaxe'),
        'equip_stone_pickaxe': dict(equip='stone_pickaxe'),
        'equip_wooden_pickaxe': dict(equip='wooden_pickaxe'),
        'equip_iron_pickaxe': dict(equip='iron_pickaxe'),
        'craft_furnace': dict(nearbyCraft='furnace'),
        'place_furnace': dict(place='furnace'),
        'smelt_iron_ingot': dict(nearbySmelt='iron_ingot'),
    }
    self.rewards = [
        CollectReward('log', once=1),
        CollectReward('planks', once=1),
        CollectReward('stick', once=1),
        CollectReward('crafting_table', once=1),
        CollectReward('wooden_pickaxe', once=1),
        CollectReward('cobblestone', once=1),
        CollectReward('stone_pickaxe', once=1),
        CollectReward('iron_ore', once=1),
        CollectReward('furnace', once=1),
        CollectReward('iron_ingot', once=1),
        CollectReward('iron_pickaxe', once=1),
        CollectReward('diamond', once=1),
        HealthReward(),
    ]
    length = kwargs.pop('length', 36000)
    env = minecraft_base.MinecraftBase(actions, *args, **kwargs)
    env = embodied.wrappers.TimeLimit(env, length)
    super().__init__(env)

  def step(self, action):
    obs = self.env.step(action)
    reward = sum([fn(obs, self.env.inventory) for fn in self.rewards])
    obs['reward'] = np.float32(reward)
    return obs


class CollectReward:

  def __init__(self, item, once=0, repeated=0):
    self.item = item
    self.once = once
    self.repeated = repeated
    self.previous = 0
    self.maximum = 0

  def __call__(self, obs, inventory):
    current = inventory[self.item]
    if obs['is_first']:
      self.previous = current
      self.maximum = current
      return 0
    reward = self.repeated * max(0, current - self.previous)
    if self.maximum == 0 and current > 0:
      reward += self.once
    self.previous = current
    self.maximum = max(self.maximum, current)
    return reward


class HealthReward:

  def __init__(self, scale=0.01):
    self.scale = scale
    self.previous = None

  def __call__(self, obs, inventory=None):
    health = obs['health']
    if obs['is_first']:
      self.previous = health
      return 0
    reward = self.scale * (health - self.previous)
    self.previous = health
    return np.float32(reward)


BASIC_ACTIONS = {
    'noop': dict(),
    'attack': dict(attack=1),
    'turn_up': dict(camera=(-15, 0)),
    'turn_down': dict(camera=(15, 0)),
    'turn_left': dict(camera=(0, -15)),
    'turn_right': dict(camera=(0, 15)),
    'forward': dict(forward=1),
    'back': dict(back=1),
    'left': dict(left=1),
    'right': dict(right=1),
    'jump': dict(jump=1, forward=1),
    'place_dirt': dict(place='dirt'),
}

</embodied/envs/minecraft.py>

<embodied/envs/minecraft_base.py>
import logging
import threading

import embodied
import numpy as np


class MinecraftBase(embodied.Env):

  _LOCK = threading.Lock()

  def __init__(
      self, actions,
      repeat=1,
      size=(64, 64),
      break_speed=100.0,
      gamma=10.0,
      sticky_attack=30,
      sticky_jump=10,
      pitch_limit=(-60, 60),
      log_inv_keys=('log', 'cobblestone', 'iron_ingot', 'diamond'),
      logs=False,
  ):
    if logs:
      logging.basicConfig(level=logging.DEBUG)
    self._repeat = repeat
    self._size = size
    if break_speed != 1.0:
      sticky_attack = 0

    # Make env
    with self._LOCK:
      from .import minecraft_minerl
      self._gymenv = minecraft_minerl.MineRLEnv(size, break_speed).make()
    from . import from_gym
    self._env = from_gym.FromGym(self._gymenv)
    self._inventory = {}

    # Observations
    self._inv_keys = [
        k for k in self._env.obs_space if k.startswith('inventory/')
        if k != 'inventory/log2']
    self._inv_log_keys = [f'inventory/{k}' for k in log_inv_keys]
    assert all(k in self._inv_keys for k in self._inv_log_keys), (
        self._inv_keys, self._inv_log_keys)
    self._step = 0
    self._max_inventory = None
    self._equip_enum = self._gymenv.observation_space[
        'equipped_items']['mainhand']['type'].values.tolist()
    self._obs_space = self.obs_space

    # Actions
    self._noop_action = minecraft_minerl.NOOP_ACTION
    actions = self._insert_defaults(actions)
    self._action_names = tuple(actions.keys())
    self._action_values = tuple(actions.values())
    message = f'Minecraft action space ({len(self._action_values)}):'
    print(message, ', '.join(self._action_names))
    self._sticky_attack_length = sticky_attack
    self._sticky_attack_counter = 0
    self._sticky_jump_length = sticky_jump
    self._sticky_jump_counter = 0
    self._pitch_limit = pitch_limit
    self._pitch = 0

  @property
  def obs_space(self):
    return {
        'image': embodied.Space(np.uint8, self._size + (3,)),
        'inventory': embodied.Space(np.float32, len(self._inv_keys), 0),
        'inventory_max': embodied.Space(np.float32, len(self._inv_keys), 0),
        'equipped': embodied.Space(np.float32, len(self._equip_enum), 0, 1),
        'reward': embodied.Space(np.float32),
        'health': embodied.Space(np.float32),
        'hunger': embodied.Space(np.float32),
        'breath': embodied.Space(np.float32),
        'is_first': embodied.Space(bool),
        'is_last': embodied.Space(bool),
        'is_terminal': embodied.Space(bool),
        **{f'log_{k}': embodied.Space(np.int64) for k in self._inv_log_keys},
        'log_player_pos': embodied.Space(np.float32, 3),
    }

  @property
  def act_space(self):
    return {
        'action': embodied.Space(np.int32, (), 0, len(self._action_values)),
        'reset': embodied.Space(bool),
    }

  def step(self, action):
    action = action.copy()
    index = action.pop('action')
    action.update(self._action_values[index])
    action = self._action(action)
    if action['reset']:
      obs = self._reset()
    else:
      following = self._noop_action.copy()
      for key in ('attack', 'forward', 'back', 'left', 'right'):
        following[key] = action[key]
      for act in [action] + ([following] * (self._repeat - 1)):
        obs = self._env.step(act)
        if self._env.info and 'error' in self._env.info:
          obs = self._reset()
          break
    obs = self._obs(obs)
    self._step += 1
    assert 'pov' not in obs, list(obs.keys())
    return obs

  @property
  def inventory(self):
    return self._inventory

  def _reset(self):
    with self._LOCK:
      obs = self._env.step({'reset': True})
    self._step = 0
    self._max_inventory = None
    self._sticky_attack_counter = 0
    self._sticky_jump_counter = 0
    self._pitch = 0
    self._inventory = {}
    return obs

  def _obs(self, obs):
    obs['inventory/log'] += obs.pop('inventory/log2')
    self._inventory = {
        k.split('/', 1)[1]: obs[k] for k in self._inv_keys
        if k != 'inventory/air'}
    inventory = np.array([obs[k] for k in self._inv_keys], np.float32)
    if self._max_inventory is None:
      self._max_inventory = inventory
    else:
      self._max_inventory = np.maximum(self._max_inventory, inventory)
    index = self._equip_enum.index(obs['equipped_items/mainhand/type'])
    equipped = np.zeros(len(self._equip_enum), np.float32)
    equipped[index] = 1.0
    player_x = obs['location_stats/xpos']
    player_y = obs['location_stats/ypos']
    player_z = obs['location_stats/zpos']
    obs = {
        'image': obs['pov'],
        'inventory': inventory,
        'inventory_max': self._max_inventory.copy(),
        'equipped': equipped,
        'health': np.float32(obs['life_stats/life'] / 20),
        'hunger': np.float32(obs['life_stats/food'] / 20),
        'breath': np.float32(obs['life_stats/air'] / 300),
        'reward': np.float32(0.0),
        'is_first': obs['is_first'],
        'is_last': obs['is_last'],
        'is_terminal': obs['is_terminal'],
        **{f'log_{k}': np.int64(obs[k]) for k in self._inv_log_keys},
        'log_player_pos': np.array([player_x, player_y, player_z], np.float32),
    }
    for key, value in obs.items():
      space = self._obs_space[key]
      if not isinstance(value, np.ndarray):
        value = np.array(value)
      assert value in space, (key, value, value.dtype, value.shape, space)
    return obs

  def _action(self, action):
    if self._sticky_attack_length:
      if action['attack']:
        self._sticky_attack_counter = self._sticky_attack_length
      if self._sticky_attack_counter > 0:
        action['attack'] = 1
        action['jump'] = 0
        self._sticky_attack_counter -= 1
    if self._sticky_jump_length:
      if action['jump']:
        self._sticky_jump_counter = self._sticky_jump_length
      if self._sticky_jump_counter > 0:
        action['jump'] = 1
        action['forward'] = 1
        self._sticky_jump_counter -= 1
    if self._pitch_limit and action['camera'][0]:
      lo, hi = self._pitch_limit
      if not (lo <= self._pitch + action['camera'][0] <= hi):
        action['camera'] = (0, action['camera'][1])
      self._pitch += action['camera'][0]
    return action

  def _insert_defaults(self, actions):
    actions = {name: action.copy() for name, action in actions.items()}
    for key, default in self._noop_action.items():
      for action in actions.values():
        if key not in action:
          action[key] = default
    return actions

</embodied/envs/minecraft_base.py>

<embodied/envs/minecraft_minerl.py>
from minerl.herobraine.env_spec import EnvSpec
from minerl.herobraine.hero import handler
from minerl.herobraine.hero import handlers
from minerl.herobraine.hero import mc
from minerl.herobraine.hero.mc import INVERSE_KEYMAP

import numpy as np

np.float = float
np.int = int
np.bool = bool


# def edit_options(**kwargs):
#   import os, pathlib, re
#   for word in os.popen('pip3 --version').read().split(' '):
#     if '-packages/pip' in word:
#       break
#   else:
#     raise RuntimeError('Could not found python package directory.')
#   packages = pathlib.Path(word).parent
#   filename = packages / 'minerl/Malmo/Minecraft/run/options.txt'
#   options = filename.read_text()
#   if 'fovEffectScale:' not in options:
#     options += 'fovEffectScale:1.0\n'
#   if 'simulationDistance:' not in options:
#     options += 'simulationDistance:12\n'
#   for key, value in kwargs.items():
#     assert f'{key}:' in options, key
#     assert isinstance(value, str), (value, type(value))
#     options = re.sub(f'{key}:.*\n', f'{key}:{value}\n', options)
#   filename.write_text(options)


# edit_options(
#     difficulty='2',
#     renderDistance='6',
#     simulationDistance='6',
#     fovEffectScale='0.0',
#     ao='1',
#     gamma='5.0',
# )


class MineRLEnv(EnvSpec):

  def __init__(self, resolution=(64, 64), break_speed=50):
    self.resolution = resolution
    self.break_speed = break_speed
    super().__init__(name='MineRLEnv-v1')

  def create_agent_start(self):
    return [
        BreakSpeedMultiplier(self.break_speed),
    ]

  def create_agent_handlers(self):
    return []

  def create_server_world_generators(self):
    return [handlers.DefaultWorldGenerator(force_reset=True)]

  def create_server_quit_producers(self):
    return [handlers.ServerQuitWhenAnyAgentFinishes()]

  def create_server_initial_conditions(self):
    return [
        handlers.TimeInitialCondition(
            allow_passage_of_time=True,
            start_time=0,
        ),
        handlers.SpawningInitialCondition(
            allow_spawning=True,
        )
    ]

  def create_observables(self):
    return [
        handlers.POVObservation(self.resolution),
        handlers.FlatInventoryObservation(mc.ALL_ITEMS),
        handlers.EquippedItemObservation(
            mc.ALL_ITEMS, _default='air', _other='other'),
        handlers.ObservationFromCurrentLocation(),
        handlers.ObservationFromLifeStats(),
    ]

  def create_actionables(self):
    kw = dict(_other='none', _default='none')
    return [
        handlers.KeybasedCommandAction('forward', INVERSE_KEYMAP['forward']),
        handlers.KeybasedCommandAction('back', INVERSE_KEYMAP['back']),
        handlers.KeybasedCommandAction('left', INVERSE_KEYMAP['left']),
        handlers.KeybasedCommandAction('right', INVERSE_KEYMAP['right']),
        handlers.KeybasedCommandAction('jump', INVERSE_KEYMAP['jump']),
        handlers.KeybasedCommandAction('sneak', INVERSE_KEYMAP['sneak']),
        handlers.KeybasedCommandAction('attack', INVERSE_KEYMAP['attack']),
        handlers.CameraAction(),
        handlers.PlaceBlock(['none'] + mc.ALL_ITEMS, **kw),
        handlers.EquipAction(['none'] + mc.ALL_ITEMS, **kw),
        handlers.CraftAction(['none'] + mc.ALL_ITEMS, **kw),
        handlers.CraftNearbyAction(['none'] + mc.ALL_ITEMS, **kw),
        handlers.SmeltItemNearby(['none'] + mc.ALL_ITEMS, **kw),
    ]

  def is_from_folder(self, folder):
    return folder == 'none'

  def get_docstring(self):
    return ''

  def determine_success_from_rewards(self, rewards):
    return True

  def create_rewardables(self):
    return []

  def create_server_decorators(self):
    return []

  def create_mission_handlers(self):
    return []

  def create_monitors(self):
    return []


class BreakSpeedMultiplier(handler.Handler):

  def __init__(self, multiplier=1.0):
    self.multiplier = multiplier

  def to_string(self):
    return f'break_speed({self.multiplier})'

  def xml_template(self):
    return '<BreakSpeedMultiplier>{{multiplier}}</BreakSpeedMultiplier>'


NOOP_ACTION = dict(
    camera=(0, 0), forward=0, back=0, left=0, right=0, attack=0, sprint=0,
    jump=0, sneak=0, craft='none', nearbyCraft='none', nearbySmelt='none',
    place='none', equip='none',
)

</embodied/envs/minecraft_minerl.py>

<embodied/envs/pinpad.py>
import collections

import embodied
import numpy as np


class PinPad(embodied.Env):

  COLORS = {
      '1': (255,   0,   0),
      '2': (  0, 255,   0),
      '3': (  0,   0, 255),
      '4': (255, 255,   0),
      '5': (255,   0, 255),
      '6': (  0, 255, 255),
      '7': (128,   0, 128),
      '8': (  0, 128, 128),
  }

  def __init__(self, task, length=10000):
    assert length > 0
    layout = {
        'three': LAYOUT_THREE,
        'four': LAYOUT_FOUR,
        'five': LAYOUT_FIVE,
        'six': LAYOUT_SIX,
        'seven': LAYOUT_SEVEN,
        'eight': LAYOUT_EIGHT,
    }[task]
    self.layout = np.array([list(line) for line in layout.split('\n')]).T
    assert self.layout.shape == (16, 14), self.layout.shape
    self.length = length
    self.random = np.random.RandomState()
    self.pads = set(self.layout.flatten().tolist()) - set('* #\n')
    self.target = tuple(sorted(self.pads))
    self.spawns = []
    for (x, y), char in np.ndenumerate(self.layout):
      if char != '#':
        self.spawns.append((x, y))
    print(f'Created PinPad env with sequence: {"->".join(self.target)}')
    self.sequence = collections.deque(maxlen=len(self.target))
    self.player = None
    self.steps = None
    self.done = None
    self.countdown = None

  @property
  def act_space(self):
    return {
        'action': embodied.Space(np.int32, (), 0, 5),
        'reset': embodied.Space(bool),
    }

  @property
  def obs_space(self):
    return {
        'image': embodied.Space(np.uint8, (64, 64, 3)),
        'reward': embodied.Space(np.float32),
        'is_first': embodied.Space(bool),
        'is_last': embodied.Space(bool),
        'is_terminal': embodied.Space(bool),
    }

  def step(self, action):
    if self.done or action['reset']:
      self.player = self.spawns[self.random.randint(len(self.spawns))]
      self.sequence.clear()
      self.steps = 0
      self.done = False
      self.countdown = 0
      return self._obs(reward=0.0, is_first=True)
    if self.countdown:
      self.countdown -= 1
      if self.countdown == 0:
        self.player = self.spawns[self.random.randint(len(self.spawns))]
        self.sequence.clear()
    reward = 0.0
    move = [(0, 0), (0, 1), (0, -1), (1, 0), (-1, 0)][action['action']]
    x = np.clip(self.player[0] + move[0], 0, 15)
    y = np.clip(self.player[1] + move[1], 0, 13)
    tile = self.layout[x][y]
    if tile != '#':
      self.player = (x, y)
    if tile in self.pads:
      if not self.sequence or self.sequence[-1] != tile:
        self.sequence.append(tile)
    if tuple(self.sequence) == self.target and not self.countdown:
      reward += 10.0
      self.countdown = 10
    self.steps += 1
    self.done = self.done or (self.steps >= self.length)
    return self._obs(reward=reward, is_last=self.done)

  def render(self):
    grid = np.zeros((16, 16, 3), np.uint8) + 255
    white = np.array([255, 255, 255])
    if self.countdown:
      grid[:] = (223, 255, 223)
    current = self.layout[self.player[0]][self.player[1]]
    for (x, y), char in np.ndenumerate(self.layout):
      if char == '#':
        grid[x, y] = (192, 192, 192)
      elif char in self.pads:
        color = np.array(self.COLORS[char])
        color = color if char == current else (10 * color + 90 * white) / 100
        grid[x, y] = color
    grid[self.player] = (0, 0, 0)
    grid[:, -2:] = (192, 192, 192)
    for i, char in enumerate(self.sequence):
      grid[2 * i + 1, -2] = self.COLORS[char]
    image = np.repeat(np.repeat(grid, 4, 0), 4, 1)
    return image.transpose((1, 0, 2))

  def _obs(self, reward, is_first=False, is_last=False, is_terminal=False):
    return dict(
        image=self.render(),
        reward=np.float32(reward),
        is_first=is_first,
        is_last=is_last,
        is_terminal=is_terminal,
    )


LAYOUT_THREE = """
################
#1111      3333#
#1111      3333#
#1111      3333#
#1111      3333#
#              #
#              #
#              #
#              #
#     2222     #
#     2222     #
#     2222     #
#     2222     #
################
""".strip('\n')

LAYOUT_FOUR = """
################
#1111      4444#
#1111      4444#
#1111      4444#
#1111      4444#
#              #
#              #
#              #
#              #
#3333      2222#
#3333      2222#
#3333      2222#
#3333      2222#
################
""".strip('\n')

LAYOUT_FIVE = """
################
#          4444#
#111       4444#
#111       4444#
#111           #
#111        555#
#           555#
#           555#
#333        555#
#333           #
#333       2222#
#333       2222#
#          2222#
################
""".strip('\n')

LAYOUT_SIX = """
################
#111        555#
#111        555#
#111        555#
#              #
#33          66#
#33          66#
#33          66#
#33          66#
#              #
#444        222#
#444        222#
#444        222#
################
""".strip('\n')

LAYOUT_SEVEN = """
################
#111        444#
#111        444#
#11          44#
#              #
#33          55#
#33          55#
#33          55#
#33          55#
#              #
#66          22#
#666  7777  222#
#666  7777  222#
################
""".strip('\n')

LAYOUT_EIGHT = """
################
#111  8888  444#
#111  8888  444#
#11          44#
#              #
#33          55#
#33          55#
#33          55#
#33          55#
#              #
#66          22#
#666  7777  222#
#666  7777  222#
################
""".strip('\n')

</embodied/envs/pinpad.py>

<embodied/envs/procgen.py>
import embodied
import numpy as np


class ProcGen(embodied.Env):

  def __init__(self, task, size=(64, 64), resize='pillow', **kwargs):
    assert resize in ('opencv', 'pillow'), resize
    import procgen  # noqa
    from . import from_gym
    self.size = size
    self.resize = resize
    if self.size == (64, 64):
      self.source = 'step'
    else:
      self.source = 'info'

    if self.source == 'info':
      kwargs['render_mode'] = 'rgb_array'
    try:
      self.env = from_gym.FromGym(f'procgen:procgen-{task}-v0', **kwargs)
    except Exception:
      self.env = from_gym.FromGym(f'procgen-{task}-v0', **kwargs)
    if self.source == 'info':
      self.inner = self.env
      while not hasattr(self.inner, 'get_info'):
        self.inner = self.inner.env

  @property
  def obs_space(self):
    spaces = self.env.obs_space.copy()
    if self.source != 'step':
      spaces['image'] = embodied.Space(np.uint8, (*self.size, 3))
    return spaces

  @property
  def act_space(self):
    return self.env.act_space

  def step(self, action):
    obs = self.env.step(action)
    if self.source == 'step':
      pass
    elif self.source == 'info':
      info = self.inner.get_info()
      assert len(info) == 1
      obs['image'] = self._resize(info[0]['rgb'], self.size, self.resize)
    else:
      raise NotImplementedError(self.source)
    return obs

  def _resize(self, image, size, method):
    if method == 'opencv':
      import cv2
      image = cv2.resize(image, size, interpolation=cv2.INTER_AREA)
      return image
    elif method == 'pillow':
      from PIL import Image
      image = Image.fromarray(image)
      image = image.resize((size[1], size[0]), Image.BILINEAR)
      image = np.array(image)
      return image
    else:
      raise NotImplementedError(method)

</embodied/envs/procgen.py>

<embodied/envs/pybullet.py>
import functools
import importlib.util

import embodied
import numpy as np

from omni_epic.envs.wrappers.vision import VisionWrapper


class PyBullet(embodied.Env):

  def __init__(self, env_path, vision=True, size=(64, 64), use_depth=True, fov=90.):
    spec = importlib.util.spec_from_file_location('env', env_path)
    module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(module)
    Env = getattr(module, 'Env')
    self._env = Env()
    if vision:
      self._env = VisionWrapper(self._env, height=size[0], width=size[1], use_depth=use_depth, fov=fov)
    self._vision = vision
    self._size = size
    self._use_depth = use_depth
    self._terminated = True
    self._info = None

  @functools.cached_property
  def obs_space(self):
    obs_space = {
        'vector': self._convert(self._env.observation_space),
        'reward': embodied.Space(np.float32),
        'is_first': embodied.Space(bool),
        'is_last': embodied.Space(bool),
        'is_terminal': embodied.Space(bool),
      }
    if self._vision:
      obs_space['image'] = embodied.Space(np.float32, self._size + (4,), low=0., high=1.) if self._use_depth else embodied.Space(np.float32, self._size + (3,), low=0., high=1.)
    return obs_space

  @functools.cached_property
  def act_space(self):
    return {
        'action': self._convert(self._env.action_space),
        'reset': embodied.Space(bool),
    }

  def step(self, action):
    if action['reset'] or self._terminated:
      self._terminated = False
      obs = self._env.reset()
      obs = {
          'vector': obs,
          'reward': np.float32(0.0),
          'is_first': True,
          'is_last': False,
          'is_terminal': False,
      }
    else:
      obs, reward, self._terminated, truncated, self._info = self._env.step(action['action'])
      obs = {
          'vector': obs,
          'reward': np.float32(reward),
          'is_first': False,
          'is_last': self._terminated or truncated,
          'is_terminal': self._terminated,
      }
    if self._vision:
      obs['image'] = self._env.vision()
    return obs

  def get_success(self):
    return self._env.get_success()

  def render(self, *args, **kwargs):
      return self._env.render(*args, **kwargs)

  def render3p(self, *args, **kwargs):
      return self._env.render3p(*args, **kwargs)

  def close(self):
    self._env.close()

  def _convert(self, space):
    if hasattr(space, 'n'):
      return embodied.Space(np.int32, (), 0, space.n)
    return embodied.Space(space.dtype, space.shape, space.low, space.high)

</embodied/envs/pybullet.py>

<embodied/replay/chunk.py>
import io

import embodied
import numpy as np


class Chunk:

  __slots__ = ('time', 'uuid', 'succ', 'length', 'size', 'data', 'saved')

  def __init__(self, size=1024):
    self.time = embodied.timestamp(millis=True)
    self.uuid = embodied.uuid()
    self.succ = embodied.uuid(0)
    # self.uuid = int(np.random.randint(1, 2 * 63))
    # self.succ = 0
    self.length = 0
    self.size = size
    self.data = None
    self.saved = False

  def __repr__(self):
    return f'Chunk({self.filename})'

  def __lt__(self, other):
    return self.time < other.time

  @property
  def filename(self):
    succ = self.succ.uuid if isinstance(self.succ, type(self)) else self.succ
    return f'{self.time}-{str(self.uuid)}-{str(succ)}-{self.length}.npz'

  @property
  def nbytes(self):
    if not self.data:
      return 0
    return sum(x.nbytes for x in self.data.values())

  def append(self, step):
    assert self.length < self.size
    if not self.data:
      example = step
      self.data = {
          k: np.empty((self.size, *v.shape), v.dtype)
          for k, v in example.items()}
    for key, value in step.items():
      self.data[key][self.length] = value
    self.length += 1
    # if self.length == self.size:
    #   [x.setflags(write=False) for x in self.data.values()]

  def update(self, index, length, mapping):
    assert 0 <= index <= self.length, (index, self.length)
    assert 0 <= index + length <= self.length, (index, length, self.length)
    for key, value in mapping.items():
      self.data[key][index: index + length] = value

  def slice(self, index, length):
    assert 0 <= index and index + length <= self.length
    return {k: v[index: index + length] for k, v in self.data.items()}

  @embodied.timer.section('chunk_save')
  def save(self, directory, log=False):
    assert not self.saved
    self.saved = True
    filename = embodied.Path(directory) / self.filename
    data = {k: v[:self.length] for k, v in self.data.items()}
    with io.BytesIO() as stream:
      np.savez_compressed(stream, **data)
      stream.seek(0)
      filename.write(stream.read(), mode='wb')
    log and print(f'Saved chunk: {filename.name}')

  @classmethod
  def load(cls, filename, error='raise'):
    assert error in ('raise', 'none')
    time, uuid, succ, length = filename.stem.split('-')
    length = int(length)
    try:
      with embodied.Path(filename).open('rb') as f:
        data = np.load(f)
        data = {k: data[k] for k in data.keys()}
    except Exception as e:
      print(f'Error loading chunk {filename}: {e}')
      if error == 'raise':
        raise
      else:
        return None
    chunk = cls(length)
    chunk.time = time
    chunk.uuid = embodied.uuid(uuid)
    chunk.succ = embodied.uuid(succ)
    # chunk.uuid = int(uuid)
    # chunk.succ = int(succ)
    chunk.length = length
    chunk.data = data
    chunk.saved = True
    return chunk

</embodied/replay/chunk.py>

<embodied/replay/indexdict.py>
class IndexDict:

  def __init__(self):
    self._indices = {}
    self._items = []

  def keys(self):
    return self._indices.keys()

  def items(self):
    return tuple(self._items)

  def __repr__(self):
    return repr(dict(self._items))

  def __len__(self):
    return len(self._items)

  def __setitem__(self, key, value):
    if key in self._indices:
      return
    self._indices[key] = len(self._items)
    self._items.append((key, value))

  def __getitem__(self, index_or_key):
    if isinstance(index_or_key, int):
      index = index_or_key
    else:
      index = self._indices[index_or_key]
    return self._items[index][1]

  def __delitem__(self, index):
    self.pop(index)

  def pop(self, index_or_key):
    if isinstance(index_or_key, int):
      index = index_or_key
      del self._indices[self._items[index][0]]
    else:
      index = self._indices.pop(index_or_key)
    value = self._items[index][1]
    last = self._items.pop()
    if index != len(self._items):
      self._items[index] = last
      self._indices[last[0]] = index
    return value

</embodied/replay/indexdict.py>

<embodied/replay/limiters.py>
import threading


class MinSize:

  def __init__(self, minimum):
    assert 1 <= minimum, minimum
    self.minimum = minimum
    self.size = 0
    self.lock = threading.Lock()

  def save(self):
    return {'size': self.size}

  def load(self, data):
    self.size = data['size']

  def want_insert(self, reason=False):
    if reason:
      return True, 'ok'
    else:
      return True

  def want_sample(self, reason=False):
    if reason:
      if self.size < self.minimum:
        return False, f'too empty: {self.size} < {self.minimum}'
      return True, 'ok'
    else:
      if self.size < self.minimum:
        return False
      return True

  def insert(self):
    with self.lock:
      self.size += 1

  def remove(self):
    with self.lock:
      self.size -= 1

  def sample(self):
    pass


class SamplesPerInsert:

  def __init__(self, samples_per_insert, tolerance, minimum=1):
    assert 1 <= minimum
    self.samples_per_insert = samples_per_insert
    self.minimum = minimum
    self.avail = -minimum
    self.min_avail = -tolerance
    self.max_avail = tolerance * samples_per_insert
    self.size = 0
    self.lock = threading.Lock()

  def save(self):
    return {'size': self.size, 'avail': self.avail}

  def load(self, data):
    self.size = data['size']
    self.avail = data['avail']

  def want_insert(self, reason=False):
    if reason:
      if self.size < self.minimum:
        return True, 'ok'
      if self.avail >= self.max_avail:
        return False, f'rate limited: {self.avail:.3f} >= {self.max_avail:.3f}'
      return True, 'ok'
    else:
      if self.size < self.minimum:
        return True
      if self.avail >= self.max_avail:
        return False
      return True

  def want_sample(self, reason=False):
    if reason:
      if self.size < self.minimum:
        return False, f'too empty: {self.size} < {self.minimum}'
      if self.avail <= self.min_avail:
        return False, f'rate limited: {self.avail:.3f} <= {self.min_avail:.3f}'
      return True, 'ok'
    else:
      if self.size < self.minimum:
        return False
      if self.avail <= self.min_avail:
        return False
      return True

  def insert(self):
    with self.lock:
      self.avail += self.samples_per_insert
      self.size += 1

  def remove(self):
    with self.lock:
      self.size -= 1

  def sample(self):
    with self.lock:
      self.avail -= 1

</embodied/replay/limiters.py>

<embodied/replay/replay.py>
import threading
import time
from collections import defaultdict, deque
from concurrent.futures import ThreadPoolExecutor
from functools import partial as bind

import embodied
import numpy as np

from . import chunk as chunklib
from . import limiters
from . import selectors


class Replay:

  def __init__(
      self, length, capacity=None, directory=None, chunksize=1024, min_size=1,
      samples_per_insert=None, tolerance=1e4, online=False, selector=None,
      save_wait=False, seed=0):
    assert not capacity or min_size <= capacity

    self.length = length
    self.capacity = capacity
    self.chunksize = chunksize

    self.sampler = selector or selectors.Uniform(seed)

    if samples_per_insert:
      self.limiter = limiters.SamplesPerInsert(
          samples_per_insert, tolerance, min_size)
    else:
      self.limiter = limiters.MinSize(min_size)

    self.chunks = {}
    self.refs = {}
    self.refs_lock = threading.RLock()

    self.items = {}
    self.fifo = deque()
    self.itemid = 0

    self.current = {}
    self.streams = defaultdict(deque)
    self.rwlock = embodied.RWLock()

    self.online = online
    if online:
      self.lengths = defaultdict(int)
      self.queue = deque()

    if directory:
      self.directory = embodied.Path(directory)
      self.directory.mkdir()
      self.workers = ThreadPoolExecutor(16, 'replay_saver')
      self.saved = set()
    else:
      self.directory = None

    self.save_wait = save_wait

    self.metrics = {
        'samples': 0,
        'sample_wait_dur': 0,
        'sample_wait_count': 0,
        'inserts': 0,
        'insert_wait_dur': 0,
        'insert_wait_count': 0,
        'updates': 0,
    }

  def __len__(self):
    return len(self.items)

  def stats(self):
    ratio = lambda x, y: x / y if y else np.nan
    m = self.metrics
    chunk_nbytes = sum(x.nbytes for x in list(self.chunks.values()))
    stats = {
        'items': len(self.items),
        'chunks': len(self.chunks),
        'streams': len(self.streams),
        'ram_gb': chunk_nbytes / (1024 ** 3),
        'inserts': m['inserts'],
        'samples': m['samples'],
        'updates': m['updates'],
        'replay_ratio': ratio(self.length * m['samples'], m['inserts']),
        'insert_wait_avg': ratio(m['insert_wait_dur'], m['inserts']),
        'insert_wait_frac': ratio(m['insert_wait_count'], m['inserts']),
        'sample_wait_avg': ratio(m['sample_wait_dur'], m['samples']),
        'sample_wait_frac': ratio(m['sample_wait_count'], m['samples']),
    }
    for key in self.metrics:
      self.metrics[key] = 0
    return stats

  @embodied.timer.section('replay_add')
  def add(self, step, worker=0):
    with self.rwlock.reading:

      step = {k: v for k, v in step.items() if not k.startswith('log_')}
      step = {k: np.asarray(v) for k, v in step.items()}

      if worker not in self.current:
        chunk = chunklib.Chunk(self.chunksize)
        with self.refs_lock:
          self.refs[chunk.uuid] = 1
        self.chunks[chunk.uuid] = chunk
        self.current[worker] = (chunk.uuid, 0)

      chunkid, index = self.current[worker]
      step['stepid'] = np.frombuffer(
          bytes(chunkid) + index.to_bytes(4, 'big'), np.uint8)
      stream = self.streams[worker]
      chunk = self.chunks[chunkid]
      assert chunk.length == index, (chunk.length, index)
      chunk.append(step)
      assert chunk.length == index + 1, (chunk.length, index + 1)
      stream.append((chunkid, index))
      with self.refs_lock:
        self.refs[chunkid] += 1

      index += 1
      if index < chunk.size:
        self.current[worker] = (chunkid, index)
      else:
        self._complete(chunk, worker)
      assert len(self.streams) == len(self.current)

      if len(stream) >= self.length:
        dur = self._wait(self.limiter.want_insert, 'Replay insert is waiting')
        # These increments are not thread safe, so the metrics will be slightly
        # wrong and it's faster than introducing a lock.
        self.metrics['inserts'] += 1
        self.metrics['insert_wait_dur'] += dur
        self.metrics['insert_wait_count'] += int(dur >= 0.001)
        chunkid, index = stream.popleft()
        self._insert(chunkid, index)

        if self.online and self.lengths[worker] % self.length == 0:
          self.queue.append((chunkid, index))

      if self.online:
        self.lengths[worker] += 1

  @embodied.timer.section('replay_update')
  def update(self, data):
    data = data.copy()
    stepid = data.pop('stepid')
    priority = data.pop('priority', None)
    assert stepid.ndim == 3, stepid.shape
    self.metrics['updates'] += int(np.prod(stepid.shape[:-1]))
    if priority is not None:
      assert priority.ndim == 2, priority.shape
      self.sampler.prioritize(
          stepid.reshape((-1, stepid.shape[-1])),
          priority.flatten())
    if data:
      for i, stepid in enumerate(stepid):
        stepid = stepid[0].tobytes()
        chunkid = embodied.uuid(stepid[:-4])
        index = int.from_bytes(stepid[-4:], 'big')
        values = {k: v[i] for k, v in data.items()}
        try:
          self._setseq(chunkid, index, values)
        except KeyError:
          pass

  @embodied.timer.section('replay_sample')
  def _sample(self):
    dur = self._wait(self.limiter.want_sample, 'Replay sample is waiting')
    self.limiter.sample()
    # These increments are not thread safe, so the metrics can be slightly
    # wrong and it's faster than introducing a lock.
    self.metrics['samples'] += 1
    self.metrics['sample_wait_dur'] += dur
    self.metrics['sample_wait_count'] += int(dur >= 0.001)
    while True:
      try:
        if self.online and self.queue:
          chunkid, index = self.queue.popleft()
          is_online = True
        else:
          with embodied.timer.section('sample'):
            itemid = self.sampler()
          chunkid, index = self.items[itemid]
          is_online = False
        seq = self._getseq(chunkid, index, concat=False)
        return seq, is_online
      except KeyError:
        continue

  def _insert(self, chunkid, index, loading=False):
    while self.capacity and len(self.items) >= self.capacity:
      self._remove(loading=loading)
    itemid = self.itemid
    self.itemid += 1
    self.items[itemid] = (chunkid, index)
    stepids = self._getseq(chunkid, index, ['stepid'])['stepid']
    self.sampler[itemid] = stepids
    self.fifo.append(itemid)
    if not loading:
      self.limiter.insert()

  def _remove(self, loading=False):
    if not loading:
      self.limiter.remove()
    itemid = self.fifo.popleft()
    del self.sampler[itemid]
    chunkid, index = self.items.pop(itemid)
    with self.refs_lock:
      self.refs[chunkid] -= 1
      if self.refs[chunkid] < 1:
        del self.refs[chunkid]
        chunk = self.chunks.pop(chunkid)
        if chunk.succ in self.refs:
          self.refs[chunk.succ] -= 1

  def _getseq(self, chunkid, index, keys=None, concat=True):
    chunk = self.chunks[chunkid]
    available = chunk.length - index
    if available >= self.length:
      with embodied.timer.section('get_slice'):
        seq = chunk.slice(index, self.length)
        if not concat:
          seq = {k: [v] for k, v in seq.items()}
        return seq
    else:
      with embodied.timer.section('get_compose'):
        parts = [chunk.slice(index, available)]
        remaining = self.length - available
        while remaining > 0:
          chunk = self.chunks[chunk.succ]
          used = min(remaining, chunk.length)
          parts.append(chunk.slice(0, used))
          remaining -= used
        seq = {k: [p[k] for p in parts] for k in keys or parts[0].keys()}
        if concat:
          seq = {k: np.concatenate(v, 0) for k, v in seq.items()}
        return seq

  def _setseq(self, chunkid, index, values):
    length = len(next(iter(values.values())))
    chunk = self.chunks[chunkid]
    available = chunk.length - index
    if available >= length:
      with embodied.timer.section('set_slice'):
        return chunk.update(index, length, values)
    else:
      with embodied.timer.section('set_compose'):
        part = {k: v[:available] for k, v in values.items()}
        values = {k: v[available:] for k, v in values.items()}
        chunk.update(index, available, part)
        remaining = length - available
        while remaining > 0:
          chunk = self.chunks[chunk.succ]
          used = min(remaining, chunk.length)
          part = {k: v[:used] for k, v in values.items()}
          values = {k: v[used:] for k, v in values.items()}
          chunk.update(0, used, part)
          remaining -= used

  def dataset(self, batch, length=None):
    # For performance, each batch should be consecutive in memory, rather than
    # a non-consecutive view into a longer batch. For example, this allows
    # near-instant serialization when sending over the network.
    while True:
      seqs, is_online = zip(*[self._sample() for _ in range(batch)])
      if not length or length == self.length:
        data = self._assemble_batch(seqs, 0, self.length)
        data = self._annotate_batch(data, is_online, is_first=True)
        yield data
      else:
        assert length <= self.length, (length, self.length)
        for t in range(0, self.length - self.length % length, length):
          data = self._assemble_batch(seqs, t, t + length)
          data = self._annotate_batch(data, is_online, is_first=(t == 0))
          yield data

  @embodied.timer.section('assemble_batch')
  def _assemble_batch(self, seqs, start, stop):
    shape = (len(seqs), stop - start)
    data = {
        key: np.empty((*shape, *parts[0].shape[1:]), parts[0].dtype)
        for key, parts in seqs[0].items()}
    for n, seq in enumerate(seqs):
      st, dt = 0, 0  # Source and destination time index.
      for p in range(len(seq['stepid'])):
        partlen = len(seq['stepid'][p])
        if start < st + partlen:
          part_start = max(0, start - st)
          part_stop = min(stop - st, partlen)
          num = part_stop - part_start
          for k in data.keys():
            data[k][n, dt: dt + num] = seq[k][p][part_start: part_stop]
          dt += num
        st += partlen
        if st >= stop:
          break
    return data

  @embodied.timer.section('annotate_batch')
  def _annotate_batch(self, data, is_online, is_first):
    data = data.copy()
    if self.online:
      broadcasted = [[x] for x in is_online]
      data['is_online'] = np.full(data['is_first'].shape, broadcasted, bool)
    if 'is_first' in data:
      if is_first:
        data['is_first'] = data['is_first'].copy()
        data['is_first'][:, 0] = True
      if 'is_last' in data:
        # Make sure that abandoned episodes have is_last set.
        next_is_first = np.roll(data['is_first'], shift=-1, axis=1)
        next_is_first[:, -1] = False
        data['is_last'] = data['is_last'] | next_is_first
    return data

  @embodied.timer.section('replay_save')
  def save(self):
    if self.directory:
      with self.rwlock.writing:
        for worker, (chunkid, _) in self.current.items():
          chunk = self.chunks[chunkid]
          if chunk.length > 0:
            self._complete(chunk, worker)
        promises = []
        for chunk in self.chunks.values():
          if chunk.length > 0 and chunk.uuid not in self.saved:
            self.saved.add(chunk.uuid)
            promises.append(self.workers.submit(chunk.save, self.directory))
        if self.save_wait:
          [promise.result() for promise in promises]
    return {'limiter': self.limiter.save()}

  @embodied.timer.section('replay_load')
  def load(self, data=None, directory=None, amount=None):

    directory = directory or self.directory
    amount = amount or self.capacity or np.inf
    if not directory:
      return
    revsorted = lambda x: list(reversed(sorted(list(x))))
    directory = embodied.Path(directory)
    names_loaded = revsorted(x.filename for x in list(self.chunks.values()))
    names_ondisk = revsorted(x.name for x in directory.glob('*.npz'))
    names_ondisk = [x for x in names_ondisk if x not in names_loaded]
    if not names_ondisk:
      return

    numitems = self._numitems(names_loaded + names_ondisk)
    uuids = [embodied.uuid(x.split('-')[1]) for x in names_ondisk]
    total = 0
    numchunks = 0
    for uuid in uuids:
      numchunks += 1
      total += numitems[uuid]
      if total >= amount:
        break

    load = bind(chunklib.Chunk.load, error='none')
    filenames = [directory / x for x in names_ondisk[:numchunks]]

    with ThreadPoolExecutor(16, 'replay_loader') as pool:
      chunks = [x for x in pool.map(load, filenames) if x]

    # We need to recompute the number of items per chunk now because some
    # chunks may be corrupted and thus not available.
    # numitems = self._numitems(chunks + list(self.chunks.values()))
    numitems = self._numitems(chunks)

    with self.rwlock.writing:
      self.saved.update([chunk.uuid for chunk in chunks])
      with self.refs_lock:
        for chunk in chunks:
          self.chunks[chunk.uuid] = chunk
          self.refs[chunk.uuid] = 0
        for chunk in reversed(chunks):
          amount = numitems[chunk.uuid]
          self.refs[chunk.uuid] += amount
          if chunk.succ in self.refs:
            self.refs[chunk.succ] += 1
          for index in range(amount):
            self._insert(chunk.uuid, index, loading=True)

    if data and 'limiter' in data:
      self.limiter.load(data.pop('limiter'))

  @embodied.timer.section('complete_chunk')
  def _complete(self, chunk, worker):
    succ = chunklib.Chunk(self.chunksize)
    with self.refs_lock:
      self.refs[chunk.uuid] -= 1
      self.refs[succ.uuid] = 2
    self.chunks[succ.uuid] = succ
    self.current[worker] = (succ.uuid, 0)
    chunk.succ = succ.uuid
    return succ

  def _numitems(self, chunks):
    chunks = [x.filename if hasattr(x, 'filename') else x for x in chunks]
    chunks = list(reversed(sorted([embodied.Path(x).stem for x in chunks])))
    times, uuids, succs, lengths = zip(*[x.split('-') for x in chunks])
    uuids = [embodied.uuid(x) for x in uuids]
    succs = [embodied.uuid(x) for x in succs]
    lengths = {k: int(v) for k, v in zip(uuids, lengths)}
    future = {}
    for uuid, succ in zip(uuids, succs):
      future[uuid] = lengths[uuid] + future.get(succ, 0)
    numitems = {}
    for uuid, succ in zip(uuids, succs):
      numitems[uuid] = lengths[uuid] + 1 - self.length + future.get(succ, 0)
    numitems = {k: np.clip(v, 0, lengths[k]) for k, v in numitems.items()}
    return numitems

  def _wait(self, predicate, message, sleep=0.01, notify=60):
    if predicate(reason=False):
      return 0
    start = last_notify = time.time()
    while not predicate(reason=False):
      if time.time() - last_notify > notify:
        allowed, reason = predicate(reason=True)
        if allowed:
          break
        dur = time.time() - start
        embodied.print(f'{message} {dur:.1f}s ({reason})')
        last_notify = time.time()
      time.sleep(sleep)
    return time.time() - start

  def clear(self):
      # Terminate any background threads or processes
      if hasattr(self, 'workers'):
          self.workers.shutdown(wait=False)

      # Clear data structures
      self.chunks.clear()
      self.refs.clear()
      self.items.clear()
      self.fifo.clear()
      self.streams.clear()

  def __del__(self):
      self.clear()

</embodied/replay/replay.py>

<embodied/replay/sampletree.py>
import numpy as np


class SampleTree:

  def __init__(self, branching=16, seed=0):
    assert 2 <= branching
    self.branching = branching
    self.root = Node()
    self.last = None
    self.entries = {}
    self.rng = np.random.default_rng(seed)

  def __len__(self):
    return len(self.entries)

  def insert(self, key, uprob):
    if not self.last:
      node = self.root
    else:
      ups = 0
      node = self.last.parent
      while node and len(node) >= self.branching:
        node = node.parent
        ups += 1
      if not node:
        node = Node()
        node.append(self.root)
        self.root = node
      for _ in range(ups):
        below = Node()
        node.append(below)
        node = below
    entry = Entry(key, uprob)
    node.append(entry)
    self.entries[key] = entry
    self.last = entry

  def remove(self, key):
    entry = self.entries.pop(key)
    entry_parent = entry.parent
    last_parent = self.last.parent
    entry.parent.remove(entry)
    if entry is not self.last:
      entry_parent.append(self.last)
    node = last_parent
    ups = 0
    while node.parent and not len(node):
      above = node.parent
      above.remove(node)
      node = above
      ups += 1
    if not len(node):
      self.last = None
      return
    while isinstance(node, Node):
      node = node.children[-1]
    self.last = node

  def update(self, key, uprob):
    entry = self.entries[key]
    entry.uprob = uprob
    entry.parent.recompute()

  def sample(self):
    node = self.root
    while isinstance(node, Node):
      uprobs = np.array([x.uprob for x in node.children])
      total = uprobs.sum()
      if not np.isfinite(total):
        finite = np.isinf(uprobs)
        probs = finite / finite.sum()
      elif total == 0:
        probs = np.ones(len(uprobs)) / len(uprobs)
      else:
        probs = uprobs / total
      choice = self.rng.choice(np.arange(len(uprobs)), p=probs)
      node = node.children[choice.item()]
    return node.key


class Node:

  __slots__ = ('parent', 'children', 'uprob')

  def __init__(self, parent=None):
    self.parent = parent
    self.children = []
    self.uprob = 0

  def __repr__(self):
    return (
        f'Node(uprob={self.uprob}, '
        f'children={[x.uprob for x in self.children]})'
    )

  def __len__(self):
    return len(self.children)

  def __bool__(self):
    return True

  def append(self, child):
    if child.parent:
      child.parent.remove(child)
    child.parent = self
    self.children.append(child)
    self.recompute()

  def remove(self, child):
    child.parent = None
    self.children.remove(child)
    self.recompute()

  def recompute(self):
    self.uprob = sum(x.uprob for x in self.children)
    self.parent and self.parent.recompute()


class Entry:

  __slots__ = ('parent', 'key', 'uprob')

  def __init__(self, key=None, uprob=None):
    self.parent = None
    self.key = key
    self.uprob = uprob

</embodied/replay/sampletree.py>

<embodied/replay/selectors.py>
from collections import defaultdict, deque

import numpy as np

from . import sampletree


class Fifo:

  def __init__(self):
    self.queue = deque()

  def __call__(self):
    return self.queue[0]

  def __setitem__(self, key, stepids):
    self.queue.append(key)

  def __delitem__(self, key):
    if self.queue[0] == key:
      self.queue.popleft()
    else:
      # This is very slow but typically not used.
      self.queue.remove(key)


class Uniform:

  def __init__(self, seed=0):
    self.indices = {}
    self.keys = []
    self.rng = np.random.default_rng(seed)

  def __call__(self):
    index = self.rng.integers(0, len(self.keys)).item()
    return self.keys[index]

  def __setitem__(self, key, stepids):
    self.indices[key] = len(self.keys)
    self.keys.append(key)

  def __delitem__(self, key):
    index = self.indices.pop(key)
    last = self.keys.pop()
    if index != len(self.keys):
      self.keys[index] = last
      self.indices[last] = index


class Recency:

  def __init__(self, uprobs, seed=0):
    assert uprobs[0] >= uprobs[-1], uprobs
    self.uprobs = uprobs
    self.tree = self._build(uprobs)
    self.rng = np.random.default_rng(seed)
    self.step = 0
    self.steps = {}
    self.items = {}

  def __call__(self):
    for retry in range(10):
      try:
        age = self._sample(self.tree, self.rng)
        if len(self.items) < len(self.uprobs):
          age = int(age / len(self.uprobs) * len(self.items))
        return self.items[self.step - 1 - age]
      except KeyError:
        # Item might have been deleted very recently.
        if retry < 9:
          import time
          time.sleep(0.01)
        else:
          raise

  def __setitem__(self, key, stepids):
    self.steps[key] = self.step
    self.items[self.step] = key
    self.step += 1

  def __delitem__(self, key):
    step = self.steps.pop(key)
    del self.items[step]

  def _sample(self, tree, rng, bfactor=16):
    path = []
    for level, prob in enumerate(tree):
      segment = prob[*path]
      path += (rng.choice(len(segment), p=segment),)
    index = sum(
        index * bfactor ** (len(tree) - level - 1)
        for level, index in enumerate(path))
    return index

  def _build(self, uprobs, bfactor=16):
    assert np.isfinite(uprobs).all(), uprobs
    assert (uprobs >= 0).all(), uprobs
    depth = int(np.ceil(np.log(len(uprobs)) / np.log(bfactor)))
    size = bfactor ** depth
    uprobs = np.concatenate([uprobs, np.zeros(size - len(uprobs))])
    tree = [uprobs]
    for level in reversed(range(depth - 1)):
      tree.insert(0, tree[0].reshape((-1, bfactor)).sum(-1))
    for level, prob in enumerate(tree):
      prob = prob.reshape([bfactor] * (1 + level))
      total = prob.sum(-1, keepdims=True)
      with np.errstate(divide='ignore', invalid='ignore'):
        tree[level] = np.where(total, prob / total, prob)
    return tree


class Prioritized:

  def __init__(
      self, exponent=1.0, initial=1.0, zero_on_sample=False,
      maxfrac=0.0, branching=16, seed=0):
    assert 0 <= maxfrac <= 1, maxfrac
    self.exponent = float(exponent)
    self.initial = float(initial)
    self.zero_on_sample = zero_on_sample
    self.maxfrac = maxfrac
    self.tree = sampletree.SampleTree(branching, seed)
    self.prios = defaultdict(lambda: self.initial)
    self.stepitems = defaultdict(list)
    self.items = {}

  def prioritize(self, stepids, priorities):
    if not isinstance(stepids[0], bytes):
      stepids = [x.tobytes() for x in stepids]
    for stepid, priority in zip(stepids, priorities):
      try:
        self.prios[stepid] = priority
      except KeyError:
        print('Ignoring priority update for removed time step.')
        pass
    items = []
    for stepid in stepids:
      items += self.stepitems[stepid]
    for key in list(set(items)):
      try:
        self.tree.update(key, self._aggregate(key))
      except KeyError:
        print('Ignoring tree update for removed time step.')
        pass

  def __call__(self):
    key = self.tree.sample()
    if self.zero_on_sample:
      zeros = [0.0] * len(self.items[key])
      self.prioritize(self.items[key], zeros)
    return key

  def __setitem__(self, key, stepids):
    if not isinstance(stepids[0], bytes):
      stepids = [x.tobytes() for x in stepids]
    self.items[key] = stepids
    [self.stepitems[stepid].append(key) for stepid in stepids]
    self.tree.insert(key, self._aggregate(key))

  def __delitem__(self, key):
    self.tree.remove(key)
    stepids = self.items.pop(key)
    for stepid in stepids:
      stepitems = self.stepitems[stepid]
      stepitems.remove(key)
      if not stepitems:
        del self.stepitems[stepid]
        del self.prios[stepid]

  def _aggregate(self, key):
    # Both list comprehensions in this function are a performance bottleneck
    # because they are called very often.
    prios = [self.prios[stepid] for stepid in self.items[key]]
    if self.exponent != 1.0:
      prios = [x ** self.exponent for x in prios]
    mean = sum(prios) / len(prios)
    if self.maxfrac:
      return self.maxfrac * max(prios) + (1 - self.maxfrac) * mean
    else:
      return mean


class Mixture:

  def __init__(self, selectors, fractions, seed=0):
    assert set(selectors.keys()) == set(fractions.keys())
    assert sum(fractions.values()) == 1, fractions
    for key, frac in list(fractions.items()):
      if not frac:
        selectors.pop(key)
        fractions.pop(key)
    keys = sorted(selectors.keys())
    self.selectors = [selectors[key] for key in keys]
    self.fractions = np.array([fractions[key] for key in keys], np.float32)
    self.rng = np.random.default_rng(seed)

  def __call__(self):
    return self.rng.choice(self.selectors, p=self.fractions)()

  def __setitem__(self, key, stepids):
    for selector in self.selectors:
      selector[key] = stepids

  def __delitem__(self, key):
    for selector in self.selectors:
      del selector[key]

  def prioritize(self, stepids, priorities):
    for selector in self.selectors:
      if hasattr(selector, 'prioritize'):
        selector.prioritize(stepids, priorities)

</embodied/replay/selectors.py>

<embodied/replay/__init__.py>
from .replay import Replay
from . import selectors

</embodied/replay/__init__.py>

<embodied/requirements.txt>
cloudpickle
colored
gputil
msgpack
numpy
psutil
ruamel.yaml
tensorflow-cpu
zmq

</embodied/requirements.txt>

<embodied/run/eval.py>
import time
import pickle
import re
from collections import defaultdict
from functools import partial as bind
import cloudpickle
from datetime import datetime

import embodied
import numpy as np
from .. import distr


class Driver:

  def __init__(self, make_env_fns, parallel=True, height=720, width=1280, **kwargs):
    assert len(make_env_fns) >= 1
    self.parallel = parallel
    self.height = height
    self.width = width
    self.kwargs = kwargs
    self.length = len(make_env_fns)
    if parallel:
      import multiprocessing as mp
      context = mp.get_context()
      self.pipes, pipes = zip(*[context.Pipe() for _ in range(self.length)])
      fns = [cloudpickle.dumps(fn) for fn in make_env_fns]
      self.procs = [
          distr.StoppableProcess(self._env_server, i, pipe, fn, start=True)
          for i, (fn, pipe) in enumerate(zip(fns, pipes))]
      self.pipes[0].send(('act_space',))
      self.act_space = self._receive(self.pipes[0])
    else:
      self.envs = [fn() for fn in make_env_fns]
      self.act_space = self.envs[0].act_space
    self.callbacks = []
    self.done = np.full((self.length,), False)
    self.acts = None
    self.carry = None
    self.reset()

  def reset(self, init_policy=None):
    self.done = np.full((self.length,), False)
    self.acts = {
        k: np.zeros((self.length,) + v.shape, v.dtype)
        for k, v in self.act_space.items()}
    self.acts['reset'] = np.ones(self.length, bool)
    self.carry = init_policy and init_policy(self.length)

  def close(self):
    if self.parallel:
      [proc.stop() for proc in self.procs]
    else:
      [env.close() for env in self.envs]

  def on_step(self, callback):
    self.callbacks.append(callback)

  def __call__(self, policy, steps=0, episodes=0):
    step, episode = 0, 0
    while step < steps or episode < episodes:
      step, episode = self._step(policy, step, episode)

  def _step(self, policy, step, episode):
    acts = self.acts
    assert all(len(x) == self.length for x in acts.values())
    assert all(isinstance(v, np.ndarray) for v in acts.values())
    acts = [{k: v[i] for k, v in acts.items()} for i in range(self.length)]
    if self.parallel:
      [pipe.send(('step', act)) for pipe, act in zip(self.pipes, acts)]
      obs = [self._receive(pipe) for pipe in self.pipes]
      [pipe.send(('get_success',)) for pipe in self.pipes]
      success = [self._receive(pipe) for pipe in self.pipes]
      [pipe.send(('render', self.height, self.width,)) for pipe in self.pipes]
      render = [self._receive(pipe) for pipe in self.pipes]
      [pipe.send(('render3p', self.height, self.width,)) for pipe in self.pipes]
      render3p = [self._receive(pipe) for pipe in self.pipes]
    else:
      obs = [env.step(act) for env, act in zip(self.envs, acts)]
      success = [env.get_success() for env in self.envs]
      render = [env.render(height=self.height, width=self.width) for env in self.envs]
      render3p = [env.render3p(height=self.height, width=self.width) for env in self.envs]
    obs = {k: np.stack([x[k] for x in obs]) for k in obs[0].keys()}
    assert all(len(x) == self.length for x in obs.values()), obs
    acts, outs, self.carry = policy(obs, self.carry, **self.kwargs)
    assert all(k not in acts for k in outs), (
        list(outs.keys()), list(acts.keys()))
    if obs['is_last'].any():
      mask = ~obs['is_last']
      acts = {k: self._mask(v, mask) for k, v in acts.items()}
    acts['reset'] = obs['is_last'].copy()
    self.acts = acts
    trans = {**obs, **acts, **outs, 'success': success, 'render': render, 'render3p': render3p,}
    for i in range(self.length):
      trn = {k: v[i] for k, v in trans.items()}
      if not self.done[i]:
        [fn(trn, i, **self.kwargs) for fn in self.callbacks]
    step += len(obs['is_first']) - self.done.sum()
    episode += (obs['is_last'] & ~self.done).sum()
    self.done |= obs['is_last']
    return step, episode

  def _mask(self, value, mask):
    while mask.ndim < value.ndim:
      mask = mask[..., None]
    return value * mask.astype(value.dtype)

  def _receive(self, pipe):
    try:
      msg, arg = pipe.recv()
      if msg == 'error':
        raise RuntimeError(arg)
      assert msg == 'result'
      return arg
    except Exception:
      print('Terminating workers due to an exception.')
      [proc.kill() for proc in self.procs]
      raise

  @staticmethod
  def _env_server(context, envid, pipe, ctor):
    try:
      ctor = cloudpickle.loads(ctor)
      env = ctor()
      while context.running:
        if not pipe.poll(0.1):
          time.sleep(0.1)
          continue
        try:
          msg, *args = pipe.recv()
        except EOFError:
          return
        if msg == 'step':
          assert len(args) == 1
          act = args[0]
          obs = env.step(act)
          pipe.send(('result', obs))
        elif msg == 'obs_space':
          assert len(args) == 0
          pipe.send(('result', env.obs_space))
        elif msg == 'act_space':
          assert len(args) == 0
          pipe.send(('result', env.act_space))
        elif msg == 'get_success':
          assert len(args) == 0
          pipe.send(('result', env.get_success()))
        elif msg == 'render':
          assert len(args) == 2
          height = args[0]
          width = args[1]
          pipe.send(('result', env.render(height=height, width=width)))
        elif msg == 'render3p':
          assert len(args) == 2
          height = args[0]
          width = args[1]
          pipe.send(('result', env.render3p(height=height, width=width)))
        else:
          raise ValueError(f'Invalid message {msg}')
    except Exception as e:
      distr.warn_remote_error(e, f'Env{envid}')
      pipe.send(('error', e))
    finally:
      print(f'Closing env {envid}')
      env.close()
      pipe.close()


def eval(make_agent, make_env, args, num_episodes, height=720, width=1280, eval_dir=None):
  assert args.from_checkpoint

  agent = make_agent()

  logdir = embodied.Path(args.logdir)
  if eval_dir is None:
    eval_dir = logdir / 'eval/'
  eval_dir.mkdir()
  step = embodied.Counter()
  episodes = defaultdict(embodied.Agg)
  policy_fps = embodied.FPS()

  @embodied.timer.section('log_step')
  def log_step(tran, worker):

    episode = episodes[worker]
    episode.add('score', tran['reward'], agg='sum')
    episode.add('length', 1, agg='sum')
    episode.add('rewards', tran['reward'], agg='stack')
    episode.add('success', tran['success'], agg='stack')

    if tran['is_first']:
      episode.reset()

    if worker < num_episodes:
      for key in args.log_keys_video:
        if key in tran:
          episode.add(f'policy_{key}', tran[key], agg='stack')
      if 'render' in tran:
        episode.add(f'policy_render', tran['render'], agg='stack')
      if 'render3p' in tran:
        episode.add(f'policy_render3p', tran['render3p'], agg='stack')
    for key, value in tran.items():
      if re.match(args.log_keys_sum, key):
        episode.add(key, value, agg='sum')
      if re.match(args.log_keys_avg, key):
        episode.add(key, value, agg='avg')
      if re.match(args.log_keys_max, key):
        episode.add(key, value, agg='max')

    if tran['is_last']:
      result = episode.result()
      timestamp = datetime.now().strftime("%Y-%m-%d_%H%M%S_%f")
      with open(eval_dir / f"episode_{timestamp}_{result['length']}.pickle", "wb") as file:
        pickle.dump(result, file)

  fns = [bind(make_env, i) for i in range(args.num_envs)]
  driver = Driver(fns, args.driver_parallel, height=height, width=width)
  driver.on_step(lambda tran, _: step.increment())
  driver.on_step(lambda tran, _: policy_fps.step())
  driver.on_step(log_step)

  checkpoint = embodied.Checkpoint()
  checkpoint.agent = agent
  checkpoint.load(args.from_checkpoint, keys=['agent'])

  print('Start evaluation')
  policy = lambda *args: agent.policy(*args, mode='eval')
  driver.reset(agent.init_policy)
  driver(policy, episodes=num_episodes)
  driver.close()
  print(f'Steps: {step.value}')
  print(f'Policy FPS: {policy_fps.result()}')

</embodied/run/eval.py>

<embodied/run/eval_only.py>
import re
from collections import defaultdict
from functools import partial as bind

import embodied
import numpy as np


def eval_only(make_agent, make_env, make_logger, args):
  assert args.from_checkpoint

  agent = make_agent()
  logger = make_logger()

  logdir = embodied.Path(args.logdir)
  logdir.mkdir()
  print('Logdir', logdir)
  step = logger.step
  usage = embodied.Usage(**args.usage)
  agg = embodied.Agg()
  epstats = embodied.Agg()
  episodes = defaultdict(embodied.Agg)
  should_log = embodied.when.Clock(args.log_every)
  policy_fps = embodied.FPS()

  @embodied.timer.section('log_step')
  def log_step(tran, worker):

    episode = episodes[worker]
    episode.add('score', tran['reward'], agg='sum')
    episode.add('length', 1, agg='sum')
    episode.add('rewards', tran['reward'], agg='stack')

    if tran['is_first']:
      episode.reset()

    if worker < args.log_video_streams:
      for key in args.log_keys_video:
        if key in tran:
          episode.add(f'policy_{key}', tran[key], agg='stack')
    for key, value in tran.items():
      if re.match(args.log_keys_sum, key):
        episode.add(key, value, agg='sum')
      if re.match(args.log_keys_avg, key):
        episode.add(key, value, agg='avg')
      if re.match(args.log_keys_max, key):
        episode.add(key, value, agg='max')

    if tran['is_last']:
      result = episode.result()
      logger.add({
          'score': result.pop('score'),
          'length': result.pop('length') - 1,
      }, prefix='episode')
      rew = result.pop('rewards')
      if len(rew) > 1:
        result['reward_rate'] = (np.abs(rew[1:] - rew[:-1]) >= 0.01).mean()
      epstats.add(result)

  fns = [bind(make_env, i) for i in range(args.num_envs)]
  driver = embodied.Driver(fns, args.driver_parallel)
  driver.on_step(lambda tran, _: step.increment())
  driver.on_step(lambda tran, _: policy_fps.step())
  driver.on_step(log_step)

  checkpoint = embodied.Checkpoint()
  checkpoint.agent = agent
  checkpoint.load(args.from_checkpoint, keys=['agent'])

  print('Start evaluation')
  policy = lambda *args: agent.policy(*args, mode='eval')
  driver.reset(agent.init_policy)
  while step < args.steps:
    driver(policy, steps=10)
    if should_log(step):
      logger.add(agg.result())
      logger.add(epstats.result(), prefix='epstats')
      logger.add(embodied.timer.stats(), prefix='timer')
      logger.add(usage.stats(), prefix='usage')
      logger.add({'fps/policy': policy_fps.result()})
      logger.write()

  logger.close()

</embodied/run/eval_only.py>

<embodied/run/parallel.py>
import re
import sys
import threading
import time
from collections import defaultdict, deque
from functools import partial as bind

import cloudpickle
import embodied
import numpy as np

prefix = lambda d, p: {f'{p}/{k}': v for k, v in d.items()}


def combined(make_agent, make_replay, make_env, make_logger, args):
  if args.num_envs:
    assert args.actor_batch <= args.num_envs, (args.actor_batch, args.num_envs)
  for key in ('actor_addr', 'replay_addr', 'logger_addr'):
    if '{auto}' in args[key]:
      port = embodied.distr.get_free_port()
      args = args.update({key: args[key].format(auto=port)})

  make_env = cloudpickle.dumps(make_env)
  make_agent = cloudpickle.dumps(make_agent)
  make_replay = cloudpickle.dumps(make_replay)
  make_logger = cloudpickle.dumps(make_logger)

  workers = [
      embodied.distr.Process(parallel_env, make_env, i, args, True)
      for i in range(args.num_envs)]
  if args.agent_process:
    workers.append(embodied.distr.Process(parallel_agent, make_agent, args))
  else:
    workers.append(embodied.distr.Thread(parallel_agent, make_agent, args))
  if not args.remote_replay:
    workers.append(embodied.distr.Process(parallel_replay, make_replay, args))
  workers.append(embodied.distr.Process(parallel_logger, make_logger, args))
  embodied.distr.run(workers, args.duration, exit_after=True)


def parallel_agent(make_agent, args):
  if isinstance(make_agent, bytes):
    make_agent = cloudpickle.loads(make_agent)
  agent = make_agent()
  barrier = threading.Barrier(2)
  workers = []
  workers.append(embodied.distr.Thread(parallel_actor, agent, barrier, args))
  workers.append(embodied.distr.Thread(parallel_learner, agent, barrier, args))
  embodied.distr.run(workers, args.duration)


def parallel_actor(agent, barrier, args):

  islist = lambda x: isinstance(x, list)
  initial = agent.init_policy(args.actor_batch)
  initial = embodied.tree.map(lambda x: x[0], initial, isleaf=islist)
  allstates = defaultdict(lambda: initial)
  barrier.wait()  # Do not collect data before learner restored checkpoint.
  fps = embodied.FPS()

  should_log = embodied.when.Clock(args.log_every)
  logger = embodied.distr.Client(
      args.logger_addr, 'ActorLogger', args.ipv6,
      maxinflight=8 * args.actor_threads, connect=True)
  replay = embodied.distr.Client(
      args.replay_addr, 'ActorReplay', args.ipv6,
      maxinflight=8 * args.actor_threads, connect=True)

  @embodied.timer.section('actor_workfn')
  def workfn(obs):
    envids = obs.pop('envid')
    fps.step(obs['is_first'].size)
    with embodied.timer.section('get_states'):
      states = [allstates[a] for a in envids]
      states = embodied.tree.map(lambda *xs: list(xs), *states)
    acts, outs, states = agent.policy(obs, states)
    assert all(k not in acts for k in outs), (
        list(outs.keys()), list(acts.keys()))
    acts['reset'] = obs['is_last'].copy()
    with embodied.timer.section('put_states'):
      for i, a in enumerate(envids):
        allstates[a] = embodied.tree.map(lambda x: x[i], states, isleaf=islist)
    trans = {'envids': envids, **obs, **acts, **outs}
    [x.setflags(write=False) for x in trans.values()]
    return acts, trans

  @embodied.timer.section('actor_donefn')
  def donefn(trans):
    replay.add_batch(trans)
    logger.trans(trans)
    if should_log():
      stats = {}
      stats['fps/policy'] = fps.result()
      stats['parallel/ep_states'] = len(allstates)
      stats.update(prefix(server.stats(), 'server/actor'))
      stats.update(prefix(logger.stats(), 'client/actor_logger'))
      stats.update(prefix(replay.stats(), 'client/actor_replay'))
      logger.add(stats)

  server = embodied.distr.ProcServer(args.actor_addr, 'Actor', args.ipv6)
  server.bind('act', workfn, donefn, args.actor_threads, args.actor_batch)
  server.run()


def parallel_learner(agent, barrier, args):

  logdir = embodied.Path(args.logdir)
  agg = embodied.Agg()
  usage = embodied.Usage(**args.usage)
  should_log = embodied.when.Clock(args.log_every)
  should_eval = embodied.when.Clock(args.eval_every)
  should_save = embodied.when.Clock(args.save_every)
  fps = embodied.FPS()
  batch_steps = args.batch_size * (args.batch_length - args.replay_context)

  checkpoint = embodied.Checkpoint(logdir / 'checkpoint.ckpt')
  checkpoint.agent = agent
  if args.from_checkpoint:
    checkpoint.load(args.from_checkpoint)
  checkpoint.load_or_save()
  logger = embodied.distr.Client(
      args.logger_addr, 'LearnerLogger', args.ipv6,
      maxinflight=1, connect=True)
  updater = embodied.distr.Client(
      args.replay_addr, 'LearnerReplayUpdater', args.ipv6,
      maxinflight=8, connect=True)
  barrier.wait()

  replays = []
  def parallel_dataset(source, prefetch=2):
    replay = embodied.distr.Client(
        args.replay_addr, f'LearnerReplay{len(replays)}', args.ipv6,
        connect=True)
    replays.append(replay)
    call = getattr(replay, source)
    futures = deque([call({}) for _ in range(prefetch)])
    while True:
      futures.append(call({}))
      yield futures.popleft().result()

  dataset_train = agent.dataset(bind(parallel_dataset, 'sample_batch_train'))
  dataset_report = agent.dataset(bind(parallel_dataset, 'sample_batch_report'))
  carry = agent.init_train(args.batch_size)
  carry_report = agent.init_report(args.batch_size)
  should_save()  # Delay first save.
  should_eval()  # Delay first eval.

  while True:

    with embodied.timer.section('learner_batch_next'):
      batch = next(dataset_train)
    with embodied.timer.section('learner_train_step'):
      outs, carry, mets = agent.train(batch, carry)
    if 'replay' in outs:
      with embodied.timer.section('learner_replay_update'):
        updater.update(outs['replay'])
    time.sleep(0.0001)
    agg.add(mets)
    fps.step(batch_steps)

    if should_eval():
      with embodied.timer.section('learner_eval'):
        mets, _ = agent.report(next(dataset_report), carry_report)
        logger.add(prefix(mets, 'report'))

    if should_log():
      with embodied.timer.section('learner_metrics'):
        stats = {}
        stats.update(prefix(agg.result(), 'train'))
        stats.update(prefix(embodied.timer.stats(), 'timer/agent'))
        stats.update(prefix(usage.stats(), 'usage/agent'))
        stats.update(prefix(logger.stats(), 'client/learner_logger'))
        stats.update(prefix(replays[0].stats(), 'client/learner_replay0'))
        stats.update({'fps/train': fps.result()})
      logger.add(stats)

    if should_save():
      checkpoint.save()


def parallel_replay(make_replay, args):
  if isinstance(make_replay, bytes):
    make_replay = cloudpickle.loads(make_replay)

  replay = make_replay()
  dataset_train = iter(replay.dataset(args.batch_size, args.batch_length))
  dataset_report = iter(replay.dataset(
      args.batch_size, args.batch_length_eval))

  should_log = embodied.when.Clock(args.log_every)
  logger = embodied.distr.Client(
      args.logger_addr, 'ReplayLogger', args.ipv6,
      maxinflight=1, connect=True)
  usage = embodied.Usage(**args.usage.update(nvsmi=False))

  should_save = embodied.when.Clock(args.save_every)
  cp = embodied.Checkpoint(embodied.Path(args.logdir) / 'replay.ckpt')
  cp.replay = replay
  cp.load_or_save()

  def add_batch(data):
    for i, envid in enumerate(data.pop('envids')):
      replay.add({k: v[i] for k, v in data.items()}, envid)
    return {}

  server = embodied.distr.Server(args.replay_addr, 'Replay', args.ipv6)
  server.bind('add_batch', add_batch, workers=1)
  server.bind('sample_batch_train', lambda _: next(dataset_train), workers=1)
  server.bind('sample_batch_report', lambda _: next(dataset_report), workers=1)
  server.bind('update', lambda data: replay.update(data), workers=1)
  with server:
    while True:
      server.check()
      should_save() and cp.save()
      time.sleep(1)
      if should_log():
        stats = prefix(replay.stats(), 'replay')
        stats.update(prefix(embodied.timer.stats(), 'timer/replay'))
        stats.update(prefix(usage.stats(), 'usage/replay'))
        stats.update(prefix(logger.stats(), 'client/replay_logger'))
        stats.update(prefix(server.stats(), 'server/replay'))
        logger.add(stats)


def parallel_logger(make_logger, args):
  if isinstance(make_logger, bytes):
    make_logger = cloudpickle.loads(make_logger)

  logger = make_logger()
  should_log = embodied.when.Clock(args.log_every)
  usage = embodied.Usage(**args.usage.update(nvsmi=False))

  should_save = embodied.when.Clock(args.save_every)
  cp = embodied.Checkpoint(embodied.Path(args.logdir) / 'logger.ckpt')
  cp.step = logger.step
  cp.load_or_save()

  parallel = embodied.Agg()
  epstats = embodied.Agg()
  episodes = defaultdict(embodied.Agg)
  updated = defaultdict(lambda: None)
  dones = defaultdict(lambda: True)

  log_keys_max = re.compile(args.log_keys_max)
  log_keys_sum = re.compile(args.log_keys_sum)
  log_keys_avg = re.compile(args.log_keys_avg)

  @embodied.timer.section('logger_addfn')
  def addfn(metrics):
    logger.add(metrics)

  @embodied.timer.section('logger_transfn')
  def transfn(trans):
    now = time.time()
    envids = trans.pop('envids')
    logger.step.increment(len(trans['is_first']))
    parallel.add('ep_starts', trans['is_first'].sum(), agg='sum')
    parallel.add('ep_ends', trans['is_last'].sum(), agg='sum')

    for i, addr in enumerate(envids):
      tran = {k: v[i] for k, v in trans.items()}

      updated[addr] = now
      episode = episodes[addr]
      if tran['is_first']:
        episode.reset()
        parallel.add('ep_abandoned', int(not dones[addr]), agg='sum')
      dones[addr] = tran['is_last']

      episode.add('score', tran['reward'], agg='sum')
      episode.add('length', 1, agg='sum')
      episode.add('rewards', tran['reward'], agg='stack')

      video_addrs = list(episodes.keys())[:args.log_video_streams]
      if addr in video_addrs:
        for key in args.log_keys_video:
          if key in tran:
            episode.add(f'policy_{key}', tran[key], agg='stack')

      for key in trans.keys():
        if log_keys_max.match(key):
          episode.add(key, tran[key], agg='max')
        if log_keys_sum.match(key):
          episode.add(key, tran[key], agg='sum')
        if log_keys_avg.match(key):
          episode.add(key, tran[key], agg='avg')

      if tran['is_last']:
        result = episode.result()
        logger.add({
            'score': result.pop('score'),
            'length': result.pop('length') - 1,
        }, prefix='episode')
        rew = result.pop('rewards')
        if len(rew) > 1:
          result['reward_rate'] = (np.abs(rew[1:] - rew[:-1]) >= 0.01).mean()
        epstats.add(result)

    for addr, last in list(updated.items()):
      if now - last >= args.log_episode_timeout:
        print('Dropping episode statistics due to timeout.')
        del episodes[addr]
        del updated[addr]

  server = embodied.distr.Server(args.logger_addr, 'Logger', args.ipv6)
  server.bind('add', addfn)
  server.bind('trans', transfn)
  with server:
    while True:
      server.check()
      should_save() and cp.save()
      time.sleep(1)
      if should_log():
        with embodied.timer.section('logger_metrics'):
          logger.add(parallel.result(), prefix='parallel')
          logger.add(epstats.result(), prefix='epstats')
          logger.add(embodied.timer.stats(), prefix='timer/logger')
          logger.add(usage.stats(), prefix='usage/logger')
          logger.add(server.stats(), prefix='server/logger')
        logger.write()


def parallel_env(make_env, envid, args, logging=False):
  if isinstance(make_env, bytes):
    make_env = cloudpickle.loads(make_env)
  assert envid >= 0, envid
  name = f'Env{envid}'

  _print = lambda x: embodied.print(f'[{name}] {x}', flush=True)
  should_log = embodied.when.Clock(args.log_every)
  if logging:
    logger = embodied.distr.Client(
        args.logger_addr, f'{name}Logger', args.ipv6,
        maxinflight=1, connect=True)
  fps = embodied.FPS()
  if envid == 0:
    usage = embodied.Usage(**args.usage.update(nvsmi=False))

  _print('Make env')
  env = make_env(envid)
  actor = embodied.distr.Client(
      args.actor_addr, name, args.ipv6, identity=envid,
      pings=10, maxage=60, connect=True)

  done = True
  while True:

    if done:
      act = {k: v.sample() for k, v in env.act_space.items()}
      act['reset'] = True
      score, length = 0, 0

    with embodied.timer.section('env_step'):
      obs = env.step(act)
    obs = {k: np.asarray(v, order='C') for k, v in obs.items()}
    score += obs['reward']
    length += 1
    fps.step(1)
    done = obs['is_last']
    if done:
      _print(f'Episode of length {length} with score {score:.2f}')

    with embodied.timer.section('env_request'):
      future = actor.act({'envid': envid, **obs})
    try:
      with embodied.timer.section('env_response'):
        act = future.result()
    except embodied.distr.NotAliveError:
      # Wait until we are connected again, so we don't unnecessarily reset the
      # environment hundreds of times while the server is unavailable.
      _print('Lost connection to server')
      actor.connect()
      done = True
    except embodied.distr.RemoteError as e:
      _print(f'Shutting down env due to agent error: {e}')
      sys.exit(0)

    if should_log() and logging and envid == 0:
      stats = {f'fps/env{envid}': fps.result()}
      stats.update(prefix(usage.stats(), f'usage/env{envid}'))
      stats.update(prefix(logger.stats(), f'client/env{envid}_logger'))
      stats.update(prefix(actor.stats(), f'client/env{envid}_actor'))
      stats.update(prefix(embodied.timer.stats(), f'timer/env{envid}'))
      logger.add(stats)

</embodied/run/parallel.py>

<embodied/run/parallel_with_eval.py>
import re
import sys
import threading
import time
from collections import defaultdict, deque
from functools import partial as bind

import cloudpickle
import embodied
import numpy as np

prefix = lambda d, p: {f'{p}/{k}': v for k, v in d.items()}


def combined(
    make_agent, make_replay, make_replay_eval, make_env, make_env_eval,
    make_logger, args):
  if args.num_envs:
    assert args.actor_batch <= args.num_envs, (args.actor_batch, args.num_envs)
  for key in ('actor_addr', 'replay_addr', 'logger_addr'):
    if '{auto}' in args[key]:
      port = embodied.distr.get_free_port()
      args = args.update({key: args[key].format(auto=port)})

  make_agent = cloudpickle.dumps(make_agent)
  make_replay = cloudpickle.dumps(make_replay)
  make_replay_eval = cloudpickle.dumps(make_replay_eval)
  make_env = cloudpickle.dumps(make_env)
  make_env_eval = cloudpickle.dumps(make_env_eval)
  make_logger = cloudpickle.dumps(make_logger)

  workers = []
  for i in range(args.num_envs):
    workers.append(embodied.distr.Process(
        parallel_env, make_env, i, args, True))
  for i in range(args.num_envs_eval):
    workers.append(embodied.distr.Process(
        parallel_env, make_env_eval, args.num_envs + i, args, True, True))
  if args.agent_process:
    workers.append(embodied.distr.Process(parallel_agent, make_agent, args))
  else:
    workers.append(embodied.distr.Thread(parallel_agent, make_agent, args))
  if not args.remote_replay:
    workers.append(embodied.distr.Process(
        parallel_replay, make_replay, make_replay_eval, args))
  workers.append(embodied.distr.Process(parallel_logger, make_logger, args))
  embodied.distr.run(workers, args.duration, exit_after=True)


def parallel_agent(make_agent, args):
  if isinstance(make_agent, bytes):
    make_agent = cloudpickle.loads(make_agent)
  agent = make_agent()
  barrier = threading.Barrier(2)
  workers = []
  workers.append(embodied.distr.Thread(parallel_actor, agent, barrier, args))
  workers.append(embodied.distr.Thread(parallel_learner, agent, barrier, args))
  embodied.distr.run(workers, args.duration)


def parallel_actor(agent, barrier, args):

  islist = lambda x: isinstance(x, list)
  initial = agent.init_policy(args.actor_batch)
  initial = embodied.tree.map(lambda x: x[0], initial, isleaf=islist)
  allstates = defaultdict(lambda: initial)
  barrier.wait()  # Do not collect data before learner restored checkpoint.
  fps = embodied.FPS()

  should_log = embodied.when.Clock(args.log_every)
  logger = embodied.distr.Client(
      args.logger_addr, 'ActorLogger', args.ipv6,
      maxinflight=8 * args.actor_threads, connect=True)
  replay = embodied.distr.Client(
      args.replay_addr, 'ActorReplay', args.ipv6,
      maxinflight=8 * args.actor_threads, connect=True)

  @embodied.timer.section('actor_workfn')
  def workfn(obs):
    envids = obs.pop('envid')
    fps.step(obs['is_first'].size)
    with embodied.timer.section('get_states'):
      states = [allstates[a] for a in envids]
      states = embodied.tree.map(lambda *xs: list(xs), *states)
    acts, outs, states = agent.policy(obs, states)
    assert all(k not in acts for k in outs), (
        list(outs.keys()), list(acts.keys()))
    acts['reset'] = obs['is_last'].copy()
    with embodied.timer.section('put_states'):
      for i, a in enumerate(envids):
        allstates[a] = embodied.tree.map(lambda x: x[i], states, isleaf=islist)
    trans = {'envids': envids, **obs, **acts, **outs}
    [x.setflags(write=False) for x in trans.values()]
    return acts, trans

  @embodied.timer.section('actor_donefn')
  def donefn(trans):
    replay.add_batch(trans)
    logger.trans(trans)
    if should_log():
      stats = {}
      stats['fps/policy'] = fps.result()
      stats['parallel/ep_states'] = len(allstates)
      stats.update(prefix(server.stats(), 'server/actor'))
      stats.update(prefix(logger.stats(), 'client/actor_logger'))
      stats.update(prefix(replay.stats(), 'client/actor_replay'))
      logger.add(stats)

  server = embodied.distr.ProcServer(args.actor_addr, 'Actor', args.ipv6)
  server.bind('act', workfn, donefn, args.actor_threads, args.actor_batch)
  server.run()


def parallel_learner(agent, barrier, args):

  logdir = embodied.Path(args.logdir)
  agg = embodied.Agg()
  usage = embodied.Usage(**args.usage)
  should_log = embodied.when.Clock(args.log_every)
  should_eval = embodied.when.Clock(args.eval_every)
  should_save = embodied.when.Clock(args.save_every)
  fps = embodied.FPS()
  batch_steps = args.batch_size * (args.batch_length - args.replay_context)

  checkpoint = embodied.Checkpoint(logdir / 'checkpoint.ckpt')
  checkpoint.agent = agent
  if args.from_checkpoint:
    checkpoint.load(args.from_checkpoint)
  checkpoint.load_or_save()
  logger = embodied.distr.Client(
      args.logger_addr, 'LearnerLogger', args.ipv6,
      maxinflight=1, connect=True)
  updater = embodied.distr.Client(
      args.replay_addr, 'LearnerReplayUpdater', args.ipv6,
      maxinflight=8, connect=True)
  barrier.wait()

  replays = []
  received = defaultdict(int)
  def parallel_dataset(source, prefetch=2):
    replay = embodied.distr.Client(
        args.replay_addr, f'LearnerReplay{len(replays)}', args.ipv6,
        connect=True)
    replays.append(replay)
    call = getattr(replay, f'sample_batch_{source}')
    futures = deque([call({}) for _ in range(prefetch)])
    while True:
      futures.append(call({}))
      batch = futures.popleft().result()
      received[source] += 1
      yield batch

  def evaluate(dataset):
    num_batches = args.replay_length_eval // args.batch_length_eval
    carry = agent.init_report(args.batch_size)
    agg = embodied.Agg()
    for _ in range(num_batches):
      batch = next(dataset)
      metrics, carry = agent.report(batch, carry)
      agg.add(metrics)
    return agg.result()

  dataset_train = agent.dataset(bind(parallel_dataset, 'train'))
  dataset_report = agent.dataset(bind(parallel_dataset, 'report'))
  dataset_eval = agent.dataset(bind(parallel_dataset, 'eval'))
  carry = agent.init_train(args.batch_size)
  should_save()  # Delay first save.
  should_eval()  # Delay first eval.

  while True:

    with embodied.timer.section('learner_batch_next'):
      batch = next(dataset_train)
    with embodied.timer.section('learner_train_step'):
      outs, carry, mets = agent.train(batch, carry)
    if 'replay' in outs:
      with embodied.timer.section('learner_replay_update'):
        updater.update(outs['replay'])
    time.sleep(0.0001)
    agg.add(mets)
    fps.step(batch_steps)

    if should_eval():
      with embodied.timer.section('learner_eval'):
        if received['report'] > 0:
          logger.add(prefix(evaluate(dataset_report), 'report'))
        if received['eval'] > 0:
          logger.add(prefix(evaluate(dataset_eval), 'eval'))

    if should_log():
      with embodied.timer.section('learner_metrics'):
        stats = {}
        stats.update(prefix(agg.result(), 'train'))
        stats.update(prefix(embodied.timer.stats(), 'timer/agent'))
        stats.update(prefix(usage.stats(), 'usage/agent'))
        stats.update(prefix(logger.stats(), 'client/learner_logger'))
        stats.update(prefix(replays[0].stats(), 'client/learner_replay0'))
        stats.update({'fps/train': fps.result()})
      logger.add(stats)

    if should_save():
      checkpoint.save()


def parallel_replay(make_replay, make_replay_eval, args):
  if isinstance(make_replay, bytes):
    make_replay = cloudpickle.loads(make_replay)
  if isinstance(make_replay_eval, bytes):
    make_replay_eval = cloudpickle.loads(make_replay_eval)

  replay = make_replay()
  replay_eval = make_replay_eval()
  dataset_train = iter(replay.dataset(
      args.batch_size, args.batch_length))
  dataset_report = iter(replay.dataset(
      args.batch_size, args.batch_length_eval))
  dataset_eval = iter(replay_eval.dataset(
      args.batch_size, args.batch_length_eval))

  should_log = embodied.when.Clock(args.log_every)
  logger = embodied.distr.Client(
      args.logger_addr, 'ReplayLogger', args.ipv6,
      maxinflight=1, connect=True)
  usage = embodied.Usage(**args.usage.update(nvsmi=False))

  should_save = embodied.when.Clock(args.save_every)
  cp = embodied.Checkpoint(embodied.Path(args.logdir) / 'replay.ckpt')
  cp.replay = replay
  cp.load_or_save()

  def add_batch(data):
    for i, envid in enumerate(data.pop('envids')):
      tran = {k: v[i] for k, v in data.items()}
      if tran.pop('is_eval', False):
        replay_eval.add(tran, envid)
      else:
        replay.add(tran, envid)
    return {}

  server = embodied.distr.Server(args.replay_addr, 'Replay', args.ipv6)
  server.bind('add_batch', add_batch, workers=1)
  server.bind('sample_batch_train', lambda _: next(dataset_train), workers=1)
  server.bind('sample_batch_report', lambda _: next(dataset_report), workers=1)
  server.bind('sample_batch_eval', lambda _: next(dataset_eval), workers=1)
  server.bind('update', lambda data: replay.update(data), workers=1)
  with server:
    while True:
      server.check()
      should_save() and cp.save()
      time.sleep(1)
      if should_log():
        stats = {}
        stats.update(prefix(replay.stats(), 'replay'))
        stats.update(prefix(replay_eval.stats(), 'replay_eval'))
        stats.update(prefix(embodied.timer.stats(), 'timer/replay'))
        stats.update(prefix(usage.stats(), 'usage/replay'))
        stats.update(prefix(logger.stats(), 'client/replay_logger'))
        stats.update(prefix(server.stats(), 'server/replay'))
        logger.add(stats)


def parallel_logger(make_logger, args):
  if isinstance(make_logger, bytes):
    make_logger = cloudpickle.loads(make_logger)

  logger = make_logger()
  should_log = embodied.when.Clock(args.log_every)
  usage = embodied.Usage(**args.usage.update(nvsmi=False))

  should_save = embodied.when.Clock(args.save_every)
  cp = embodied.Checkpoint(embodied.Path(args.logdir) / 'logger.ckpt')
  cp.step = logger.step
  cp.load_or_save()

  parallel = embodied.Agg()
  epstats = embodied.Agg()
  episodes = defaultdict(embodied.Agg)
  updated = defaultdict(lambda: None)
  dones = defaultdict(lambda: True)

  log_keys_max = re.compile(args.log_keys_max)
  log_keys_sum = re.compile(args.log_keys_sum)
  log_keys_avg = re.compile(args.log_keys_avg)

  @embodied.timer.section('logger_addfn')
  def addfn(metrics):
    logger.add(metrics)

  @embodied.timer.section('logger_transfn')
  def transfn(trans):
    now = time.time()
    envids = trans.pop('envids')
    logger.step.increment(len(trans['is_first']))
    parallel.add('ep_starts', trans['is_first'].sum(), agg='sum')
    parallel.add('ep_ends', trans['is_last'].sum(), agg='sum')

    for i, addr in enumerate(envids):
      tran = {k: v[i] for k, v in trans.items()}

      updated[addr] = now
      episode = episodes[addr]
      if tran['is_first']:
        episode.reset()
        parallel.add('ep_abandoned', int(not dones[addr]), agg='sum')
      dones[addr] = tran['is_last']

      episode.add('score', tran['reward'], agg='sum')
      episode.add('length', 1, agg='sum')
      episode.add('rewards', tran['reward'], agg='stack')

      video_addrs = list(episodes.keys())[:args.log_video_streams]
      if addr in video_addrs:
        for key in args.log_keys_video:
          if key in tran:
            episode.add(f'policy_{key}', tran[key], agg='stack')

      for key in trans.keys():
        if log_keys_max.match(key):
          episode.add(key, tran[key], agg='max')
        if log_keys_sum.match(key):
          episode.add(key, tran[key], agg='sum')
        if log_keys_avg.match(key):
          episode.add(key, tran[key], agg='avg')

      if tran['is_last']:
        result = episode.result()
        logger.add({
            'score': result.pop('score'),
            'length': result.pop('length') - 1,
        }, prefix='episode')
        rew = result.pop('rewards')
        if len(rew) > 1:
          result['reward_rate'] = (np.abs(rew[1:] - rew[:-1]) >= 0.01).mean()
        epstats.add(result)

    for addr, last in list(updated.items()):
      if now - last >= args.log_episode_timeout:
        print('Dropping episode statistics due to timeout.')
        del episodes[addr]
        del updated[addr]

  server = embodied.distr.Server(args.logger_addr, 'Logger', args.ipv6)
  server.bind('add', addfn)
  server.bind('trans', transfn)
  with server:
    while True:
      server.check()
      should_save() and cp.save()
      time.sleep(1)
      if should_log():
        with embodied.timer.section('logger_metrics'):
          logger.add(parallel.result(), prefix='parallel')
          logger.add(epstats.result(), prefix='epstats')
          logger.add(embodied.timer.stats(), prefix='timer/logger')
          logger.add(usage.stats(), prefix='usage/logger')
          logger.add(server.stats(), prefix='server/logger')
        logger.write()


def parallel_env(make_env, envid, args, logging=False, is_eval=False):
  if isinstance(make_env, bytes):
    make_env = cloudpickle.loads(make_env)
  assert envid >= 0, envid
  name = f'Env{envid}'

  _print = lambda x: embodied.print(f'[{name}] {x}', flush=True)
  should_log = embodied.when.Clock(args.log_every)
  if logging and envid == 0:
    logger = embodied.distr.Client(
        args.logger_addr, f'{name}Logger', args.ipv6,
        maxinflight=1, connect=True)
  fps = embodied.FPS()
  if envid == 0:
    usage = embodied.Usage(**args.usage.update(nvsmi=False))

  _print('Make env')
  env = make_env(envid)
  actor = embodied.distr.Client(
      args.actor_addr, name, args.ipv6, identity=envid,
      pings=10, maxage=60, connect=True)

  done = True
  while True:

    if done:
      act = {k: v.sample() for k, v in env.act_space.items()}
      act['reset'] = True
      score, length = 0, 0

    with embodied.timer.section('env_step'):
      obs = env.step(act)
    obs = {k: np.asarray(v, order='C') for k, v in obs.items()}
    obs['is_eval'] = is_eval
    score += obs['reward']
    length += 1
    fps.step(1)
    done = obs['is_last']
    if done:
      _print(f'Episode of length {length} with score {score:.2f}')

    with embodied.timer.section('env_request'):
      future = actor.act({'envid': envid, **obs})
    try:
      with embodied.timer.section('env_response'):
        act = future.result()
    except embodied.distr.NotAliveError:
      # Wait until we are connected again, so we don't unnecessarily reset the
      # environment hundreds of times while the server is unavailable.
      _print('Lost connection to server')
      actor.connect()
      done = True
    except embodied.distr.RemoteError as e:
      _print(f'Shutting down env due to agent error: {e}')
      sys.exit(0)

    if should_log() and logging and envid == 0:
      stats = {f'fps/env{envid}': fps.result()}
      stats.update(prefix(usage.stats(), f'usage/env{envid}'))
      stats.update(prefix(logger.stats(), f'client/env{envid}_logger'))
      stats.update(prefix(actor.stats(), f'client/env{envid}_actor'))
      stats.update(prefix(embodied.timer.stats(), f'timer/env{envid}'))
      logger.add(stats)

</embodied/run/parallel_with_eval.py>

<embodied/run/train.py>
from datetime import datetime
import pickle
from pathlib import Path
import re
from collections import defaultdict
from functools import partial as bind

import numpy as np
import embodied
from embodied.run.eval import Driver as DriverEval
from analysis.visualize_dreamer import visualize_episodes


def train(make_agent, make_replay, make_env, make_logger, args):

  agent = make_agent()
  replay = make_replay()
  logger = make_logger()

  logdir = embodied.Path(args.logdir)
  logdir.mkdir()
  print('Logdir', logdir)
  eval_dir = logdir / 'eval/'
  eval_dir.mkdir()

  step = logger.step
  usage = embodied.Usage(**args.usage)
  agg = embodied.Agg()
  epstats = embodied.Agg()
  episodes = defaultdict(embodied.Agg)
  policy_fps = embodied.FPS()
  train_fps = embodied.FPS()

  batch_steps = args.batch_size * (args.batch_length - args.replay_context)
  should_expl = embodied.when.Until(args.expl_until)
  should_train = embodied.when.Ratio(args.train_ratio / batch_steps)
  should_log = embodied.when.Clock(args.log_every)
  should_eval = embodied.when.Clock(args.eval_every)

  @embodied.timer.section('log_step')
  def log_step(tran, worker):

    episode = episodes[worker]
    episode.add('score', tran['reward'], agg='sum')
    episode.add('length', 1, agg='sum')
    episode.add('rewards', tran['reward'], agg='stack')

    if tran['is_first']:
      episode.reset()

    if worker < args.log_video_streams:
      for key in args.log_keys_video:
        if key in tran:
          episode.add(f'policy_{key}', tran[key], agg='stack')
    for key, value in tran.items():
      if re.match(args.log_keys_sum, key):
        episode.add(key, value, agg='sum')
      if re.match(args.log_keys_avg, key):
        episode.add(key, value, agg='avg')
      if re.match(args.log_keys_max, key):
        episode.add(key, value, agg='max')

    if tran['is_last']:
      result = episode.result()
      logger.add({
          'score': result.pop('score'),
          'length': result.pop('length'),
      }, prefix='episode')
      rew = result.pop('rewards')
      if len(rew) > 1:
        result['reward_rate'] = (np.abs(rew[1:] - rew[:-1]) >= 0.01).mean()
      epstats.add(result)

  @embodied.timer.section('log_step_eval')
  def log_step_eval(tran, worker):

    episode = episodes[worker]
    episode.add('score', tran['reward'], agg='sum')
    episode.add('length', 1, agg='sum')
    episode.add('rewards', tran['reward'], agg='stack')
    episode.add('success', tran['success'], agg='stack')

    if tran['is_first']:
      episode.reset()

    if worker < args.eval_eps:
      for key in args.log_keys_video:
        if key in tran:
          episode.add(f'policy_{key}', tran[key], agg='stack')
      if 'render' in tran:
        episode.add(f'policy_render', tran['render'], agg='stack')
      if 'render3p' in tran:
        episode.add(f'policy_render3p', tran['render3p'], agg='stack')
    for key, value in tran.items():
      if re.match(args.log_keys_sum, key):
        episode.add(key, value, agg='sum')
      if re.match(args.log_keys_avg, key):
        episode.add(key, value, agg='avg')
      if re.match(args.log_keys_max, key):
        episode.add(key, value, agg='max')

    if tran['is_last']:
      result = episode.result()
      timestamp = datetime.now().strftime("%Y-%m-%d_%H%M%S_%f")
      with open(eval_dir / f"episode_{timestamp}_{result['length']}.pickle", "wb") as file:
        pickle.dump(result, file)

  fns = [bind(make_env, i) for i in range(args.num_envs)]
  driver = embodied.Driver(fns, args.driver_parallel)
  driver.on_step(lambda tran, _: step.increment())
  driver.on_step(lambda tran, _: policy_fps.step())
  driver.on_step(replay.add)
  driver.on_step(log_step)

  fns = [bind(make_env, i) for i in range(args.eval_eps)]
  driver_eval = DriverEval(fns, args.driver_parallel, height=90, width=160)
  driver_eval.on_step(log_step_eval)

  dataset_train = iter(agent.dataset(bind(
      replay.dataset, args.batch_size, args.batch_length)))
  dataset_report = iter(agent.dataset(bind(
      replay.dataset, args.batch_size, args.batch_length_eval)))
  carry = [agent.init_train(args.batch_size)]
  carry_report = agent.init_report(args.batch_size)

  def train_step(tran, worker):
    if len(replay) < args.batch_size or step < args.train_fill:
      return
    for _ in range(should_train(step)):
      with embodied.timer.section('dataset_next'):
        batch = next(dataset_train)
      outs, carry[0], mets = agent.train(batch, carry[0])
      train_fps.step(batch_steps)
      if 'replay' in outs:
        replay.update(outs['replay'])
      agg.add(mets, prefix='train')
  driver.on_step(train_step)

  checkpoint = embodied.Checkpoint(logdir / 'checkpoint.ckpt')
  checkpoint.step = step
  checkpoint.agent = agent
  if args.from_checkpoint:
    checkpoint.load(args.from_checkpoint, keys=['step', 'agent'])
  checkpoint.load_or_save()

  print('Start training loop')
  policy = lambda *args: agent.policy(
      *args, mode='explore' if should_expl(step) else 'train')
  driver.reset(agent.init_policy)
  while step < args.steps:

    driver(policy, steps=10)

    if should_eval(step) and len(replay):
      mets, _ = agent.report(next(dataset_report), carry_report)
      logger.add(mets, prefix='report')

    if should_log(step):
      logger.add(agg.result())
      logger.add(epstats.result(), prefix='epstats')
      logger.add(embodied.timer.stats(), prefix='timer')
      logger.add(replay.stats(), prefix='replay')
      logger.add(usage.stats(), prefix='usage')
      logger.add({'fps/policy': policy_fps.result()})
      logger.add({'fps/train': train_fps.result()})
      logger.write()

  checkpoint.save(keys=['step', 'agent'])
  replay.clear()
  logger.close()
  driver.close()

  print('Start evaluation')
  policy = lambda *args: agent.policy(*args, mode='eval')
  driver_eval.reset(agent.init_policy)
  driver_eval(policy, episodes=args.eval_eps)
  visualize_episodes(Path(str(eval_dir)))

  driver_eval.close()

</embodied/run/train.py>

<embodied/run/train_eval.py>
import re
from collections import defaultdict
from functools import partial as bind

import embodied
import numpy as np


def train_eval(
    make_agent, make_train_replay, make_eval_replay,
    make_train_env, make_eval_env, make_logger, args):

  agent = make_agent()
  train_replay = make_train_replay()
  eval_replay = make_eval_replay()
  logger = make_logger()

  logdir = embodied.Path(args.logdir)
  logdir.mkdir()
  print('Logdir', logdir)
  step = logger.step
  usage = embodied.Usage(**args.usage)
  agg = embodied.Agg()
  train_episodes = defaultdict(embodied.Agg)
  train_epstats = embodied.Agg()
  eval_episodes = defaultdict(embodied.Agg)
  eval_epstats = embodied.Agg()
  policy_fps = embodied.FPS()
  train_fps = embodied.FPS()

  batch_steps = args.batch_size * (args.batch_length - args.replay_context)
  should_expl = embodied.when.Until(args.expl_until)
  should_train = embodied.when.Ratio(args.train_ratio / batch_steps)
  should_log = embodied.when.Clock(args.log_every)
  should_save = embodied.when.Clock(args.save_every)
  should_eval = embodied.when.Clock(args.eval_every)

  @embodied.timer.section('log_step')
  def log_step(tran, worker, mode):
    episodes = dict(train=train_episodes, eval=eval_episodes)[mode]
    epstats = dict(train=train_epstats, eval=eval_epstats)[mode]

    episode = episodes[worker]
    episode.add('score', tran['reward'], agg='sum')
    episode.add('length', 1, agg='sum')
    episode.add('rewards', tran['reward'], agg='stack')

    if tran['is_first']:
      episode.reset()

    if worker < args.log_video_streams:
      for key in args.log_keys_video:
        if key in tran:
          episode.add(f'policy_{key}', tran[key], agg='stack')
    for key, value in tran.items():
      if re.match(args.log_keys_sum, key):
        episode.add(key, value, agg='sum')
      if re.match(args.log_keys_avg, key):
        episode.add(key, value, agg='avg')
      if re.match(args.log_keys_max, key):
        episode.add(key, value, agg='max')

    if tran['is_last']:
      result = episode.result()
      logger.add({
          'score': result.pop('score'),
          'length': result.pop('length'),
      }, prefix='episode')
      rew = result.pop('rewards')
      if len(rew) > 1:
        result['reward_rate'] = (np.abs(rew[1:] - rew[:-1]) >= 0.01).mean()
      epstats.add(result)

  fns = [bind(make_train_env, i) for i in range(args.num_envs)]
  train_driver = embodied.Driver(fns, args.driver_parallel)
  train_driver.on_step(lambda tran, _: step.increment())
  train_driver.on_step(lambda tran, _: policy_fps.step())
  train_driver.on_step(train_replay.add)
  train_driver.on_step(bind(log_step, mode='train'))

  fns = [bind(make_eval_env, i) for i in range(args.num_envs)]
  eval_driver = embodied.Driver(fns, args.driver_parallel)
  eval_driver.on_step(eval_replay.add)
  eval_driver.on_step(bind(log_step, mode='eval'))
  eval_driver.on_step(lambda tran, _: policy_fps.step())

  dataset_train = agent.dataset(
      bind(train_replay.dataset, args.batch_size, args.batch_length))
  dataset_report = agent.dataset(
      bind(train_replay.dataset, args.batch_size, args.batch_length_eval))
  dataset_eval = agent.dataset(
      bind(eval_replay.dataset, args.batch_size, args.batch_length_eval))
  carry = [agent.init_train(args.batch_size)]
  carry_report = agent.init_report(args.batch_size)

  def train_step(tran, worker):
    if len(train_replay) < args.batch_size or step < args.train_fill:
      return
    for _ in range(should_train(step)):
      with embodied.timer.section('dataset_next'):
        batch = next(dataset_train)
      outs, carry[0], mets = agent.train(batch, carry[0])
      train_fps.step(batch_steps)
      if 'replay' in outs:
        train_replay.update(outs['replay'])
      agg.add(mets, prefix='train')
  train_driver.on_step(train_step)

  checkpoint = embodied.Checkpoint(logdir / 'checkpoint.ckpt')
  checkpoint.step = step
  checkpoint.agent = agent
  checkpoint.train_replay = train_replay
  checkpoint.eval_replay = eval_replay
  if args.from_checkpoint:
    checkpoint.load(args.from_checkpoint)
  checkpoint.load_or_save()
  should_save(step)  # Register that we just saved.

  print('Start training loop')
  train_policy = lambda *args: agent.policy(
      *args, mode='explore' if should_expl(step) else 'train')
  eval_policy = lambda *args: agent.policy(*args, mode='eval')
  train_driver.reset(agent.init_policy)
  while step < args.steps:

    if should_eval(step):
      print('Start evaluation')
      eval_driver.reset(agent.init_policy)
      eval_driver(eval_policy, episodes=args.eval_eps)
      logger.add(eval_epstats.result(), prefix='epstats')
      if len(train_replay):
        mets, _ = agent.report(next(dataset_report), carry_report)
        logger.add(mets, prefix='report')
      if len(eval_replay):
        mets, _ = agent.report(next(dataset_eval), carry_report)
        logger.add(mets, prefix='eval')

    train_driver(train_policy, steps=10)

    if should_log(step):
      logger.add(agg.result())
      logger.add(train_epstats.result(), prefix='epstats')
      logger.add(embodied.timer.stats(), prefix='timer')
      logger.add(train_replay.stats(), prefix='replay')
      logger.add(usage.stats(), prefix='usage')
      logger.add({'fps/policy': policy_fps.result()})
      logger.add({'fps/train': train_fps.result()})
      logger.write()

    if should_save(step):
      checkpoint.save()

  logger.close()

</embodied/run/train_eval.py>

<embodied/run/train_holdout.py>
import re
from collections import defaultdict
from functools import partial as bind

import embodied
import numpy as np


def train_holdout(
    make_agent, make_train_replay, make_eval_replay,
    make_env, make_logger, args):

  agent = make_agent()
  train_replay = make_train_replay()
  eval_replay = make_eval_replay()
  logger = make_logger()

  logdir = embodied.Path(args.logdir)
  logdir.mkdir()
  print('Logdir', logdir)
  step = logger.step
  usage = embodied.Usage(**args.usage)
  agg = embodied.Agg()
  episodes = defaultdict(embodied.Agg)
  epstats = embodied.Agg()
  policy_fps = embodied.FPS()
  train_fps = embodied.FPS()

  batch_steps = args.batch_size * args.batch_length
  should_expl = embodied.when.Until(args.expl_until)
  should_train = embodied.when.Ratio(args.train_ratio / batch_steps)
  should_log = embodied.when.Clock(args.log_every)
  should_save = embodied.when.Clock(args.save_every)

  @embodied.timer.section('log_step')
  def log_step(tran, worker):

    episode = episodes[worker]
    episode.add('score', tran['reward'], agg='sum')
    episode.add('length', 1, agg='sum')
    episode.add('rewards', tran['reward'], agg='stack')

    if tran['is_first']:
      episode.reset()

    if worker < args.log_video_streams:
      for key in args.log_keys_video:
        if key in tran:
          episode.add(f'policy_{key}', tran[key], agg='stack')
    for key, value in tran.items():
      if re.match(args.log_keys_sum, key):
        episode.add(key, value, agg='sum')
      if re.match(args.log_keys_avg, key):
        episode.add(key, value, agg='avg')
      if re.match(args.log_keys_max, key):
        episode.add(key, value, agg='max')

    if tran['is_last']:
      result = episode.result()
      logger.add({
          'score': result.pop('score'),
          'length': result.pop('length'),
      }, prefix='episode')
      rew = result.pop('rewards')
      if len(rew) > 1:
        result['reward_rate'] = (np.abs(rew[1:] - rew[:-1]) >= 0.01).mean()
      epstats.add(result)

  fns = [bind(make_env, i) for i in range(args.num_envs)]
  driver = embodied.Driver(fns, args.driver_parallel)
  driver.on_step(lambda tran, _: step.increment())
  driver.on_step(lambda tran, _: policy_fps.step())
  driver.on_step(train_replay.add)
  driver.on_step(log_step)

  dataset_train = agent.dataset(
      bind(train_replay.dataset, args.batch_size, args.batch_length))
  dataset_report = agent.dataset(
      bind(train_replay.dataset, args.batch_size, args.batch_length_eval))
  dataset_eval = agent.dataset(
      bind(eval_replay.dataset, args.batch_size, args.batch_length_eval))

  carry = [agent.init_train(args.batch_size)]
  carry_report = agent.init_report(args.batch_size)

  def train_step(tran, worker):
    if len(train_replay) < args.batch_size or step < args.train_fill:
      return
    for _ in range(should_train(step)):
      with embodied.timer.section('dataset_next'):
        batch = next(dataset_train)
      outs, carry[0], mets = agent.train(batch, carry[0])
      train_fps.step(batch_steps)
      if 'replay' in outs:
        train_replay.update(outs['replay'])
      agg.add(mets, prefix='train')
  driver.on_step(train_step)

  checkpoint = embodied.Checkpoint(logdir / 'checkpoint.ckpt')
  checkpoint.step = step
  checkpoint.agent = agent
  checkpoint.train_replay = train_replay
  checkpoint.eval_replay = eval_replay
  if args.from_checkpoint:
    checkpoint.load(args.from_checkpoint)
  checkpoint.load_or_save()
  should_save(step)  # Register that we just saved.

  print('Start training loop')
  policy = lambda *args: agent.policy(
      *args, mode='explore' if should_expl(step) else 'train')
  driver.reset(agent.init_policy)
  while step < args.steps:

    driver(policy, steps=10)

    if should_log(step):
      logger.add(agg.result())
      logger.add(epstats.result(), prefix='epstats')
      if len(train_replay):
        mets, _ = agent.report(next(dataset_report), init_report)
        logger.add(mets, prefix='report')
      if len(eval_replay):
        mets, _ = agent.report(next(dataset_eval), init_report)
        logger.add(mets, prefix='eval')
      logger.add(embodied.timer.stats(), prefix='timer')
      logger.add(train_replay.stats(), prefix='replay')
      logger.add(usage.stats(), prefix='usage')
      logger.add({'fps/policy': policy_fps.result()})
      logger.add({'fps/train': train_fps.result()})
      logger.write()

    if should_save(step):
      checkpoint.save()

  logger.close()

</embodied/run/train_holdout.py>

<embodied/run/__init__.py>
from .eval_only import eval_only
from .eval import eval
from .train import train
from .train_eval import train_eval
from .train_holdout import train_holdout

from . import parallel
from . import parallel_with_eval

</embodied/run/__init__.py>

<embodied/scripts/install-dmlab.sh>
#!/bin/sh
set -eu

# Dependencies
apt-get update && apt-get install -y \
    build-essential curl freeglut3 gettext git libffi-dev libglu1-mesa \
    libglu1-mesa-dev libjpeg-dev liblua5.1-0-dev libosmesa6-dev \
    libsdl2-dev lua5.1 pkg-config python-setuptools python3-dev \
    software-properties-common unzip zip zlib1g-dev g++
pip install numpy wheel dm-env

# Bazel
apt-get install -y apt-transport-https curl gnupg
curl -fsSL https://bazel.build/bazel-release.pub.gpg | gpg --dearmor > bazel.gpg
mv bazel.gpg /etc/apt/trusted.gpg.d/
echo "deb [arch=amd64] https://storage.googleapis.com/bazel-apt stable jdk1.8" | tee /etc/apt/sources.list.d/bazel.list
apt-get update && apt-get install -y bazel

# Build
git clone https://github.com/deepmind/lab.git
cd lab
echo 'build --cxxopt=-std=c++17' > .bazelrc
bazel build -c opt //python/pip_package:build_pip_package
./bazel-bin/python/pip_package/build_pip_package /tmp/dmlab_pkg
pip install --force-reinstall /tmp/dmlab_pkg/deepmind_lab-*.whl
DEST="$(python -c 'import site; print(site.getsitepackages()[0])')/deepmind_lab"
cp -rfL bazel-bin/* "$DEST"
cp "$DEST/deepmind/level_generation/compile_map_sh" "$DEST/deepmind/level_generation/compile_map.sh"
cd ..
rm -rf lab

# Dataset
mkdir dmlab_data
cd dmlab_data
pip install Pillow
curl https://bradylab.ucsd.edu/stimuli/ObjectsAll.zip -o ObjectsAll.zip
unzip ObjectsAll.zip
cd OBJECTSALL
python << EOM
import os
from PIL import Image
files = [f for f in os.listdir('.') if f.lower().endswith('jpg')]
for i, file in enumerate(sorted(files)):
  print(file)
  im = Image.open(file)
  im.save('../%04d.png' % (i+1))
EOM
cd ..
rm -rf __MACOSX OBJECTSALL ObjectsAll.zip
sed -i "s/DATASET_PATH = ''/DATASET_PATH = '\/embodied\/dmlab_data'/" "$DEST/baselab/game_scripts/datasets/brady_konkle_oliva2008.lua"

# Test
python -c "import deepmind_lab; deepmind_lab.Lab('contributed/dmlab30/explore_goal_locations_small', []).reset();"
python -c "import deepmind_lab; deepmind_lab.Lab('contributed/dmlab30/psychlab_arbitrary_visuomotor_mapping', []).reset();"

# Cleanup
apt-get clean

</embodied/scripts/install-dmlab.sh>

<embodied/scripts/install-minecraft.sh>
#!/bin/sh
set -eu

apt-get update
apt-get install -y openjdk-8-jdk
apt-get clean

pip install https://github.com/danijar/minerl/releases/download/v0.4.4-patched/minerl_mirror-0.4.4-cp311-cp311-linux_x86_64.whl

# apt-get update
# apt-get install -y openjdk-8-jdk
# apt-get clean
# pip install git+https://github.com/danijar/minerl.git@10f8d48

</embodied/scripts/install-minecraft.sh>

<embodied/scripts/print.py>
import argparse
import functools
import json
import multiprocessing as mp
import pathlib
import re

import numpy as np
import pandas as pd
import rich.console
import tqdm


def main():
  console = rich.console.Console()
  args = parse_args()
  paths = []
  for directory in args.indirs:
    paths += list(directory.expanduser().resolve().glob(args.pattern))
  tensor, tasks, methods, seeds = load_scores(sorted(set(paths)), args)
  console.print(f'Tasks ({len(tasks)}): [cyan]{", ".join(tasks)}[/cyan]')
  console.print(f'Methods ({len(methods)}): [cyan]{", ".join(methods)}[/cyan]')
  console.print(f'Seed ({len(seeds)}): [cyan]{", ".join(seeds)}[/cyan]')
  if not tasks or not methods or not seeds:
    console.print('Nothing to print!', style='red')
    return

  path = pathlib.Path('~/scores/atari_baselines.json').expanduser()
  baselines = json.loads(path.read_text())
  select = lambda baselines, name: {
      k: v[name] for k, v in baselines.items() if name in v}
  if args.normalize:
    mins = select(baselines, 'random')
    maxs = select(baselines, 'human_gamer')
    mins = np.array([mins[task] for task in tasks])
    maxs = np.array([maxs[task] for task in tasks])

  # maxs = maxs[:, None, None]
  # mins = mins[:, None, None]
  # normed = (tensor - mins) / (maxs - mins)
  # means = 100 * np.nanmean(normed, 0)
  # medians = 100 * np.nanmedian(normed, 0)

  averaged = np.round(np.nanmean(tensor, -1), 3)
  if args.normalize:
    maxs = maxs[:, None]
    mins = mins[:, None]
    normed = (averaged - mins) / (maxs - mins)
  else:
    normed = averaged
  means = 100 * np.nanmean(normed, 0)
  medians = 100 * np.nanmedian(normed, 0)

  completed = np.isfinite(normed).sum(0)
  print('')
  print('Methods:', methods)
  print('Means:', means)
  print('Medians:', medians)
  print('Tasks:', tasks)
  for i, method in enumerate(methods):
    # raw = np.round(np.nanmean(tensor[:, i], -1), 3).tolist()
    print('\n', {method: dict(zip(tasks, averaged[:, i]))})
  for i, method in enumerate(methods):
    mean = means[i]
    median = medians[i]
    print(f'\n{method}')
    # print(f' Mean HNS:     {np.nanmean(mean):6.0f} {np.nanstd(mean):.0f}')
    # print(f' Median HNS:   {np.nanmean(median):6.0f} {np.nanstd(median):.0f}')
    print(f' Mean HNS:    {mean:.1f}')
    print(f' Median HNS:  {median:.1f}')
    print(f' Completed:   {completed[i]}')


def load_scores(paths, args):
  console = rich.console.Console()
  tasks, methods, seeds = zip(*[x.parts[-4:-1] for x in paths])
  matched = lambda name, patterns: any(re.search(p, name) for p in patterns)
  tasks = [x for x in natsort(set(tasks)) if matched(x, args.tasks)]
  methods = [x for x in natsort(set(methods)) if matched(x, args.methods)]
  seeds = natsort(set(seeds))
  paths = [x for x in paths if x.parts[-4] in tasks and x.parts[-3] in methods]
  console.print(f'Loading {len(paths)} scores...')
  jobs = [functools.partial(load_score, path, args) for path in paths]
  if args.workers > 1:
    with mp.Pool(args.workers) as pool:
      promises = [pool.apply_async(j) for j in jobs]
      scores = [promise.get() for promise in tqdm.tqdm(promises)]
  else:
    scores = [job() for job in tqdm.tqdm(jobs)]
  tensor = np.empty((len(tasks), len(methods), len(seeds)))
  tensor[:] = np.nan
  for path, score in zip(paths, scores):
    if score is None:
      pass
    task, method, seed = path.parts[-4:-1]
    tensor[tasks.index(task), methods.index(method), seeds.index(seed)] = score
  return tensor, tasks, methods, seeds


def load_score(path, args):
  try:
    console = rich.console.Console()
    task, method, seed = path.parts[-4:-1]
    df = load_json(path)
    df = df[[args.xaxis, args.yaxis]].dropna()
    xs = df[args.xaxis].to_numpy()
    ys = df[args.yaxis].to_numpy()
    if not len(xs):
      console.print(
          f'Skipping {task} {method} {seed} that has not reported scores!',
          style='red')
      return None
    # if xs[-1] < args.point - args.before:
    #   console.print(
    #       f'Skipping {task} {method} {seed} that only reached to step '
    #       f'{xs[-1]} but needed {args.point - args.before}!', style='red')
    #   return None

    # stop = (xs <= args.point + args.tolerance).sum()
    # start = (xs < args.point + args.tolerance - args.before).sum()
    # start = min(start, start - 1)

    stop = (xs <= args.point + args.tolerance).sum() + 2
    start = max(0, stop - args.episodes)

    assert start < stop, (start, stop, task, method, seed, xs)
    score = ys[start: stop].mean()
    return score
  except Exception as e:
    console.print(f'Exception loading {path}:\n {e}', style='red')
    return None


def load_json(path):
  try:
    return pd.read_json(path, lines=True)
  except ValueError:
    records = []
    for i, line in enumerate(pathlib.Path(path).read_text().split('\n')):
      if not line:
        continue
      try:
        records.append(json.loads(line))
      except ValueError:
        print(f'Skipping invalid JSON line {i} in {path}.')
    return pd.DataFrame(records)


def natsort(sequence):
  pattern = re.compile(r'([0-9]+)')
  return sorted(sequence, key=lambda x: [
      (int(y) if y.isdigit() else y) for y in pattern.split(x)])


def parse_args(argv=None):
  boolean = lambda x: bool(['False', 'True'].index(x))
  parser = argparse.ArgumentParser()
  parser.add_argument('--indirs', nargs='+', type=pathlib.Path, required=True)
  parser.add_argument('--pattern', type=str, default='**/scores.jsonl')
  parser.add_argument('--workers', type=int, default=1)
  parser.add_argument('--tasks', nargs='+', default=[r'.*'])
  parser.add_argument('--methods', nargs='+', default=[r'.*'])
  parser.add_argument('--xaxis', type=str, default='step')
  parser.add_argument('--yaxis', type=str, default='episode/score')
  parser.add_argument('--point', type=float, default=4e5)
  parser.add_argument('--before', type=float, default=3e4)
  parser.add_argument('--tolerance', type=float, default=100)
  parser.add_argument('--episodes', type=int, default=5)
  parser.add_argument('--normalize', type=boolean, default=True)
  parser.add_argument('--stats', type=str, nargs='*', default=[
      'mean', 'median', 'tasks'])
  args = parser.parse_args(argv)
  args.indirs = tuple([x.expanduser() for x in args.indirs])
  if args.stats == ['none']:
    args.stats = []
  return args


if __name__ == "__main__":
  main()

</embodied/scripts/print.py>

<embodied/scripts/xvfb_run.sh>
xvfb-run -a -s "-screen 0 1024x768x24 -ac +extension GLX +render -noreset" "$@"
# xvfb-run "$@"

</embodied/scripts/xvfb_run.sh>

<embodied/tests/distr/test_process.py>
import multiprocessing as mp
import pathlib
import sys
import time
import traceback

sys.path.append(str(pathlib.Path(__file__).parent.parent.parent.parent))

import embodied
import pytest


class TestProcess:

  def test_kill(self):
    def fn():
      while True:
        time.sleep(0.01)
    worker = embodied.distr.Process(fn, start=True)
    assert worker.running
    worker.kill()
    assert not worker.running
    worker.join()  # Noop

  def test_stop(self):
    def fn(context, q):
      q.put('start')
      while context.running:
        time.sleep(0.01)
      q.put('stop')
    q = mp.get_context().SimpleQueue()
    worker = embodied.distr.StoppableProcess(fn, q)
    worker.start()
    worker.stop()
    assert q.get() == 'start'
    assert q.get() == 'stop'

  def test_exitcode(self):
    worker = embodied.distr.Process(lambda: None)
    assert worker.exitcode is None
    worker.start()
    worker.join()
    assert worker.exitcode == 0

  def test_exception(self):
    def fn1234(q):
      q.put(42)
      raise KeyError('foo')
    q = mp.get_context().SimpleQueue()
    worker = embodied.distr.Process(fn1234, q, start=True)
    q.get()
    time.sleep(0.5)
    assert not worker.running
    assert worker.exitcode == 1
    with pytest.raises(KeyError) as info:
      worker.check()
    worker.kill()  # Shoud not hang or reraise.
    with pytest.raises(KeyError) as info:
      worker.check()  # Can reraise multiple times.
    assert repr(info.value) == "KeyError('foo')"
    e = info.value
    typ, tb = type(e), e.__traceback__
    tb = ''.join(traceback.format_exception(typ, e, tb))
    assert "KeyError: 'foo'" in tb
    if sys.version_info.minor >= 11:
      assert 'Traceback' in tb
      assert ' File ' in tb
      assert 'fn1234' in tb

  def test_nested_kill(self):
    q = mp.get_context().SimpleQueue()
    def inner():
      while True:
        time.sleep(0.01)
    def outer(q):
      child = embodied.distr.Process(inner, start=True)
      q.put(child.pid)
      while True:
        time.sleep(0.01)
    parent = embodied.distr.Process(outer, q, start=True)
    child_pid = q.get()
    assert embodied.distr.proc_alive(parent.pid)
    assert embodied.distr.proc_alive(child_pid)
    parent.kill()
    assert not embodied.distr.proc_alive(parent.pid)
    assert not embodied.distr.proc_alive(child_pid)

  def test_nested_exception(self):
    q = mp.get_context().SimpleQueue()
    def inner():
      time.sleep(0.1)
      raise KeyError('foo')
    def outer(q):
      child = embodied.distr.Process(inner, start=True)
      q.put(child.pid)
      while True:
        child.check()
        time.sleep(0.01)
    parent = embodied.distr.Process(outer, q, start=True)
    child_pid = q.get()
    assert embodied.distr.proc_alive(parent.pid)
    assert embodied.distr.proc_alive(child_pid)
    with pytest.raises(KeyError) as info:
      while True:
        parent.check()
        time.sleep(0.1)
    assert repr(info.value) == "KeyError('foo')"
    assert not embodied.distr.proc_alive(parent.pid)
    assert not embodied.distr.proc_alive(child_pid)

</embodied/tests/distr/test_process.py>

<embodied/tests/distr/test_server.py>
import pathlib
import queue
import sys
import threading
import time

sys.path.append(str(pathlib.Path(__file__).parent.parent.parent.parent))

import embodied
import numpy as np
import pytest

SERVERS = [
    embodied.distr.Server,
    embodied.distr.ProcServer,
]

ADDRESSES = [
    'tcp://localhost:{port}',
    'ipc:///tmp/test-{port}',
]


class TestServer:

  @pytest.mark.parametrize('Server', SERVERS)
  @pytest.mark.parametrize('addr', ADDRESSES)
  def test_single_client(self, Server, addr):
    addr = addr.format(port=embodied.distr.get_free_port())
    def function(data):
      assert data == {'foo': np.array(1)}
      return {'foo': 2 * data['foo']}
    server = Server(addr)
    server.bind('function', function)
    with server:
      client = embodied.distr.Client(addr, pings=0, maxage=1)
      client.connect(retry=False, timeout=1)
      future = client.function({'foo': np.array(1)})
      result = future.result()
      assert result['foo'] == 2

  @pytest.mark.parametrize('Server', SERVERS)
  @pytest.mark.parametrize('addr', ADDRESSES)
  def test_multiple_clients(self, Server, addr):
    addr = addr.format(port=embodied.distr.get_free_port())
    server = Server(addr)
    server.bind('function', lambda data: data)
    with server:
      clients = []
      for i in range(10):
        client = embodied.distr.Client(addr, i, pings=0, maxage=1)
        client.connect()
        clients.append(client)
      futures = [
          client.function({'foo': i}) for i, client in enumerate(clients)]
      results = [future.result()['foo'] for future in futures]
      assert results == list(range(10))

  @pytest.mark.parametrize('Server', SERVERS)
  @pytest.mark.parametrize('addr', ADDRESSES)
  def test_multiple_methods(self, Server, addr):
    addr = addr.format(port=embodied.distr.get_free_port())
    server = Server(addr)
    server.bind('add', lambda data: {'z': data['x'] + data['y']})
    server.bind('sub', lambda data: {'z': data['x'] - data['y']})
    with server:
      client = embodied.distr.Client(addr, pings=0, maxage=0.1)
      client.connect(retry=False, timeout=1)
      assert client.add({'x': 42, 'y': 13}).result()['z'] == 55
      assert client.sub({'x': 42, 'y': 13}).result()['z'] == 29

  @pytest.mark.parametrize('Server', SERVERS)
  @pytest.mark.parametrize('addr', ADDRESSES)
  def test_connect_before_server(self, Server, addr):
    addr = addr.format(port=embodied.distr.get_free_port())
    server = Server(addr)
    server.bind('function', lambda data: {'foo': 2 * data['foo']})
    barrier = threading.Barrier(2)
    results = queue.SimpleQueue()
    def client():
      client = embodied.distr.Client(addr, pings=0, maxage=1)
      barrier.wait()
      client.connect(retry=False, timeout=1)
      future = client.function({'foo': np.array(1)})
      result = future.result()
      results.put(result)
    thread = embodied.distr.Thread(client, start=True)
    barrier.wait()
    time.sleep(0.2)
    with server:
      assert results.get()['foo'] == 2
    thread.join()

  @pytest.mark.parametrize('Server', SERVERS)
  @pytest.mark.parametrize('addr', ADDRESSES)
  def test_future_order(self, Server, addr):
    addr = addr.format(port=embodied.distr.get_free_port())
    server = Server(addr)
    server.bind('function', lambda data: data)
    with server:
      client = embodied.distr.Client(addr, 0, pings=0, maxage=1)
      client.connect(retry=False, timeout=1)
      future1 = client.function({'foo': 1})
      future2 = client.function({'foo': 2})
      future3 = client.function({'foo': 3})
      assert future2.result()['foo'] == 2
      assert future1.result()['foo'] == 1
      assert future3.result()['foo'] == 3

  @pytest.mark.parametrize('Server', SERVERS)
  @pytest.mark.parametrize('addr', ADDRESSES)
  def test_future_cleanup(self, Server, addr):
    addr = addr.format(port=embodied.distr.get_free_port())
    server = Server(addr)
    server.bind('function', lambda data: data)
    with server:
      client = embodied.distr.Client(
          addr, 0, pings=0, maxage=1, maxinflight=None, errors=False)
      client.connect(retry=False, timeout=1)
      client.function({'foo': 1})
      client.function({'foo': 2})
      future3 = client.function({'foo': np.array(3)})
      assert future3.result()['foo'] == 3
      del future3
      assert not list(client.futures.keys())

  @pytest.mark.parametrize('Server', SERVERS)
  @pytest.mark.parametrize('addr', ADDRESSES)
  def test_maxinflight(self, Server, addr):
    addr = addr.format(port=embodied.distr.get_free_port())
    server = Server(addr)

    parallel = [0]
    lock = threading.Lock()
    def workfn(data):
      with lock:
        parallel[0] += 1
        assert parallel[0] <= 2
      time.sleep(0.2)
      with lock:
        parallel[0] -= 1
      return data
    server.bind('function', workfn, workers=4)

    with server:
      client = embodied.distr.Client(
          addr, 0, pings=0, maxage=1, maxinflight=2)
      client.connect(retry=False, timeout=1)
      futures = [client.function({'foo': i}) for i in range(4)]
      results = [future.result()['foo'] for future in futures]
      assert results == list(range(4))

  @pytest.mark.parametrize('Server', SERVERS)
  @pytest.mark.parametrize('addr', ADDRESSES)
  def test_future_cleanup_errors(self, Server, addr):
    addr = addr.format(port=embodied.distr.get_free_port())
    server = Server(addr)
    server.bind('function', lambda data: data)
    with server:
      client = embodied.distr.Client(addr, 0, pings=0, maxage=1, errors=True)
      client.connect(retry=False, timeout=1)
      client.function({'foo': 1})
      client.function({'foo': 2})
      client.function({'foo': 3})
      assert len(client.futures) == 3
      assert len(client.queue) == 3
      time.sleep(0.1)
      [x.check() for x in client.queue]
      assert all(x.done() for x in client.queue)
      client.function({'foo': 4})
      assert len(client.futures) == 1
      assert len(client.queue) == 1

  @pytest.mark.parametrize('Server', SERVERS)
  @pytest.mark.parametrize('addr', ADDRESSES)
  def test_ping_alive(self, Server, addr):
    addr = addr.format(port=embodied.distr.get_free_port())
    def slow(data):
      time.sleep(0.1)
      return data
    server = Server(addr)
    server.bind('function', slow)
    with server:
      client = embodied.distr.Client(addr, pings=0.01, maxage=0.05)
      client.connect()
      assert client.function({'foo': 0}).result() == {'foo': 0}

  @pytest.mark.parametrize('Server', SERVERS)
  @pytest.mark.parametrize('addr', ADDRESSES)
  def test_ping_dead(self, Server, addr):
    addr = addr.format(port=embodied.distr.get_free_port())
    def slow(data):
      time.sleep(0.2)
      return data
    server = Server(addr)
    server.bind('function', slow)
    with server:
      client = embodied.distr.Client(addr, pings=0.1, maxage=0.01)
      client.connect()
      with pytest.raises(embodied.distr.NotAliveError):
        client.function({'foo': 0}).result()

  @pytest.mark.parametrize('Server', SERVERS)
  @pytest.mark.parametrize('addr', ADDRESSES)
  def test_remote_error(self, Server, addr):
    addr = addr.format(port=embodied.distr.get_free_port())
    def error(data):
      raise RuntimeError('foo')
    server = Server(addr, errors=True)
    server.bind('function', error)
    with server:
      client = embodied.distr.Client(addr, errors=False, connect=True)
      future = client.function({'bar': 0})
      with pytest.raises(embodied.distr.RemoteError) as info1:
        future.result()
      time.sleep(0.1)
      with pytest.raises(RuntimeError) as info2:
        server.check()
    assert repr(info1.value) == '''RemoteError("RuntimeError('foo')")'''
    assert repr(info2.value) == "RuntimeError('foo')"

  @pytest.mark.parametrize('Server', SERVERS)
  @pytest.mark.parametrize('addr', ADDRESSES)
  def test_remote_client_errors(self, Server, addr):
    addr = addr.format(port=embodied.distr.get_free_port())
    def error(data):
      raise RuntimeError(data['foo'])
    server = Server(addr, errors=False)
    server.bind('function', error)
    with server:
      client = embodied.distr.Client(addr, connect=True, errors=True)
      client.function({'foo': 1})
      time.sleep(0.2)
      assert len(client.queue) == 1
      client.queue[0].check()
      assert client.queue[0].done()
      with pytest.raises(embodied.distr.RemoteError) as info:
        client.function({'foo': 2})
    assert repr(info.value) == "RemoteError('RuntimeError(array(1))')"

  @pytest.mark.parametrize('Server', SERVERS)
  @pytest.mark.parametrize('addr', ADDRESSES)
  def test_donefn_ordered(self, Server, addr):
    addr = addr.format(port=embodied.distr.get_free_port())
    rng = np.random.default_rng(0)
    completed = []
    logged = []
    def sometimes_wait(data):
      if rng.uniform() < 0.5:
        time.sleep(0.1)
      completed.append(data['i'])
      return data, data
    def donefn(data):
      logged.append(data['i'])
    server = Server(addr, workers=2)
    server.bind('function', sometimes_wait, donefn)
    with server:
      client = embodied.distr.Client(addr, pings=0, maxage=1)
      client.connect()
      futures = [client.function({'i': i}) for i in range(10)]
      results = [future.result()['i'] for future in futures]
    assert results == list(range(10))
    assert logged == list(range(10))
    assert completed != list(range(10))

  @pytest.mark.parametrize('Server', SERVERS)
  @pytest.mark.parametrize('addr', ADDRESSES)
  @pytest.mark.parametrize('workers', (1, 4))
  def test_donefn_no_backlog(self, Server, addr, workers):
    addr = addr.format(port=embodied.distr.get_free_port())
    lock = threading.Lock()
    work_calls = [0]
    done_calls = [0]
    def workfn(data):
      with lock:
        work_calls[0] += 1
        assert work_calls[0] <= done_calls[0] + 2 * workers
      return data, data
    def donefn(data):
      with lock:
        done_calls[0] += 1
      time.sleep(0.01)
    server = Server(addr, workers=workers)
    server.bind('function', workfn, donefn)
    with server:
      client = embodied.distr.Client(addr, pings=0, maxage=1, connect=True)
      futures = [client.function({'i': i}) for i in range(20)]
      [future.result() for future in futures]

  @pytest.mark.parametrize('Server', SERVERS)
  @pytest.mark.parametrize('addr', ADDRESSES)
  def test_connect_retry(self, Server, addr):
    addr = addr.format(port=embodied.distr.get_free_port())
    results = []
    def client():
      try:
        client = embodied.distr.Client(addr)
        client.connect(retry=True, timeout=0.01)
        future = client.function({'foo': np.array(1)})
        results.append(future.result())
      except Exception as e:
        results.append(e)
    threading.Thread(target=client).start()
    time.sleep(0.2)
    server = Server(addr)
    server.bind('function', lambda data: data)
    with server:
      while not results:
        time.sleep(0.001)
    assert results == [{'foo': 1}]

  @pytest.mark.parametrize('Server', SERVERS)
  @pytest.mark.parametrize('addr', ADDRESSES)
  def test_shared_pool(self, Server, addr):
    addr = addr.format(port=embodied.distr.get_free_port())
    def slow_function(data):
      time.sleep(0.1)
      return data
    def fast_function(data):
      time.sleep(0.01)
      return data
    server = Server(addr, workers=1)
    server.bind('slow_function', slow_function)
    server.bind('fast_function', fast_function)
    with server:
      client = embodied.distr.Client(addr)
      client.connect()
      slow_future = client.slow_function({'foo': 0})
      fast_future = client.fast_function({'foo': 0})
      assert not slow_future.done()
      fast_future.result()
      assert slow_future.done()

  @pytest.mark.parametrize('Server', SERVERS)
  @pytest.mark.parametrize('addr', ADDRESSES)
  def test_separate_pools(self, Server, addr):
    addr = addr.format(port=embodied.distr.get_free_port())
    def slow_function(data):
      time.sleep(0.1)
      return data
    def fast_function(data):
      time.sleep(0.01)
      return data
    server = Server(addr)
    server.bind('slow_function', slow_function, workers=1)
    server.bind('fast_function', fast_function, workers=1)
    with server:
      client = embodied.distr.Client(addr)
      client.connect()
      slow_future = client.slow_function({'foo': 0})
      fast_future = client.fast_function({'foo': 0})
      fast_future.result()
      assert not slow_future.done()

  @pytest.mark.parametrize('Server', SERVERS)
  @pytest.mark.parametrize('addr', ADDRESSES)
  @pytest.mark.parametrize('batch', (1, 2, 4))
  def test_batching_single(self, Server, addr, batch):
    addr = addr.format(port=embodied.distr.get_free_port())
    calls = [0]
    def function(data):
      assert set(data.keys()) == {'foo'}
      assert data['foo'].shape == (batch, 1)
      calls[0] += 1
      return data
    server = Server(addr)
    server.bind('function', function, batch=batch)
    with server:
      client = embodied.distr.Client(addr, pings=0, maxage=1)
      client.connect(retry=False, timeout=1)
      futures = [client.function({'foo': [i]}) for i in range(batch)]
      results = [future.result()['foo'][0] for future in futures]
      assert calls[0] == 1
      assert results == list(range(batch))

  @pytest.mark.parametrize('Server', SERVERS)
  @pytest.mark.parametrize('addr', ADDRESSES)
  @pytest.mark.parametrize('batch', (1, 2, 4))
  def test_batching_multiple(self, Server, addr, batch):
    addr = addr.format(port=embodied.distr.get_free_port())
    def function(data):
      return data
    server = Server(addr)
    server.bind('function', function, batch=batch)
    with server:
      clients = []
      for _ in range(3):
        client = embodied.distr.Client(addr, pings=0, maxage=1)
        client.connect(retry=False, timeout=1)
        clients.append(client)
      futures = ([], [], [])
      refs = ([], [], [])
      for n in range(batch):
        for i, client in enumerate(clients):
          futures[i].append(client.function({'foo': [i * n]}))
          refs[i].append(i * n)
      assert refs[0] == [x.result()['foo'][0] for x in futures[0]]
      assert refs[1] == [x.result()['foo'][0] for x in futures[1]]
      assert refs[2] == [x.result()['foo'][0] for x in futures[2]]

  @pytest.mark.parametrize('Server', SERVERS)
  @pytest.mark.parametrize('inner_addr', ADDRESSES)
  @pytest.mark.parametrize('outer_addr', ADDRESSES)
  @pytest.mark.parametrize('workers', (1, 10))
  def test_proxy(self, Server, inner_addr, outer_addr, workers):
    inner_addr = inner_addr.format(port=embodied.distr.get_free_port())
    outer_addr = outer_addr.format(port=embodied.distr.get_free_port())
    proxy_client = embodied.distr.Client(inner_addr)
    proxy_server = Server(outer_addr, workers=workers)
    proxy_server.bind('function', lambda x: proxy_client.function(x).result())
    server = Server(inner_addr)
    server.bind('function', lambda data: {'foo': 2 * data['foo']})
    with server:
      proxy_client.connect(retry=False, timeout=1)
      with proxy_server:
        client = embodied.distr.Client(outer_addr, pings=0, maxage=1)
        client.connect(retry=False, timeout=1)
        futures = [client.function({'foo': 13}) for _ in range(10)]
        results = [future.result()['foo'] for future in futures]
        assert all(result == 26 for result in results)

  @pytest.mark.parametrize('Server', SERVERS)
  @pytest.mark.parametrize('inner_addr', ADDRESSES)
  @pytest.mark.parametrize('outer_addr', ADDRESSES)
  @pytest.mark.parametrize('workers', (2, 3, 10))
  def test_proxy_batched(self, Server, inner_addr, outer_addr, workers):
    inner_addr = inner_addr.format(port=embodied.distr.get_free_port())
    outer_addr = outer_addr.format(port=embodied.distr.get_free_port())
    proxy_client = embodied.distr.Client(inner_addr)
    proxy_server = Server(outer_addr)
    proxy_server.bind(
        'function', lambda x: proxy_client.function(x).result(),
        batch=2, workers=workers)
    server = Server(inner_addr)
    server.bind(
        'function', lambda data: {'foo': 2 * data['foo']}, workers=workers)
    with server:
      proxy_client.connect(retry=False, timeout=1)
      with proxy_server:
        client = embodied.distr.Client(outer_addr, pings=0, maxage=1)
        client.connect(retry=False, timeout=1)
        futures = [client.function({'foo': 13}) for _ in range(10)]
        results = [future.result()['foo'] for future in futures]
        print(results)
        assert all(result == 26 for result in results)

  @pytest.mark.parametrize('Server', SERVERS)
  @pytest.mark.parametrize('addr', ADDRESSES)
  def test_empty_dict(self, Server, addr):
    addr = addr.format(port=embodied.distr.get_free_port())
    client = embodied.distr.Client(addr, pings=0, maxage=1)
    server = Server(addr)
    def workfn(data):
      assert data == {}
      return {}
    server.bind('function', workfn)
    with server:
      client.connect(retry=False, timeout=1)
      assert client.function({}).result() == {}

</embodied/tests/distr/test_server.py>

<embodied/tests/distr/test_thread.py>
import pathlib
import queue
import sys
import time
import traceback

sys.path.append(str(pathlib.Path(__file__).parent.parent.parent.parent))

import embodied
import pytest


class TestThread:

  def test_kill(self):
    def fn():
      while True:
        time.sleep(0.01)
    worker = embodied.distr.Thread(fn, start=True)
    worker.kill()
    assert not worker.running
    worker.join()
    assert not worker.running
    worker.join()  # Noop

  def test_stop(self):
    def fn(context, q):
      q.put('start')
      while context.running:
        time.sleep(0.01)
      q.put('stop')
    q = queue.SimpleQueue()
    worker = embodied.distr.StoppableThread(fn, q)
    worker.start()
    worker.stop()
    assert q.get() == 'start'
    assert q.get() == 'stop'

  def test_exitcode(self):
    worker = embodied.distr.Thread(lambda: None)
    assert worker.exitcode is None
    worker.start()
    worker.join()
    assert worker.exitcode == 0

  def test_exception(self):
    def fn1234(q):
      q.put(42)
      raise KeyError('foo')
    q = queue.SimpleQueue()
    worker = embodied.distr.Thread(fn1234, q, start=True)
    q.get()
    time.sleep(0.01)
    assert not worker.running
    assert worker.exitcode == 1
    with pytest.raises(KeyError) as info:
      worker.check()
    worker.kill()  # Shoud not hang or reraise.
    with pytest.raises(KeyError) as info:
      worker.check()  # Can reraise multiple times.
    assert repr(info.value) == "KeyError('foo')"
    e = info.value
    typ, tb = type(e), e.__traceback__
    tb = ''.join(traceback.format_exception(typ, e, tb))
    assert 'Traceback' in tb
    assert ' File ' in tb
    assert 'fn1234' in tb
    assert "KeyError: 'foo'" in tb

  def test_nested_exception(self):
    threads = []
    def inner():
      raise KeyError('foo')
    def outer():
      child = embodied.distr.Thread(inner, start=True)
      threads.append(child)
      while True:
        child.check()
        time.sleep(0.01)
    parent = embodied.distr.Thread(outer)
    threads.append(parent)
    parent.start()
    time.sleep(0.1)
    with pytest.raises(KeyError) as info:
      parent.check()
    assert repr(info.value) == "KeyError('foo')"
    assert not threads[0].running
    assert not threads[1].running

</embodied/tests/distr/test_thread.py>

<embodied/tests/run/test_parallel.py>
import pathlib
import sys
from collections import deque
from functools import partial as bind

sys.path.append(str(pathlib.Path(__file__).parent.parent.parent.parent))
sys.path.append(str(pathlib.Path(__file__).parent))

import embodied
import numpy as np
import pytest

import utils


class TestParallel:

  @pytest.mark.parametrize('train_ratio', (-1, 1, 128))
  def test_run_loop(self, tmpdir, train_ratio):
    addr = 'ipc:///tmp/teststats'
    received = deque(maxlen=1)
    server = embodied.distr.Server(addr, name='TestStats')
    server.bind('report', lambda stats: received.append(stats))
    server.start()

    args = self._make_args(tmpdir, train_ratio)
    ports = []
    for key in ('actor_addr', 'replay_addr', 'logger_addr'):
      ports.append(args[key].replace('-', ':').split(':')[-1])

    embodied.run.parallel.combined(
        bind(self._make_agent, addr),
        bind(self._make_replay, args),
        self._make_env, self._make_logger, args)
    stats = received[0]
    print('Stats:', stats)
    assert stats['lifetime'] > 7
    assert stats['env_steps'] > 1000
    if args.train_ratio > -1:
      replay_steps = stats['env_steps'] * args.train_ratio
      assert np.allclose(stats['replay_steps'], replay_steps, 100, 0.1)
    else:
      assert stats['replay_steps'] > 100
    assert stats['reports'] >= 1
    assert stats['saves'] >= 2
    assert stats['loads'] == 0
    # for port in ports:
    #   assert embodied.distr.port_free(port)

    embodied.run.parallel.combined(
        bind(self._make_agent, addr),
        bind(self._make_replay, args),
        self._make_env, self._make_logger, args)
    stats = received[0]
    assert stats['loads'] == 1
    # for port in ports:
    #   assert embodied.distr.port_free(port)

  def _make_agent(self, queue):
    env = self._make_env(0)
    agent = utils.TestAgent(env.obs_space, env.act_space, queue)
    env.close()
    return agent

  def _make_env(self, index):
    from embodied.envs import dummy
    return dummy.Dummy('disc', size=(64, 64), length=100)

  def _make_replay(self, args):
    kwargs = {'length': args.batch_length, 'capacity': 1e4}
    if args.train_ratio > -1:
      kwargs['samples_per_insert'] = args.train_ratio / args.batch_length
    return embodied.replay.Replay(**kwargs)

  def _make_logger(self):
    return embodied.Logger(embodied.Counter(), [
        embodied.logger.TerminalOutput(),
    ])

  def _make_args(self, logdir, train_ratio):
    actor_port = embodied.distr.get_free_port()
    replay_port = embodied.distr.get_free_port()
    logger_port = embodied.distr.get_free_port()
    return embodied.Config(
        logdir=str(logdir),
        num_envs=4,
        duration=10,
        log_every=3,
        save_every=5,
        eval_every=5,
        train_ratio=float(train_ratio),
        train_fill=100,
        batch_size=8,
        batch_length=16,
        batch_length_eval=8,
        replay_context=0,
        expl_until=0,
        from_checkpoint='',
        usage=dict(psutil=True, nvsmi=False),
        log_zeros=False,
        log_video_streams=4,
        log_video_fps=20,
        log_keys_video=['image'],
        log_keys_sum='^$',
        log_keys_avg='^$',
        log_keys_max='^$',
        log_episode_timeout=60.0,
        actor_addr=f'tcp://localhost:{actor_port}',
        replay_addr=f'ipc:///tmp/replay-{replay_port}',
        logger_addr=f'ipc:///tmp/logger-{logger_port}',
        # replay_addr=f'tcp://localhost:{replay_port}',
        # logger_addr=f'tcp://localhost:{logger_port}',
        actor_batch=2,
        actor_threads=4,
        env_replica=-1,
        ipv6=False,
        timer=True,
        agent_process=False,
        remote_replay=False,
    )

</embodied/tests/run/test_parallel.py>

<embodied/tests/run/test_train.py>
import pathlib
import sys
from functools import partial as bind

sys.path.append(str(pathlib.Path(__file__).parent.parent.parent.parent))
sys.path.append(str(pathlib.Path(__file__).parent))

import embodied
import numpy as np
import pytest

import utils


class TestTrain:

  @pytest.mark.parametrize('strategy', ('blocking', 'process', 'thread'))
  def test_run_loop(self, tmpdir, strategy):
    args = self._make_args(tmpdir)
    agent = self._make_agent()
    embodied.run.train(
        lambda: agent, bind(self._make_replay, args),
        self._make_env, self._make_logger, args)
    stats = agent.stats()
    print('Stats:', stats)
    replay_steps = args.steps * args.train_ratio
    assert stats['lifetime'] > 8  # Otherwise decrease log and ckpt interval.
    assert np.allclose(stats['env_steps'], args.steps, 100, 0.1)
    assert np.allclose(stats['replay_steps'], replay_steps, 100, 0.1)
    assert stats['reports'] >= 1
    assert stats['saves'] >= 2
    assert stats['loads'] == 0
    args = args.update(steps=args.steps + 1e4)
    embodied.run.train(
        lambda: agent, bind(self._make_replay, args),
        self._make_env, self._make_logger, args)
    stats = agent.stats()
    assert stats['loads'] == 1
    assert np.allclose(stats['env_steps'], args.steps, 100, 0.1)

  def _make_agent(self):
    env = self._make_env(0)
    agent = utils.TestAgent(env.obs_space, env.act_space)
    env.close()
    return agent

  def _make_env(self, index):
    from embodied.envs import dummy
    return dummy.Dummy('disc', size=(64, 64), length=100)

  def _make_replay(self, args):
    kwargs = {'length': args.batch_length, 'capacity': 1e4}
    return embodied.replay.Replay(**kwargs)

  def _make_logger(self):
    return embodied.Logger(embodied.Counter(), [
        embodied.logger.TerminalOutput(),
    ])

  def _make_args(self, logdir):
    return embodied.Config(
        logdir=str(logdir),
        num_envs=4,
        steps=5e4,
        log_every=3,
        save_every=5,
        eval_every=5,
        train_ratio=32.0,
        train_fill=100,
        batch_size=8,
        batch_length=16,
        batch_length_eval=8,
        replay_context=0,
        expl_until=0,
        from_checkpoint='',
        usage=dict(psutil=True, nvsmi=False),
        log_zeros=False,
        log_video_streams=4,
        log_video_fps=20,
        log_keys_video=['image'],
        log_keys_sum='^$',
        log_keys_avg='^$',
        log_keys_max='^$',
        driver_parallel=True,
    )

</embodied/tests/run/test_train.py>

<embodied/tests/run/utils.py>
import time

import embodied
import numpy as np


class TestAgent:

  def __init__(self, obs_space, act_space, addr=None):
    self.obs_space = obs_space
    self.act_space = act_space
    if addr:
      self.client = embodied.distr.Client(addr, connect=True)
      self.should_stats = embodied.when.Clock(1)
    else:
      self.client = None
    self._stats = {
        'env_steps': 0, 'replay_steps': 0, 'reports': 0,
        'saves': 0, 'loads': 0, 'created': time.time(),
    }

  def _watcher(self):
    while True:
      if self.queue.empty():
        self.queue.put(self.stats())
      else:
        time.sleep(0.01)

  def stats(self):
    stats = self._stats.copy()
    stats['lifetime'] = time.time() - stats.pop('created')
    return stats

  def init_policy(self, batch_size):
    return (np.zeros(batch_size),)

  def init_train(self, batch_size):
    return (np.zeros(batch_size),)

  def init_report(self, batch_size):
    return ()

  def policy(self, obs, carry, mode='train'):
    B = len(obs['is_first'])
    self._stats['env_steps'] += B
    carry, = carry
    carry = np.asarray(carry)

    assert carry.shape == (B,)
    assert not any(k.startswith('log_') for k in obs.keys())

    target = (carry + 1) * (1 - obs['is_first'])
    assert (obs['step'] == target).all()
    carry = target

    if self.client and self.should_stats():
      self.client.report(self.stats())

    act = {
        k: np.stack([v.sample() for _ in range(B)])
        for k, v in self.act_space.items() if k != 'reset'}
    return act, {}, (carry,)

  def train(self, data, carry):
    B, T = data['step'].shape
    carry, = carry
    assert carry.shape == (B,)
    assert not any(k.startswith('log_') for k in data.keys())
    self._stats['replay_steps'] += B * T
    for t in range(T):
      current = data['step'][:, t]
      reset = data['is_first'][:, t]
      target = (1 - reset) * (carry + 1) + reset * current
      assert (current == target).all()
      carry = current

    outs = {}
    metrics = {}
    return outs, (carry,), metrics

  def report(self, data, carry):
    self._stats['reports'] += 1
    return {
        'scalar': np.float32(0),
        'vector': np.zeros(10),
        'image1': np.zeros((64, 64, 1)),
        'image3': np.zeros((64, 64, 3)),
        'video': np.zeros((10, 64, 64, 3)),
    }, carry

  def dataset(self, generator):
    return generator()

  def save(self):
    self._stats['saves'] += 1
    return self._stats

  def load(self, data):
    self._stats = data
    self._stats['loads'] += 1

</embodied/tests/run/utils.py>

<embodied/tests/test_driver.py>
import pathlib
import sys
from functools import partial as bind

sys.path.append(str(pathlib.Path(__file__).parent.parent.parent))

import embodied
import numpy as np


class TestDriver:

  def test_episode_length(self):
    agent = self._make_agent()
    driver = embodied.Driver([self._make_env])
    driver.reset(agent.init_policy)
    seq = []
    driver.on_step(lambda tran, _: seq.append(tran))
    driver(agent.policy, episodes=1)
    assert len(seq) == 11

  def test_first_step(self):
    agent = self._make_agent()
    driver = embodied.Driver([self._make_env])
    driver.reset(agent.init_policy)
    seq = []
    driver.on_step(lambda tran, _: seq.append(tran))
    driver(agent.policy, episodes=2)
    for index in [0, 11]:
      assert seq[index]['is_first'].item() is True
      assert seq[index]['is_last'].item() is False
    for index in [1, 10, 12]:
      assert seq[index]['is_first'].item() is False

  def test_last_step(self):
    agent = self._make_agent()
    driver = embodied.Driver([self._make_env])
    driver.reset(agent.init_policy)
    seq = []
    driver.on_step(lambda tran, _: seq.append(tran))
    driver(agent.policy, episodes=2)
    for index in [10, 21]:
      assert seq[index]['is_last'].item() is True
      assert seq[index]['is_first'].item() is False
    for index in [0, 1, 9, 11, 20]:
      assert seq[index]['is_last'].item() is False

  def test_env_reset(self):
    agent = self._make_agent()
    driver = embodied.Driver([bind(self._make_env, length=5)])
    driver.reset(agent.init_policy)
    seq = []
    driver.on_step(lambda tran, _: seq.append(tran))
    action = np.array([1])
    driver(lambda obs, state: ({'action': action}, {}, state), episodes=2)
    assert len(seq) == 12
    seq = {k: np.array([seq[i][k] for i in range(len(seq))]) for k in seq[0]}
    assert (seq['is_first'] == [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]).all()
    assert (seq['is_last']  == [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1]).all()
    assert (seq['reset']    == [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1]).all()
    assert (seq['action']   == [1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0]).all()

  def test_agent_inputs(self):
    agent = self._make_agent()
    driver = embodied.Driver([self._make_env])
    driver.reset(agent.init_policy)
    inputs = []
    states = []
    def policy(obs, state=None, mode='train'):
      inputs.append(obs)
      states.append(state)
      act, _, _ = agent.policy(obs, state, mode)
      return act, {}, 'state'
    seq = []
    driver.on_step(lambda tran, _: seq.append(tran))
    driver(policy, episodes=2)
    assert len(seq) == 22
    assert states == ([()] + ['state'] * 21)
    for index in [0, 11]:
      assert inputs[index]['is_first'].item() is True
    for index in [1, 10, 12, 21]:
      assert inputs[index]['is_first'].item() is False
    for index in [10, 21]:
      assert inputs[index]['is_last'].item() is True
    for index in [0, 1, 9, 11, 20]:
      assert inputs[index]['is_last'].item() is False

  def test_unexpected_reset(self):

    class UnexpectedReset(embodied.Wrapper):
      """Send is_first without preceeding is_last."""
      def __init__(self, env, when):
        super().__init__(env)
        self._when = when
        self._step = 0
      def step(self, action):
        if self._step == self._when:
          action = action.copy()
          action['reset'] = np.ones_like(action['reset'])
        self._step += 1
        return self.env.step(action)

    env = self._make_env(length=4)
    env = UnexpectedReset(env, when=3)
    agent = self._make_agent()
    driver = embodied.Driver([lambda: env])
    driver.reset(agent.init_policy)
    steps = []
    driver.on_step(lambda tran, _: steps.append(tran))
    driver(agent.policy, episodes=1)
    assert len(steps) == 8
    steps = {k: np.array([x[k] for x in steps]) for k in steps[0]}
    assert (steps['reset'] == [0, 0, 0, 0, 0, 0, 0, 1]).all()
    assert (steps['is_first'] == [1, 0, 0, 1, 0, 0, 0, 0]).all()
    assert (steps['is_last'] == [0, 0, 0, 0, 0, 0, 0, 1]).all()

  def _make_env(self, length=10):
    from embodied.envs import dummy
    return dummy.Dummy('disc', length=length)

  def _make_agent(self):
    env = self._make_env()
    agent = embodied.RandomAgent(env.obs_space, env.act_space)
    env.close()
    return agent

</embodied/tests/test_driver.py>

<embodied/tests/test_path.py>
import pathlib
import sys

sys.path.append(str(pathlib.Path(__file__).parent.parent.parent))

import embodied


class TestDriver:

  def test_str_canonical(self):
    examples = ['/', 'foo/bar', 'file.txt', '/bar.tar.gz']
    for example in examples:
      assert str(embodied.Path(example)) == example

  def test_parent_and_name(self):
    examples = ['foo/bar', '/bar.tar.gz', 'file.txt', 'foo/bar/baz']
    for example in examples:
      path = embodied.Path(example)
      assert path == path.parent / path.name

  def test_stem_and_suffix(self):
    examples = ['foo/bar', '/bar.tar.gz', 'file.txt', 'foo/bar/baz']
    for example in examples:
      path = embodied.Path(example)
      assert path.name == path.stem + path.suffix

  def test_leading_dot(self):
    assert str(embodied.Path('')) == '.'
    assert str(embodied.Path('.')) == '.'
    assert str(embodied.Path('./')) == '.'
    assert str(embodied.Path('./foo')) == 'foo'

  def test_trailing_slash(self):
    assert str(embodied.Path('./')) == '.'
    assert str(embodied.Path('a/')) == 'a'
    assert str(embodied.Path('foo/bar/')) == 'foo/bar'

  # @pytest.mark.filterwarnings('ignore::DeprecationWarning')
  # def test_protocols(self):
  #   assert str(embodied.Path('gs://')) == ('gs://')
  #   assert str(embodied.Path('gs://foo/bar')) == 'gs://foo/bar'

  def test_parent(self):
    empty = embodied.Path('.')
    root = embodied.Path('/')
    assert (root / 'foo' / 'bar.txt').parent.parent == root
    assert (empty / 'foo' / 'bar.txt').parent.parent == empty
    assert root.parent == root
    assert empty.parent == empty

</embodied/tests/test_path.py>

<embodied/tests/test_replay.py>
import collections
import pathlib
import sys
import threading
import time

sys.path.append(str(pathlib.Path(__file__).parent.parent.parent))

import embodied
import numpy as np
import pytest


REPLAYS_UNLIMITED = [
    embodied.replay.Replay,
    # embodied.replay.Reverb,
]

REPLAYS_SAVECHUNKS = [
    embodied.replay.Replay,
]

REPLAYS_UNIFORM = [
    embodied.replay.Replay,
]


def unbatched(dataset):
  for batch in dataset:
    yield {k: v[0] for k, v in batch.items()}


@pytest.mark.filterwarnings('ignore:.*Pillow.*')
@pytest.mark.filterwarnings('ignore:.*the imp module.*')
@pytest.mark.filterwarnings('ignore:.*distutils.*')
class TestReplay:

  @pytest.mark.parametrize('Replay', REPLAYS_UNLIMITED)
  def test_multiple_keys(self, Replay):
    replay = Replay(length=5, capacity=10)
    for step in range(30):
      replay.add({'image': np.zeros((64, 64, 3)), 'action': np.zeros(12)})
    seq = next(unbatched(replay.dataset(1)))
    assert set(seq.keys()) == {'stepid', 'image', 'action'}
    assert seq['stepid'].shape == (5, 20)
    assert seq['image'].shape == (5, 64, 64, 3)
    assert seq['action'].shape == (5, 12)

  @pytest.mark.parametrize('Replay', REPLAYS_UNLIMITED)
  @pytest.mark.parametrize(
      'length,workers,capacity',
      [(1, 1, 1), (2, 1, 2), (5, 1, 10), (1, 2, 2), (5, 3, 15), (2, 7, 20)])
  def test_capacity_exact(self, Replay, length, workers, capacity):
    replay = Replay(length, capacity)
    for step in range(30):
      for worker in range(workers):
        replay.add({'step': step}, worker)
      target = min(workers * max(0, (step + 1) - length + 1), capacity)
      assert len(replay) == target

  @pytest.mark.parametrize('Replay', REPLAYS_UNLIMITED)
  @pytest.mark.parametrize(
      'length,workers,capacity,chunksize',
      [(1, 1, 1, 128), (2, 1, 2, 128), (5, 1, 10, 128), (1, 2, 2, 128),
       (5, 3, 15, 128), (2, 7, 20, 128), (7, 2, 27, 4)])
  def test_sample_sequences(
      self, Replay, length, workers, capacity, chunksize):
    replay = Replay(length, capacity, chunksize=chunksize)
    for step in range(30):
      for worker in range(workers):
        replay.add({'step': step, 'worker': worker}, worker)
    dataset = unbatched(replay.dataset(1))
    for _ in range(10):
      seq = next(dataset)
      assert (seq['step'] - seq['step'][0] == np.arange(length)).all()
      assert (seq['worker'] == seq['worker'][0]).all()

  @pytest.mark.parametrize('Replay', REPLAYS_UNLIMITED)
  @pytest.mark.parametrize(
      'length,capacity', [(1, 1), (2, 2), (5, 10), (1, 2), (5, 15), (2, 20)])
  def test_sample_single(self, Replay, length, capacity):
    replay = Replay(length, capacity)
    for step in range(length):
      replay.add({'step': step})
    dataset = unbatched(replay.dataset(1))
    for _ in range(10):
      seq = next(dataset)
      assert (seq['step'] == np.arange(length)).all()

  @pytest.mark.parametrize('Replay', REPLAYS_UNIFORM)
  def test_sample_uniform(self, Replay):
    replay = Replay(capacity=20, length=5, seed=0)
    for step in range(7):
      replay.add({'step': step})
    assert len(replay) == 3
    histogram = collections.defaultdict(int)
    dataset = unbatched(replay.dataset(1))
    for _ in range(100):
      seq = next(dataset)
      histogram[seq['step'][0]] += 1
    assert len(histogram) == 3, histogram
    histogram = tuple(histogram.values())
    assert histogram[0] > 20
    assert histogram[1] > 20
    assert histogram[2] > 20

  @pytest.mark.parametrize('Replay', REPLAYS_UNLIMITED)
  def test_workers_simple(self, Replay):
    replay = Replay(length=2, capacity=20)
    replay.add({'step': 0}, worker=0)
    replay.add({'step': 1}, worker=1)
    replay.add({'step': 2}, worker=0)
    replay.add({'step': 3}, worker=1)
    dataset = unbatched(replay.dataset(1))
    for _ in range(10):
      seq = next(dataset)
      assert tuple(seq['step']) in ((0, 2), (1, 3))

  @pytest.mark.parametrize('Replay', REPLAYS_UNLIMITED)
  def test_workers_random(self, Replay, length=4, capacity=30):
    rng = np.random.default_rng(seed=0)
    replay = Replay(length, capacity)
    streams = {i: iter(range(10)) for i in range(3)}
    for _ in range(40):
      worker = int(rng.integers(0, 3, ()))
      try:
        step = {'step': next(streams[worker]), 'stream': worker}
        replay.add(step, worker=worker)
      except StopIteration:
        pass
    histogram = collections.defaultdict(int)
    dataset = unbatched(replay.dataset(1))
    for _ in range(10):
      seq = next(dataset)
      assert (seq['step'] - seq['step'][0] == np.arange(length)).all()
      assert (seq['stream'] == seq['stream'][0]).all()
      histogram[int(seq['stream'][0])] += 1
    assert all(count > 0 for count in histogram.values())

  @pytest.mark.parametrize('Replay', REPLAYS_UNLIMITED)
  @pytest.mark.parametrize(
      'length,workers,capacity',
      [(1, 1, 1), (2, 1, 2), (5, 1, 10), (1, 2, 2), (5, 3, 15), (2, 7, 20)])
  def test_worker_delay(self, Replay, length, workers, capacity):
    # embodied.uuid.reset(debug=True)
    replay = Replay(length, capacity)
    rng = np.random.default_rng(seed=0)
    streams = [iter(range(10)) for _ in range(workers)]
    while streams:
      try:
        worker = rng.integers(0, len(streams))
        replay.add({'step': next(streams[worker])}, worker)
      except StopIteration:
        del streams[worker]

  @pytest.mark.parametrize('Replay', REPLAYS_UNLIMITED)
  @pytest.mark.parametrize(
      'length,capacity,chunksize',
      [(1, 1, 128), (3, 10, 128), (5, 100, 128), (5, 25, 2)])
  def test_restore_exact(self, tmpdir, Replay, length, capacity, chunksize):
    embodied.uuid.reset(debug=True)
    replay = Replay(
        length, capacity, directory=tmpdir, chunksize=chunksize,
        save_wait=True)
    for step in range(30):
      replay.add({'step': step})
    num_items = np.clip(30 - length + 1, 0, capacity)
    assert len(replay) == num_items
    data = replay.save()
    replay = Replay(length, capacity, directory=tmpdir)
    replay.load(data)
    assert len(replay) == num_items
    dataset = unbatched(replay.dataset(1))
    for _ in range(len(replay)):
      assert len(next(dataset)['step']) == length

  @pytest.mark.parametrize('Replay', REPLAYS_UNLIMITED)
  @pytest.mark.parametrize(
      'length,capacity,chunksize',
      [(1, 1, 128), (3, 10, 128), (5, 100, 128), (5, 25, 2)])
  def test_restore_noclear(self, tmpdir, Replay, length, capacity, chunksize):
    embodied.uuid.reset(debug=True)
    replay = Replay(
        length, capacity, directory=tmpdir, chunksize=chunksize,
        save_wait=True)
    for _ in range(30):
      replay.add({'foo': 13})
    num_items = np.clip(30 - length + 1, 0, capacity)
    assert len(replay) == num_items
    data = replay.save()
    for _ in range(30):
      replay.add({'foo': 42})
    replay.load(data)
    dataset = unbatched(replay.dataset(1))
    if capacity < num_items:
      for _ in range(len(replay)):
        assert next(dataset)['foo'] == 13

  @pytest.mark.parametrize('Replay', REPLAYS_UNLIMITED)
  @pytest.mark.parametrize('workers', [1, 2, 5])
  @pytest.mark.parametrize('length,capacity', [(1, 1), (3, 10), (5, 100)])
  def test_restore_workers(self, tmpdir, Replay, workers, length, capacity):
    capacity *= workers
    replay = Replay(
        length, capacity, directory=tmpdir, save_wait=True)
    for step in range(50):
      for worker in range(workers):
        replay.add({'step': step}, worker)
    num_items = np.clip((50 - length + 1) * workers, 0, capacity)
    assert len(replay) == num_items
    data = replay.save()
    replay = Replay(length, capacity, directory=tmpdir)
    replay.load(data)
    assert len(replay) == num_items
    dataset = unbatched(replay.dataset(1))
    for _ in range(len(replay)):
      assert len(next(dataset)['step']) == length

  @pytest.mark.parametrize('Replay', REPLAYS_SAVECHUNKS)
  @pytest.mark.parametrize(
      'length,capacity,chunksize', [(1, 1, 1), (3, 10, 5), (5, 100, 12)])
  def test_restore_chunks_exact(
      self, tmpdir, Replay, length, capacity, chunksize):
    embodied.uuid.reset(debug=True)
    assert len(list(embodied.Path(tmpdir).glob('*.npz'))) == 0
    replay = Replay(
        length, capacity, directory=tmpdir, chunksize=chunksize,
        save_wait=True)
    for step in range(30):
      replay.add({'step': step})
    num_items = np.clip(30 - length + 1, 0, capacity)
    assert len(replay) == num_items
    data = replay.save()
    filenames = list(embodied.Path(tmpdir).glob('*.npz'))
    lengths = [int(x.stem.split('-')[3]) for x in filenames]
    stored_steps = min(capacity + length - 1, 30)
    total_chunks = int(np.ceil(30 / chunksize))
    pruned_chunks = int(np.floor((30 - stored_steps) / chunksize))
    assert len(filenames) == total_chunks - pruned_chunks
    last_chunk_empty = total_chunks * chunksize - 30
    saved_steps = (total_chunks - pruned_chunks) * chunksize - last_chunk_empty
    assert sum(lengths) == saved_steps
    assert all(1 <= x <= chunksize for x in lengths)
    replay = Replay(length, capacity, directory=tmpdir, chunksize=chunksize)
    replay.load(data)
    assert sorted(embodied.Path(tmpdir).glob('*.npz')) == sorted(filenames)
    assert len(replay) == num_items
    dataset = unbatched(replay.dataset(1))
    for _ in range(len(replay)):
      assert len(next(dataset)['step']) == length

  @pytest.mark.parametrize('Replay', REPLAYS_SAVECHUNKS)
  @pytest.mark.parametrize('workers', [1, 2, 5])
  @pytest.mark.parametrize(
      'length,capacity,chunksize', [(1, 1, 1), (3, 10, 5), (5, 100, 12)])
  def test_restore_chunks_workers(
      self, tmpdir, Replay, workers, length, capacity, chunksize):
    capacity *= workers
    replay = Replay(
        length, capacity, directory=tmpdir, chunksize=chunksize,
        save_wait=True)
    for step in range(50):
      for worker in range(workers):
        replay.add({'step': step}, worker)
    num_items = np.clip((50 - length + 1) * workers, 0, capacity)
    assert len(replay) == num_items
    data = replay.save()
    filenames = list(embodied.Path(tmpdir).glob('*.npz'))
    lengths = [int(x.stem.split('-')[3]) for x in filenames]
    stored_steps = min(capacity // workers + length - 1, 50)
    total_chunks = int(np.ceil(50 / chunksize))
    pruned_chunks = int(np.floor((50 - stored_steps) / chunksize))
    assert len(filenames) == (total_chunks - pruned_chunks) * workers
    last_chunk_empty = total_chunks * chunksize - 50
    saved_steps = (total_chunks - pruned_chunks) * chunksize - last_chunk_empty
    assert sum(lengths) == saved_steps * workers
    replay = Replay(length, capacity, directory=tmpdir, chunksize=chunksize)
    replay.load(data)
    assert len(replay) == num_items
    dataset = unbatched(replay.dataset(1))
    for _ in range(len(replay)):
      assert len(next(dataset)['step']) == length

  @pytest.mark.parametrize('Replay', REPLAYS_UNLIMITED)
  @pytest.mark.parametrize(
      'length,capacity,chunksize',
      [(1, 1, 128), (3, 10, 128), (5, 100, 128), (5, 25, 2)])
  def test_restore_insert(self, tmpdir, Replay, length, capacity, chunksize):
    embodied.uuid.reset(debug=True)
    replay = Replay(
        length, capacity, directory=tmpdir, chunksize=chunksize,
        save_wait=True)
    inserts = int(1.5 * chunksize)
    for step in range(inserts):
      replay.add({'step': step})
    num_items = np.clip(inserts - length + 1, 0, capacity)
    assert len(replay) == num_items
    data = replay.save()
    replay = Replay(length, capacity, directory=tmpdir)
    replay.load(data)
    assert len(replay) == num_items
    dataset = unbatched(replay.dataset(1))
    for _ in range(len(replay)):
      assert len(next(dataset)['step']) == length
    for step in range(inserts):
      replay.add({'step': step})
    num_items = np.clip(2 * (inserts - length + 1), 0, capacity)
    assert len(replay) == num_items

  @pytest.mark.parametrize('Replay', REPLAYS_UNLIMITED)
  def test_threading(
      self, tmpdir, Replay, length=5, capacity=128, chunksize=32,
      adders=8, samplers=4):
    embodied.uuid.reset(debug=True)
    replay = Replay(
        length, capacity, directory=tmpdir, chunksize=chunksize,
        save_wait=True)
    running = [True]

    def adder():
      ident = threading.get_ident()
      step = 0
      while running[0]:
        replay.add({'step': step}, worker=ident)
        step += 1
        time.sleep(0.001)

    def sampler():
      dataset = unbatched(replay.dataset(1))
      while running[0]:
        seq = next(dataset)
        assert (seq['step'] - seq['step'][0] == np.arange(length)).all()
        time.sleep(0.001)

    workers = []
    for _ in range(adders):
      workers.append(threading.Thread(target=adder))
    for _ in range(samplers):
      workers.append(threading.Thread(target=sampler))

    try:
      [worker.start() for worker in workers]
      for _ in range(4):

        time.sleep(0.1)
        stats = replay.stats()
        assert stats['inserts'] > 0
        assert stats['samples'] > 0

        print('SAVING')
        data = replay.save()
        time.sleep(0.1)

        print('LOADING')
        replay.load(data)

    finally:
      running[0] = False
      [worker.join() for worker in workers]

    assert len(replay) == capacity

</embodied/tests/test_replay.py>

<embodied/tests/test_sampletree.py>
import collections
import pathlib
import sys

sys.path.append(str(pathlib.Path(__file__).parent.parent.parent))

import numpy as np
import pytest
from embodied.replay import sampletree


class TestSampleTree:

  @pytest.mark.parametrize('branching', [2, 3, 5, 10])
  def test_root_sum(self, branching):
    tree = sampletree.SampleTree(branching)
    entries = range(50)
    for index, uprob in enumerate(entries):
      assert tree.root.uprob == sum(entries[:index])
      tree.insert(index, uprob)

  @pytest.mark.parametrize('inserts', [1, 2, 10, 100])
  @pytest.mark.parametrize('branching', [2, 3, 5, 10])
  def test_depth_inserts(self, inserts, branching):
    tree = sampletree.SampleTree(branching)
    for index in range(inserts):
      tree.insert(index, 1)
    assert len(tree) == inserts
    depths = self._find_leave_depths(tree)
    target = max(1, int(np.ceil(np.log(inserts) / np.log(branching))))
    assert all(x == target for x in depths)

  @pytest.mark.parametrize('inserts', [2, 10, 100])
  @pytest.mark.parametrize('remove_every', [2, 3, 4])
  @pytest.mark.parametrize('branching', [2, 3, 5, 10])
  def test_depth_removals(self, inserts, remove_every, branching):
    tree = sampletree.SampleTree(branching)
    for index in range(0, inserts, 1):
      tree.insert(index, 1)
    removals = list(range(0, inserts, remove_every))
    for index in removals:
      tree.remove(index)
    assert len(tree) == inserts - len(removals)
    depths = self._find_leave_depths(tree)
    target = max(1, int(np.ceil(np.log(inserts) / np.log(branching))))
    assert all(x == target for x in depths)

  @pytest.mark.parametrize('inserts', [2, 10, 100])
  @pytest.mark.parametrize('branching', [2, 3, 5, 10])
  def test_removal_num_nodes(self, inserts, branching):
    tree = sampletree.SampleTree(branching)
    assert len(self._get_flat_nodes(tree)) == 1
    rng = np.random.default_rng(seed=0)
    for key in rng.permutation(np.arange(inserts)):
      tree.insert(key, 1)
    num_nodes = len(self._get_flat_nodes(tree))
    for key in rng.permutation(np.arange(inserts)):
      tree.remove(key)
    assert len(self._get_flat_nodes(tree)) == 1
    for key in rng.permutation(np.arange(inserts)):
      tree.insert(key, 1)
    assert len(self._get_flat_nodes(tree)) == num_nodes

  @pytest.mark.parametrize('branching', [2, 3, 5, 10])
  def test_sample_single(self, branching):
    tree = sampletree.SampleTree(branching)
    tree.insert(12, 1.0)
    tree.insert(123, 1.0)
    tree.insert(42, 1.0)
    tree.remove(12)
    tree.remove(42)
    for _ in range(10):
      assert tree.sample() == 123

  @pytest.mark.parametrize('inserts', [2, 10])
  @pytest.mark.parametrize('branching', [2, 3, 5, 10])
  @pytest.mark.parametrize('uprob', [1e-5, 1.0, 1e5])
  def test_sample_uniform(self, inserts, branching, uprob):
    tree = sampletree.SampleTree(branching, seed=0)
    keys = list(range(inserts))
    for key in keys:
      tree.insert(key, 1.0)
    for key in keys[::3]:
      tree.remove(key)
      keys.remove(key)
    histogram = collections.defaultdict(int)
    for _ in range(100 * len(keys)):
      key = tree.sample()
      histogram[key] += 1
    assert len(histogram) > 0
    assert len(histogram) == len(keys)
    assert all(k in histogram for k in keys)
    for key, count in histogram.items():
      prob = count / (100 * len(keys))
      assert prob > 0.5 * (1 / len(keys))

  @pytest.mark.parametrize('scale', [1e-5, 1, 1e5])
  @pytest.mark.parametrize('branching', [2, 3, 5, 10])
  def test_sample_frequencies(self, scale, branching):
    tree = sampletree.SampleTree(branching, seed=0)
    keys = [0, 1, 2, 3, 4, 5]
    uprobs = [0, 3, 1, 1, 2, 2]
    entries = dict(zip(keys, uprobs))
    for key, uprob in entries.items():
      tree.insert(key, scale * uprob)
    histogram = collections.defaultdict(int)
    for _ in range(100 * len(entries)):
      key = tree.sample()
      histogram[key] += 1
    assert len(histogram) > 0
    total = sum(entries.values())
    for key, uprob in entries.items():
      if uprob == 0:
        assert key not in histogram
    for key, count in histogram.items():
      prob = count / (100 * len(entries))
      target = entries[key] / total
      assert 0.7 * target < prob < 1.3 * target

  @pytest.mark.parametrize('branching', [2, 3, 5, 10])
  def test_update_frequencies(self, branching):
    tree = sampletree.SampleTree(branching, seed=0)
    keys = [0, 1, 2, 3, 4, 5]
    uprobs = [0, 3, 1, 1, 2, 2]
    entries = dict(zip(keys, uprobs))
    for key in entries.keys():
      tree.insert(key, 100)
    for key, uprob in entries.items():
      tree.update(key, uprob)
    histogram = collections.defaultdict(int)
    for _ in range(100 * len(entries)):
      key = tree.sample()
      histogram[key] += 1
    assert len(histogram) > 0
    total = sum(entries.values())
    for key, uprob in entries.items():
      if uprob == 0:
        assert key not in histogram
    for key, count in histogram.items():
      prob = count / (100 * len(entries))
      target = entries[key] / total
      assert 0.7 * target < prob < 1.3 * target

  @pytest.mark.parametrize('branching', [2, 3, 5, 10])
  def test_zero_probs_mixed(self, branching):
    tree = sampletree.SampleTree(branching, seed=0)
    impossible = []
    for index in range(100):
      if index % 3 == 0:
        tree.insert(index, 1.0)
      else:
        tree.insert(index, 0.0)
        impossible.append(index)
    for _ in range(1000):
      assert tree.sample() not in impossible

  @pytest.mark.parametrize('branching', [2, 3, 5, 10])
  def test_zero_probs_only(self, branching):
    tree = sampletree.SampleTree(branching, seed=0)
    for index in range(100):
      tree.insert(index, 0.0)
    for _ in range(1000):
      assert tree.sample() in range(100)

  @pytest.mark.parametrize('branching', [2, 3, 5, 10])
  def test_infinity_probs(self, branching):
    tree = sampletree.SampleTree(branching, seed=0)
    possible = []
    for index in range(100):
      if index % 3 == 0:
        tree.insert(index, np.inf)
        possible.append(index)
      else:
        tree.insert(index, 1.0)
    for _ in range(1000):
      assert tree.sample() in possible

  def _find_leave_depths(self, tree):
    depths = []
    queue = [(tree.root, 0)]
    while queue:
      node, depth = queue.pop()
      if hasattr(node, 'children'):
        for child in node.children:
          queue.append((child, depth + 1))
      else:
        depths.append(depth)
    assert len(depths) > 0
    return depths

  def _get_flat_nodes(self, tree):
    nodes = []
    queue = [tree.root]
    while queue:
      node = queue.pop()
      nodes.append(node)
      if hasattr(node, 'children'):
        queue += node.children
    return nodes

</embodied/tests/test_sampletree.py>

<embodied/__init__.py>
__version__ = '1.1.0'

from .core import *

from . import distr
from . import envs
from . import replay
from . import run

try:
  from rich import traceback
  import numpy as np
  import jax

  traceback.install(
      # show_locals=True,
      suppress=[np, jax])

except ImportError:
  pass

</embodied/__init__.py>

<flattened_repo._omni.txt>
<run_utils.py>
import cv2
import base64
import numpy as np
import os
import re
import json
import hydra
from omegaconf import DictConfig
from omegaconf import OmegaConf
from textwrap import dedent

from embodied.envs.pybullet import PyBullet
from omni_epic.robots import robot_dict
from omni_epic.core.fm import FM


# Function to get images at specified intervals from a video file
def get_images_from_video(video_file, interval=62):
	# Open the video file
	cap = cv2.VideoCapture(video_file)
	if not cap.isOpened():
		print("Error: Could not open video.")
		return None
	# Calculate the interval between each image to be captured
	total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
	# Skip the first 10 frames to get to the interesting parts
	frames_to_capture = range(10, total_frames, interval)
	images = []
	for frame_id in frames_to_capture:
		# Read the current frame position of the video file
		cap.set(cv2.CAP_PROP_POS_FRAMES, frame_id)
		ret, frame = cap.read()
		if ret:
			images.append(frame)
		else:
			print(f"Error: Could not read frame {frame_id}")
			break
	# Release the video capture object
	cap.release()
	return images

# Save images into output directory
def save_images(images, output_dir):
	os.makedirs(output_dir, exist_ok=True)
	# Save individual images
	for i, image in enumerate(images):
		cv2.imwrite(f'{output_dir}/image_{i}.png', image)

	# Label image number on the top left corner of each image
	for i, image in enumerate(images):
		cv2.putText(image, f'{i+1}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2, cv2.LINE_AA)

	n_per_row = 8
	# Calculate the number of images to be padded
	padded_images = images.copy()
	remainder = len(padded_images) % n_per_row
	if remainder != 0:
		padding = n_per_row - remainder
		# Create a dummy image with the same shape as the last image in the list
		dummy_image = np.zeros_like(padded_images[-1])
		# Add the dummy image to the list of images
		padded_images.extend([dummy_image] * padding)

	# Save concated images, only have N images per row
	concat_image = np.concatenate([
		 np.concatenate(padded_images[i:i+n_per_row], axis=1) \
			for i in range(0, len(padded_images), n_per_row)], axis=0)
	cv2.imwrite(f'{output_dir}/concat_image.png', concat_image)

	return concat_image

# Function to encode the image
def encode_image(image_path):
	with open(image_path, "rb") as image_file:
		return base64.b64encode(image_file.read()).decode('utf-8')

def get_envcode_path(run_folder):
	input_config = OmegaConf.load(os.path.join(run_folder, "./.hydra/config.yaml"))
	return input_config['env']['path']

def parse_task_desc_from_env_code(env_code):
	# Only search after class definition
	task_desc = re.search(r'class Env.*?:\s*\"\"\"(.+?)\"\"\"', env_code, re.DOTALL).group(1)
	# For each line in taskdesc, remove leading and trailing whitespaces
	task_desc = '\n'.join([line.strip() for line in task_desc.split('\n')]).strip()
	return task_desc

def get_task_desc_from_env_path(env_path):
	env = PyBullet(env_path=env_path, vision=False)._env
	task_desc = dedent(env.__doc__).strip()
	return task_desc

def get_task_success_from_file(success_file):
	# Read file
	with open(success_file, "r") as f:
		text = f.read().strip()
		step_successes = text.split('\n')
		step_successes = [x == 'True' for x in step_successes]
	# Determine final task success
	success = any(step_successes)
	return success

def get_task_success_from_folder(run_folder, voting='majority'):
	# Get task success from saved files
	success_files = [f for f in os.listdir(run_folder) if f.endswith('.txt') and f.startswith('success')]
	success_files = [os.path.join(run_folder, f) for f in success_files]
	# Process overall task success
	task_successes = [get_task_success_from_file(f) for f in success_files]
	if voting == 'majority':
		task_success = sum(task_successes) >= len(task_successes) / 2
	elif voting == 'all':
		task_success = all(task_successes)
	else:
		task_success = any(task_successes)
	return task_success

def get_task_success_file_from_folder(run_folder):
	# Get task success from saved files
	success_files = [f for f in os.listdir(run_folder) if f.endswith('.txt') and f.startswith('success')]
	success_files = [os.path.join(run_folder, f) for f in success_files]
	# Process overall task success
	task_successes = [get_task_success_from_file(f) for f in success_files]
	# Return the first successful file
	for i, task_success in enumerate(task_successes):
		if task_success:
			return success_files[i]
	return None

</run_utils.py>


</flattened_repo._omni.txt>

<game/backend/app.py>
import eventlet
eventlet.monkey_patch()

from flask_cors import CORS
from flask_socketio import SocketIO, join_room
from flask import Flask, render_template, Response, request, jsonify

import requests
import threading
import time

from textwrap import dedent
import re
import json
import os
from datetime import datetime
import cv2
import numpy as np
from omegaconf import OmegaConf
from absl import logging
from absl import app as absl_app
import shutil

from embodied.envs.pybullet import PyBullet
from main import main


app = Flask(__name__)

# Configure logging
current_time = datetime.now().strftime("%Y%m%d_%H%M%S")
LOGDIR = os.path.abspath(f"/workspace/src/game/backend/omni_epic_logs/{current_time}")
os.makedirs(LOGDIR, exist_ok=True)
logging.get_absl_handler().use_absl_log_file('application', LOGDIR)
logging.set_verbosity(logging.INFO)

# Adding CORS policies here
CORS(app, resources={r"/*": {"origins": "*"}})
socketio = SocketIO(app, cors_allowed_origins="*")


def load_archive(archive_filepath):
    # Load the archive file and return the codepaths
    with open(archive_filepath, 'r') as f:
        content = f.read()
        json_str = re.split('(?<=})\n(?={)', content)[-1]
        json_obj = json.loads(json_str)
    return json_obj["codepaths"]


# Initialize the game environment
if not os.path.exists(os.path.join(LOGDIR, "archive.jsonl")):
    shutil.copy("./game/backend/env_codes/archive.jsonl", LOGDIR)
ARCHIVE = load_archive(os.path.join(LOGDIR, "archive.jsonl"))
ARCHIVE_INDEX = 0
LOOP_ARCHIVE = False  # Loop through the archive, instead of generating new levels
ENV_PATH = ARCHIVE[ARCHIVE_INDEX]
ENV = PyBullet(env_path=ENV_PATH, vision=False)._env
TASK_DESC = dedent(ENV.__doc__).strip().split('\n')[0]
ENV.reset()
SUCCESS = False

# Recording actions
IS_RECORDING = False
RECORDED_ACTIONS = []
RECORDED_FRAMES = []
MAX_RECORD_STEPS = 10000

# Generation variables
TASKGEN_CHOOSE_PROBS = np.ones(len(ARCHIVE))
ITERATE_SAME_TASK_COUNT = 0
GENERATING_NEXT_LEVEL = False

# Access variables
ACCESS_USER_ID = None
CURR_ACCESS_CODE = None
SECRET_ACESS_CODE = "omni_epic_is_awesome_0123"


@app.route('/')
def index():
    return render_template('index.html')

def gen_frames():
    global ENV, SUCCESS, GENERATING_NEXT_LEVEL
    while True:
        socketio.sleep(0.01)  # Let SocketIO manage app sleeping
        for i in range(5):
            action_do_nothing = 0
            observation, reward, terminated, truncated, info = ENV.step(action_do_nothing)
            # Skip recording the last empty action
            if i < 4:
                record_action_logic(action_do_nothing, None)
            # # Check if the game is terminated
            # if terminated:
            #     handle_reset()
            #     break

        # Emit reward to the frontend
        socketio.emit('reward_update', {'reward': reward})
        # Update generating next level status
        socketio.emit('generating_next_level', {'generating': GENERATING_NEXT_LEVEL})

        # Check if the level is successfully completed
        SUCCESS = ENV.get_success() or SUCCESS
        if SUCCESS:
            socketio.emit('level_complete', {'message': 'Level completed!'})

        frame = ENV.render3p(height=180, width=320)
        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # convert frame from BGR to RGB
        record_action_logic(action_do_nothing, frame.tolist())  # record the last empty action
        if not frame.flags['C_CONTIGUOUS']:
            frame = np.ascontiguousarray(frame, dtype=np.uint8)
        ret, buffer = cv2.imencode('.jpg', frame)
        frame = buffer.tobytes()
        yield (b'--frame\r\n'
               b'Content-Type: image/jpeg\r\n\r\n' + frame + b'\r\n')

# TODO: Add an ID from user socket io so that the feeds are different for different users
@app.route('/video_feed')
def video_feed():
    return Response(gen_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')

@socketio.on('connect')
def handle_connect():
    global TASK_DESC
    user_id = request.sid  # Get the ID of the connected user
    # print(f"User {user_id} connected")  # Print the ID of the connected user
    socketio.emit('connected_message', {'message': 'You are connected!'}, room=request.sid)  # Send a connected message to the connected user
    join_room(request.sid)  # Join a room with the user's ID
    socketio.emit('env_description', {'description': TASK_DESC})  # Update env description

def record_action_logic(action, frame=None):
    global IS_RECORDING, RECORDED_ACTIONS, RECORDED_FRAMES, MAX_RECORD_STEPS
    if IS_RECORDING:
        if len(RECORDED_ACTIONS) < MAX_RECORD_STEPS:
            RECORDED_ACTIONS.append(action)
            RECORDED_FRAMES.append(frame)  # NOTE: comment this out to not record frames, save space when debugging
        else:
            stop_recording()  # Automatically stop recording if max steps reached

def check_valid_user():
    global ACCESS_USER_ID
    user_id = request.sid
    if ACCESS_USER_ID is None or user_id != ACCESS_USER_ID:
        # print(f"User {user_id} is not authorized")
        return False
    return True

@socketio.on('action')
def handle_action(json):
    global ENV, ACCESS_USER_ID

    if not check_valid_user():
        return

    action = int(json['action'])
    repeat_num = 5 if action in [1, 2] else 2
    for _ in range(repeat_num):
        observation, reward, terminated, truncated, info = ENV.step(action)
        record_action_logic(action, None)

@socketio.on('reset')
def handle_reset():
    global ENV, IS_RECORDING, SUCCESS

    if not check_valid_user():
        return

    logging.info("Resetting the game")
    ENV.reset()
    SUCCESS = False
    socketio.emit('reset_message', {'message': 'Game reset! Start again!'})
    if IS_RECORDING:
        stop_recording()
    socketio.emit('env_description', {'description': TASK_DESC})

@socketio.on('prev_level')
def handle_prev_level():
    global ARCHIVE, ARCHIVE_INDEX, ENV, ENV_PATH, TASK_DESC, \
           IS_RECORDING, SUCCESS, TASKGEN_CHOOSE_PROBS, ITERATE_SAME_TASK_COUNT, \
           LOOP_ARCHIVE, GENERATING_NEXT_LEVEL

    if not check_valid_user():
        return

    logging.info("Loading previous level")

    # Stop recording
    if IS_RECORDING:
        stop_recording()

    # Load the previous env in the archive
    if ARCHIVE_INDEX > 0:
        ARCHIVE_INDEX -= 1

    # Load the new env
    ENV_PATH = ARCHIVE[ARCHIVE_INDEX]
    ENV.close()  # Close the current env
    ENV = PyBullet(env_path=ENV_PATH, vision=False)._env
    TASK_DESC = dedent(ENV.__doc__).strip().split('\n')[0]
    ENV.reset()
    SUCCESS = False
    socketio.emit('next_level_message', {'message': 'Next level started!'})
    socketio.emit('env_description', {'description': TASK_DESC})

@socketio.on('next_level')
def handle_next_level():
    global ARCHIVE, ARCHIVE_INDEX, ENV, ENV_PATH, TASK_DESC, \
           IS_RECORDING, SUCCESS, TASKGEN_CHOOSE_PROBS, ITERATE_SAME_TASK_COUNT, \
           LOOP_ARCHIVE, GENERATING_NEXT_LEVEL

    if not check_valid_user():
        return

    logging.info("Generating next level")
    GENERATING_NEXT_LEVEL = True

    # Stop recording
    if IS_RECORDING:
        stop_recording()

    # Check if we need to generate a new level
    if ARCHIVE_INDEX >= len(ARCHIVE) - 1:
        if LOOP_ARCHIVE:
            # Loop through the archive
            ARCHIVE_INDEX = 0
        else:  # Generate a new level with OMNI-EPIC
            # Load OMNI-EPIC config
            config = OmegaConf.load(f"/workspace/src/configs/omni_epic.yaml")

            # Current env failed
            if not SUCCESS:
                TASKGEN_CHOOSE_PROBS = np.delete(TASKGEN_CHOOSE_PROBS, -1)
                # Update archive with the failed env
                with open(os.path.join(LOGDIR, 'archive.jsonl'), 'r') as f:
                    content = f.read()
                    json_str = re.split('(?<=})\n(?={)', content)[-1]
                    json_obj = json.loads(json_str)
                    json_obj["codepaths"] = [x for x in json_obj["codepaths"] if x != ENV_PATH]
                    json_obj["failedtrain"].append(ENV_PATH)
                    with open(os.path.join(LOGDIR, 'archive.jsonl'), 'a') as f:
                        f.write(json.dumps(json_obj, indent=4) + '\n')
                if ITERATE_SAME_TASK_COUNT < config.task_iterator.max_iterations:
                    # Update OMNI-EPIC config to iterate on the same task
                    config.success_detector.use_vision = False  # Only works without vision
                    config.override_vars['iterate_same_task'] = True
                    config.override_vars['task_description'] = dedent(ENV.__doc__).strip()
                    config.override_vars['task_envpath'] = ENV_PATH
                    ITERATE_SAME_TASK_COUNT += 1
                else:
                    ITERATE_SAME_TASK_COUNT = 0
            else:
                ITERATE_SAME_TASK_COUNT = 0

            # Generate next level
            config.logdir = LOGDIR
            config.robot = 'r2d2'
            config.iterate_until_success_gen = True
            config.enable_moi = True
            config.train_agent = False
            config.archive_from_ckpt = os.path.join(LOGDIR, 'archive.jsonl')
            config.add_examples = False
            config.task_generator.num_add_examples = 5
            config.task_iterator.num_examples = 5
            config.model_of_interestingness.num_examples = 5
            config.override_vars['taskgen_choose_probs'] = TASKGEN_CHOOSE_PROBS.tolist()
            omni_epic_vars = main(config)  # NOTE: comment this out to not gen things when debugging
            TASKGEN_CHOOSE_PROBS = omni_epic_vars['taskgen_choose_probs']

            # Reload archive and env
            ARCHIVE = load_archive(os.path.join(LOGDIR, 'archive.jsonl'))
            ARCHIVE_INDEX = len(ARCHIVE) - 1
    else:
        # Load the next env in the archive
        ARCHIVE_INDEX += 1

    # Load the new env
    ENV_PATH = ARCHIVE[ARCHIVE_INDEX]
    ENV.close()  # Close the current env
    ENV = PyBullet(env_path=ENV_PATH, vision=False)._env
    TASK_DESC = dedent(ENV.__doc__).strip().split('\n')[0]
    ENV.reset()
    SUCCESS = False
    socketio.emit('next_level_message', {'message': 'Next level started!'})
    socketio.emit('env_description', {'description': TASK_DESC})
    GENERATING_NEXT_LEVEL = False

@socketio.on('start_recording')
def start_recording():
    global IS_RECORDING, RECORDED_ACTIONS, RECORDED_FRAMES
    IS_RECORDING = True
    RECORDED_ACTIONS = []
    RECORDED_FRAMES = []
    logging.info("Started recording actions.")

@socketio.on('stop_recording')
def stop_recording():
    global IS_RECORDING, ENV_PATH, RECORDED_ACTIONS, RECOREDED_FRAMES
    IS_RECORDING = False
    data = {
        "env_filepath": ENV_PATH,
        "recorded_actions": RECORDED_ACTIONS,
        "recorded_frames": RECORDED_FRAMES,
    }
    with open(os.path.join(LOGDIR, 'recorded_actions.jsonl'), 'a') as f:
        json.dump(data, f)
        f.write('\n')
    logging.info("Stopped recording actions. Total actions recorded: {}. Data saved to 'recorded_actions.json'".format(len(RECORDED_ACTIONS)))
    socketio.emit('not_recording_status')

@socketio.on('mark_success')
def handle_mark_success():
    global SUCCESS
    if not check_valid_user():
        return
    SUCCESS = True
    socketio.emit('success_marked', {'message': 'Success marked!'})
    logging.info("Environment success marked as True.")

@socketio.on('mark_failure')
def handle_mark_failure():
    global SUCCESS
    if not check_valid_user():
        return
    SUCCESS = False
    socketio.emit('failure_marked', {'message': 'Failure marked!'})
    logging.info("Environment success marked as False.")

@socketio.on('access_code')
def handle_access(access_code):
    global ACCESS_USER_ID
    user_id = request.sid
    if (CURR_ACCESS_CODE != None and access_code == CURR_ACCESS_CODE) or access_code == SECRET_ACESS_CODE:
        ACCESS_USER_ID = user_id
        socketio.emit('access_granted', {'granted': True})
    else:
        socketio.emit('access_granted', {'granted': False})

# Global variable to store the booking status
booking_status = {
    "isBookingOngoing": False,
    "accessCode": ""
}

# URL of the HonoJS endpoint
HONOJS_URL = 'https://api.boopr.xyz/isBookingOngoing'
BEARER_TOKEN = 'api_OAWIJDIUWHJDAWHJIUDOahjwiudhDA9812738712iuahjdwiUDW*&E912hiu4hwtf9g0w78Y'

def fetch_booking_status():
    global booking_status, CURR_ACCESS_CODE, ACCESS_USER_ID
    headers = {
        'Authorization': f'Bearer {BEARER_TOKEN}'
    }
    try:
        response = requests.get(HONOJS_URL, headers=headers)
        if response.status_code == 200:
            booking_status = response.json()
            # print(f"Updated booking status: {booking_status}")
            CURR_ACCESS_CODE = booking_status.get('accessCode')
            if ACCESS_USER_ID == None:
                socketio.emit('show_access_code', {'show': True, 'accessCode': CURR_ACCESS_CODE})
            else:
                socketio.emit('show_access_code', {'show': True, 'accessCode': CURR_ACCESS_CODE})
                # socketio.emit('show_access_code', {'show': False, 'accessCode': CURR_ACCESS_CODE})
        else:
            # print(f"Failed to fetch booking status. HTTP Status: {response.status_code}")
            pass
    except Exception as e:
        # print(f"Error fetching booking status: {e}")
        pass

def update_booking_status():
    global booking_status, CURR_ACCESS_CODE
    while True:
        CURR_ACCESS_CODE = None
        booking_status = {}
        fetch_booking_status()
        time.sleep(30)

@app.route('/check-access-code', methods=['POST'])
def check_access_code():
    code = request.json.get('accessCode')
    if code == booking_status.get('accessCode'):
        return jsonify({"message": "Access code is valid", "isBookingOngoing": booking_status.get('isBookingOngoing')})
    else:
        return jsonify({"message": "Access code is invalid", "isBookingOngoing": booking_status.get('isBookingOngoing')}), 403

@socketio.on('connect')
def handle_connect():
    socketio.emit('booking_status', booking_status)

@app.route('/test')
def test():
    return "Test route is working!"

if __name__ == "__main__":
    threading.Thread(target=update_booking_status, daemon=True).start()
    absl_app.run(lambda argv: socketio.run(app, host='0.0.0.0', port=3005))

</game/backend/app.py>

<game/backend/env_codes/cross_bridge.py>
import numpy as np
from omni_epic.envs.r2d2.base import R2D2Env


class Env(R2D2Env):
    """
    Cross a pride-colored bridge to reach a platform.

    Description:
    - A start platform and an end platform (each 3 m in size and 0.5 m in thickness) are placed 30 m apart.
    - The two platforms are connected by a bridge (2 m wide) divided in multiple segments. Each segment has a different color corresponding to the pride colors.
    The robot is initialized on the start platform.
    The task of the robot is to cross the bridge to reach the end platform as fast as possible.

    Success:
    The task is successfully completed when the robot reaches the end platform.

    Rewards:
    To help the robot complete the task:
    - The robot receives a reward for each time step it remains on the bridge or platforms, encouraging steady progress.
    - The robot is rewarded based on how much it reduces the distance to the end platform, incentivizing swift movement towards the goal.

    Termination:
    The task terminates immediately if the robot falls off the start platform, any segment of the bridge, or the end platform.
    """

    def __init__(self):
        super().__init__()

        # Init start platform
        self.platform_size = [3., 3., 0.5]
        self.platform_start_position = [0., 0., 0.]
        self.platform_end_position = [self.platform_start_position[0] + 30., self.platform_start_position[1], self.platform_start_position[2]]
        self.platform_start_id = self.create_box(mass=0., half_extents=[self.platform_size[0] / 2, self.platform_size[1] / 2, self.platform_size[2] / 2], position=self.platform_start_position, color=[0.8, 0.8, 0.8, 1.])
        self.platform_end_id = self.create_box(mass=0., half_extents=[self.platform_size[0] / 2, self.platform_size[1] / 2, self.platform_size[2] / 2], position=self.platform_end_position, color=[0.8, 0.8, 0.8, 1.])

        # Init bridge
        self.bridge_length = self.platform_end_position[0] - self.platform_start_position[0] - self.platform_size[0]
        self.bridge_width = 2.
        pride_colors = [
            [1.0, 0.0, 0.0, 1.],  # Red
            [1.0, 0.5, 0.0, 1.],  # Orange
            [1.0, 1.0, 0.0, 1.],  # Yellow
            [0.0, 0.5, 0.0, 1.],  # Green
            [0.0, 0.0, 1.0, 1.],  # Blue
            [0.7, 0.0, 1.0, 1.],  # Violet
        ]

        # Segment length
        num_colors = len(pride_colors)
        segment_size = self.bridge_length / num_colors

        # Create segments
        for i, color in enumerate(pride_colors):
            segment_id = self.create_box(mass=0., half_extents=[segment_size / 2, self.bridge_width / 2, self.platform_size[2] / 2], position=[self.platform_start_position[0] + self.platform_size[0] / 2 + segment_size / 2 + i * segment_size, self.platform_start_position[1], self.platform_start_position[2]], color=color)
            self._p.changeDynamics(bodyUniqueId=segment_id, linkIndex=-1, lateralFriction=0.8, restitution=0.5)

    def create_box(self, mass, half_extents, position, color):
        collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents)
        visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents, rgbaColor=color)
        return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position)

    def get_object_position(self, object_id):
        return np.asarray(self._p.getBasePositionAndOrientation(object_id)[0])

    def get_distance_to_object(self, object_id):
        object_position = self.get_object_position(object_id)
        robot_position = self.robot.links["base"].position
        return np.linalg.norm(object_position[:2] - robot_position[:2])

    def reset(self):
        observation = super().reset()

        # Reset robot position on start platform
        self._p.resetBasePositionAndOrientation(self.robot.robot_id, [self.platform_start_position[0], self.platform_start_position[1], self.platform_start_position[2] + self.platform_size[2] / 2 + self.robot.links["base"].position_init[2]], self.robot.links["base"].orientation_init)

        return observation

    def step(self, action):
        # Before taking action
        self.distance_to_platform_end = self.get_distance_to_object(self.platform_end_id)

        observation, reward, terminated, truncated, info = super().step(action)

        return observation, reward, terminated, truncated, info

    def get_task_rewards(self, action):
        # After taking action
        new_distance_to_platform_end = self.get_distance_to_object(self.platform_end_id)

        # Survival
        survival = 1.

        # Reach end platform
        reach_platform_end = (self.distance_to_platform_end - new_distance_to_platform_end) / self.dt

        return {"survival": survival, "reach_platform_end": reach_platform_end}

    def get_terminated(self, action):
        # Terminate if fall off
        return self.robot.links["base"].position[2] < self.platform_start_position[2]

    def get_success(self):
        # Success if reach end platform
        is_on_platform_end = self.get_distance_to_object(self.platform_end_id) < self.platform_size[2] / 2
        return is_on_platform_end

</game/backend/env_codes/cross_bridge.py>

<game/backend/env_codes/cross_lava.py>
import numpy as np
from omni_epic.envs.r2d2.base import R2D2Env


class Env(R2D2Env):
    """
    Cross over lava on a boat to reach a target zone.

    Description:
    - The lava is simulated with an orange, 10 x 10 m heightfield.
    - There are two platforms on either side of the lava, each measuring 5 x 10 m. One serves as the start platform and the other as the end platform.
    - The boat is a box with dimensions 3 meters in length, 2 meters in width, and 0.2 meters in height. It is initialized next to the start platform at a random y-position.
    - The boat has a button that, when pressed, activates the boat to move over the lava at a speed of 3 meters per second.
    - The end platform has a target zone indicated by a green, transparent sphere.
    The robot's task is to jump onto the boat from the start platform, press the button to activate the boat, and travel across the lava to reach the end platform. The robot must then enter the target zone to complete the task.

    Success:
    The task is successfully completed when the robot enters the target zone on the end platform.

    Rewards:
    To guide the robot to complete the task:
    - The robot receives a reward for each time step it remains active and does not fall off or touch the lava.
    - The robot is rewarded for making progress towards pressing the button on the boat.
    - Additional rewards are given for progressing towards the target zone, with a significant bonus for entering the target zone.

    Termination:
    The task terminates immediately if the robot falls off the platform or the boat, or if it touches the simulated lava.
    """

    def __init__(self):
        super().__init__()

        # Init lava
        self.lava_size = [10., 10.]
        self.lava_height = 0.1
        self.lava_position = [0., 0., 0.]
        self.lava_id = self.create_heightfield(
            size=self.lava_size,
            height_max=self.lava_height,  # create small bumps to create a fluid-like surface
            position=self.lava_position,
            resolution=20,  # number of points per meter
            repeats=2,
        )
        self._p.changeVisualShape(objectUniqueId=self.lava_id, linkIndex=-1, rgbaColor=[1., 0.3, 0.1, 1.])  # change to lava color

        # Init platforms
        self.platform_size = [5., self.lava_size[1], 1.]
        self.platform_start_position = [self.lava_position[0] - self.lava_size[0] / 2 - self.platform_size[0] / 2, self.lava_position[1], self.lava_position[2]]
        self.platform_end_position = [self.lava_position[0] + self.lava_size[0] / 2 + self.platform_size[0] / 2, self.lava_position[1], self.lava_position[2]]
        self.platform_start_id = self.create_box(mass=0., half_extents=[self.platform_size[0] / 2, self.platform_size[1] / 2, self.platform_size[2] / 2], position=self.platform_start_position, color=[0.3, 0.3, 0.3, 1.])
        self.platform_end_id = self.create_box(mass=0., half_extents=[self.platform_size[0] / 2, self.platform_size[1] / 2, self.platform_size[2] / 2], position=self.platform_end_position, color=[0.3, 0.3, 0.3, 1.])
        self._p.changeDynamics(bodyUniqueId=self.platform_start_id, linkIndex=-1, lateralFriction=0.8, restitution=0.5)
        self._p.changeDynamics(bodyUniqueId=self.platform_end_id, linkIndex=-1, lateralFriction=0.8, restitution=0.5)

        # Init boat
        self.boat_size = [3., 2., 0.2]
        self.boat_position_init = [self.lava_position[0] - self.lava_size[0] / 2 + self.boat_size[0] / 2, self.lava_position[1], self.boat_size[2] / 2]
        self.boat_speed = 3.
        self.boat_id = self.create_box(mass=0., half_extents=[self.boat_size[0] / 2, self.boat_size[1] / 2, self.boat_size[2] / 2], position=self.boat_position_init, color=[0.8, 0.8, 0.8, 1.])
        self._p.changeDynamics(bodyUniqueId=self.boat_id, linkIndex=-1, lateralFriction=0.8, restitution=0.5)

        # Init button
        self.button_radius = 0.25
        self.button_height = 0.25
        self.button_position_init = [self.boat_position_init[0] + self.boat_size[0] / 4, self.lava_position[1], self.boat_position_init[2] + self.boat_size[2] / 2 + self.button_height / 2]  # put button on the right side of the boat
        self.button_id = self.create_cylinder(mass=0., radius=self.button_radius, height=self.button_height, position=self.button_position_init, color=[0., 0.5, 0., 1.])

        # Init target zone
        self.target_zone_radius = 1.5
        self.target_zone_id = self.create_sphere(mass=0., radius=self.target_zone_radius, collision=False, position=[self.platform_end_position[0], self.platform_end_position[1], self.platform_end_position[2] + self.platform_size[2] / 2], color=[0., 1., 0., 0.5])

        self.objects_on_boat = [self.button_id]

    def create_box(self, mass, half_extents, position, color):
        collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents)
        visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents, rgbaColor=color)
        return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position)

    def create_cylinder(self, mass, radius, height, position, color):
        collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_CYLINDER, radius=radius, height=height)
        visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_CYLINDER, radius=radius, length=height, rgbaColor=color)
        return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position)

    def create_sphere(self, mass, radius, collision, position, color):
        if collision:
            collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_SPHERE, radius=radius)
            visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_SPHERE, radius=radius, rgbaColor=color)
            return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position)
        else:
            visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_SPHERE, radius=radius, rgbaColor=color)
            return self._p.createMultiBody(baseMass=mass, baseVisualShapeIndex=visual_shape_id, basePosition=position)

    def create_heightfield(self, size, height_max, position, resolution, repeats=2):
        heightfield_data = np.random.uniform(low=0., high=height_max, size=(int(size[0] * resolution / repeats), int(size[1] * resolution / repeats)))
        heightfield_data = np.repeat(np.repeat(heightfield_data, repeats, axis=0), repeats, axis=1)
        mesh_scale = [1/resolution, 1/resolution, 1.]
        heightfield_collision_shape_id = self._p.createCollisionShape(
            shapeType=self._p.GEOM_HEIGHTFIELD,
            meshScale=mesh_scale,
            heightfieldData=heightfield_data.reshape(-1),
            numHeightfieldRows=heightfield_data.shape[0],
            numHeightfieldColumns=heightfield_data.shape[1],
        )
        return self._p.createMultiBody(baseMass=0., baseCollisionShapeIndex=heightfield_collision_shape_id, basePosition=[position[0], position[1], position[2] + mesh_scale[2] * height_max / 2])

    def get_object_position(self, object_id):
        return np.asarray(self._p.getBasePositionAndOrientation(object_id)[0])

    def get_distance_to_object(self, object_id):
        object_position = self.get_object_position(object_id)
        robot_position = self.robot.links["base"].position
        return np.linalg.norm(object_position[:2] - robot_position[:2])

    def reset(self):
        observation = super().reset()

        # Reset boat position
        boat_y_init = np.random.uniform(low=-self.lava_size[1] / 2 + self.boat_size[1] / 2, high=self.lava_size[1] / 2 - self.boat_size[1] / 2)  # randomize y position
        self._p.resetBasePositionAndOrientation(self.boat_id, [self.boat_position_init[0], boat_y_init, self.boat_position_init[2]], [0., 0., 0., 1.])

        # Reset button position
        self._p.resetBasePositionAndOrientation(self.button_id, [self.button_position_init[0], boat_y_init, self.button_position_init[2]], [0., 0., 0., 1.])

        # Reset target zone
        target_zone_y = np.random.uniform(low=-self.lava_size[1] / 2 + self.target_zone_radius, high=self.lava_size[1] / 2 - self.target_zone_radius)  # randomize y position
        self.target_zone_position = [self.platform_end_position[0], target_zone_y, self.platform_end_position[2] + self.platform_size[2] / 2]
        self._p.resetBasePositionAndOrientation(self.target_zone_id, self.target_zone_position, [0., 0., 0., 1.])

        # Reset robot position
        self._p.resetBasePositionAndOrientation(self.robot.robot_id, [self.platform_start_position[0], self.platform_start_position[1], self.platform_start_position[2] + self.platform_size[2] / 2 + self.robot.links["base"].position_init[2]], self.robot.links["base"].orientation_init)

        return observation

    def step(self, action):
        # Before taking action
        self.distance_to_button = self.get_distance_to_object(self.button_id)
        self.distance_to_target_zone = self.get_distance_to_object(self.target_zone_id)
        self.has_touched_platform_end = len(self._p.getContactPoints(bodyA=self.robot.robot_id, bodyB=self.platform_end_id)) > 0

        observation, reward, terminated, truncated, info = super().step(action)

        # Check if button is pressed
        contact_points = self._p.getContactPoints(bodyA=self.robot.robot_id, bodyB=self.button_id)
        button_pressed = len(contact_points) > 0

        if button_pressed:
            # Move boat and everything on boat forward
            for body_id in [self.boat_id] + self.objects_on_boat:
                body_position = self.get_object_position(body_id)
                new_object_position = body_position + np.array([self.boat_speed * self.dt, 0., 0.])
                self._p.resetBasePositionAndOrientation(body_id, new_object_position, [0., 0., 0., 1.])

        return observation, reward, terminated, truncated, info

    def get_task_rewards(self, action):
        # After taking action
        new_distance_to_button = self.get_distance_to_object(self.button_id)
        new_distance_to_target_zone = self.get_distance_to_object(self.target_zone_id)

        # Survival
        survival = 1.

        # Reach button
        reach_button = (self.distance_to_button - new_distance_to_button) / self.dt

        # Reach target zone
        reach_target_zone = (self.distance_to_target_zone - new_distance_to_target_zone) / self.dt
        if self.distance_to_target_zone < self.target_zone_radius:
            reach_target_zone += 5.

        return {"survival": survival, "reach_button": reach_button, "reach_target_zone": reach_target_zone}

    def get_terminated(self, action):
        # Terminate if touch lava
        contact_points = self._p.getContactPoints(bodyA=self.robot.robot_id, bodyB=self.lava_id)
        is_touching_lava = len(contact_points) > 0

        # Terminate if fall off
        is_fall_off = self.robot.links["base"].position[2] < self.platform_start_position[2]
        return is_touching_lava or is_fall_off

    def get_success(self):
        # Success if stand in the target zone
        distance_to_target_zone = self.get_distance_to_object(self.target_zone_id)
        return distance_to_target_zone < self.target_zone_radius

</game/backend/env_codes/cross_lava.py>

<game/backend/env_codes/go_down_stairs.py>
import numpy as np
from omni_epic.envs.r2d2.base import R2D2Env


class Env(R2D2Env):
    """
    Descend a series of stairs to reach the ground.

    Description:
    - The environment consists of a ground platform (1000 m x 10 m x 10 m) and a set of 10 steps.
    - Each step has dimensions of 1 m in length, 10 m in width, and 0.2 m in height.
    - The steps are positioned to form a descending staircase starting from an initial height, with each subsequent step lower than the previous one.
    The robot is initialized at the top of the stairs.

    Success:
    The task is completed when the robot successfully descends the stairs and touches the ground platform.

    Rewards:
    The help the robot complete the task:
    - The robot is rewarded for survival at each time step.
    - The robot is rewarded for forward velocity, incentivizing it to move down the stairs.

    Termination:
    The task terminates immediately if the robot falls off the stairs or the ground platform.
    """

    def __init__(self):
        super().__init__()

        # Init ground
        self.ground_size = [1000., 10., 10.]
        self.ground_position = [0., 0., 0.]
        self.ground_id = self.create_box(mass=0., half_extents=[self.ground_size[0] / 2, self.ground_size[1] / 2, self.ground_size[2] / 2], position=self.ground_position, color=[0.5, 0.5, 0.5, 1.])
        self._p.changeDynamics(bodyUniqueId=self.ground_id, linkIndex=-1, lateralFriction=0.8, restitution=0.5)

        # Init stairs
        self.num_steps = 10
        self.step_size = [1.0, 10., 0.2]
        self.step_position_init = [self.ground_position[0], self.ground_position[1], self.ground_position[2] + self.ground_size[2] / 2 + self.num_steps * self.step_size[2]]
        self.create_stairs_down(step_size=self.step_size, step_position_init=self.step_position_init, num_steps=self.num_steps)

    def create_box(self, mass, half_extents, position, color):
        collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents)
        visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents, rgbaColor=color)
        return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position)

    def create_stairs_down(self, step_size, step_position_init, num_steps):
        color_1 = np.array([1., 0., 0.])
        color_2 = np.array([0., 0., 1.])
        for i in range(num_steps):
            step_position = [step_position_init[0] + i * step_size[0], step_position_init[1], step_position_init[2] - i * step_size[2]]
            interpolation = i / (num_steps - 1)
            step_color = (1 - interpolation) * color_1 + interpolation * color_2  # shade steps for visualization
            self.create_box(mass=0., half_extents=[step_size[0] / 2, step_size[1] / 2, step_size[2] / 2], position=step_position, color=np.append(step_color, 1.))

    def reset(self):
        observation = super().reset()

        # Reset robot position at the top of the stairs
        self._p.resetBasePositionAndOrientation(self.robot.robot_id, [self.step_position_init[0], self.step_position_init[1], self.step_position_init[2] + self.step_size[2] / 2 + self.robot.links["base"].position_init[2]], self.robot.links["base"].orientation_init)

        return observation

    def step(self, action):
        # Before taking action
        self.position = self.robot.links["base"].position

        observation, reward, terminated, truncated, info = super().step(action)

        return observation, reward, terminated, truncated, info

    def get_task_rewards(self, action):
        # After taking action
        new_position = self.robot.links["base"].position

        # Survival
        survival = 1.

        # Forward velocity
        forward_velocity = (new_position[0] - self.position[0]) / self.dt

        return {"survival": survival, "forward_velocity": forward_velocity}

    def get_terminated(self, action):
        # Terminate if fall off
        return self.robot.links["base"].position[2] < self.ground_position[2]

    def get_success(self):
        # Success if reach end stairs and touch ground
        contact_points = self._p.getContactPoints(bodyA=self.robot.robot_id, bodyB=self.ground_id)
        is_on_ground = len(contact_points) > 0
        return is_on_ground

</game/backend/env_codes/go_down_stairs.py>

<game/backend/env_codes/go_forward.py>
import numpy as np
from omni_epic.envs.r2d2.base import R2D2Env


class Env(R2D2Env):
    """
    Go forward.

    Description:
    The robot is standing on a flat ground represented by a box.
    The task of the robot is to go forward as fast as possible.

    Success:
    The task is completed if the robot runs forward for 10 meters.

    Rewards:
    The help the robot complete the task:
    - The robot is rewarded for survival at each time step.
    - The robot is rewarded for forward velocity, incentivizing it to move forward quickly.

    Termination:
    None.
    """

    def __init__(self):
        super().__init__()

        # Init ground
        self.ground_size = [1000., 1000., 10.]
        self.ground_position = [0., 0., 0.]
        self.ground_id = self.create_box(mass=0., half_extents=[self.ground_size[0] / 2, self.ground_size[1] / 2, self.ground_size[2] / 2], position=self.ground_position, color=[0.5, 0.5, 0.5, 1.])
        self._p.changeDynamics(bodyUniqueId=self.ground_id, linkIndex=-1, lateralFriction=0.8, restitution=0.5)

    def create_box(self, mass, half_extents, position, color):
        collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents)
        visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents, rgbaColor=color)
        return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position)

    def reset(self):
        observation = super().reset()

        # Reset robot position
        self._p.resetBasePositionAndOrientation(self.robot.robot_id, [self.ground_position[0], self.ground_position[1], self.ground_position[2] + self.ground_size[2] / 2 + self.robot.links["base"].position_init[2]], self.robot.links["base"].orientation_init)

        return observation

    def step(self, action):
        # Before taking action
        self.position = self.robot.links["base"].position

        observation, reward, terminated, truncated, info = super().step(action)

        return observation, reward, terminated, truncated, info

    def get_task_rewards(self, action):
        # After taking action
        new_position = self.robot.links["base"].position

        # Survival
        survival = 1.

        # Forward velocity
        forward_velocity = (new_position[0] - self.position[0]) / self.dt

        return {"survival": survival, "forward_velocity": forward_velocity}

    def get_terminated(self, action):
        # No termination
        return False

    def get_success(self):
        # Success if run forward for 10 meters
        return self.robot.links["base"].position[0] > 10.

</game/backend/env_codes/go_forward.py>

<game/backend/env_codes/go_to_box.py>
import numpy as np
from omni_epic.envs.r2d2.base import R2D2Env


class Env(R2D2Env):
    """
    Reach a box.

    Description:
    - The environment consists of a large flat ground measuring 1000 x 1000 x 10 meters.
    - A box with dimensions 1 x 1 x 1 meter is placed randomly on the ground in a radius of 25 m around the robot. To avoid collisions, the box cannot spawn in a radius of 2 m around the robot.
    - The robot is initialized at a fixed position on the ground.
    The task of the robot is to reach and touch the box.

    Success:
    The task is completed if the robot makes contact with the box.

    Rewards:
    To help the robot complete the task:
    - The robot is rewarded for survival.
    - The robot is rewarded for moving closer to the box.

    Termination:
    None.
    """

    def __init__(self):
        super().__init__()

        # Init ground
        self.ground_size = [1000., 1000., 10.]
        self.ground_position = [0., 0., 0.]
        self.ground_id = self.create_box(mass=0., half_extents=[self.ground_size[0] / 2, self.ground_size[1] / 2, self.ground_size[2] / 2], position=self.ground_position, color=[0.5, 0.5, 0.5, 1.])
        self._p.changeDynamics(bodyUniqueId=self.ground_id, linkIndex=-1, lateralFriction=0.8, restitution=0.5)

        # Init box
        self.box_size = [1., 1., 1.]
        self.box_id = self.create_box(mass=1., half_extents=[self.box_size[0] / 2, self.box_size[1] / 2, self.box_size[2] / 2], position=[0., 0., 0.], color=[1., 0., 0., 1.])

        # Starting position of the robot
        self.robot_position_init = [self.ground_position[0], self.ground_position[1], self.ground_position[2] + self.ground_size[2] / 2 + self.robot.links["base"].position_init[2]]

    def create_box(self, mass, half_extents, position, color):
        collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents)
        visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents, rgbaColor=color)
        return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position)

    def get_object_position(self, object_id):
        return np.asarray(self._p.getBasePositionAndOrientation(object_id)[0])

    def get_distance_to_object(self, object_id):
        object_position = self.get_object_position(object_id)
        robot_position = self.robot.links["base"].position
        return np.linalg.norm(object_position[:2] - robot_position[:2])

    def reset(self):
        observation = super().reset()

        # Reset robot position on ground
        self._p.resetBasePositionAndOrientation(self.robot.robot_id, self.robot_position_init, self.robot.links["base"].orientation_init)

        # Reset box position
        angle = np.random.uniform(0., 2 * np.pi)
        radius = np.random.uniform(2., 25.)
        self._p.resetBasePositionAndOrientation(self.box_id, [self.robot_position_init[0] + radius * np.cos(angle), self.robot_position_init[1] + radius * np.sin(angle), self.ground_position[2] + self.ground_size[2] / 2 + self.box_size[2] / 2], [0., 0., 0., 1.])

        return observation

    def step(self, action):
        # Before taking action
        self.distance_to_box = self.get_distance_to_object(self.box_id)

        observation, reward, terminated, truncated, info = super().step(action)

        return observation, reward, terminated, truncated, info

    def get_task_rewards(self, action):
        # After taking action
        new_distance_to_box = self.get_distance_to_object(self.box_id)

        # Survival
        survival = 1.

        # Reach box
        reach_box = (self.distance_to_box - new_distance_to_box) / self.dt

        return {"survival": survival, "reach_box": reach_box}

    def get_terminated(self, action):
        # No termination
        return False

    def get_success(self):
        # Success if touch box
        contact_points_box = self._p.getContactPoints(bodyA=self.robot.robot_id, bodyB=self.box_id)
        is_touching_box = len(contact_points_box) > 0
        return is_touching_box

</game/backend/env_codes/go_to_box.py>

<game/backend/env_codes/kick_ball.py>
import numpy as np
from omni_epic.envs.r2d2.base import R2D2Env


class Env(R2D2Env):
    """
    Kick a ball.

    Description:
    - The environment consists of a large flat ground measuring 1000 x 1000 x 10 meters.
    - A ball with a radius of 0.5 meters is placed randomly on the ground.
    - The robot is initialized at a fixed position on the ground.
    - The task of the robot is to move across the ground, reach the ball, and kick it as far away as possible.

    Success:
    The task is successfully completed if the robot kicks the ball so that it moves more than 10 meters away from its initial position.

    Rewards:
    To help the robot complete the task:
    - The robot is rewarded for survival.
    - The robot is rewarded for decreasing its distance to the ball.
    - The robot is rewarded for increasing the velocity of the ball to guide the robot to kick the ball.

    Termination:
    The task does not have a specific termination condition.
    """

    def __init__(self):
        super().__init__()

        # Init ground
        self.ground_size = [1000., 1000., 10.]
        self.ground_position = [0., 0., 0.]
        self.ground_id = self.create_box(mass=0., half_extents=[self.ground_size[0] / 2, self.ground_size[1] / 2, self.ground_size[2] / 2], position=self.ground_position, color=[0.5, 0.5, 0.5, 1.])
        self._p.changeDynamics(bodyUniqueId=self.ground_id, linkIndex=-1, lateralFriction=0.8, restitution=0.5)

        # Init ball
        self.ball_radius = 0.5
        self.ball_id = self.create_sphere(mass=1., radius=self.ball_radius, position=[0., 0., 0.], color=[1., 0., 0., 1.])

        # Starting position of the robot
        self.robot_position_init = [self.ground_position[0], self.ground_position[1], self.ground_position[2] + self.ground_size[2] / 2 + self.robot.links["base"].position_init[2]]

    def create_box(self, mass, half_extents, position, color):
        collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents)
        visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents, rgbaColor=color)
        return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position)

    def create_sphere(self, mass, radius, position, color):
        collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_SPHERE, radius=radius)
        visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_SPHERE, radius=radius, rgbaColor=color)
        return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position)

    def get_object_position(self, object_id):
        return np.asarray(self._p.getBasePositionAndOrientation(object_id)[0])

    def get_distance_to_object(self, object_id):
        object_position = self.get_object_position(object_id)
        robot_position = self.robot.links["base"].position
        return np.linalg.norm(object_position[:2] - robot_position[:2])

    def reset(self):
        observation = super().reset()

        # Reset robot position on ground
        self._p.resetBasePositionAndOrientation(self.robot.robot_id, self.robot_position_init, self.robot.links["base"].orientation_init)

        # Reset ball position
        ball_y_init = np.random.uniform(self.robot_position_init[1] - 2., self.robot_position_init[1] + 2.)
        self._p.resetBasePositionAndOrientation(self.ball_id, [self.robot_position_init[0] + 5., ball_y_init, self.ground_position[2] + self.ground_size[2] / 2 + self.ball_radius], [0., 0., 0., 1.])

        return observation

    def step(self, action):
        # Before taking action
        self.distance_to_ball = self.get_distance_to_object(self.ball_id)
        self.ball_position = self.get_object_position(self.ball_id)

        observation, reward, terminated, truncated, info = super().step(action)

        return observation, reward, terminated, truncated, info

    def get_task_rewards(self, action):
        # After taking action
        new_distance_to_ball = self.get_distance_to_object(self.ball_id)
        new_ball_position = self.get_object_position(self.ball_id) 

        # Survival
        survival = 1.

        # Reach ball
        reach_ball = (self.distance_to_ball - new_distance_to_ball) / self.dt

        # Velocity of ball
        ball_velocity = np.linalg.norm(new_ball_position - self.ball_position) / self.dt

        return {"survival": survival, "reach_ball": reach_ball, "ball_velocity": ball_velocity}

    def get_terminated(self, action):
        # No termination
        return False

    def get_success(self):
        # Success if kick ball 10 meters away from origin
        ball_distance_to_origin = np.linalg.norm(self.get_object_position(self.ball_id))
        return ball_distance_to_origin > 10.

</game/backend/env_codes/kick_ball.py>

<game/backend/env_codes/maze.py>
import numpy as np
from omni_epic.envs.r2d2.base import R2D2Env


class Env(R2D2Env):
    """
    Navigate through a maze to reach the end position.

    Description:
    - The environment consists of a large flat ground measuring 1000 x 1000 x 10 m.
    - A maze is constructed on the ground using walls of height 1 meter and scale 3 m per cell.
    - The maze is represented by a 2D array where 0 indicates an empty space, 1 indicates a wall, 2 indicates the start position, and 3 indicates the end position.
    - The robot is initialized at the start position in the maze.
    - The task of the robot is to navigate through the maze and reach the end position.

    Success:
    The task is completed if the robot reaches the end position in the maze.

    Rewards:
    To guide the robot to complete the task:
    - The robot receives a reward at each time step for survival.
    - The robot is rewarded for making progress towards the end position in the maze.

    Termination:
    The task does not have a specific termination condition and continues until the robot successfully reaches the end position.
    """

    def __init__(self):
        super().__init__()

        # Init ground
        self.ground_size = [1000., 1000., 10.]
        self.ground_position = [0., 0., 0.]
        self.ground_id = self.create_box(mass=0., half_extents=[self.ground_size[0] / 2, self.ground_size[1] / 2, self.ground_size[2] / 2], position=self.ground_position, color=[0.5, 0.5, 0.5, 1.])
        self._p.changeDynamics(bodyUniqueId=self.ground_id, linkIndex=-1, lateralFriction=0.8, restitution=0.5)

        # Init maze - 0 is empty, 1 is wall, 2 is start, 3 is end
        self.maze_height = 1.
        self.maze_scale = 3.
        maze = np.array([
            [1, 1, 1, 3, 1, 1],
            [1, 0, 0, 0, 0, 1],
            [1, 0, 1, 1, 0, 1],
            [2, 0, 0, 0, 0, 1],
            [1, 1, 1, 1, 1, 1],
        ])
        for index, value in np.ndenumerate(maze):
                if value == 1:
                    self.create_box(0., half_extents=[self.maze_scale / 2, self.maze_scale / 2, self.maze_height / 2], position=[self.maze_scale * index[1], -self.maze_scale * index[0], self.ground_position[2] + self.ground_size[2] / 2 + self.maze_height / 2], color=[0.2, 0.2, 0.2, 1])

        # Get start and end position
        start_position_index = np.squeeze(np.argwhere(maze == 2))
        self.start_position = self.maze_scale * np.array([start_position_index[1], -start_position_index[0]])
        end_position_index = np.squeeze(np.argwhere(maze == 3))
        self.end_position = self.maze_scale * np.array([end_position_index[1], -end_position_index[0]])

    def create_box(self, mass, half_extents, position, color):
        collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents)
        visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents, rgbaColor=color)
        return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position)

    def reset(self):
        observation = super().reset()

        # Reset robot position at start position
        self._p.resetBasePositionAndOrientation(self.robot.robot_id, [self.start_position[0], self.start_position[1], self.ground_position[2] + self.ground_size[2] / 2 + self.robot.links["base"].position_init[2]], self.robot.links["base"].orientation_init)

        return observation

    def step(self, action):
        # Before taking action
        self.position = self.robot.links["base"].position
        self.distance_to_end = np.linalg.norm(self.position[:2] - self.end_position)

        observation, reward, terminated, truncated, info = super().step(action)

        return observation, reward, terminated, truncated, info

    def get_task_rewards(self, action):
        # After taking action
        new_position = self.robot.links["base"].position
        new_distance_to_end = np.linalg.norm(new_position[:2] - self.end_position)

        # Survival
        survival = 1.

        # Progress in the maze
        maze_progress = (self.distance_to_end - new_distance_to_end) / self.dt

        return {"survival": survival, "maze_progress": maze_progress}

    def get_terminated(self, action):
        # No termination
        return False

    def get_success(self):
        # Success if reach end of maze
        return np.linalg.norm(self.robot.links["base"].position[:2] - self.end_position) < self.maze_scale

</game/backend/env_codes/maze.py>

<game/backend/env_codes/open_door.py>
import numpy as np
from omni_epic.envs.r2d2.base import R2D2Env


class Env(R2D2Env):
    """
    Activate a lever to open a door and move through the door.

    Description:
    - The environment consists of a large platform measuring 1000 x 10 x 0.1 meters.
    - The robot is initialized at a fixed position on the platform.
    - A door with dimensions 0.5 x 2 x 2 meters is placed on the platform, 5 m away from the robot, initially closed.
    - The door is flanked by walls to prevent the robot from bypassing it.
    - A lever is placed on the platform, 2 meters to the left of the door.
    - The task of the robot is to move to the lever, activate it to open the door, and then pass through the door.

    Success:
    The task is successfully completed if the robot passes through the door and moves more than 10 m beyond the initial position.

    Rewards:
    To guide the robot to complete the task:
    - The robot receives a survival reward at each time step.
    - The robot is rewarded for decreasing its distance to the lever.
    - The robot receives a bonus rewards for activating the lever to open the door.
    - Once the door is open, the robot is rewarded for moving forward.

    Termination:
    The task terminates immediately if the robot falls off the stairs or the ground platform.
    """

    def __init__(self):
        super().__init__()

        self.robot_position_init = [0., 0., 0.]

        # Init platform
        self.platform_size = [1000., 10., 0.1]
        self.platform_position = [self.robot_position_init[0] + self.platform_size[0] / 2 - 2., self.robot_position_init[1], self.robot_position_init[2] - self.platform_size[2] / 2]  # offset by 2 m to avoid off-edge or on-edge placement
        self.platform_id = self.create_box(mass=0., half_extents=[self.platform_size[0] / 2, self.platform_size[1] / 2, self.platform_size[2] / 2], position=self.platform_position, color=[0.5, 0.5, 0.5, 1.])
        self._p.changeDynamics(bodyUniqueId=self.platform_id, linkIndex=-1, lateralFriction=0.8, restitution=0.5)

        # Init door
        self.door_size = [0.5, 2., 2.]
        self.door_position_init = [self.robot_position_init[0] + 5., self.platform_position[1], self.platform_position[2] + self.platform_size[2] / 2 + self.door_size[2] / 2]
        self.door_id = self.create_box(mass=0., half_extents=[self.door_size[0] / 2, self.door_size[1] / 2, self.door_size[2] / 2], position=self.door_position_init, color=[1., 0., 0., 1.])
        self.door_open = False

        # Init wall
        self.wall_size = [self.door_size[0], (self.platform_size[1] - self.door_size[1]) / 2, self.door_size[2]]  # walls plus door span the full platform to prevent robot to go around
        self.create_box(mass=0., half_extents=[self.wall_size[0] / 2, self.wall_size[1] / 2, self.wall_size[2] / 2], position=[self.door_position_init[0], self.door_position_init[1] + self.door_size[1] / 2 + self.wall_size[1] / 2, self.platform_position[2] + self.platform_size[2] / 2 + self.wall_size[2] / 2], color=[0., 0., 1., 1.])  # left section
        self.create_box(mass=0., half_extents=[self.wall_size[0] / 2, self.wall_size[1] / 2, self.wall_size[2] / 2], position=[self.door_position_init[0], self.door_position_init[1] - self.door_size[1] / 2 - self.wall_size[1] / 2, self.platform_position[2] + self.platform_size[2] / 2 + self.wall_size[2] / 2], color=[0., 0., 1., 1.])  # right section

        # Init lever
        self.lever_radius = 0.05
        self.lever_height = 0.5
        lever_position = [self.door_position_init[0] - 2., self.door_size[1], self.platform_position[2] + self.platform_size[2] / 2 + self.lever_height / 2]  # two meters to the left of the door on the platform
        self.lever_id = self.create_cylinder(mass=0., radius=self.lever_radius, height=self.lever_height, position=lever_position, color=[0.5, 0.25, 0., 1.])

    def create_box(self, mass, half_extents, position, color):
        collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents)
        visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents, rgbaColor=color)
        return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position)

    def create_cylinder(self, mass, radius, height, position, color):
        collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_CYLINDER, radius=radius, height=height)
        visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_CYLINDER, radius=radius, length=height, rgbaColor=color)
        return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position)

    def get_object_position(self, object_id):
        return np.asarray(self._p.getBasePositionAndOrientation(object_id)[0])

    def get_distance_to_object(self, object_id):
        object_position = self.get_object_position(object_id)
        robot_position = self.robot.links["base"].position
        return np.linalg.norm(object_position[:2] - robot_position[:2])

    def reset(self):
        observation = super().reset()

        # Reset door
        self.door_open = False
        self._p.resetBasePositionAndOrientation(self.door_id, self.door_position_init, [0., 0., 0., 1.])

        # Reset robot position
        self._p.resetBasePositionAndOrientation(self.robot.robot_id, [self.robot_position_init[0], self.robot_position_init[1], self.robot_position_init[2] + self.robot.links["base"].position_init[2]], self.robot.links["base"].orientation_init)

        return observation

    def step(self, action):
        # Before taking action
        self.position = self.robot.links["base"].position
        self.distance_to_lever = self.get_distance_to_object(self.lever_id)

        observation, reward, terminated, truncated, info = super().step(action)

        contact_points = self._p.getContactPoints(bodyA=self.robot.robot_id, bodyB=self.lever_id)
        if len(contact_points) > 0 and not self.door_open:
            self.door_open = True
            self._p.resetBasePositionAndOrientation(self.door_id, [self.door_position_init[0], self.door_position_init[1] + self.door_size[1], self.door_position_init[2]], [0., 0., 0., 1.])

        return observation, reward, terminated, truncated, info

    def get_task_rewards(self, action):
        # After taking action
        new_position = self.robot.links["base"].position
        new_distance_to_lever = self.get_distance_to_object(self.lever_id)

        # Survival
        survival = 1.

        # Reach lever
        if not self.door_open and len(self._p.getContactPoints(bodyA=self.robot.robot_id, bodyB=self.lever_id)) == 0:
            reach_lever = (self.distance_to_lever - new_distance_to_lever) / self.dt
        elif not self.door_open and len(self._p.getContactPoints(bodyA=self.robot.robot_id, bodyB=self.lever_id)) > 0:
            reach_lever = 10.
        else:
            reach_lever = 0.

        # Forward velocity
        if self.door_open:
            forward_velocity = (new_position[0] - self.position[0]) / self.dt
        else:
            forward_velocity = 0.

        return {"survival": survival, "reach_lever": reach_lever, "forward_velocity": forward_velocity}

    def get_terminated(self, action):
        # Terminate if fall off
        return self.robot.links["base"].position[2] < self.platform_position[2]

    def get_success(self):
        # Success if pass through door
        return self.robot.links["base"].position[0] > 10.

</game/backend/env_codes/open_door.py>

<game/backend/requirements.txt>
absl-py==2.1.0
annotated-types==0.6.0
anthropic==0.25.6
antlr4-python3-runtime==4.9.3
anyio==4.3.0
appdirs==1.4.4
appnope==0.1.4
asttokens==2.4.1
astunparse==1.6.3
beautifulsoup4==4.12.3
bidict==0.23.1
blinker==1.7.0
brax==0.10.3
cachetools==5.3.3
certifi==2024.2.2
charset-normalizer==3.3.2
chex==0.1.86
click==8.1.7
cloudpickle==3.0.0
comm==0.2.2
contextlib2==21.6.0
contourpy==1.2.1
cycler==0.12.1
debugpy==1.8.1
decorator==4.4.2
distrax==0.1.5
distro==1.9.0
dm-env==1.6
dm-tree==0.1.8
dnspython==2.6.1
docker-pycreds==0.4.0
etils==1.7.0
eventlet==0.36.1
exceptiongroup==1.2.1
executing==2.0.1
filelock==3.13.4
flashbax==0.1.2
Flask==3.0.3
Flask-Cors==4.0.0
Flask-SocketIO==5.3.6
flax==0.8.2
fonttools==4.51.0
fsspec==2024.3.1
gast==0.5.4
gdown==4.6.3
gitdb==4.0.11
GitPython==3.1.43
glfw==2.7.0
google-ai-generativelanguage==0.6.2
google-api-core==2.18.0
google-api-python-client==2.126.0
google-auth==2.29.0
google-auth-httplib2==0.2.0
google-generativeai==0.5.2
googleapis-common-protos==1.63.0
greenlet==3.0.3
grpcio==1.62.2
grpcio-status==1.62.2
gym==0.26.2
gym-notices==0.0.8
h11==0.14.0
httpcore==1.0.5
httplib2==0.22.0
httpx==0.27.0
huggingface-hub==0.22.2
hydra-core==1.3.2
idna==3.7
imageio==2.34.0
imageio-ffmpeg==0.4.9
importlib_resources==6.4.0
ipykernel==6.29.4
ipython==8.23.0
itsdangerous==2.2.0
jax==0.4.26
jaxlib==0.4.26
jaxopt==0.8.3
jedi==0.19.1
Jinja2==3.1.3
joblib==1.4.0
jupyter_client==8.6.1
jupyter_core==5.7.2
kiwisolver==1.4.5
markdown-it-py==3.0.0
MarkupSafe==2.1.5
matplotlib==3.8.4
matplotlib-inline==0.1.7
mdurl==0.1.2
mediapy==1.2.0
ml-collections==0.1.1
ml-dtypes==0.4.0
moviepy==1.0.3
msgpack==1.0.8
mujoco==3.1.4
mujoco-mjx==3.1.4
nest-asyncio==1.6.0
numpy==1.26.4
omegaconf==2.3.0
openai==1.23.1
opencv-python==4.9.0.80
opt-einsum==3.3.0
optax==0.2.2
orbax-checkpoint==0.5.9
packaging==24.0
pandas==2.2.2
parso==0.8.4
patsy==0.5.6
pexpect==4.9.0
pillow==10.3.0
platformdirs==4.2.0
proglog==0.1.10
prompt-toolkit==3.0.43
proto-plus==1.23.0
protobuf==4.25.3
psutil==5.9.8
ptyprocess==0.7.0
pure-eval==0.2.2
pyasn1==0.6.0
pyasn1_modules==0.4.0
pybullet==3.2.6
pydantic==2.7.0
pydantic_core==2.18.1
Pygments==2.17.2
PyOpenGL==3.1.7
pyparsing==3.1.2
PySocks==1.7.1
python-dateutil==2.9.0.post0
python-engineio==4.9.0
python-socketio==5.11.2
pytinyrenderer==0.0.14
pytz==2024.1
PyYAML==6.0.1
pyzmq==26.0.1
requests==2.31.0
rich==13.7.1
rsa==4.9
ruamel.yaml==0.18.6
ruamel.yaml.clib==0.2.8
scikit-learn==1.4.2
scipy==1.13.0
seaborn==0.13.2
sentry-sdk==1.45.0
setproctitle==1.3.3
shapely==2.0.4
simple-websocket==1.0.0
six==1.16.0
smmap==5.0.1
sniffio==1.3.1
soupsieve==2.5
stack-data==0.6.3
statsmodels==0.14.2
tensorboardX==2.6.2.2
tensorflow-probability==0.24.0
tensorstore==0.1.56
threadpoolctl==3.4.0
tokenizers==0.19.1
toolz==0.12.1
tornado==6.4
tqdm==4.66.2
traitlets==5.14.3
trimesh==4.3.1
typing_extensions==4.11.0
tzdata==2024.1
uritemplate==4.1.1
urllib3==2.2.1
uvicorn==0.29.0
wandb==0.16.6
wcwidth==0.2.13
Werkzeug==3.0.2
wsproto==1.2.0
zipp==3.18.1

</game/backend/requirements.txt>

<game/backend/templates/index.html>
<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>R2D2 Run Game</title>
<script src="https://cdnjs.cloudflare.com/ajax/libs/socket.io/4.0.0/socket.io.js"></script>
<style>
    #gameDisplay {
        display: flex;
        justify-content: space-between;
        align-items: center;
    }
    #videoContainer {
        position: relative;
        width: 640px;
        height: 480px;
    }
    #envDescription, #recordingStatus {
        width: 200px;
        padding: 15px;
        background-color: #f0f0f0;
        border: 1px solid #ddd;
        font-size: 16px;
        text-align: center;
    }
    button {
        margin: 5px;
        padding: 10px 20px;
        font-size: 16px;
    }
    #status {
        margin-top: 20px;
        font-size: 20px;
        color: green;
    }
</style>
<script type="text/javascript">
    document.addEventListener('DOMContentLoaded', function() {
        var socket = io.connect(location.protocol + '//' + document.domain + ':' + location.port);
        var recordButton = document.getElementById('recordButton');

        document.addEventListener('keydown', function(event) {
            let action = null;
            if (event.keyCode === 38) {  // Up arrow
                action = 1;
            } else if (event.keyCode === 40) {  // Down arrow
                action = 2;
            } else if (event.keyCode === 39) {  // Right arrow
                action = 3;
            } else if (event.keyCode === 37) {  // Left arrow
                action = 4;
            } else if (event.keyCode === 32) {  // Space bar
                action = 5;
            }
            if (action !== null) {
                socket.emit('action', {action: action});
            }
        });

        document.getElementById('resetButton').addEventListener('click', function() {
            socket.emit('reset');
        });

        document.getElementById('nextLevelButton').addEventListener('click', function() {
            socket.emit('next_level');
            document.getElementById('status').textContent = "Generating next level...";
        });

        document.getElementById('markSuccessButton').addEventListener('click', function() {
            socket.emit('mark_success');
            document.getElementById('status').textContent = "Success Marked!";
        });

        recordButton.addEventListener('click', function() {
            if (this.textContent === "Record Actions") {
                this.textContent = "Stop Recording";
                socket.emit('start_recording');
                document.getElementById('recordingStatus').textContent = "Recording...";
            } else {
                this.textContent = "Record Actions";
                socket.emit('stop_recording');
            }
        });

        socket.on('not_recording_status', function() {
            recordButton.textContent = "Record Actions";
            document.getElementById('recordingStatus').textContent = "Not Recording";
        });

        socket.on('connected_message', function(data) {
            document.getElementById('status').textContent = data.message;
        });

        socket.on('reset_message', function(data) {
            document.getElementById('status').textContent = data.message;
        });

        socket.on('next_level_message', function(data) {
            document.getElementById('status').textContent = data.message;
        });

        socket.on('level_complete', function(data) {
            document.getElementById('status').textContent = data.message;
        });

        socket.on('env_description', function(data) {
            document.getElementById('envDescription').textContent = "Task: " + data.description;
        });

        socket.on('reward_update', function(data) {
            var formattedReward = parseFloat(data.reward).toFixed(1);
            document.getElementById('rewardDisplay').textContent = "Current Reward: " + formattedReward;
        });

        socket.on('success_marked', function(data) {
            document.getElementById('status').textContent = data.message;
        });
    });
</script>
</head>
<body>
<h1>R2D2 Run Game Streaming</h1>
<div id="gameDisplay">
    <div id="videoContainer">
        <img src="{{ url_for('video_feed') }}" alt="Game Stream" style="width:90%;">
    </div>
    <div id="rewardDisplay">Current Reward: 0</div>
    <div id="envDescription"></div>
</div>
<button id="resetButton">Reset Level</button>
<button id="nextLevelButton">Next Level</button>
<button id="recordButton">Record Actions</button>
<button id="markSuccessButton">Mark Success</button>
<div id="status"></div>
<div id="recordingStatus">Not Recording</div>
</body>
</html>

</game/backend/templates/index.html>

<game/frontend/components.json>
{
  "$schema": "https://ui.shadcn.com/schema.json",
  "style": "default",
  "rsc": true,
  "tsx": true,
  "tailwind": {
    "config": "tailwind.config.ts",
    "css": "src/app/globals.css",
    "baseColor": "slate",
    "cssVariables": false
  },
  "aliases": {
    "components": "@/components",
    "utils": "@/lib/utils"
  }
}
</game/frontend/components.json>

<game/frontend/package-lock.json>
{
  "name": "game",
  "version": "0.1.0",
  "lockfileVersion": 3,
  "requires": true,
  "packages": {
    "": {
      "name": "game",
      "version": "0.1.0",
      "dependencies": {
        "next": "14.2.2",
        "react": "^18",
        "react-dom": "^18"
      },
      "devDependencies": {
        "@types/node": "^20",
        "@types/react": "^18",
        "@types/react-dom": "^18",
        "eslint": "^8",
        "eslint-config-next": "14.2.2",
        "postcss": "^8",
        "tailwindcss": "^3.4.1",
        "typescript": "^5"
      }
    },
    "node_modules/@aashutoshrathi/word-wrap": {
      "version": "1.2.6",
      "resolved": "https://registry.npmjs.org/@aashutoshrathi/word-wrap/-/word-wrap-1.2.6.tgz",
      "integrity": "sha512-1Yjs2SvM8TflER/OD3cOjhWWOZb58A2t7wpE2S9XfBYTiIl+XFhQG2bjy4Pu1I+EAlCNUzRDYDdFwFYUKvXcIA==",
      "dev": true,
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/@alloc/quick-lru": {
      "version": "5.2.0",
      "resolved": "https://registry.npmjs.org/@alloc/quick-lru/-/quick-lru-5.2.0.tgz",
      "integrity": "sha512-UrcABB+4bUrFABwbluTIBErXwvbsU/V7TZWfmbgJfbkwiBuziS9gxdODUyuiecfdGQ85jglMW6juS3+z5TsKLw==",
      "dev": true,
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/@babel/runtime": {
      "version": "7.24.4",
      "resolved": "https://registry.npmjs.org/@babel/runtime/-/runtime-7.24.4.tgz",
      "integrity": "sha512-dkxf7+hn8mFBwKjs9bvBlArzLVxVbS8usaPUDd5p2a9JCL9tB8OaOVN1isD4+Xyk4ns89/xeOmbQvgdK7IIVdA==",
      "dev": true,
      "dependencies": {
        "regenerator-runtime": "^0.14.0"
      },
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@eslint-community/eslint-utils": {
      "version": "4.4.0",
      "resolved": "https://registry.npmjs.org/@eslint-community/eslint-utils/-/eslint-utils-4.4.0.tgz",
      "integrity": "sha512-1/sA4dwrzBAyeUoQ6oxahHKmrZvsnLCg4RfxW3ZFGGmQkSNQPFNLV9CUEFQP1x9EYXHTo5p6xdhZM1Ne9p/AfA==",
      "dev": true,
      "dependencies": {
        "eslint-visitor-keys": "^3.3.0"
      },
      "engines": {
        "node": "^12.22.0 || ^14.17.0 || >=16.0.0"
      },
      "peerDependencies": {
        "eslint": "^6.0.0 || ^7.0.0 || >=8.0.0"
      }
    },
    "node_modules/@eslint-community/regexpp": {
      "version": "4.10.0",
      "resolved": "https://registry.npmjs.org/@eslint-community/regexpp/-/regexpp-4.10.0.tgz",
      "integrity": "sha512-Cu96Sd2By9mCNTx2iyKOmq10v22jUVQv0lQnlGNy16oE9589yE+QADPbrMGCkA51cKZSg3Pu/aTJVTGfL/qjUA==",
      "dev": true,
      "engines": {
        "node": "^12.0.0 || ^14.0.0 || >=16.0.0"
      }
    },
    "node_modules/@eslint/eslintrc": {
      "version": "2.1.4",
      "resolved": "https://registry.npmjs.org/@eslint/eslintrc/-/eslintrc-2.1.4.tgz",
      "integrity": "sha512-269Z39MS6wVJtsoUl10L60WdkhJVdPG24Q4eZTH3nnF6lpvSShEK3wQjDX9JRWAUPvPh7COouPpU9IrqaZFvtQ==",
      "dev": true,
      "dependencies": {
        "ajv": "^6.12.4",
        "debug": "^4.3.2",
        "espree": "^9.6.0",
        "globals": "^13.19.0",
        "ignore": "^5.2.0",
        "import-fresh": "^3.2.1",
        "js-yaml": "^4.1.0",
        "minimatch": "^3.1.2",
        "strip-json-comments": "^3.1.1"
      },
      "engines": {
        "node": "^12.22.0 || ^14.17.0 || >=16.0.0"
      },
      "funding": {
        "url": "https://opencollective.com/eslint"
      }
    },
    "node_modules/@eslint/js": {
      "version": "8.57.0",
      "resolved": "https://registry.npmjs.org/@eslint/js/-/js-8.57.0.tgz",
      "integrity": "sha512-Ys+3g2TaW7gADOJzPt83SJtCDhMjndcDMFVQ/Tj9iA1BfJzFKD9mAUXT3OenpuPHbI6P/myECxRJrofUsDx/5g==",
      "dev": true,
      "engines": {
        "node": "^12.22.0 || ^14.17.0 || >=16.0.0"
      }
    },
    "node_modules/@humanwhocodes/config-array": {
      "version": "0.11.14",
      "resolved": "https://registry.npmjs.org/@humanwhocodes/config-array/-/config-array-0.11.14.tgz",
      "integrity": "sha512-3T8LkOmg45BV5FICb15QQMsyUSWrQ8AygVfC7ZG32zOalnqrilm018ZVCw0eapXux8FtA33q8PSRSstjee3jSg==",
      "dev": true,
      "dependencies": {
        "@humanwhocodes/object-schema": "^2.0.2",
        "debug": "^4.3.1",
        "minimatch": "^3.0.5"
      },
      "engines": {
        "node": ">=10.10.0"
      }
    },
    "node_modules/@humanwhocodes/module-importer": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/@humanwhocodes/module-importer/-/module-importer-1.0.1.tgz",
      "integrity": "sha512-bxveV4V8v5Yb4ncFTT3rPSgZBOpCkjfK0y4oVVVJwIuDVBRMDXrPyXRL988i5ap9m9bnyEEjWfm5WkBmtffLfA==",
      "dev": true,
      "engines": {
        "node": ">=12.22"
      },
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/nzakas"
      }
    },
    "node_modules/@humanwhocodes/object-schema": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/@humanwhocodes/object-schema/-/object-schema-2.0.3.tgz",
      "integrity": "sha512-93zYdMES/c1D69yZiKDBj0V24vqNzB/koF26KPaagAfd3P/4gUlh3Dys5ogAK+Exi9QyzlD8x/08Zt7wIKcDcA==",
      "dev": true
    },
    "node_modules/@isaacs/cliui": {
      "version": "8.0.2",
      "resolved": "https://registry.npmjs.org/@isaacs/cliui/-/cliui-8.0.2.tgz",
      "integrity": "sha512-O8jcjabXaleOG9DQ0+ARXWZBTfnP4WNAqzuiJK7ll44AmxGKv/J2M4TPjxjY3znBCfvBXFzucm1twdyFybFqEA==",
      "dev": true,
      "dependencies": {
        "string-width": "^5.1.2",
        "string-width-cjs": "npm:string-width@^4.2.0",
        "strip-ansi": "^7.0.1",
        "strip-ansi-cjs": "npm:strip-ansi@^6.0.1",
        "wrap-ansi": "^8.1.0",
        "wrap-ansi-cjs": "npm:wrap-ansi@^7.0.0"
      },
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@isaacs/cliui/node_modules/ansi-regex": {
      "version": "6.0.1",
      "resolved": "https://registry.npmjs.org/ansi-regex/-/ansi-regex-6.0.1.tgz",
      "integrity": "sha512-n5M855fKb2SsfMIiFFoVrABHJC8QtHwVx+mHWP3QcEqBHYienj5dHSgjbxtC0WEZXYt4wcD6zrQElDPhFuZgfA==",
      "dev": true,
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/chalk/ansi-regex?sponsor=1"
      }
    },
    "node_modules/@isaacs/cliui/node_modules/strip-ansi": {
      "version": "7.1.0",
      "resolved": "https://registry.npmjs.org/strip-ansi/-/strip-ansi-7.1.0.tgz",
      "integrity": "sha512-iq6eVVI64nQQTRYq2KtEg2d2uU7LElhTJwsH4YzIHZshxlgZms/wIc4VoDQTlG/IvVIrBKG06CrZnp0qv7hkcQ==",
      "dev": true,
      "dependencies": {
        "ansi-regex": "^6.0.1"
      },
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/chalk/strip-ansi?sponsor=1"
      }
    },
    "node_modules/@jridgewell/gen-mapping": {
      "version": "0.3.5",
      "resolved": "https://registry.npmjs.org/@jridgewell/gen-mapping/-/gen-mapping-0.3.5.tgz",
      "integrity": "sha512-IzL8ZoEDIBRWEzlCcRhOaCupYyN5gdIK+Q6fbFdPDg6HqX6jpkItn7DFIpW9LQzXG6Df9sA7+OKnq0qlz/GaQg==",
      "dev": true,
      "dependencies": {
        "@jridgewell/set-array": "^1.2.1",
        "@jridgewell/sourcemap-codec": "^1.4.10",
        "@jridgewell/trace-mapping": "^0.3.24"
      },
      "engines": {
        "node": ">=6.0.0"
      }
    },
    "node_modules/@jridgewell/resolve-uri": {
      "version": "3.1.2",
      "resolved": "https://registry.npmjs.org/@jridgewell/resolve-uri/-/resolve-uri-3.1.2.tgz",
      "integrity": "sha512-bRISgCIjP20/tbWSPWMEi54QVPRZExkuD9lJL+UIxUKtwVJA8wW1Trb1jMs1RFXo1CBTNZ/5hpC9QvmKWdopKw==",
      "dev": true,
      "engines": {
        "node": ">=6.0.0"
      }
    },
    "node_modules/@jridgewell/set-array": {
      "version": "1.2.1",
      "resolved": "https://registry.npmjs.org/@jridgewell/set-array/-/set-array-1.2.1.tgz",
      "integrity": "sha512-R8gLRTZeyp03ymzP/6Lil/28tGeGEzhx1q2k703KGWRAI1VdvPIXdG70VJc2pAMw3NA6JKL5hhFu1sJX0Mnn/A==",
      "dev": true,
      "engines": {
        "node": ">=6.0.0"
      }
    },
    "node_modules/@jridgewell/sourcemap-codec": {
      "version": "1.4.15",
      "resolved": "https://registry.npmjs.org/@jridgewell/sourcemap-codec/-/sourcemap-codec-1.4.15.tgz",
      "integrity": "sha512-eF2rxCRulEKXHTRiDrDy6erMYWqNw4LPdQ8UQA4huuxaQsVeRPFl2oM8oDGxMFhJUWZf9McpLtJasDDZb/Bpeg==",
      "dev": true
    },
    "node_modules/@jridgewell/trace-mapping": {
      "version": "0.3.25",
      "resolved": "https://registry.npmjs.org/@jridgewell/trace-mapping/-/trace-mapping-0.3.25.tgz",
      "integrity": "sha512-vNk6aEwybGtawWmy/PzwnGDOjCkLWSD2wqvjGGAgOAwCGWySYXfYoxt00IJkTF+8Lb57DwOb3Aa0o9CApepiYQ==",
      "dev": true,
      "dependencies": {
        "@jridgewell/resolve-uri": "^3.1.0",
        "@jridgewell/sourcemap-codec": "^1.4.14"
      }
    },
    "node_modules/@next/env": {
      "version": "14.2.2",
      "resolved": "https://registry.npmjs.org/@next/env/-/env-14.2.2.tgz",
      "integrity": "sha512-sk72qRfM1Q90XZWYRoJKu/UWlTgihrASiYw/scb15u+tyzcze3bOuJ/UV6TBOQEeUaxOkRqGeuGUdiiuxc5oqw=="
    },
    "node_modules/@next/eslint-plugin-next": {
      "version": "14.2.2",
      "resolved": "https://registry.npmjs.org/@next/eslint-plugin-next/-/eslint-plugin-next-14.2.2.tgz",
      "integrity": "sha512-q+Ec2648JtBpKiu/FSJm8HAsFXlNvioHeBCbTP12T1SGcHYwhqHULSfQgFkPgHDu3kzNp2Kem4J54bK4rPQ5SQ==",
      "dev": true,
      "dependencies": {
        "glob": "10.3.10"
      }
    },
    "node_modules/@next/swc-darwin-arm64": {
      "version": "14.2.2",
      "resolved": "https://registry.npmjs.org/@next/swc-darwin-arm64/-/swc-darwin-arm64-14.2.2.tgz",
      "integrity": "sha512-3iPgMhzbalizGwHNFUcGnDhFPSgVBHQ8aqSTAMxB5BvJG0oYrDf1WOJZlbXBgunOEj/8KMVbejEur/FpvFsgFQ==",
      "cpu": [
        "arm64"
      ],
      "optional": true,
      "os": [
        "darwin"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@next/swc-darwin-x64": {
      "version": "14.2.2",
      "resolved": "https://registry.npmjs.org/@next/swc-darwin-x64/-/swc-darwin-x64-14.2.2.tgz",
      "integrity": "sha512-x7Afi/jt0ZBRUZHTi49yyej4o8znfIMHO4RvThuoc0P+uli8Jd99y5GKjxoYunPKsXL09xBXEM1+OQy2xEL0Ag==",
      "cpu": [
        "x64"
      ],
      "optional": true,
      "os": [
        "darwin"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@next/swc-linux-arm64-gnu": {
      "version": "14.2.2",
      "resolved": "https://registry.npmjs.org/@next/swc-linux-arm64-gnu/-/swc-linux-arm64-gnu-14.2.2.tgz",
      "integrity": "sha512-zbfPtkk7L41ODMJwSp5VbmPozPmMMQrzAc0HAUomVeVIIwlDGs/UCqLJvLNDt4jpWgc21SjjyIn762lNGrMaUA==",
      "cpu": [
        "arm64"
      ],
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@next/swc-linux-arm64-musl": {
      "version": "14.2.2",
      "resolved": "https://registry.npmjs.org/@next/swc-linux-arm64-musl/-/swc-linux-arm64-musl-14.2.2.tgz",
      "integrity": "sha512-wPbS3pI/JU16rm3XdLvvTmlsmm1nd+sBa2ohXgBZcShX4TgOjD4R+RqHKlI1cjo/jDZKXt6OxmcU0Iys0OC/yg==",
      "cpu": [
        "arm64"
      ],
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@next/swc-linux-x64-gnu": {
      "version": "14.2.2",
      "resolved": "https://registry.npmjs.org/@next/swc-linux-x64-gnu/-/swc-linux-x64-gnu-14.2.2.tgz",
      "integrity": "sha512-NqWOHqqq8iC9tuHvZxjQ2tX+jWy2X9y8NX2mcB4sj2bIccuCxbIZrU/ThFPZZPauygajZuVQ6zediejQHwZHwQ==",
      "cpu": [
        "x64"
      ],
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@next/swc-linux-x64-musl": {
      "version": "14.2.2",
      "resolved": "https://registry.npmjs.org/@next/swc-linux-x64-musl/-/swc-linux-x64-musl-14.2.2.tgz",
      "integrity": "sha512-lGepHhwb9sGhCcU7999+iK1ZZT+6rrIoVg40MP7DZski9GIZP80wORSbt5kJzh9v2x2ev2lxC6VgwMQT0PcgTA==",
      "cpu": [
        "x64"
      ],
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@next/swc-win32-arm64-msvc": {
      "version": "14.2.2",
      "resolved": "https://registry.npmjs.org/@next/swc-win32-arm64-msvc/-/swc-win32-arm64-msvc-14.2.2.tgz",
      "integrity": "sha512-TZSh/48SfcLEQ4rD25VVn2kdIgUWmMflRX3OiyPwGNXn3NiyPqhqei/BaqCYXViIQ+6QsG9R0C8LftMqy8JPMA==",
      "cpu": [
        "arm64"
      ],
      "optional": true,
      "os": [
        "win32"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@next/swc-win32-ia32-msvc": {
      "version": "14.2.2",
      "resolved": "https://registry.npmjs.org/@next/swc-win32-ia32-msvc/-/swc-win32-ia32-msvc-14.2.2.tgz",
      "integrity": "sha512-M0tBVNMEBJN2ZNQWlcekMn6pvLria7Sa2Fai5znm7CCJz4pP3lrvlSxhKdkCerk0D9E0bqx5yAo3o2Q7RrD4gA==",
      "cpu": [
        "ia32"
      ],
      "optional": true,
      "os": [
        "win32"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@next/swc-win32-x64-msvc": {
      "version": "14.2.2",
      "resolved": "https://registry.npmjs.org/@next/swc-win32-x64-msvc/-/swc-win32-x64-msvc-14.2.2.tgz",
      "integrity": "sha512-a/20E/wtTJZ3Ykv3f/8F0l7TtgQa2LWHU2oNB9bsu0VjqGuGGHmm/q6waoUNQYTVPYrrlxxaHjJcDV6aiSTt/w==",
      "cpu": [
        "x64"
      ],
      "optional": true,
      "os": [
        "win32"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@nodelib/fs.scandir": {
      "version": "2.1.5",
      "resolved": "https://registry.npmjs.org/@nodelib/fs.scandir/-/fs.scandir-2.1.5.tgz",
      "integrity": "sha512-vq24Bq3ym5HEQm2NKCr3yXDwjc7vTsEThRDnkp2DK9p1uqLR+DHurm/NOTo0KG7HYHU7eppKZj3MyqYuMBf62g==",
      "dev": true,
      "dependencies": {
        "@nodelib/fs.stat": "2.0.5",
        "run-parallel": "^1.1.9"
      },
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/@nodelib/fs.stat": {
      "version": "2.0.5",
      "resolved": "https://registry.npmjs.org/@nodelib/fs.stat/-/fs.stat-2.0.5.tgz",
      "integrity": "sha512-RkhPPp2zrqDAQA/2jNhnztcPAlv64XdhIp7a7454A5ovI7Bukxgt7MX7udwAu3zg1DcpPU0rz3VV1SeaqvY4+A==",
      "dev": true,
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/@nodelib/fs.walk": {
      "version": "1.2.8",
      "resolved": "https://registry.npmjs.org/@nodelib/fs.walk/-/fs.walk-1.2.8.tgz",
      "integrity": "sha512-oGB+UxlgWcgQkgwo8GcEGwemoTFt3FIO9ababBmaGwXIoBKZ+GTy0pP185beGg7Llih/NSHSV2XAs1lnznocSg==",
      "dev": true,
      "dependencies": {
        "@nodelib/fs.scandir": "2.1.5",
        "fastq": "^1.6.0"
      },
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/@pkgjs/parseargs": {
      "version": "0.11.0",
      "resolved": "https://registry.npmjs.org/@pkgjs/parseargs/-/parseargs-0.11.0.tgz",
      "integrity": "sha512-+1VkjdD0QBLPodGrJUeqarH8VAIvQODIbwh9XpP5Syisf7YoQgsJKPNFoqqLQlu+VQ/tVSshMR6loPMn8U+dPg==",
      "dev": true,
      "optional": true,
      "engines": {
        "node": ">=14"
      }
    },
    "node_modules/@rushstack/eslint-patch": {
      "version": "1.10.2",
      "resolved": "https://registry.npmjs.org/@rushstack/eslint-patch/-/eslint-patch-1.10.2.tgz",
      "integrity": "sha512-hw437iINopmQuxWPSUEvqE56NCPsiU8N4AYtfHmJFckclktzK9YQJieD3XkDCDH4OjL+C7zgPUh73R/nrcHrqw==",
      "dev": true
    },
    "node_modules/@swc/counter": {
      "version": "0.1.3",
      "resolved": "https://registry.npmjs.org/@swc/counter/-/counter-0.1.3.tgz",
      "integrity": "sha512-e2BR4lsJkkRlKZ/qCHPw9ZaSxc0MVUd7gtbtaB7aMvHeJVYe8sOB8DBZkP2DtISHGSku9sCK6T6cnY0CtXrOCQ=="
    },
    "node_modules/@swc/helpers": {
      "version": "0.5.5",
      "resolved": "https://registry.npmjs.org/@swc/helpers/-/helpers-0.5.5.tgz",
      "integrity": "sha512-KGYxvIOXcceOAbEk4bi/dVLEK9z8sZ0uBB3Il5b1rhfClSpcX0yfRO0KmTkqR2cnQDymwLB+25ZyMzICg/cm/A==",
      "dependencies": {
        "@swc/counter": "^0.1.3",
        "tslib": "^2.4.0"
      }
    },
    "node_modules/@types/json5": {
      "version": "0.0.29",
      "resolved": "https://registry.npmjs.org/@types/json5/-/json5-0.0.29.tgz",
      "integrity": "sha512-dRLjCWHYg4oaA77cxO64oO+7JwCwnIzkZPdrrC71jQmQtlhM556pwKo5bUzqvZndkVbeFLIIi+9TC40JNF5hNQ==",
      "dev": true
    },
    "node_modules/@types/node": {
      "version": "20.12.7",
      "resolved": "https://registry.npmjs.org/@types/node/-/node-20.12.7.tgz",
      "integrity": "sha512-wq0cICSkRLVaf3UGLMGItu/PtdY7oaXaI/RVU+xliKVOtRna3PRY57ZDfztpDL0n11vfymMUnXv8QwYCO7L1wg==",
      "dev": true,
      "dependencies": {
        "undici-types": "~5.26.4"
      }
    },
    "node_modules/@types/prop-types": {
      "version": "15.7.12",
      "resolved": "https://registry.npmjs.org/@types/prop-types/-/prop-types-15.7.12.tgz",
      "integrity": "sha512-5zvhXYtRNRluoE/jAp4GVsSduVUzNWKkOZrCDBWYtE7biZywwdC2AcEzg+cSMLFRfVgeAFqpfNabiPjxFddV1Q==",
      "dev": true
    },
    "node_modules/@types/react": {
      "version": "18.2.79",
      "resolved": "https://registry.npmjs.org/@types/react/-/react-18.2.79.tgz",
      "integrity": "sha512-RwGAGXPl9kSXwdNTafkOEuFrTBD5SA2B3iEB96xi8+xu5ddUa/cpvyVCSNn+asgLCTHkb5ZxN8gbuibYJi4s1w==",
      "dev": true,
      "dependencies": {
        "@types/prop-types": "*",
        "csstype": "^3.0.2"
      }
    },
    "node_modules/@types/react-dom": {
      "version": "18.2.25",
      "resolved": "https://registry.npmjs.org/@types/react-dom/-/react-dom-18.2.25.tgz",
      "integrity": "sha512-o/V48vf4MQh7juIKZU2QGDfli6p1+OOi5oXx36Hffpc9adsHeXjVp8rHuPkjd8VT8sOJ2Zp05HR7CdpGTIUFUA==",
      "dev": true,
      "dependencies": {
        "@types/react": "*"
      }
    },
    "node_modules/@typescript-eslint/parser": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@typescript-eslint/parser/-/parser-7.2.0.tgz",
      "integrity": "sha512-5FKsVcHTk6TafQKQbuIVkXq58Fnbkd2wDL4LB7AURN7RUOu1utVP+G8+6u3ZhEroW3DF6hyo3ZEXxgKgp4KeCg==",
      "dev": true,
      "dependencies": {
        "@typescript-eslint/scope-manager": "7.2.0",
        "@typescript-eslint/types": "7.2.0",
        "@typescript-eslint/typescript-estree": "7.2.0",
        "@typescript-eslint/visitor-keys": "7.2.0",
        "debug": "^4.3.4"
      },
      "engines": {
        "node": "^16.0.0 || >=18.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/typescript-eslint"
      },
      "peerDependencies": {
        "eslint": "^8.56.0"
      },
      "peerDependenciesMeta": {
        "typescript": {
          "optional": true
        }
      }
    },
    "node_modules/@typescript-eslint/scope-manager": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@typescript-eslint/scope-manager/-/scope-manager-7.2.0.tgz",
      "integrity": "sha512-Qh976RbQM/fYtjx9hs4XkayYujB/aPwglw2choHmf3zBjB4qOywWSdt9+KLRdHubGcoSwBnXUH2sR3hkyaERRg==",
      "dev": true,
      "dependencies": {
        "@typescript-eslint/types": "7.2.0",
        "@typescript-eslint/visitor-keys": "7.2.0"
      },
      "engines": {
        "node": "^16.0.0 || >=18.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/typescript-eslint"
      }
    },
    "node_modules/@typescript-eslint/types": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@typescript-eslint/types/-/types-7.2.0.tgz",
      "integrity": "sha512-XFtUHPI/abFhm4cbCDc5Ykc8npOKBSJePY3a3s+lwumt7XWJuzP5cZcfZ610MIPHjQjNsOLlYK8ASPaNG8UiyA==",
      "dev": true,
      "engines": {
        "node": "^16.0.0 || >=18.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/typescript-eslint"
      }
    },
    "node_modules/@typescript-eslint/typescript-estree": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@typescript-eslint/typescript-estree/-/typescript-estree-7.2.0.tgz",
      "integrity": "sha512-cyxS5WQQCoBwSakpMrvMXuMDEbhOo9bNHHrNcEWis6XHx6KF518tkF1wBvKIn/tpq5ZpUYK7Bdklu8qY0MsFIA==",
      "dev": true,
      "dependencies": {
        "@typescript-eslint/types": "7.2.0",
        "@typescript-eslint/visitor-keys": "7.2.0",
        "debug": "^4.3.4",
        "globby": "^11.1.0",
        "is-glob": "^4.0.3",
        "minimatch": "9.0.3",
        "semver": "^7.5.4",
        "ts-api-utils": "^1.0.1"
      },
      "engines": {
        "node": "^16.0.0 || >=18.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/typescript-eslint"
      },
      "peerDependenciesMeta": {
        "typescript": {
          "optional": true
        }
      }
    },
    "node_modules/@typescript-eslint/typescript-estree/node_modules/brace-expansion": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/brace-expansion/-/brace-expansion-2.0.1.tgz",
      "integrity": "sha512-XnAIvQ8eM+kC6aULx6wuQiwVsnzsi9d3WxzV3FpWTGA19F621kwdbsAcFKXgKUHZWsy+mY6iL1sHTxWEFCytDA==",
      "dev": true,
      "dependencies": {
        "balanced-match": "^1.0.0"
      }
    },
    "node_modules/@typescript-eslint/typescript-estree/node_modules/minimatch": {
      "version": "9.0.3",
      "resolved": "https://registry.npmjs.org/minimatch/-/minimatch-9.0.3.tgz",
      "integrity": "sha512-RHiac9mvaRw0x3AYRgDC1CxAP7HTcNrrECeA8YYJeWnpo+2Q5CegtZjaotWTWxDG3UeGA1coE05iH1mPjT/2mg==",
      "dev": true,
      "dependencies": {
        "brace-expansion": "^2.0.1"
      },
      "engines": {
        "node": ">=16 || 14 >=14.17"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/@typescript-eslint/visitor-keys": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@typescript-eslint/visitor-keys/-/visitor-keys-7.2.0.tgz",
      "integrity": "sha512-c6EIQRHhcpl6+tO8EMR+kjkkV+ugUNXOmeASA1rlzkd8EPIriavpWoiEz1HR/VLhbVIdhqnV6E7JZm00cBDx2A==",
      "dev": true,
      "dependencies": {
        "@typescript-eslint/types": "7.2.0",
        "eslint-visitor-keys": "^3.4.1"
      },
      "engines": {
        "node": "^16.0.0 || >=18.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/typescript-eslint"
      }
    },
    "node_modules/@ungap/structured-clone": {
      "version": "1.2.0",
      "resolved": "https://registry.npmjs.org/@ungap/structured-clone/-/structured-clone-1.2.0.tgz",
      "integrity": "sha512-zuVdFrMJiuCDQUMCzQaD6KL28MjnqqN8XnAqiEq9PNm/hCPTSGfrXCOfwj1ow4LFb/tNymJPwsNbVePc1xFqrQ==",
      "dev": true
    },
    "node_modules/acorn": {
      "version": "8.11.3",
      "resolved": "https://registry.npmjs.org/acorn/-/acorn-8.11.3.tgz",
      "integrity": "sha512-Y9rRfJG5jcKOE0CLisYbojUjIrIEE7AGMzA/Sm4BslANhbS+cDMpgBdcPT91oJ7OuJ9hYJBx59RjbhxVnrF8Xg==",
      "dev": true,
      "bin": {
        "acorn": "bin/acorn"
      },
      "engines": {
        "node": ">=0.4.0"
      }
    },
    "node_modules/acorn-jsx": {
      "version": "5.3.2",
      "resolved": "https://registry.npmjs.org/acorn-jsx/-/acorn-jsx-5.3.2.tgz",
      "integrity": "sha512-rq9s+JNhf0IChjtDXxllJ7g41oZk5SlXtp0LHwyA5cejwn7vKmKp4pPri6YEePv2PU65sAsegbXtIinmDFDXgQ==",
      "dev": true,
      "peerDependencies": {
        "acorn": "^6.0.0 || ^7.0.0 || ^8.0.0"
      }
    },
    "node_modules/ajv": {
      "version": "6.12.6",
      "resolved": "https://registry.npmjs.org/ajv/-/ajv-6.12.6.tgz",
      "integrity": "sha512-j3fVLgvTo527anyYyJOGTYJbG+vnnQYvE0m5mmkc1TK+nxAppkCLMIL0aZ4dblVCNoGShhm+kzE4ZUykBoMg4g==",
      "dev": true,
      "dependencies": {
        "fast-deep-equal": "^3.1.1",
        "fast-json-stable-stringify": "^2.0.0",
        "json-schema-traverse": "^0.4.1",
        "uri-js": "^4.2.2"
      },
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/epoberezkin"
      }
    },
    "node_modules/ansi-regex": {
      "version": "5.0.1",
      "resolved": "https://registry.npmjs.org/ansi-regex/-/ansi-regex-5.0.1.tgz",
      "integrity": "sha512-quJQXlTSUGL2LH9SUXo8VwsY4soanhgo6LNSm84E1LBcE8s3O0wpdiRzyR9z/ZZJMlMWv37qOOb9pdJlMUEKFQ==",
      "dev": true,
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/ansi-styles": {
      "version": "4.3.0",
      "resolved": "https://registry.npmjs.org/ansi-styles/-/ansi-styles-4.3.0.tgz",
      "integrity": "sha512-zbB9rCJAT1rbjiVDb2hqKFHNYLxgtk8NURxZ3IZwD3F6NtxbXZQCnnSi1Lkx+IDohdPlFp222wVALIheZJQSEg==",
      "dev": true,
      "dependencies": {
        "color-convert": "^2.0.1"
      },
      "engines": {
        "node": ">=8"
      },
      "funding": {
        "url": "https://github.com/chalk/ansi-styles?sponsor=1"
      }
    },
    "node_modules/any-promise": {
      "version": "1.3.0",
      "resolved": "https://registry.npmjs.org/any-promise/-/any-promise-1.3.0.tgz",
      "integrity": "sha512-7UvmKalWRt1wgjL1RrGxoSJW/0QZFIegpeGvZG9kjp8vrRu55XTHbwnqq2GpXm9uLbcuhxm3IqX9OB4MZR1b2A==",
      "dev": true
    },
    "node_modules/anymatch": {
      "version": "3.1.3",
      "resolved": "https://registry.npmjs.org/anymatch/-/anymatch-3.1.3.tgz",
      "integrity": "sha512-KMReFUr0B4t+D+OBkjR3KYqvocp2XaSzO55UcB6mgQMd3KbcE+mWTyvVV7D/zsdEbNnV6acZUutkiHQXvTr1Rw==",
      "dev": true,
      "dependencies": {
        "normalize-path": "^3.0.0",
        "picomatch": "^2.0.4"
      },
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/arg": {
      "version": "5.0.2",
      "resolved": "https://registry.npmjs.org/arg/-/arg-5.0.2.tgz",
      "integrity": "sha512-PYjyFOLKQ9y57JvQ6QLo8dAgNqswh8M1RMJYdQduT6xbWSgK36P/Z/v+p888pM69jMMfS8Xd8F6I1kQ/I9HUGg==",
      "dev": true
    },
    "node_modules/argparse": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/argparse/-/argparse-2.0.1.tgz",
      "integrity": "sha512-8+9WqebbFzpX9OR+Wa6O29asIogeRMzcGtAINdpMHHyAg10f05aSFVBbcEqGf/PXw1EjAZ+q2/bEBg3DvurK3Q==",
      "dev": true
    },
    "node_modules/aria-query": {
      "version": "5.3.0",
      "resolved": "https://registry.npmjs.org/aria-query/-/aria-query-5.3.0.tgz",
      "integrity": "sha512-b0P0sZPKtyu8HkeRAfCq0IfURZK+SuwMjY1UXGBU27wpAiTwQAIlq56IbIO+ytk/JjS1fMR14ee5WBBfKi5J6A==",
      "dev": true,
      "dependencies": {
        "dequal": "^2.0.3"
      }
    },
    "node_modules/array-buffer-byte-length": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/array-buffer-byte-length/-/array-buffer-byte-length-1.0.1.tgz",
      "integrity": "sha512-ahC5W1xgou+KTXix4sAO8Ki12Q+jf4i0+tmk3sC+zgcynshkHxzpXdImBehiUYKKKDwvfFiJl1tZt6ewscS1Mg==",
      "dev": true,
      "dependencies": {
        "call-bind": "^1.0.5",
        "is-array-buffer": "^3.0.4"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/array-includes": {
      "version": "3.1.8",
      "resolved": "https://registry.npmjs.org/array-includes/-/array-includes-3.1.8.tgz",
      "integrity": "sha512-itaWrbYbqpGXkGhZPGUulwnhVf5Hpy1xiCFsGqyIGglbBxmG5vSjxQen3/WGOjPpNEv1RtBLKxbmVXm8HpJStQ==",
      "dev": true,
      "dependencies": {
        "call-bind": "^1.0.7",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.2",
        "es-object-atoms": "^1.0.0",
        "get-intrinsic": "^1.2.4",
        "is-string": "^1.0.7"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/array-union": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/array-union/-/array-union-2.1.0.tgz",
      "integrity": "sha512-HGyxoOTYUyCM6stUe6EJgnd4EoewAI7zMdfqO+kGjnlZmBDz/cR5pf8r/cR4Wq60sL/p0IkcjUEEPwS3GFrIyw==",
      "dev": true,
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/array.prototype.findlast": {
      "version": "1.2.5",
      "resolved": "https://registry.npmjs.org/array.prototype.findlast/-/array.prototype.findlast-1.2.5.tgz",
      "integrity": "sha512-CVvd6FHg1Z3POpBLxO6E6zr+rSKEQ9L6rZHAaY7lLfhKsWYUBBOuMs0e9o24oopj6H+geRCX0YJ+TJLBK2eHyQ==",
      "dev": true,
      "dependencies": {
        "call-bind": "^1.0.7",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.2",
        "es-errors": "^1.3.0",
        "es-object-atoms": "^1.0.0",
        "es-shim-unscopables": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/array.prototype.findlastindex": {
      "version": "1.2.5",
      "resolved": "https://registry.npmjs.org/array.prototype.findlastindex/-/array.prototype.findlastindex-1.2.5.tgz",
      "integrity": "sha512-zfETvRFA8o7EiNn++N5f/kaCw221hrpGsDmcpndVupkPzEc1Wuf3VgC0qby1BbHs7f5DVYjgtEU2LLh5bqeGfQ==",
      "dev": true,
      "dependencies": {
        "call-bind": "^1.0.7",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.2",
        "es-errors": "^1.3.0",
        "es-object-atoms": "^1.0.0",
        "es-shim-unscopables": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/array.prototype.flat": {
      "version": "1.3.2",
      "resolved": "https://registry.npmjs.org/array.prototype.flat/-/array.prototype.flat-1.3.2.tgz",
      "integrity": "sha512-djYB+Zx2vLewY8RWlNCUdHjDXs2XOgm602S9E7P/UpHgfeHL00cRiIF+IN/G/aUJ7kGPb6yO/ErDI5V2s8iycA==",
      "dev": true,
      "dependencies": {
        "call-bind": "^1.0.2",
        "define-properties": "^1.2.0",
        "es-abstract": "^1.22.1",
        "es-shim-unscopables": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/array.prototype.flatmap": {
      "version": "1.3.2",
      "resolved": "https://registry.npmjs.org/array.prototype.flatmap/-/array.prototype.flatmap-1.3.2.tgz",
      "integrity": "sha512-Ewyx0c9PmpcsByhSW4r+9zDU7sGjFc86qf/kKtuSCRdhfbk0SNLLkaT5qvcHnRGgc5NP/ly/y+qkXkqONX54CQ==",
      "dev": true,
      "dependencies": {
        "call-bind": "^1.0.2",
        "define-properties": "^1.2.0",
        "es-abstract": "^1.22.1",
        "es-shim-unscopables": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/array.prototype.toreversed": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/array.prototype.toreversed/-/array.prototype.toreversed-1.1.2.tgz",
      "integrity": "sha512-wwDCoT4Ck4Cz7sLtgUmzR5UV3YF5mFHUlbChCzZBQZ+0m2cl/DH3tKgvphv1nKgFsJ48oCSg6p91q2Vm0I/ZMA==",
      "dev": true,
      "dependencies": {
        "call-bind": "^1.0.2",
        "define-properties": "^1.2.0",
        "es-abstract": "^1.22.1",
        "es-shim-unscopables": "^1.0.0"
      }
    },
    "node_modules/array.prototype.tosorted": {
      "version": "1.1.3",
      "resolved": "https://registry.npmjs.org/array.prototype.tosorted/-/array.prototype.tosorted-1.1.3.tgz",
      "integrity": "sha512-/DdH4TiTmOKzyQbp/eadcCVexiCb36xJg7HshYOYJnNZFDj33GEv0P7GxsynpShhq4OLYJzbGcBDkLsDt7MnNg==",
      "dev": true,
      "dependencies": {
        "call-bind": "^1.0.5",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.22.3",
        "es-errors": "^1.1.0",
        "es-shim-unscopables": "^1.0.2"
      }
    },
    "node_modules/arraybuffer.prototype.slice": {
      "version": "1.0.3",
      "resolved": "https://registry.npmjs.org/arraybuffer.prototype.slice/-/arraybuffer.prototype.slice-1.0.3.tgz",
      "integrity": "sha512-bMxMKAjg13EBSVscxTaYA4mRc5t1UAXa2kXiGTNfZ079HIWXEkKmkgFrh/nJqamaLSrXO5H4WFFkPEaLJWbs3A==",
      "dev": true,
      "dependencies": {
        "array-buffer-byte-length": "^1.0.1",
        "call-bind": "^1.0.5",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.22.3",
        "es-errors": "^1.2.1",
        "get-intrinsic": "^1.2.3",
        "is-array-buffer": "^3.0.4",
        "is-shared-array-buffer": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/ast-types-flow": {
      "version": "0.0.8",
      "resolved": "https://registry.npmjs.org/ast-types-flow/-/ast-types-flow-0.0.8.tgz",
      "integrity": "sha512-OH/2E5Fg20h2aPrbe+QL8JZQFko0YZaF+j4mnQ7BGhfavO7OpSLa8a0y9sBwomHdSbkhTS8TQNayBfnW5DwbvQ==",
      "dev": true
    },
    "node_modules/available-typed-arrays": {
      "version": "1.0.7",
      "resolved": "https://registry.npmjs.org/available-typed-arrays/-/available-typed-arrays-1.0.7.tgz",
      "integrity": "sha512-wvUjBtSGN7+7SjNpq/9M2Tg350UZD3q62IFZLbRAR1bSMlCo1ZaeW+BJ+D090e4hIIZLBcTDWe4Mh4jvUDajzQ==",
      "dev": true,
      "dependencies": {
        "possible-typed-array-names": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/axe-core": {
      "version": "4.7.0",
      "resolved": "https://registry.npmjs.org/axe-core/-/axe-core-4.7.0.tgz",
      "integrity": "sha512-M0JtH+hlOL5pLQwHOLNYZaXuhqmvS8oExsqB1SBYgA4Dk7u/xx+YdGHXaK5pyUfed5mYXdlYiphWq3G8cRi5JQ==",
      "dev": true,
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/axobject-query": {
      "version": "3.2.1",
      "resolved": "https://registry.npmjs.org/axobject-query/-/axobject-query-3.2.1.tgz",
      "integrity": "sha512-jsyHu61e6N4Vbz/v18DHwWYKK0bSWLqn47eeDSKPB7m8tqMHF9YJ+mhIk2lVteyZrY8tnSj/jHOv4YiTCuCJgg==",
      "dev": true,
      "dependencies": {
        "dequal": "^2.0.3"
      }
    },
    "node_modules/balanced-match": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/balanced-match/-/balanced-match-1.0.2.tgz",
      "integrity": "sha512-3oSeUO0TMV67hN1AmbXsK4yaqU7tjiHlbxRDZOpH0KW9+CeX4bRAaX0Anxt0tx2MrpRpWwQaPwIlISEJhYU5Pw==",
      "dev": true
    },
    "node_modules/binary-extensions": {
      "version": "2.3.0",
      "resolved": "https://registry.npmjs.org/binary-extensions/-/binary-extensions-2.3.0.tgz",
      "integrity": "sha512-Ceh+7ox5qe7LJuLHoY0feh3pHuUDHAcRUeyL2VYghZwfpkNIy/+8Ocg0a3UuSoYzavmylwuLWQOf3hl0jjMMIw==",
      "dev": true,
      "engines": {
        "node": ">=8"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/brace-expansion": {
      "version": "1.1.11",
      "resolved": "https://registry.npmjs.org/brace-expansion/-/brace-expansion-1.1.11.tgz",
      "integrity": "sha512-iCuPHDFgrHX7H2vEI/5xpz07zSHB00TpugqhmYtVmMO6518mCuRMoOYFldEBl0g187ufozdaHgWKcYFb61qGiA==",
      "dev": true,
      "dependencies": {
        "balanced-match": "^1.0.0",
        "concat-map": "0.0.1"
      }
    },
    "node_modules/braces": {
      "version": "3.0.2",
      "resolved": "https://registry.npmjs.org/braces/-/braces-3.0.2.tgz",
      "integrity": "sha512-b8um+L1RzM3WDSzvhm6gIz1yfTbBt6YTlcEKAvsmqCZZFw46z626lVj9j1yEPW33H5H+lBQpZMP1k8l+78Ha0A==",
      "dev": true,
      "dependencies": {
        "fill-range": "^7.0.1"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/busboy": {
      "version": "1.6.0",
      "resolved": "https://registry.npmjs.org/busboy/-/busboy-1.6.0.tgz",
      "integrity": "sha512-8SFQbg/0hQ9xy3UNTB0YEnsNBbWfhf7RtnzpL7TkBiTBRfrQ9Fxcnz7VJsleJpyp6rVLvXiuORqjlHi5q+PYuA==",
      "dependencies": {
        "streamsearch": "^1.1.0"
      },
      "engines": {
        "node": ">=10.16.0"
      }
    },
    "node_modules/call-bind": {
      "version": "1.0.7",
      "resolved": "https://registry.npmjs.org/call-bind/-/call-bind-1.0.7.tgz",
      "integrity": "sha512-GHTSNSYICQ7scH7sZ+M2rFopRoLh8t2bLSW6BbgrtLsahOIB5iyAVJf9GjWK3cYTDaMj4XdBpM1cA6pIS0Kv2w==",
      "dev": true,
      "dependencies": {
        "es-define-property": "^1.0.0",
        "es-errors": "^1.3.0",
        "function-bind": "^1.1.2",
        "get-intrinsic": "^1.2.4",
        "set-function-length": "^1.2.1"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/callsites": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/callsites/-/callsites-3.1.0.tgz",
      "integrity": "sha512-P8BjAsXvZS+VIDUI11hHCQEv74YT67YUi5JJFNWIqL235sBmjX4+qx9Muvls5ivyNENctx46xQLQ3aTuE7ssaQ==",
      "dev": true,
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/camelcase-css": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/camelcase-css/-/camelcase-css-2.0.1.tgz",
      "integrity": "sha512-QOSvevhslijgYwRx6Rv7zKdMF8lbRmx+uQGx2+vDc+KI/eBnsy9kit5aj23AgGu3pa4t9AgwbnXWqS+iOY+2aA==",
      "dev": true,
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/caniuse-lite": {
      "version": "1.0.30001611",
      "resolved": "https://registry.npmjs.org/caniuse-lite/-/caniuse-lite-1.0.30001611.tgz",
      "integrity": "sha512-19NuN1/3PjA3QI8Eki55N8my4LzfkMCRLgCVfrl/slbSAchQfV0+GwjPrK3rq37As4UCLlM/DHajbKkAqbv92Q==",
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/browserslist"
        },
        {
          "type": "tidelift",
          "url": "https://tidelift.com/funding/github/npm/caniuse-lite"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ]
    },
    "node_modules/chalk": {
      "version": "4.1.2",
      "resolved": "https://registry.npmjs.org/chalk/-/chalk-4.1.2.tgz",
      "integrity": "sha512-oKnbhFyRIXpUuez8iBMmyEa4nbj4IOQyuhc/wy9kY7/WVPcwIO9VA668Pu8RkO7+0G76SLROeyw9CpQ061i4mA==",
      "dev": true,
      "dependencies": {
        "ansi-styles": "^4.1.0",
        "supports-color": "^7.1.0"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/chalk/chalk?sponsor=1"
      }
    },
    "node_modules/chokidar": {
      "version": "3.6.0",
      "resolved": "https://registry.npmjs.org/chokidar/-/chokidar-3.6.0.tgz",
      "integrity": "sha512-7VT13fmjotKpGipCW9JEQAusEPE+Ei8nl6/g4FBAmIm0GOOLMua9NDDo/DWp0ZAxCr3cPq5ZpBqmPAQgDda2Pw==",
      "dev": true,
      "dependencies": {
        "anymatch": "~3.1.2",
        "braces": "~3.0.2",
        "glob-parent": "~5.1.2",
        "is-binary-path": "~2.1.0",
        "is-glob": "~4.0.1",
        "normalize-path": "~3.0.0",
        "readdirp": "~3.6.0"
      },
      "engines": {
        "node": ">= 8.10.0"
      },
      "funding": {
        "url": "https://paulmillr.com/funding/"
      },
      "optionalDependencies": {
        "fsevents": "~2.3.2"
      }
    },
    "node_modules/chokidar/node_modules/glob-parent": {
      "version": "5.1.2",
      "resolved": "https://registry.npmjs.org/glob-parent/-/glob-parent-5.1.2.tgz",
      "integrity": "sha512-AOIgSQCepiJYwP3ARnGx+5VnTu2HBYdzbGP45eLw1vr3zB3vZLeyed1sC9hnbcOc9/SrMyM5RPQrkGz4aS9Zow==",
      "dev": true,
      "dependencies": {
        "is-glob": "^4.0.1"
      },
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/client-only": {
      "version": "0.0.1",
      "resolved": "https://registry.npmjs.org/client-only/-/client-only-0.0.1.tgz",
      "integrity": "sha512-IV3Ou0jSMzZrd3pZ48nLkT9DA7Ag1pnPzaiQhpW7c3RbcqqzvzzVu+L8gfqMp/8IM2MQtSiqaCxrrcfu8I8rMA=="
    },
    "node_modules/color-convert": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/color-convert/-/color-convert-2.0.1.tgz",
      "integrity": "sha512-RRECPsj7iu/xb5oKYcsFHSppFNnsj/52OVTRKb4zP5onXwVF3zVmmToNcOfGC+CRDpfK/U584fMg38ZHCaElKQ==",
      "dev": true,
      "dependencies": {
        "color-name": "~1.1.4"
      },
      "engines": {
        "node": ">=7.0.0"
      }
    },
    "node_modules/color-name": {
      "version": "1.1.4",
      "resolved": "https://registry.npmjs.org/color-name/-/color-name-1.1.4.tgz",
      "integrity": "sha512-dOy+3AuW3a2wNbZHIuMZpTcgjGuLU/uBL/ubcZF9OXbDo8ff4O8yVp5Bf0efS8uEoYo5q4Fx7dY9OgQGXgAsQA==",
      "dev": true
    },
    "node_modules/commander": {
      "version": "4.1.1",
      "resolved": "https://registry.npmjs.org/commander/-/commander-4.1.1.tgz",
      "integrity": "sha512-NOKm8xhkzAjzFx8B2v5OAHT+u5pRQc2UCa2Vq9jYL/31o2wi9mxBA7LIFs3sV5VSC49z6pEhfbMULvShKj26WA==",
      "dev": true,
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/concat-map": {
      "version": "0.0.1",
      "resolved": "https://registry.npmjs.org/concat-map/-/concat-map-0.0.1.tgz",
      "integrity": "sha512-/Srv4dswyQNBfohGpz9o6Yb3Gz3SrUDqBH5rTuhGR7ahtlbYKnVxw2bCFMRljaA7EXHaXZ8wsHdodFvbkhKmqg==",
      "dev": true
    },
    "node_modules/cross-spawn": {
      "version": "7.0.3",
      "resolved": "https://registry.npmjs.org/cross-spawn/-/cross-spawn-7.0.3.tgz",
      "integrity": "sha512-iRDPJKUPVEND7dHPO8rkbOnPpyDygcDFtWjpeWNCgy8WP2rXcxXL8TskReQl6OrB2G7+UJrags1q15Fudc7G6w==",
      "dev": true,
      "dependencies": {
        "path-key": "^3.1.0",
        "shebang-command": "^2.0.0",
        "which": "^2.0.1"
      },
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/cssesc": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/cssesc/-/cssesc-3.0.0.tgz",
      "integrity": "sha512-/Tb/JcjK111nNScGob5MNtsntNM1aCNUDipB/TkwZFhyDrrE47SOx/18wF2bbjgc3ZzCSKW1T5nt5EbFoAz/Vg==",
      "dev": true,
      "bin": {
        "cssesc": "bin/cssesc"
      },
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/csstype": {
      "version": "3.1.3",
      "resolved": "https://registry.npmjs.org/csstype/-/csstype-3.1.3.tgz",
      "integrity": "sha512-M1uQkMl8rQK/szD0LNhtqxIPLpimGm8sOBwU7lLnCpSbTyY3yeU1Vc7l4KT5zT4s/yOxHH5O7tIuuLOCnLADRw==",
      "dev": true
    },
    "node_modules/damerau-levenshtein": {
      "version": "1.0.8",
      "resolved": "https://registry.npmjs.org/damerau-levenshtein/-/damerau-levenshtein-1.0.8.tgz",
      "integrity": "sha512-sdQSFB7+llfUcQHUQO3+B8ERRj0Oa4w9POWMI/puGtuf7gFywGmkaLCElnudfTiKZV+NvHqL0ifzdrI8Ro7ESA==",
      "dev": true
    },
    "node_modules/data-view-buffer": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/data-view-buffer/-/data-view-buffer-1.0.1.tgz",
      "integrity": "sha512-0lht7OugA5x3iJLOWFhWK/5ehONdprk0ISXqVFn/NFrDu+cuc8iADFrGQz5BnRK7LLU3JmkbXSxaqX+/mXYtUA==",
      "dev": true,
      "dependencies": {
        "call-bind": "^1.0.6",
        "es-errors": "^1.3.0",
        "is-data-view": "^1.0.1"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/data-view-byte-length": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/data-view-byte-length/-/data-view-byte-length-1.0.1.tgz",
      "integrity": "sha512-4J7wRJD3ABAzr8wP+OcIcqq2dlUKp4DVflx++hs5h5ZKydWMI6/D/fAot+yh6g2tHh8fLFTvNOaVN357NvSrOQ==",
      "dev": true,
      "dependencies": {
        "call-bind": "^1.0.7",
        "es-errors": "^1.3.0",
        "is-data-view": "^1.0.1"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/data-view-byte-offset": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/data-view-byte-offset/-/data-view-byte-offset-1.0.0.tgz",
      "integrity": "sha512-t/Ygsytq+R995EJ5PZlD4Cu56sWa8InXySaViRzw9apusqsOO2bQP+SbYzAhR0pFKoB+43lYy8rWban9JSuXnA==",
      "dev": true,
      "dependencies": {
        "call-bind": "^1.0.6",
        "es-errors": "^1.3.0",
        "is-data-view": "^1.0.1"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/debug": {
      "version": "4.3.4",
      "resolved": "https://registry.npmjs.org/debug/-/debug-4.3.4.tgz",
      "integrity": "sha512-PRWFHuSU3eDtQJPvnNY7Jcket1j0t5OuOsFzPPzsekD52Zl8qUfFIPEiswXqIvHWGVHOgX+7G/vCNNhehwxfkQ==",
      "dev": true,
      "dependencies": {
        "ms": "2.1.2"
      },
      "engines": {
        "node": ">=6.0"
      },
      "peerDependenciesMeta": {
        "supports-color": {
          "optional": true
        }
      }
    },
    "node_modules/deep-is": {
      "version": "0.1.4",
      "resolved": "https://registry.npmjs.org/deep-is/-/deep-is-0.1.4.tgz",
      "integrity": "sha512-oIPzksmTg4/MriiaYGO+okXDT7ztn/w3Eptv/+gSIdMdKsJo0u4CfYNFJPy+4SKMuCqGw2wxnA+URMg3t8a/bQ==",
      "dev": true
    },
    "node_modules/define-data-property": {
      "version": "1.1.4",
      "resolved": "https://registry.npmjs.org/define-data-property/-/define-data-property-1.1.4.tgz",
      "integrity": "sha512-rBMvIzlpA8v6E+SJZoo++HAYqsLrkg7MSfIinMPFhmkorw7X+dOXVJQs+QT69zGkzMyfDnIMN2Wid1+NbL3T+A==",
      "dev": true,
      "dependencies": {
        "es-define-property": "^1.0.0",
        "es-errors": "^1.3.0",
        "gopd": "^1.0.1"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/define-properties": {
      "version": "1.2.1",
      "resolved": "https://registry.npmjs.org/define-properties/-/define-properties-1.2.1.tgz",
      "integrity": "sha512-8QmQKqEASLd5nx0U1B1okLElbUuuttJ/AnYmRXbbbGDWh6uS208EjD4Xqq/I9wK7u0v6O08XhTWnt5XtEbR6Dg==",
      "dev": true,
      "dependencies": {
        "define-data-property": "^1.0.1",
        "has-property-descriptors": "^1.0.0",
        "object-keys": "^1.1.1"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/dequal": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/dequal/-/dequal-2.0.3.tgz",
      "integrity": "sha512-0je+qPKHEMohvfRTCEo3CrPG6cAzAYgmzKyxRiYSSDkS6eGJdyVJm7WaYA5ECaAD9wLB2T4EEeymA5aFVcYXCA==",
      "dev": true,
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/didyoumean": {
      "version": "1.2.2",
      "resolved": "https://registry.npmjs.org/didyoumean/-/didyoumean-1.2.2.tgz",
      "integrity": "sha512-gxtyfqMg7GKyhQmb056K7M3xszy/myH8w+B4RT+QXBQsvAOdc3XymqDDPHx1BgPgsdAA5SIifona89YtRATDzw==",
      "dev": true
    },
    "node_modules/dir-glob": {
      "version": "3.0.1",
      "resolved": "https://registry.npmjs.org/dir-glob/-/dir-glob-3.0.1.tgz",
      "integrity": "sha512-WkrWp9GR4KXfKGYzOLmTuGVi1UWFfws377n9cc55/tb6DuqyF6pcQ5AbiHEshaDpY9v6oaSr2XCDidGmMwdzIA==",
      "dev": true,
      "dependencies": {
        "path-type": "^4.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/dlv": {
      "version": "1.1.3",
      "resolved": "https://registry.npmjs.org/dlv/-/dlv-1.1.3.tgz",
      "integrity": "sha512-+HlytyjlPKnIG8XuRG8WvmBP8xs8P71y+SKKS6ZXWoEgLuePxtDoUEiH7WkdePWrQ5JBpE6aoVqfZfJUQkjXwA==",
      "dev": true
    },
    "node_modules/doctrine": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/doctrine/-/doctrine-3.0.0.tgz",
      "integrity": "sha512-yS+Q5i3hBf7GBkd4KG8a7eBNNWNGLTaEwwYWUijIYM7zrlYDM0BFXHjjPWlWZ1Rg7UaddZeIDmi9jF3HmqiQ2w==",
      "dev": true,
      "dependencies": {
        "esutils": "^2.0.2"
      },
      "engines": {
        "node": ">=6.0.0"
      }
    },
    "node_modules/eastasianwidth": {
      "version": "0.2.0",
      "resolved": "https://registry.npmjs.org/eastasianwidth/-/eastasianwidth-0.2.0.tgz",
      "integrity": "sha512-I88TYZWc9XiYHRQ4/3c5rjjfgkjhLyW2luGIheGERbNQ6OY7yTybanSpDXZa8y7VUP9YmDcYa+eyq4ca7iLqWA==",
      "dev": true
    },
    "node_modules/emoji-regex": {
      "version": "9.2.2",
      "resolved": "https://registry.npmjs.org/emoji-regex/-/emoji-regex-9.2.2.tgz",
      "integrity": "sha512-L18DaJsXSUk2+42pv8mLs5jJT2hqFkFE4j21wOmgbUqsZ2hL72NsUU785g9RXgo3s0ZNgVl42TiHp3ZtOv/Vyg==",
      "dev": true
    },
    "node_modules/enhanced-resolve": {
      "version": "5.16.0",
      "resolved": "https://registry.npmjs.org/enhanced-resolve/-/enhanced-resolve-5.16.0.tgz",
      "integrity": "sha512-O+QWCviPNSSLAD9Ucn8Awv+poAkqn3T1XY5/N7kR7rQO9yfSGWkYZDwpJ+iKF7B8rxaQKWngSqACpgzeapSyoA==",
      "dev": true,
      "dependencies": {
        "graceful-fs": "^4.2.4",
        "tapable": "^2.2.0"
      },
      "engines": {
        "node": ">=10.13.0"
      }
    },
    "node_modules/es-abstract": {
      "version": "1.23.3",
      "resolved": "https://registry.npmjs.org/es-abstract/-/es-abstract-1.23.3.tgz",
      "integrity": "sha512-e+HfNH61Bj1X9/jLc5v1owaLYuHdeHHSQlkhCBiTK8rBvKaULl/beGMxwrMXjpYrv4pz22BlY570vVePA2ho4A==",
      "dev": true,
      "dependencies": {
        "array-buffer-byte-length": "^1.0.1",
        "arraybuffer.prototype.slice": "^1.0.3",
        "available-typed-arrays": "^1.0.7",
        "call-bind": "^1.0.7",
        "data-view-buffer": "^1.0.1",
        "data-view-byte-length": "^1.0.1",
        "data-view-byte-offset": "^1.0.0",
        "es-define-property": "^1.0.0",
        "es-errors": "^1.3.0",
        "es-object-atoms": "^1.0.0",
        "es-set-tostringtag": "^2.0.3",
        "es-to-primitive": "^1.2.1",
        "function.prototype.name": "^1.1.6",
        "get-intrinsic": "^1.2.4",
        "get-symbol-description": "^1.0.2",
        "globalthis": "^1.0.3",
        "gopd": "^1.0.1",
        "has-property-descriptors": "^1.0.2",
        "has-proto": "^1.0.3",
        "has-symbols": "^1.0.3",
        "hasown": "^2.0.2",
        "internal-slot": "^1.0.7",
        "is-array-buffer": "^3.0.4",
        "is-callable": "^1.2.7",
        "is-data-view": "^1.0.1",
        "is-negative-zero": "^2.0.3",
        "is-regex": "^1.1.4",
        "is-shared-array-buffer": "^1.0.3",
        "is-string": "^1.0.7",
        "is-typed-array": "^1.1.13",
        "is-weakref": "^1.0.2",
        "object-inspect": "^1.13.1",
        "object-keys": "^1.1.1",
        "object.assign": "^4.1.5",
        "regexp.prototype.flags": "^1.5.2",
        "safe-array-concat": "^1.1.2",
        "safe-regex-test": "^1.0.3",
        "string.prototype.trim": "^1.2.9",
        "string.prototype.trimend": "^1.0.8",
        "string.prototype.trimstart": "^1.0.8",
        "typed-array-buffer": "^1.0.2",
        "typed-array-byte-length": "^1.0.1",
        "typed-array-byte-offset": "^1.0.2",
        "typed-array-length": "^1.0.6",
        "unbox-primitive": "^1.0.2",
        "which-typed-array": "^1.1.15"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/es-define-property": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/es-define-property/-/es-define-property-1.0.0.tgz",
      "integrity": "sha512-jxayLKShrEqqzJ0eumQbVhTYQM27CfT1T35+gCgDFoL82JLsXqTJ76zv6A0YLOgEnLUMvLzsDsGIrl8NFpT2gQ==",
      "dev": true,
      "dependencies": {
        "get-intrinsic": "^1.2.4"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/es-errors": {
      "version": "1.3.0",
      "resolved": "https://registry.npmjs.org/es-errors/-/es-errors-1.3.0.tgz",
      "integrity": "sha512-Zf5H2Kxt2xjTvbJvP2ZWLEICxA6j+hAmMzIlypy4xcBg1vKVnx89Wy0GbS+kf5cwCVFFzdCFh2XSCFNULS6csw==",
      "dev": true,
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/es-iterator-helpers": {
      "version": "1.0.18",
      "resolved": "https://registry.npmjs.org/es-iterator-helpers/-/es-iterator-helpers-1.0.18.tgz",
      "integrity": "sha512-scxAJaewsahbqTYrGKJihhViaM6DDZDDoucfvzNbK0pOren1g/daDQ3IAhzn+1G14rBG7w+i5N+qul60++zlKA==",
      "dev": true,
      "dependencies": {
        "call-bind": "^1.0.7",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.0",
        "es-errors": "^1.3.0",
        "es-set-tostringtag": "^2.0.3",
        "function-bind": "^1.1.2",
        "get-intrinsic": "^1.2.4",
        "globalthis": "^1.0.3",
        "has-property-descriptors": "^1.0.2",
        "has-proto": "^1.0.3",
        "has-symbols": "^1.0.3",
        "internal-slot": "^1.0.7",
        "iterator.prototype": "^1.1.2",
        "safe-array-concat": "^1.1.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/es-object-atoms": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/es-object-atoms/-/es-object-atoms-1.0.0.tgz",
      "integrity": "sha512-MZ4iQ6JwHOBQjahnjwaC1ZtIBH+2ohjamzAO3oaHcXYup7qxjF2fixyH+Q71voWHeOkI2q/TnJao/KfXYIZWbw==",
      "dev": true,
      "dependencies": {
        "es-errors": "^1.3.0"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/es-set-tostringtag": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/es-set-tostringtag/-/es-set-tostringtag-2.0.3.tgz",
      "integrity": "sha512-3T8uNMC3OQTHkFUsFq8r/BwAXLHvU/9O9mE0fBc/MY5iq/8H7ncvO947LmYA6ldWw9Uh8Yhf25zu6n7nML5QWQ==",
      "dev": true,
      "dependencies": {
        "get-intrinsic": "^1.2.4",
        "has-tostringtag": "^1.0.2",
        "hasown": "^2.0.1"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/es-shim-unscopables": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/es-shim-unscopables/-/es-shim-unscopables-1.0.2.tgz",
      "integrity": "sha512-J3yBRXCzDu4ULnQwxyToo/OjdMx6akgVC7K6few0a7F/0wLtmKKN7I73AH5T2836UuXRqN7Qg+IIUw/+YJksRw==",
      "dev": true,
      "dependencies": {
        "hasown": "^2.0.0"
      }
    },
    "node_modules/es-to-primitive": {
      "version": "1.2.1",
      "resolved": "https://registry.npmjs.org/es-to-primitive/-/es-to-primitive-1.2.1.tgz",
      "integrity": "sha512-QCOllgZJtaUo9miYBcLChTUaHNjJF3PYs1VidD7AwiEj1kYxKeQTctLAezAOH5ZKRH0g2IgPn6KwB4IT8iRpvA==",
      "dev": true,
      "dependencies": {
        "is-callable": "^1.1.4",
        "is-date-object": "^1.0.1",
        "is-symbol": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/escape-string-regexp": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/escape-string-regexp/-/escape-string-regexp-4.0.0.tgz",
      "integrity": "sha512-TtpcNJ3XAzx3Gq8sWRzJaVajRs0uVxA2YAkdb1jm2YkPz4G6egUFAyA3n5vtEIZefPk5Wa4UXbKuS5fKkJWdgA==",
      "dev": true,
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/eslint": {
      "version": "8.57.0",
      "resolved": "https://registry.npmjs.org/eslint/-/eslint-8.57.0.tgz",
      "integrity": "sha512-dZ6+mexnaTIbSBZWgou51U6OmzIhYM2VcNdtiTtI7qPNZm35Akpr0f6vtw3w1Kmn5PYo+tZVfh13WrhpS6oLqQ==",
      "dev": true,
      "dependencies": {
        "@eslint-community/eslint-utils": "^4.2.0",
        "@eslint-community/regexpp": "^4.6.1",
        "@eslint/eslintrc": "^2.1.4",
        "@eslint/js": "8.57.0",
        "@humanwhocodes/config-array": "^0.11.14",
        "@humanwhocodes/module-importer": "^1.0.1",
        "@nodelib/fs.walk": "^1.2.8",
        "@ungap/structured-clone": "^1.2.0",
        "ajv": "^6.12.4",
        "chalk": "^4.0.0",
        "cross-spawn": "^7.0.2",
        "debug": "^4.3.2",
        "doctrine": "^3.0.0",
        "escape-string-regexp": "^4.0.0",
        "eslint-scope": "^7.2.2",
        "eslint-visitor-keys": "^3.4.3",
        "espree": "^9.6.1",
        "esquery": "^1.4.2",
        "esutils": "^2.0.2",
        "fast-deep-equal": "^3.1.3",
        "file-entry-cache": "^6.0.1",
        "find-up": "^5.0.0",
        "glob-parent": "^6.0.2",
        "globals": "^13.19.0",
        "graphemer": "^1.4.0",
        "ignore": "^5.2.0",
        "imurmurhash": "^0.1.4",
        "is-glob": "^4.0.0",
        "is-path-inside": "^3.0.3",
        "js-yaml": "^4.1.0",
        "json-stable-stringify-without-jsonify": "^1.0.1",
        "levn": "^0.4.1",
        "lodash.merge": "^4.6.2",
        "minimatch": "^3.1.2",
        "natural-compare": "^1.4.0",
        "optionator": "^0.9.3",
        "strip-ansi": "^6.0.1",
        "text-table": "^0.2.0"
      },
      "bin": {
        "eslint": "bin/eslint.js"
      },
      "engines": {
        "node": "^12.22.0 || ^14.17.0 || >=16.0.0"
      },
      "funding": {
        "url": "https://opencollective.com/eslint"
      }
    },
    "node_modules/eslint-config-next": {
      "version": "14.2.2",
      "resolved": "https://registry.npmjs.org/eslint-config-next/-/eslint-config-next-14.2.2.tgz",
      "integrity": "sha512-12/uFc0KX+wUs7EDpOUGKMXBXZJiBVGdK5/m/QgXOCg2mQ0bQWoKSWNrCeOg7Vum6Kw1d1TW453W6xh+GbHquw==",
      "dev": true,
      "dependencies": {
        "@next/eslint-plugin-next": "14.2.2",
        "@rushstack/eslint-patch": "^1.3.3",
        "@typescript-eslint/parser": "^5.4.2 || ^6.0.0 || 7.0.0 - 7.2.0",
        "eslint-import-resolver-node": "^0.3.6",
        "eslint-import-resolver-typescript": "^3.5.2",
        "eslint-plugin-import": "^2.28.1",
        "eslint-plugin-jsx-a11y": "^6.7.1",
        "eslint-plugin-react": "^7.33.2",
        "eslint-plugin-react-hooks": "^4.5.0 || 5.0.0-canary-7118f5dd7-20230705"
      },
      "peerDependencies": {
        "eslint": "^7.23.0 || ^8.0.0",
        "typescript": ">=3.3.1"
      },
      "peerDependenciesMeta": {
        "typescript": {
          "optional": true
        }
      }
    },
    "node_modules/eslint-import-resolver-node": {
      "version": "0.3.9",
      "resolved": "https://registry.npmjs.org/eslint-import-resolver-node/-/eslint-import-resolver-node-0.3.9.tgz",
      "integrity": "sha512-WFj2isz22JahUv+B788TlO3N6zL3nNJGU8CcZbPZvVEkBPaJdCV4vy5wyghty5ROFbCRnm132v8BScu5/1BQ8g==",
      "dev": true,
      "dependencies": {
        "debug": "^3.2.7",
        "is-core-module": "^2.13.0",
        "resolve": "^1.22.4"
      }
    },
    "node_modules/eslint-import-resolver-node/node_modules/debug": {
      "version": "3.2.7",
      "resolved": "https://registry.npmjs.org/debug/-/debug-3.2.7.tgz",
      "integrity": "sha512-CFjzYYAi4ThfiQvizrFQevTTXHtnCqWfe7x1AhgEscTz6ZbLbfoLRLPugTQyBth6f8ZERVUSyWHFD/7Wu4t1XQ==",
      "dev": true,
      "dependencies": {
        "ms": "^2.1.1"
      }
    },
    "node_modules/eslint-import-resolver-typescript": {
      "version": "3.6.1",
      "resolved": "https://registry.npmjs.org/eslint-import-resolver-typescript/-/eslint-import-resolver-typescript-3.6.1.tgz",
      "integrity": "sha512-xgdptdoi5W3niYeuQxKmzVDTATvLYqhpwmykwsh7f6HIOStGWEIL9iqZgQDF9u9OEzrRwR8no5q2VT+bjAujTg==",
      "dev": true,
      "dependencies": {
        "debug": "^4.3.4",
        "enhanced-resolve": "^5.12.0",
        "eslint-module-utils": "^2.7.4",
        "fast-glob": "^3.3.1",
        "get-tsconfig": "^4.5.0",
        "is-core-module": "^2.11.0",
        "is-glob": "^4.0.3"
      },
      "engines": {
        "node": "^14.18.0 || >=16.0.0"
      },
      "funding": {
        "url": "https://opencollective.com/unts/projects/eslint-import-resolver-ts"
      },
      "peerDependencies": {
        "eslint": "*",
        "eslint-plugin-import": "*"
      }
    },
    "node_modules/eslint-module-utils": {
      "version": "2.8.1",
      "resolved": "https://registry.npmjs.org/eslint-module-utils/-/eslint-module-utils-2.8.1.tgz",
      "integrity": "sha512-rXDXR3h7cs7dy9RNpUlQf80nX31XWJEyGq1tRMo+6GsO5VmTe4UTwtmonAD4ZkAsrfMVDA2wlGJ3790Ys+D49Q==",
      "dev": true,
      "dependencies": {
        "debug": "^3.2.7"
      },
      "engines": {
        "node": ">=4"
      },
      "peerDependenciesMeta": {
        "eslint": {
          "optional": true
        }
      }
    },
    "node_modules/eslint-module-utils/node_modules/debug": {
      "version": "3.2.7",
      "resolved": "https://registry.npmjs.org/debug/-/debug-3.2.7.tgz",
      "integrity": "sha512-CFjzYYAi4ThfiQvizrFQevTTXHtnCqWfe7x1AhgEscTz6ZbLbfoLRLPugTQyBth6f8ZERVUSyWHFD/7Wu4t1XQ==",
      "dev": true,
      "dependencies": {
        "ms": "^2.1.1"
      }
    },
    "node_modules/eslint-plugin-import": {
      "version": "2.29.1",
      "resolved": "https://registry.npmjs.org/eslint-plugin-import/-/eslint-plugin-import-2.29.1.tgz",
      "integrity": "sha512-BbPC0cuExzhiMo4Ff1BTVwHpjjv28C5R+btTOGaCRC7UEz801up0JadwkeSk5Ued6TG34uaczuVuH6qyy5YUxw==",
      "dev": true,
      "dependencies": {
        "array-includes": "^3.1.7",
        "array.prototype.findlastindex": "^1.2.3",
        "array.prototype.flat": "^1.3.2",
        "array.prototype.flatmap": "^1.3.2",
        "debug": "^3.2.7",
        "doctrine": "^2.1.0",
        "eslint-import-resolver-node": "^0.3.9",
        "eslint-module-utils": "^2.8.0",
        "hasown": "^2.0.0",
        "is-core-module": "^2.13.1",
        "is-glob": "^4.0.3",
        "minimatch": "^3.1.2",
        "object.fromentries": "^2.0.7",
        "object.groupby": "^1.0.1",
        "object.values": "^1.1.7",
        "semver": "^6.3.1",
        "tsconfig-paths": "^3.15.0"
      },
      "engines": {
        "node": ">=4"
      },
      "peerDependencies": {
        "eslint": "^2 || ^3 || ^4 || ^5 || ^6 || ^7.2.0 || ^8"
      }
    },
    "node_modules/eslint-plugin-import/node_modules/debug": {
      "version": "3.2.7",
      "resolved": "https://registry.npmjs.org/debug/-/debug-3.2.7.tgz",
      "integrity": "sha512-CFjzYYAi4ThfiQvizrFQevTTXHtnCqWfe7x1AhgEscTz6ZbLbfoLRLPugTQyBth6f8ZERVUSyWHFD/7Wu4t1XQ==",
      "dev": true,
      "dependencies": {
        "ms": "^2.1.1"
      }
    },
    "node_modules/eslint-plugin-import/node_modules/doctrine": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/doctrine/-/doctrine-2.1.0.tgz",
      "integrity": "sha512-35mSku4ZXK0vfCuHEDAwt55dg2jNajHZ1odvF+8SSr82EsZY4QmXfuWso8oEd8zRhVObSN18aM0CjSdoBX7zIw==",
      "dev": true,
      "dependencies": {
        "esutils": "^2.0.2"
      },
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/eslint-plugin-import/node_modules/semver": {
      "version": "6.3.1",
      "resolved": "https://registry.npmjs.org/semver/-/semver-6.3.1.tgz",
      "integrity": "sha512-BR7VvDCVHO+q2xBEWskxS6DJE1qRnb7DxzUrogb71CWoSficBxYsiAGd+Kl0mmq/MprG9yArRkyrQxTO6XjMzA==",
      "dev": true,
      "bin": {
        "semver": "bin/semver.js"
      }
    },
    "node_modules/eslint-plugin-jsx-a11y": {
      "version": "6.8.0",
      "resolved": "https://registry.npmjs.org/eslint-plugin-jsx-a11y/-/eslint-plugin-jsx-a11y-6.8.0.tgz",
      "integrity": "sha512-Hdh937BS3KdwwbBaKd5+PLCOmYY6U4f2h9Z2ktwtNKvIdIEu137rjYbcb9ApSbVJfWxANNuiKTD/9tOKjK9qOA==",
      "dev": true,
      "dependencies": {
        "@babel/runtime": "^7.23.2",
        "aria-query": "^5.3.0",
        "array-includes": "^3.1.7",
        "array.prototype.flatmap": "^1.3.2",
        "ast-types-flow": "^0.0.8",
        "axe-core": "=4.7.0",
        "axobject-query": "^3.2.1",
        "damerau-levenshtein": "^1.0.8",
        "emoji-regex": "^9.2.2",
        "es-iterator-helpers": "^1.0.15",
        "hasown": "^2.0.0",
        "jsx-ast-utils": "^3.3.5",
        "language-tags": "^1.0.9",
        "minimatch": "^3.1.2",
        "object.entries": "^1.1.7",
        "object.fromentries": "^2.0.7"
      },
      "engines": {
        "node": ">=4.0"
      },
      "peerDependencies": {
        "eslint": "^3 || ^4 || ^5 || ^6 || ^7 || ^8"
      }
    },
    "node_modules/eslint-plugin-react": {
      "version": "7.34.1",
      "resolved": "https://registry.npmjs.org/eslint-plugin-react/-/eslint-plugin-react-7.34.1.tgz",
      "integrity": "sha512-N97CxlouPT1AHt8Jn0mhhN2RrADlUAsk1/atcT2KyA/l9Q/E6ll7OIGwNumFmWfZ9skV3XXccYS19h80rHtgkw==",
      "dev": true,
      "dependencies": {
        "array-includes": "^3.1.7",
        "array.prototype.findlast": "^1.2.4",
        "array.prototype.flatmap": "^1.3.2",
        "array.prototype.toreversed": "^1.1.2",
        "array.prototype.tosorted": "^1.1.3",
        "doctrine": "^2.1.0",
        "es-iterator-helpers": "^1.0.17",
        "estraverse": "^5.3.0",
        "jsx-ast-utils": "^2.4.1 || ^3.0.0",
        "minimatch": "^3.1.2",
        "object.entries": "^1.1.7",
        "object.fromentries": "^2.0.7",
        "object.hasown": "^1.1.3",
        "object.values": "^1.1.7",
        "prop-types": "^15.8.1",
        "resolve": "^2.0.0-next.5",
        "semver": "^6.3.1",
        "string.prototype.matchall": "^4.0.10"
      },
      "engines": {
        "node": ">=4"
      },
      "peerDependencies": {
        "eslint": "^3 || ^4 || ^5 || ^6 || ^7 || ^8"
      }
    },
    "node_modules/eslint-plugin-react-hooks": {
      "version": "4.6.0",
      "resolved": "https://registry.npmjs.org/eslint-plugin-react-hooks/-/eslint-plugin-react-hooks-4.6.0.tgz",
      "integrity": "sha512-oFc7Itz9Qxh2x4gNHStv3BqJq54ExXmfC+a1NjAta66IAN87Wu0R/QArgIS9qKzX3dXKPI9H5crl9QchNMY9+g==",
      "dev": true,
      "engines": {
        "node": ">=10"
      },
      "peerDependencies": {
        "eslint": "^3.0.0 || ^4.0.0 || ^5.0.0 || ^6.0.0 || ^7.0.0 || ^8.0.0-0"
      }
    },
    "node_modules/eslint-plugin-react/node_modules/doctrine": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/doctrine/-/doctrine-2.1.0.tgz",
      "integrity": "sha512-35mSku4ZXK0vfCuHEDAwt55dg2jNajHZ1odvF+8SSr82EsZY4QmXfuWso8oEd8zRhVObSN18aM0CjSdoBX7zIw==",
      "dev": true,
      "dependencies": {
        "esutils": "^2.0.2"
      },
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/eslint-plugin-react/node_modules/resolve": {
      "version": "2.0.0-next.5",
      "resolved": "https://registry.npmjs.org/resolve/-/resolve-2.0.0-next.5.tgz",
      "integrity": "sha512-U7WjGVG9sH8tvjW5SmGbQuui75FiyjAX72HX15DwBBwF9dNiQZRQAg9nnPhYy+TUnE0+VcrttuvNI8oSxZcocA==",
      "dev": true,
      "dependencies": {
        "is-core-module": "^2.13.0",
        "path-parse": "^1.0.7",
        "supports-preserve-symlinks-flag": "^1.0.0"
      },
      "bin": {
        "resolve": "bin/resolve"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/eslint-plugin-react/node_modules/semver": {
      "version": "6.3.1",
      "resolved": "https://registry.npmjs.org/semver/-/semver-6.3.1.tgz",
      "integrity": "sha512-BR7VvDCVHO+q2xBEWskxS6DJE1qRnb7DxzUrogb71CWoSficBxYsiAGd+Kl0mmq/MprG9yArRkyrQxTO6XjMzA==",
      "dev": true,
      "bin": {
        "semver": "bin/semver.js"
      }
    },
    "node_modules/eslint-scope": {
      "version": "7.2.2",
      "resolved": "https://registry.npmjs.org/eslint-scope/-/eslint-scope-7.2.2.tgz",
      "integrity": "sha512-dOt21O7lTMhDM+X9mB4GX+DZrZtCUJPL/wlcTqxyrx5IvO0IYtILdtrQGQp+8n5S0gwSVmOf9NQrjMOgfQZlIg==",
      "dev": true,
      "dependencies": {
        "esrecurse": "^4.3.0",
        "estraverse": "^5.2.0"
      },
      "engines": {
        "node": "^12.22.0 || ^14.17.0 || >=16.0.0"
      },
      "funding": {
        "url": "https://opencollective.com/eslint"
      }
    },
    "node_modules/eslint-visitor-keys": {
      "version": "3.4.3",
      "resolved": "https://registry.npmjs.org/eslint-visitor-keys/-/eslint-visitor-keys-3.4.3.tgz",
      "integrity": "sha512-wpc+LXeiyiisxPlEkUzU6svyS1frIO3Mgxj1fdy7Pm8Ygzguax2N3Fa/D/ag1WqbOprdI+uY6wMUl8/a2G+iag==",
      "dev": true,
      "engines": {
        "node": "^12.22.0 || ^14.17.0 || >=16.0.0"
      },
      "funding": {
        "url": "https://opencollective.com/eslint"
      }
    },
    "node_modules/espree": {
      "version": "9.6.1",
      "resolved": "https://registry.npmjs.org/espree/-/espree-9.6.1.tgz",
      "integrity": "sha512-oruZaFkjorTpF32kDSI5/75ViwGeZginGGy2NoOSg3Q9bnwlnmDm4HLnkl0RE3n+njDXR037aY1+x58Z/zFdwQ==",
      "dev": true,
      "dependencies": {
        "acorn": "^8.9.0",
        "acorn-jsx": "^5.3.2",
        "eslint-visitor-keys": "^3.4.1"
      },
      "engines": {
        "node": "^12.22.0 || ^14.17.0 || >=16.0.0"
      },
      "funding": {
        "url": "https://opencollective.com/eslint"
      }
    },
    "node_modules/esquery": {
      "version": "1.5.0",
      "resolved": "https://registry.npmjs.org/esquery/-/esquery-1.5.0.tgz",
      "integrity": "sha512-YQLXUplAwJgCydQ78IMJywZCceoqk1oH01OERdSAJc/7U2AylwjhSCLDEtqwg811idIS/9fIU5GjG73IgjKMVg==",
      "dev": true,
      "dependencies": {
        "estraverse": "^5.1.0"
      },
      "engines": {
        "node": ">=0.10"
      }
    },
    "node_modules/esrecurse": {
      "version": "4.3.0",
      "resolved": "https://registry.npmjs.org/esrecurse/-/esrecurse-4.3.0.tgz",
      "integrity": "sha512-KmfKL3b6G+RXvP8N1vr3Tq1kL/oCFgn2NYXEtqP8/L3pKapUA4G8cFVaoF3SU323CD4XypR/ffioHmkti6/Tag==",
      "dev": true,
      "dependencies": {
        "estraverse": "^5.2.0"
      },
      "engines": {
        "node": ">=4.0"
      }
    },
    "node_modules/estraverse": {
      "version": "5.3.0",
      "resolved": "https://registry.npmjs.org/estraverse/-/estraverse-5.3.0.tgz",
      "integrity": "sha512-MMdARuVEQziNTeJD8DgMqmhwR11BRQ/cBP+pLtYdSTnf3MIO8fFeiINEbX36ZdNlfU/7A9f3gUw49B3oQsvwBA==",
      "dev": true,
      "engines": {
        "node": ">=4.0"
      }
    },
    "node_modules/esutils": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/esutils/-/esutils-2.0.3.tgz",
      "integrity": "sha512-kVscqXk4OCp68SZ0dkgEKVi6/8ij300KBWTJq32P/dYeWTSwK41WyTxalN1eRmA5Z9UU/LX9D7FWSmV9SAYx6g==",
      "dev": true,
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/fast-deep-equal": {
      "version": "3.1.3",
      "resolved": "https://registry.npmjs.org/fast-deep-equal/-/fast-deep-equal-3.1.3.tgz",
      "integrity": "sha512-f3qQ9oQy9j2AhBe/H9VC91wLmKBCCU/gDOnKNAYG5hswO7BLKj09Hc5HYNz9cGI++xlpDCIgDaitVs03ATR84Q==",
      "dev": true
    },
    "node_modules/fast-glob": {
      "version": "3.3.2",
      "resolved": "https://registry.npmjs.org/fast-glob/-/fast-glob-3.3.2.tgz",
      "integrity": "sha512-oX2ruAFQwf/Orj8m737Y5adxDQO0LAB7/S5MnxCdTNDd4p6BsyIVsv9JQsATbTSq8KHRpLwIHbVlUNatxd+1Ow==",
      "dev": true,
      "dependencies": {
        "@nodelib/fs.stat": "^2.0.2",
        "@nodelib/fs.walk": "^1.2.3",
        "glob-parent": "^5.1.2",
        "merge2": "^1.3.0",
        "micromatch": "^4.0.4"
      },
      "engines": {
        "node": ">=8.6.0"
      }
    },
    "node_modules/fast-glob/node_modules/glob-parent": {
      "version": "5.1.2",
      "resolved": "https://registry.npmjs.org/glob-parent/-/glob-parent-5.1.2.tgz",
      "integrity": "sha512-AOIgSQCepiJYwP3ARnGx+5VnTu2HBYdzbGP45eLw1vr3zB3vZLeyed1sC9hnbcOc9/SrMyM5RPQrkGz4aS9Zow==",
      "dev": true,
      "dependencies": {
        "is-glob": "^4.0.1"
      },
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/fast-json-stable-stringify": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/fast-json-stable-stringify/-/fast-json-stable-stringify-2.1.0.tgz",
      "integrity": "sha512-lhd/wF+Lk98HZoTCtlVraHtfh5XYijIjalXck7saUtuanSDyLMxnHhSXEDJqHxD7msR8D0uCmqlkwjCV8xvwHw==",
      "dev": true
    },
    "node_modules/fast-levenshtein": {
      "version": "2.0.6",
      "resolved": "https://registry.npmjs.org/fast-levenshtein/-/fast-levenshtein-2.0.6.tgz",
      "integrity": "sha512-DCXu6Ifhqcks7TZKY3Hxp3y6qphY5SJZmrWMDrKcERSOXWQdMhU9Ig/PYrzyw/ul9jOIyh0N4M0tbC5hodg8dw==",
      "dev": true
    },
    "node_modules/fastq": {
      "version": "1.17.1",
      "resolved": "https://registry.npmjs.org/fastq/-/fastq-1.17.1.tgz",
      "integrity": "sha512-sRVD3lWVIXWg6By68ZN7vho9a1pQcN/WBFaAAsDDFzlJjvoGx0P8z7V1t72grFJfJhu3YPZBuu25f7Kaw2jN1w==",
      "dev": true,
      "dependencies": {
        "reusify": "^1.0.4"
      }
    },
    "node_modules/file-entry-cache": {
      "version": "6.0.1",
      "resolved": "https://registry.npmjs.org/file-entry-cache/-/file-entry-cache-6.0.1.tgz",
      "integrity": "sha512-7Gps/XWymbLk2QLYK4NzpMOrYjMhdIxXuIvy2QBsLE6ljuodKvdkWs/cpyJJ3CVIVpH0Oi1Hvg1ovbMzLdFBBg==",
      "dev": true,
      "dependencies": {
        "flat-cache": "^3.0.4"
      },
      "engines": {
        "node": "^10.12.0 || >=12.0.0"
      }
    },
    "node_modules/fill-range": {
      "version": "7.0.1",
      "resolved": "https://registry.npmjs.org/fill-range/-/fill-range-7.0.1.tgz",
      "integrity": "sha512-qOo9F+dMUmC2Lcb4BbVvnKJxTPjCm+RRpe4gDuGrzkL7mEVl/djYSu2OdQ2Pa302N4oqkSg9ir6jaLWJ2USVpQ==",
      "dev": true,
      "dependencies": {
        "to-regex-range": "^5.0.1"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/find-up": {
      "version": "5.0.0",
      "resolved": "https://registry.npmjs.org/find-up/-/find-up-5.0.0.tgz",
      "integrity": "sha512-78/PXT1wlLLDgTzDs7sjq9hzz0vXD+zn+7wypEe4fXQxCmdmqfGsEPQxmiCSQI3ajFV91bVSsvNtrJRiW6nGng==",
      "dev": true,
      "dependencies": {
        "locate-path": "^6.0.0",
        "path-exists": "^4.0.0"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/flat-cache": {
      "version": "3.2.0",
      "resolved": "https://registry.npmjs.org/flat-cache/-/flat-cache-3.2.0.tgz",
      "integrity": "sha512-CYcENa+FtcUKLmhhqyctpclsq7QF38pKjZHsGNiSQF5r4FtoKDWabFDl3hzaEQMvT1LHEysw5twgLvpYYb4vbw==",
      "dev": true,
      "dependencies": {
        "flatted": "^3.2.9",
        "keyv": "^4.5.3",
        "rimraf": "^3.0.2"
      },
      "engines": {
        "node": "^10.12.0 || >=12.0.0"
      }
    },
    "node_modules/flatted": {
      "version": "3.3.1",
      "resolved": "https://registry.npmjs.org/flatted/-/flatted-3.3.1.tgz",
      "integrity": "sha512-X8cqMLLie7KsNUDSdzeN8FYK9rEt4Dt67OsG/DNGnYTSDBG4uFAJFBnUeiV+zCVAvwFy56IjM9sH51jVaEhNxw==",
      "dev": true
    },
    "node_modules/for-each": {
      "version": "0.3.3",
      "resolved": "https://registry.npmjs.org/for-each/-/for-each-0.3.3.tgz",
      "integrity": "sha512-jqYfLp7mo9vIyQf8ykW2v7A+2N4QjeCeI5+Dz9XraiO1ign81wjiH7Fb9vSOWvQfNtmSa4H2RoQTrrXivdUZmw==",
      "dev": true,
      "dependencies": {
        "is-callable": "^1.1.3"
      }
    },
    "node_modules/foreground-child": {
      "version": "3.1.1",
      "resolved": "https://registry.npmjs.org/foreground-child/-/foreground-child-3.1.1.tgz",
      "integrity": "sha512-TMKDUnIte6bfb5nWv7V/caI169OHgvwjb7V4WkeUvbQQdjr5rWKqHFiKWb/fcOwB+CzBT+qbWjvj+DVwRskpIg==",
      "dev": true,
      "dependencies": {
        "cross-spawn": "^7.0.0",
        "signal-exit": "^4.0.1"
      },
      "engines": {
        "node": ">=14"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/fs.realpath": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/fs.realpath/-/fs.realpath-1.0.0.tgz",
      "integrity": "sha512-OO0pH2lK6a0hZnAdau5ItzHPI6pUlvI7jMVnxUQRtw4owF2wk8lOSabtGDCTP4Ggrg2MbGnWO9X8K1t4+fGMDw==",
      "dev": true
    },
    "node_modules/fsevents": {
      "version": "2.3.3",
      "resolved": "https://registry.npmjs.org/fsevents/-/fsevents-2.3.3.tgz",
      "integrity": "sha512-5xoDfX+fL7faATnagmWPpbFtwh/R77WmMMqqHGS65C3vvB0YHrgF+B1YmZ3441tMj5n63k0212XNoJwzlhffQw==",
      "dev": true,
      "hasInstallScript": true,
      "optional": true,
      "os": [
        "darwin"
      ],
      "engines": {
        "node": "^8.16.0 || ^10.6.0 || >=11.0.0"
      }
    },
    "node_modules/function-bind": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/function-bind/-/function-bind-1.1.2.tgz",
      "integrity": "sha512-7XHNxH7qX9xG5mIwxkhumTox/MIRNcOgDrxWsMt2pAr23WHp6MrRlN7FBSFpCpr+oVO0F744iUgR82nJMfG2SA==",
      "dev": true,
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/function.prototype.name": {
      "version": "1.1.6",
      "resolved": "https://registry.npmjs.org/function.prototype.name/-/function.prototype.name-1.1.6.tgz",
      "integrity": "sha512-Z5kx79swU5P27WEayXM1tBi5Ze/lbIyiNgU3qyXUOf9b2rgXYyF9Dy9Cx+IQv/Lc8WCG6L82zwUPpSS9hGehIg==",
      "dev": true,
      "dependencies": {
        "call-bind": "^1.0.2",
        "define-properties": "^1.2.0",
        "es-abstract": "^1.22.1",
        "functions-have-names": "^1.2.3"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/functions-have-names": {
      "version": "1.2.3",
      "resolved": "https://registry.npmjs.org/functions-have-names/-/functions-have-names-1.2.3.tgz",
      "integrity": "sha512-xckBUXyTIqT97tq2x2AMb+g163b5JFysYk0x4qxNFwbfQkmNZoiRHb6sPzI9/QV33WeuvVYBUIiD4NzNIyqaRQ==",
      "dev": true,
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/get-intrinsic": {
      "version": "1.2.4",
      "resolved": "https://registry.npmjs.org/get-intrinsic/-/get-intrinsic-1.2.4.tgz",
      "integrity": "sha512-5uYhsJH8VJBTv7oslg4BznJYhDoRI6waYCxMmCdnTrcCrHA/fCFKoTFz2JKKE0HdDFUF7/oQuhzumXJK7paBRQ==",
      "dev": true,
      "dependencies": {
        "es-errors": "^1.3.0",
        "function-bind": "^1.1.2",
        "has-proto": "^1.0.1",
        "has-symbols": "^1.0.3",
        "hasown": "^2.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/get-symbol-description": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/get-symbol-description/-/get-symbol-description-1.0.2.tgz",
      "integrity": "sha512-g0QYk1dZBxGwk+Ngc+ltRH2IBp2f7zBkBMBJZCDerh6EhlhSR6+9irMCuT/09zD6qkarHUSn529sK/yL4S27mg==",
      "dev": true,
      "dependencies": {
        "call-bind": "^1.0.5",
        "es-errors": "^1.3.0",
        "get-intrinsic": "^1.2.4"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/get-tsconfig": {
      "version": "4.7.3",
      "resolved": "https://registry.npmjs.org/get-tsconfig/-/get-tsconfig-4.7.3.tgz",
      "integrity": "sha512-ZvkrzoUA0PQZM6fy6+/Hce561s+faD1rsNwhnO5FelNjyy7EMGJ3Rz1AQ8GYDWjhRs/7dBLOEJvhK8MiEJOAFg==",
      "dev": true,
      "dependencies": {
        "resolve-pkg-maps": "^1.0.0"
      },
      "funding": {
        "url": "https://github.com/privatenumber/get-tsconfig?sponsor=1"
      }
    },
    "node_modules/glob": {
      "version": "10.3.10",
      "resolved": "https://registry.npmjs.org/glob/-/glob-10.3.10.tgz",
      "integrity": "sha512-fa46+tv1Ak0UPK1TOy/pZrIybNNt4HCv7SDzwyfiOZkvZLEbjsZkJBPtDHVshZjbecAoAGSC20MjLDG/qr679g==",
      "dev": true,
      "dependencies": {
        "foreground-child": "^3.1.0",
        "jackspeak": "^2.3.5",
        "minimatch": "^9.0.1",
        "minipass": "^5.0.0 || ^6.0.2 || ^7.0.0",
        "path-scurry": "^1.10.1"
      },
      "bin": {
        "glob": "dist/esm/bin.mjs"
      },
      "engines": {
        "node": ">=16 || 14 >=14.17"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/glob-parent": {
      "version": "6.0.2",
      "resolved": "https://registry.npmjs.org/glob-parent/-/glob-parent-6.0.2.tgz",
      "integrity": "sha512-XxwI8EOhVQgWp6iDL+3b0r86f4d6AX6zSU55HfB4ydCEuXLXc5FcYeOu+nnGftS4TEju/11rt4KJPTMgbfmv4A==",
      "dev": true,
      "dependencies": {
        "is-glob": "^4.0.3"
      },
      "engines": {
        "node": ">=10.13.0"
      }
    },
    "node_modules/glob/node_modules/brace-expansion": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/brace-expansion/-/brace-expansion-2.0.1.tgz",
      "integrity": "sha512-XnAIvQ8eM+kC6aULx6wuQiwVsnzsi9d3WxzV3FpWTGA19F621kwdbsAcFKXgKUHZWsy+mY6iL1sHTxWEFCytDA==",
      "dev": true,
      "dependencies": {
        "balanced-match": "^1.0.0"
      }
    },
    "node_modules/glob/node_modules/minimatch": {
      "version": "9.0.4",
      "resolved": "https://registry.npmjs.org/minimatch/-/minimatch-9.0.4.tgz",
      "integrity": "sha512-KqWh+VchfxcMNRAJjj2tnsSJdNbHsVgnkBhTNrW7AjVo6OvLtxw8zfT9oLw1JSohlFzJ8jCoTgaoXvJ+kHt6fw==",
      "dev": true,
      "dependencies": {
        "brace-expansion": "^2.0.1"
      },
      "engines": {
        "node": ">=16 || 14 >=14.17"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/globals": {
      "version": "13.24.0",
      "resolved": "https://registry.npmjs.org/globals/-/globals-13.24.0.tgz",
      "integrity": "sha512-AhO5QUcj8llrbG09iWhPU2B204J1xnPeL8kQmVorSsy+Sjj1sk8gIyh6cUocGmH4L0UuhAJy+hJMRA4mgA4mFQ==",
      "dev": true,
      "dependencies": {
        "type-fest": "^0.20.2"
      },
      "engines": {
        "node": ">=8"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/globalthis": {
      "version": "1.0.3",
      "resolved": "https://registry.npmjs.org/globalthis/-/globalthis-1.0.3.tgz",
      "integrity": "sha512-sFdI5LyBiNTHjRd7cGPWapiHWMOXKyuBNX/cWJ3NfzrZQVa8GI/8cofCl74AOVqq9W5kNmguTIzJ/1s2gyI9wA==",
      "dev": true,
      "dependencies": {
        "define-properties": "^1.1.3"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/globby": {
      "version": "11.1.0",
      "resolved": "https://registry.npmjs.org/globby/-/globby-11.1.0.tgz",
      "integrity": "sha512-jhIXaOzy1sb8IyocaruWSn1TjmnBVs8Ayhcy83rmxNJ8q2uWKCAj3CnJY+KpGSXCueAPc0i05kVvVKtP1t9S3g==",
      "dev": true,
      "dependencies": {
        "array-union": "^2.1.0",
        "dir-glob": "^3.0.1",
        "fast-glob": "^3.2.9",
        "ignore": "^5.2.0",
        "merge2": "^1.4.1",
        "slash": "^3.0.0"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/gopd": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/gopd/-/gopd-1.0.1.tgz",
      "integrity": "sha512-d65bNlIadxvpb/A2abVdlqKqV563juRnZ1Wtk6s1sIR8uNsXR70xqIzVqxVf1eTqDunwT2MkczEeaezCKTZhwA==",
      "dev": true,
      "dependencies": {
        "get-intrinsic": "^1.1.3"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/graceful-fs": {
      "version": "4.2.11",
      "resolved": "https://registry.npmjs.org/graceful-fs/-/graceful-fs-4.2.11.tgz",
      "integrity": "sha512-RbJ5/jmFcNNCcDV5o9eTnBLJ/HszWV0P73bc+Ff4nS/rJj+YaS6IGyiOL0VoBYX+l1Wrl3k63h/KrH+nhJ0XvQ=="
    },
    "node_modules/graphemer": {
      "version": "1.4.0",
      "resolved": "https://registry.npmjs.org/graphemer/-/graphemer-1.4.0.tgz",
      "integrity": "sha512-EtKwoO6kxCL9WO5xipiHTZlSzBm7WLT627TqC/uVRd0HKmq8NXyebnNYxDoBi7wt8eTWrUrKXCOVaFq9x1kgag==",
      "dev": true
    },
    "node_modules/has-bigints": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/has-bigints/-/has-bigints-1.0.2.tgz",
      "integrity": "sha512-tSvCKtBr9lkF0Ex0aQiP9N+OpV4zi2r/Nee5VkRDbaqv35RLYMzbwQfFSZZH0kR+Rd6302UJZ2p/bJCEoR3VoQ==",
      "dev": true,
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/has-flag": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/has-flag/-/has-flag-4.0.0.tgz",
      "integrity": "sha512-EykJT/Q1KjTWctppgIAgfSO0tKVuZUjhgMr17kqTumMl6Afv3EISleU7qZUzoXDFTAHTDC4NOoG/ZxU3EvlMPQ==",
      "dev": true,
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/has-property-descriptors": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/has-property-descriptors/-/has-property-descriptors-1.0.2.tgz",
      "integrity": "sha512-55JNKuIW+vq4Ke1BjOTjM2YctQIvCT7GFzHwmfZPGo5wnrgkid0YQtnAleFSqumZm4az3n2BS+erby5ipJdgrg==",
      "dev": true,
      "dependencies": {
        "es-define-property": "^1.0.0"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/has-proto": {
      "version": "1.0.3",
      "resolved": "https://registry.npmjs.org/has-proto/-/has-proto-1.0.3.tgz",
      "integrity": "sha512-SJ1amZAJUiZS+PhsVLf5tGydlaVB8EdFpaSO4gmiUKUOxk8qzn5AIy4ZeJUmh22znIdk/uMAUT2pl3FxzVUH+Q==",
      "dev": true,
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/has-symbols": {
      "version": "1.0.3",
      "resolved": "https://registry.npmjs.org/has-symbols/-/has-symbols-1.0.3.tgz",
      "integrity": "sha512-l3LCuF6MgDNwTDKkdYGEihYjt5pRPbEg46rtlmnSPlUbgmB8LOIrKJbYYFBSbnPaJexMKtiPO8hmeRjRz2Td+A==",
      "dev": true,
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/has-tostringtag": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/has-tostringtag/-/has-tostringtag-1.0.2.tgz",
      "integrity": "sha512-NqADB8VjPFLM2V0VvHUewwwsw0ZWBaIdgo+ieHtK3hasLz4qeCRjYcqfB6AQrBggRKppKF8L52/VqdVsO47Dlw==",
      "dev": true,
      "dependencies": {
        "has-symbols": "^1.0.3"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/hasown": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/hasown/-/hasown-2.0.2.tgz",
      "integrity": "sha512-0hJU9SCPvmMzIBdZFqNPXWa6dqh7WdH0cII9y+CyS8rG3nL48Bclra9HmKhVVUHyPWNH5Y7xDwAB7bfgSjkUMQ==",
      "dev": true,
      "dependencies": {
        "function-bind": "^1.1.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/ignore": {
      "version": "5.3.1",
      "resolved": "https://registry.npmjs.org/ignore/-/ignore-5.3.1.tgz",
      "integrity": "sha512-5Fytz/IraMjqpwfd34ke28PTVMjZjJG2MPn5t7OE4eUCUNf8BAa7b5WUS9/Qvr6mwOQS7Mk6vdsMno5he+T8Xw==",
      "dev": true,
      "engines": {
        "node": ">= 4"
      }
    },
    "node_modules/import-fresh": {
      "version": "3.3.0",
      "resolved": "https://registry.npmjs.org/import-fresh/-/import-fresh-3.3.0.tgz",
      "integrity": "sha512-veYYhQa+D1QBKznvhUHxb8faxlrwUnxseDAbAp457E0wLNio2bOSKnjYDhMj+YiAq61xrMGhQk9iXVk5FzgQMw==",
      "dev": true,
      "dependencies": {
        "parent-module": "^1.0.0",
        "resolve-from": "^4.0.0"
      },
      "engines": {
        "node": ">=6"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/imurmurhash": {
      "version": "0.1.4",
      "resolved": "https://registry.npmjs.org/imurmurhash/-/imurmurhash-0.1.4.tgz",
      "integrity": "sha512-JmXMZ6wuvDmLiHEml9ykzqO6lwFbof0GG4IkcGaENdCRDDmMVnny7s5HsIgHCbaq0w2MyPhDqkhTUgS2LU2PHA==",
      "dev": true,
      "engines": {
        "node": ">=0.8.19"
      }
    },
    "node_modules/inflight": {
      "version": "1.0.6",
      "resolved": "https://registry.npmjs.org/inflight/-/inflight-1.0.6.tgz",
      "integrity": "sha512-k92I/b08q4wvFscXCLvqfsHCrjrF7yiXsQuIVvVE7N82W3+aqpzuUdBbfhWcy/FZR3/4IgflMgKLOsvPDrGCJA==",
      "dev": true,
      "dependencies": {
        "once": "^1.3.0",
        "wrappy": "1"
      }
    },
    "node_modules/inherits": {
      "version": "2.0.4",
      "resolved": "https://registry.npmjs.org/inherits/-/inherits-2.0.4.tgz",
      "integrity": "sha512-k/vGaX4/Yla3WzyMCvTQOXYeIHvqOKtnqBduzTHpzpQZzAskKMhZ2K+EnBiSM9zGSoIFeMpXKxa4dYeZIQqewQ==",
      "dev": true
    },
    "node_modules/internal-slot": {
      "version": "1.0.7",
      "resolved": "https://registry.npmjs.org/internal-slot/-/internal-slot-1.0.7.tgz",
      "integrity": "sha512-NGnrKwXzSms2qUUih/ILZ5JBqNTSa1+ZmP6flaIp6KmSElgE9qdndzS3cqjrDovwFdmwsGsLdeFgB6suw+1e9g==",
      "dev": true,
      "dependencies": {
        "es-errors": "^1.3.0",
        "hasown": "^2.0.0",
        "side-channel": "^1.0.4"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/is-array-buffer": {
      "version": "3.0.4",
      "resolved": "https://registry.npmjs.org/is-array-buffer/-/is-array-buffer-3.0.4.tgz",
      "integrity": "sha512-wcjaerHw0ydZwfhiKbXJWLDY8A7yV7KhjQOpb83hGgGfId/aQa4TOvwyzn2PuswW2gPCYEL/nEAiSVpdOj1lXw==",
      "dev": true,
      "dependencies": {
        "call-bind": "^1.0.2",
        "get-intrinsic": "^1.2.1"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-async-function": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/is-async-function/-/is-async-function-2.0.0.tgz",
      "integrity": "sha512-Y1JXKrfykRJGdlDwdKlLpLyMIiWqWvuSd17TvZk68PLAOGOoF4Xyav1z0Xhoi+gCYjZVeC5SI+hYFOfvXmGRCA==",
      "dev": true,
      "dependencies": {
        "has-tostringtag": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-bigint": {
      "version": "1.0.4",
      "resolved": "https://registry.npmjs.org/is-bigint/-/is-bigint-1.0.4.tgz",
      "integrity": "sha512-zB9CruMamjym81i2JZ3UMn54PKGsQzsJeo6xvN3HJJ4CAsQNB6iRutp2To77OfCNuoxspsIhzaPoO1zyCEhFOg==",
      "dev": true,
      "dependencies": {
        "has-bigints": "^1.0.1"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-binary-path": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/is-binary-path/-/is-binary-path-2.1.0.tgz",
      "integrity": "sha512-ZMERYes6pDydyuGidse7OsHxtbI7WVeUEozgR/g7rd0xUimYNlvZRE/K2MgZTjWy725IfelLeVcEM97mmtRGXw==",
      "dev": true,
      "dependencies": {
        "binary-extensions": "^2.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/is-boolean-object": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/is-boolean-object/-/is-boolean-object-1.1.2.tgz",
      "integrity": "sha512-gDYaKHJmnj4aWxyj6YHyXVpdQawtVLHU5cb+eztPGczf6cjuTdwve5ZIEfgXqH4e57An1D1AKf8CZ3kYrQRqYA==",
      "dev": true,
      "dependencies": {
        "call-bind": "^1.0.2",
        "has-tostringtag": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-callable": {
      "version": "1.2.7",
      "resolved": "https://registry.npmjs.org/is-callable/-/is-callable-1.2.7.tgz",
      "integrity": "sha512-1BC0BVFhS/p0qtw6enp8e+8OD0UrK0oFLztSjNzhcKA3WDuJxxAPXzPuPtKkjEY9UUoEWlX/8fgKeu2S8i9JTA==",
      "dev": true,
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-core-module": {
      "version": "2.13.1",
      "resolved": "https://registry.npmjs.org/is-core-module/-/is-core-module-2.13.1.tgz",
      "integrity": "sha512-hHrIjvZsftOsvKSn2TRYl63zvxsgE0K+0mYMoH6gD4omR5IWB2KynivBQczo3+wF1cCkjzvptnI9Q0sPU66ilw==",
      "dev": true,
      "dependencies": {
        "hasown": "^2.0.0"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-data-view": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/is-data-view/-/is-data-view-1.0.1.tgz",
      "integrity": "sha512-AHkaJrsUVW6wq6JS8y3JnM/GJF/9cf+k20+iDzlSaJrinEo5+7vRiteOSwBhHRiAyQATN1AmY4hwzxJKPmYf+w==",
      "dev": true,
      "dependencies": {
        "is-typed-array": "^1.1.13"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-date-object": {
      "version": "1.0.5",
      "resolved": "https://registry.npmjs.org/is-date-object/-/is-date-object-1.0.5.tgz",
      "integrity": "sha512-9YQaSxsAiSwcvS33MBk3wTCVnWK+HhF8VZR2jRxehM16QcVOdHqPn4VPHmRK4lSr38n9JriurInLcP90xsYNfQ==",
      "dev": true,
      "dependencies": {
        "has-tostringtag": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-extglob": {
      "version": "2.1.1",
      "resolved": "https://registry.npmjs.org/is-extglob/-/is-extglob-2.1.1.tgz",
      "integrity": "sha512-SbKbANkN603Vi4jEZv49LeVJMn4yGwsbzZworEoyEiutsN3nJYdbO36zfhGJ6QEDpOZIFkDtnq5JRxmvl3jsoQ==",
      "dev": true,
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/is-finalizationregistry": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/is-finalizationregistry/-/is-finalizationregistry-1.0.2.tgz",
      "integrity": "sha512-0by5vtUJs8iFQb5TYUHHPudOR+qXYIMKtiUzvLIZITZUjknFmziyBJuLhVRc+Ds0dREFlskDNJKYIdIzu/9pfw==",
      "dev": true,
      "dependencies": {
        "call-bind": "^1.0.2"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-fullwidth-code-point": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/is-fullwidth-code-point/-/is-fullwidth-code-point-3.0.0.tgz",
      "integrity": "sha512-zymm5+u+sCsSWyD9qNaejV3DFvhCKclKdizYaJUuHA83RLjb7nSuGnddCHGv0hk+KY7BMAlsWeK4Ueg6EV6XQg==",
      "dev": true,
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/is-generator-function": {
      "version": "1.0.10",
      "resolved": "https://registry.npmjs.org/is-generator-function/-/is-generator-function-1.0.10.tgz",
      "integrity": "sha512-jsEjy9l3yiXEQ+PsXdmBwEPcOxaXWLspKdplFUVI9vq1iZgIekeC0L167qeu86czQaxed3q/Uzuw0swL0irL8A==",
      "dev": true,
      "dependencies": {
        "has-tostringtag": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-glob": {
      "version": "4.0.3",
      "resolved": "https://registry.npmjs.org/is-glob/-/is-glob-4.0.3.tgz",
      "integrity": "sha512-xelSayHH36ZgE7ZWhli7pW34hNbNl8Ojv5KVmkJD4hBdD3th8Tfk9vYasLM+mXWOZhFkgZfxhLSnrwRr4elSSg==",
      "dev": true,
      "dependencies": {
        "is-extglob": "^2.1.1"
      },
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/is-map": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/is-map/-/is-map-2.0.3.tgz",
      "integrity": "sha512-1Qed0/Hr2m+YqxnM09CjA2d/i6YZNfF6R2oRAOj36eUdS6qIV/huPJNSEpKbupewFs+ZsJlxsjjPbc0/afW6Lw==",
      "dev": true,
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-negative-zero": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/is-negative-zero/-/is-negative-zero-2.0.3.tgz",
      "integrity": "sha512-5KoIu2Ngpyek75jXodFvnafB6DJgr3u8uuK0LEZJjrU19DrMD3EVERaR8sjz8CCGgpZvxPl9SuE1GMVPFHx1mw==",
      "dev": true,
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-number": {
      "version": "7.0.0",
      "resolved": "https://registry.npmjs.org/is-number/-/is-number-7.0.0.tgz",
      "integrity": "sha512-41Cifkg6e8TylSpdtTpeLVMqvSBEVzTttHvERD741+pnZ8ANv0004MRL43QKPDlK9cGvNp6NZWZUBlbGXYxxng==",
      "dev": true,
      "engines": {
        "node": ">=0.12.0"
      }
    },
    "node_modules/is-number-object": {
      "version": "1.0.7",
      "resolved": "https://registry.npmjs.org/is-number-object/-/is-number-object-1.0.7.tgz",
      "integrity": "sha512-k1U0IRzLMo7ZlYIfzRu23Oh6MiIFasgpb9X76eqfFZAqwH44UI4KTBvBYIZ1dSL9ZzChTB9ShHfLkR4pdW5krQ==",
      "dev": true,
      "dependencies": {
        "has-tostringtag": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-path-inside": {
      "version": "3.0.3",
      "resolved": "https://registry.npmjs.org/is-path-inside/-/is-path-inside-3.0.3.tgz",
      "integrity": "sha512-Fd4gABb+ycGAmKou8eMftCupSir5lRxqf4aD/vd0cD2qc4HL07OjCeuHMr8Ro4CoMaeCKDB0/ECBOVWjTwUvPQ==",
      "dev": true,
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/is-regex": {
      "version": "1.1.4",
      "resolved": "https://registry.npmjs.org/is-regex/-/is-regex-1.1.4.tgz",
      "integrity": "sha512-kvRdxDsxZjhzUX07ZnLydzS1TU/TJlTUHHY4YLL87e37oUA49DfkLqgy+VjFocowy29cKvcSiu+kIv728jTTVg==",
      "dev": true,
      "dependencies": {
        "call-bind": "^1.0.2",
        "has-tostringtag": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-set": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/is-set/-/is-set-2.0.3.tgz",
      "integrity": "sha512-iPAjerrse27/ygGLxw+EBR9agv9Y6uLeYVJMu+QNCoouJ1/1ri0mGrcWpfCqFZuzzx3WjtwxG098X+n4OuRkPg==",
      "dev": true,
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-shared-array-buffer": {
      "version": "1.0.3",
      "resolved": "https://registry.npmjs.org/is-shared-array-buffer/-/is-shared-array-buffer-1.0.3.tgz",
      "integrity": "sha512-nA2hv5XIhLR3uVzDDfCIknerhx8XUKnstuOERPNNIinXG7v9u+ohXF67vxm4TPTEPU6lm61ZkwP3c9PCB97rhg==",
      "dev": true,
      "dependencies": {
        "call-bind": "^1.0.7"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-string": {
      "version": "1.0.7",
      "resolved": "https://registry.npmjs.org/is-string/-/is-string-1.0.7.tgz",
      "integrity": "sha512-tE2UXzivje6ofPW7l23cjDOMa09gb7xlAqG6jG5ej6uPV32TlWP3NKPigtaGeHNu9fohccRYvIiZMfOOnOYUtg==",
      "dev": true,
      "dependencies": {
        "has-tostringtag": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-symbol": {
      "version": "1.0.4",
      "resolved": "https://registry.npmjs.org/is-symbol/-/is-symbol-1.0.4.tgz",
      "integrity": "sha512-C/CPBqKWnvdcxqIARxyOh4v1UUEOCHpgDa0WYgpKDFMszcrPcffg5uhwSgPCLD2WWxmq6isisz87tzT01tuGhg==",
      "dev": true,
      "dependencies": {
        "has-symbols": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-typed-array": {
      "version": "1.1.13",
      "resolved": "https://registry.npmjs.org/is-typed-array/-/is-typed-array-1.1.13.tgz",
      "integrity": "sha512-uZ25/bUAlUY5fR4OKT4rZQEBrzQWYV9ZJYGGsUmEJ6thodVJ1HX64ePQ6Z0qPWP+m+Uq6e9UugrE38jeYsDSMw==",
      "dev": true,
      "dependencies": {
        "which-typed-array": "^1.1.14"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-weakmap": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/is-weakmap/-/is-weakmap-2.0.2.tgz",
      "integrity": "sha512-K5pXYOm9wqY1RgjpL3YTkF39tni1XajUIkawTLUo9EZEVUFga5gSQJF8nNS7ZwJQ02y+1YCNYcMh+HIf1ZqE+w==",
      "dev": true,
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-weakref": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/is-weakref/-/is-weakref-1.0.2.tgz",
      "integrity": "sha512-qctsuLZmIQ0+vSSMfoVvyFe2+GSEvnmZ2ezTup1SBse9+twCCeial6EEi3Nc2KFcf6+qz2FBPnjXsk8xhKSaPQ==",
      "dev": true,
      "dependencies": {
        "call-bind": "^1.0.2"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-weakset": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/is-weakset/-/is-weakset-2.0.3.tgz",
      "integrity": "sha512-LvIm3/KWzS9oRFHugab7d+M/GcBXuXX5xZkzPmN+NxihdQlZUQ4dWuSV1xR/sq6upL1TJEDrfBgRepHFdBtSNQ==",
      "dev": true,
      "dependencies": {
        "call-bind": "^1.0.7",
        "get-intrinsic": "^1.2.4"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/isarray": {
      "version": "2.0.5",
      "resolved": "https://registry.npmjs.org/isarray/-/isarray-2.0.5.tgz",
      "integrity": "sha512-xHjhDr3cNBK0BzdUJSPXZntQUx/mwMS5Rw4A7lPJ90XGAO6ISP/ePDNuo0vhqOZU+UD5JoodwCAAoZQd3FeAKw==",
      "dev": true
    },
    "node_modules/isexe": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/isexe/-/isexe-2.0.0.tgz",
      "integrity": "sha512-RHxMLp9lnKHGHRng9QFhRCMbYAcVpn69smSGcq3f36xjgVVWThj4qqLbTLlq7Ssj8B+fIQ1EuCEGI2lKsyQeIw==",
      "dev": true
    },
    "node_modules/iterator.prototype": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/iterator.prototype/-/iterator.prototype-1.1.2.tgz",
      "integrity": "sha512-DR33HMMr8EzwuRL8Y9D3u2BMj8+RqSE850jfGu59kS7tbmPLzGkZmVSfyCFSDxuZiEY6Rzt3T2NA/qU+NwVj1w==",
      "dev": true,
      "dependencies": {
        "define-properties": "^1.2.1",
        "get-intrinsic": "^1.2.1",
        "has-symbols": "^1.0.3",
        "reflect.getprototypeof": "^1.0.4",
        "set-function-name": "^2.0.1"
      }
    },
    "node_modules/jackspeak": {
      "version": "2.3.6",
      "resolved": "https://registry.npmjs.org/jackspeak/-/jackspeak-2.3.6.tgz",
      "integrity": "sha512-N3yCS/NegsOBokc8GAdM8UcmfsKiSS8cipheD/nivzr700H+nsMOxJjQnvwOcRYVuFkdH0wGUvW2WbXGmrZGbQ==",
      "dev": true,
      "dependencies": {
        "@isaacs/cliui": "^8.0.2"
      },
      "engines": {
        "node": ">=14"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      },
      "optionalDependencies": {
        "@pkgjs/parseargs": "^0.11.0"
      }
    },
    "node_modules/jiti": {
      "version": "1.21.0",
      "resolved": "https://registry.npmjs.org/jiti/-/jiti-1.21.0.tgz",
      "integrity": "sha512-gFqAIbuKyyso/3G2qhiO2OM6shY6EPP/R0+mkDbyspxKazh8BXDC5FiFsUjlczgdNz/vfra0da2y+aHrusLG/Q==",
      "dev": true,
      "bin": {
        "jiti": "bin/jiti.js"
      }
    },
    "node_modules/js-tokens": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/js-tokens/-/js-tokens-4.0.0.tgz",
      "integrity": "sha512-RdJUflcE3cUzKiMqQgsCu06FPu9UdIJO0beYbPhHN4k6apgJtifcoCtT9bcxOpYBtpD2kCM6Sbzg4CausW/PKQ=="
    },
    "node_modules/js-yaml": {
      "version": "4.1.0",
      "resolved": "https://registry.npmjs.org/js-yaml/-/js-yaml-4.1.0.tgz",
      "integrity": "sha512-wpxZs9NoxZaJESJGIZTyDEaYpl0FKSA+FB9aJiyemKhMwkxQg63h4T1KJgUGHpTqPDNRcmmYLugrRjJlBtWvRA==",
      "dev": true,
      "dependencies": {
        "argparse": "^2.0.1"
      },
      "bin": {
        "js-yaml": "bin/js-yaml.js"
      }
    },
    "node_modules/json-buffer": {
      "version": "3.0.1",
      "resolved": "https://registry.npmjs.org/json-buffer/-/json-buffer-3.0.1.tgz",
      "integrity": "sha512-4bV5BfR2mqfQTJm+V5tPPdf+ZpuhiIvTuAB5g8kcrXOZpTT/QwwVRWBywX1ozr6lEuPdbHxwaJlm9G6mI2sfSQ==",
      "dev": true
    },
    "node_modules/json-schema-traverse": {
      "version": "0.4.1",
      "resolved": "https://registry.npmjs.org/json-schema-traverse/-/json-schema-traverse-0.4.1.tgz",
      "integrity": "sha512-xbbCH5dCYU5T8LcEhhuh7HJ88HXuW3qsI3Y0zOZFKfZEHcpWiHU/Jxzk629Brsab/mMiHQti9wMP+845RPe3Vg==",
      "dev": true
    },
    "node_modules/json-stable-stringify-without-jsonify": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/json-stable-stringify-without-jsonify/-/json-stable-stringify-without-jsonify-1.0.1.tgz",
      "integrity": "sha512-Bdboy+l7tA3OGW6FjyFHWkP5LuByj1Tk33Ljyq0axyzdk9//JSi2u3fP1QSmd1KNwq6VOKYGlAu87CisVir6Pw==",
      "dev": true
    },
    "node_modules/json5": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/json5/-/json5-1.0.2.tgz",
      "integrity": "sha512-g1MWMLBiz8FKi1e4w0UyVL3w+iJceWAFBAaBnnGKOpNa5f8TLktkbre1+s6oICydWAm+HRUGTmI+//xv2hvXYA==",
      "dev": true,
      "dependencies": {
        "minimist": "^1.2.0"
      },
      "bin": {
        "json5": "lib/cli.js"
      }
    },
    "node_modules/jsx-ast-utils": {
      "version": "3.3.5",
      "resolved": "https://registry.npmjs.org/jsx-ast-utils/-/jsx-ast-utils-3.3.5.tgz",
      "integrity": "sha512-ZZow9HBI5O6EPgSJLUb8n2NKgmVWTwCvHGwFuJlMjvLFqlGG6pjirPhtdsseaLZjSibD8eegzmYpUZwoIlj2cQ==",
      "dev": true,
      "dependencies": {
        "array-includes": "^3.1.6",
        "array.prototype.flat": "^1.3.1",
        "object.assign": "^4.1.4",
        "object.values": "^1.1.6"
      },
      "engines": {
        "node": ">=4.0"
      }
    },
    "node_modules/keyv": {
      "version": "4.5.4",
      "resolved": "https://registry.npmjs.org/keyv/-/keyv-4.5.4.tgz",
      "integrity": "sha512-oxVHkHR/EJf2CNXnWxRLW6mg7JyCCUcG0DtEGmL2ctUo1PNTin1PUil+r/+4r5MpVgC/fn1kjsx7mjSujKqIpw==",
      "dev": true,
      "dependencies": {
        "json-buffer": "3.0.1"
      }
    },
    "node_modules/language-subtag-registry": {
      "version": "0.3.22",
      "resolved": "https://registry.npmjs.org/language-subtag-registry/-/language-subtag-registry-0.3.22.tgz",
      "integrity": "sha512-tN0MCzyWnoz/4nHS6uxdlFWoUZT7ABptwKPQ52Ea7URk6vll88bWBVhodtnlfEuCcKWNGoc+uGbw1cwa9IKh/w==",
      "dev": true
    },
    "node_modules/language-tags": {
      "version": "1.0.9",
      "resolved": "https://registry.npmjs.org/language-tags/-/language-tags-1.0.9.tgz",
      "integrity": "sha512-MbjN408fEndfiQXbFQ1vnd+1NoLDsnQW41410oQBXiyXDMYH5z505juWa4KUE1LqxRC7DgOgZDbKLxHIwm27hA==",
      "dev": true,
      "dependencies": {
        "language-subtag-registry": "^0.3.20"
      },
      "engines": {
        "node": ">=0.10"
      }
    },
    "node_modules/levn": {
      "version": "0.4.1",
      "resolved": "https://registry.npmjs.org/levn/-/levn-0.4.1.tgz",
      "integrity": "sha512-+bT2uH4E5LGE7h/n3evcS/sQlJXCpIp6ym8OWJ5eV6+67Dsql/LaaT7qJBAt2rzfoa/5QBGBhxDix1dMt2kQKQ==",
      "dev": true,
      "dependencies": {
        "prelude-ls": "^1.2.1",
        "type-check": "~0.4.0"
      },
      "engines": {
        "node": ">= 0.8.0"
      }
    },
    "node_modules/lilconfig": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/lilconfig/-/lilconfig-2.1.0.tgz",
      "integrity": "sha512-utWOt/GHzuUxnLKxB6dk81RoOeoNeHgbrXiuGk4yyF5qlRz+iIVWu56E2fqGHFrXz0QNUhLB/8nKqvRH66JKGQ==",
      "dev": true,
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/lines-and-columns": {
      "version": "1.2.4",
      "resolved": "https://registry.npmjs.org/lines-and-columns/-/lines-and-columns-1.2.4.tgz",
      "integrity": "sha512-7ylylesZQ/PV29jhEDl3Ufjo6ZX7gCqJr5F7PKrqc93v7fzSymt1BpwEU8nAUXs8qzzvqhbjhK5QZg6Mt/HkBg==",
      "dev": true
    },
    "node_modules/locate-path": {
      "version": "6.0.0",
      "resolved": "https://registry.npmjs.org/locate-path/-/locate-path-6.0.0.tgz",
      "integrity": "sha512-iPZK6eYjbxRu3uB4/WZ3EsEIMJFMqAoopl3R+zuq0UjcAm/MO6KCweDgPfP3elTztoKP3KtnVHxTn2NHBSDVUw==",
      "dev": true,
      "dependencies": {
        "p-locate": "^5.0.0"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/lodash.merge": {
      "version": "4.6.2",
      "resolved": "https://registry.npmjs.org/lodash.merge/-/lodash.merge-4.6.2.tgz",
      "integrity": "sha512-0KpjqXRVvrYyCsX1swR/XTK0va6VQkQM6MNo7PqW77ByjAhoARA8EfrP1N4+KlKj8YS0ZUCtRT/YUuhyYDujIQ==",
      "dev": true
    },
    "node_modules/loose-envify": {
      "version": "1.4.0",
      "resolved": "https://registry.npmjs.org/loose-envify/-/loose-envify-1.4.0.tgz",
      "integrity": "sha512-lyuxPGr/Wfhrlem2CL/UcnUc1zcqKAImBDzukY7Y5F/yQiNdko6+fRLevlw1HgMySw7f611UIY408EtxRSoK3Q==",
      "dependencies": {
        "js-tokens": "^3.0.0 || ^4.0.0"
      },
      "bin": {
        "loose-envify": "cli.js"
      }
    },
    "node_modules/lru-cache": {
      "version": "10.2.0",
      "resolved": "https://registry.npmjs.org/lru-cache/-/lru-cache-10.2.0.tgz",
      "integrity": "sha512-2bIM8x+VAf6JT4bKAljS1qUWgMsqZRPGJS6FSahIMPVvctcNhyVp7AJu7quxOW9jwkryBReKZY5tY5JYv2n/7Q==",
      "dev": true,
      "engines": {
        "node": "14 || >=16.14"
      }
    },
    "node_modules/merge2": {
      "version": "1.4.1",
      "resolved": "https://registry.npmjs.org/merge2/-/merge2-1.4.1.tgz",
      "integrity": "sha512-8q7VEgMJW4J8tcfVPy8g09NcQwZdbwFEqhe/WZkoIzjn/3TGDwtOCYtXGxA3O8tPzpczCCDgv+P2P5y00ZJOOg==",
      "dev": true,
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/micromatch": {
      "version": "4.0.5",
      "resolved": "https://registry.npmjs.org/micromatch/-/micromatch-4.0.5.tgz",
      "integrity": "sha512-DMy+ERcEW2q8Z2Po+WNXuw3c5YaUSFjAO5GsJqfEl7UjvtIuFKO6ZrKvcItdy98dwFI2N1tg3zNIdKaQT+aNdA==",
      "dev": true,
      "dependencies": {
        "braces": "^3.0.2",
        "picomatch": "^2.3.1"
      },
      "engines": {
        "node": ">=8.6"
      }
    },
    "node_modules/minimatch": {
      "version": "3.1.2",
      "resolved": "https://registry.npmjs.org/minimatch/-/minimatch-3.1.2.tgz",
      "integrity": "sha512-J7p63hRiAjw1NDEww1W7i37+ByIrOWO5XQQAzZ3VOcL0PNybwpfmV/N05zFAzwQ9USyEcX6t3UO+K5aqBQOIHw==",
      "dev": true,
      "dependencies": {
        "brace-expansion": "^1.1.7"
      },
      "engines": {
        "node": "*"
      }
    },
    "node_modules/minimist": {
      "version": "1.2.8",
      "resolved": "https://registry.npmjs.org/minimist/-/minimist-1.2.8.tgz",
      "integrity": "sha512-2yyAR8qBkN3YuheJanUpWC5U3bb5osDywNB8RzDVlDwDHbocAJveqqj1u8+SVD7jkWT4yvsHCpWqqWqAxb0zCA==",
      "dev": true,
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/minipass": {
      "version": "7.0.4",
      "resolved": "https://registry.npmjs.org/minipass/-/minipass-7.0.4.tgz",
      "integrity": "sha512-jYofLM5Dam9279rdkWzqHozUo4ybjdZmCsDHePy5V/PbBcVMiSZR97gmAy45aqi8CK1lG2ECd356FU86avfwUQ==",
      "dev": true,
      "engines": {
        "node": ">=16 || 14 >=14.17"
      }
    },
    "node_modules/ms": {
      "version": "2.1.2",
      "resolved": "https://registry.npmjs.org/ms/-/ms-2.1.2.tgz",
      "integrity": "sha512-sGkPx+VjMtmA6MX27oA4FBFELFCZZ4S4XqeGOXCv68tT+jb3vk/RyaKWP0PTKyWtmLSM0b+adUTEvbs1PEaH2w==",
      "dev": true
    },
    "node_modules/mz": {
      "version": "2.7.0",
      "resolved": "https://registry.npmjs.org/mz/-/mz-2.7.0.tgz",
      "integrity": "sha512-z81GNO7nnYMEhrGh9LeymoE4+Yr0Wn5McHIZMK5cfQCl+NDX08sCZgUc9/6MHni9IWuFLm1Z3HTCXu2z9fN62Q==",
      "dev": true,
      "dependencies": {
        "any-promise": "^1.0.0",
        "object-assign": "^4.0.1",
        "thenify-all": "^1.0.0"
      }
    },
    "node_modules/nanoid": {
      "version": "3.3.7",
      "resolved": "https://registry.npmjs.org/nanoid/-/nanoid-3.3.7.tgz",
      "integrity": "sha512-eSRppjcPIatRIMC1U6UngP8XFcz8MQWGQdt1MTBQ7NaAmvXDfvNxbvWV3x2y6CdEUciCSsDHDQZbhYaB8QEo2g==",
      "funding": [
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "bin": {
        "nanoid": "bin/nanoid.cjs"
      },
      "engines": {
        "node": "^10 || ^12 || ^13.7 || ^14 || >=15.0.1"
      }
    },
    "node_modules/natural-compare": {
      "version": "1.4.0",
      "resolved": "https://registry.npmjs.org/natural-compare/-/natural-compare-1.4.0.tgz",
      "integrity": "sha512-OWND8ei3VtNC9h7V60qff3SVobHr996CTwgxubgyQYEpg290h9J0buyECNNJexkFm5sOajh5G116RYA1c8ZMSw==",
      "dev": true
    },
    "node_modules/next": {
      "version": "14.2.2",
      "resolved": "https://registry.npmjs.org/next/-/next-14.2.2.tgz",
      "integrity": "sha512-oGwUaa2bCs47FbuxWMpOoXtBMPYpvTPgdZr3UAo+pu7Ns00z9otmYpoeV1HEiYL06AlRQQIA/ypK526KjJfaxg==",
      "dependencies": {
        "@next/env": "14.2.2",
        "@swc/helpers": "0.5.5",
        "busboy": "1.6.0",
        "caniuse-lite": "^1.0.30001579",
        "graceful-fs": "^4.2.11",
        "postcss": "8.4.31",
        "styled-jsx": "5.1.1"
      },
      "bin": {
        "next": "dist/bin/next"
      },
      "engines": {
        "node": ">=18.17.0"
      },
      "optionalDependencies": {
        "@next/swc-darwin-arm64": "14.2.2",
        "@next/swc-darwin-x64": "14.2.2",
        "@next/swc-linux-arm64-gnu": "14.2.2",
        "@next/swc-linux-arm64-musl": "14.2.2",
        "@next/swc-linux-x64-gnu": "14.2.2",
        "@next/swc-linux-x64-musl": "14.2.2",
        "@next/swc-win32-arm64-msvc": "14.2.2",
        "@next/swc-win32-ia32-msvc": "14.2.2",
        "@next/swc-win32-x64-msvc": "14.2.2"
      },
      "peerDependencies": {
        "@opentelemetry/api": "^1.1.0",
        "@playwright/test": "^1.41.2",
        "react": "^18.2.0",
        "react-dom": "^18.2.0",
        "sass": "^1.3.0"
      },
      "peerDependenciesMeta": {
        "@opentelemetry/api": {
          "optional": true
        },
        "@playwright/test": {
          "optional": true
        },
        "sass": {
          "optional": true
        }
      }
    },
    "node_modules/next/node_modules/postcss": {
      "version": "8.4.31",
      "resolved": "https://registry.npmjs.org/postcss/-/postcss-8.4.31.tgz",
      "integrity": "sha512-PS08Iboia9mts/2ygV3eLpY5ghnUcfLV/EXTOW1E2qYxJKGGBUtNjN76FYHnMs36RmARn41bC0AZmn+rR0OVpQ==",
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/postcss/"
        },
        {
          "type": "tidelift",
          "url": "https://tidelift.com/funding/github/npm/postcss"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "dependencies": {
        "nanoid": "^3.3.6",
        "picocolors": "^1.0.0",
        "source-map-js": "^1.0.2"
      },
      "engines": {
        "node": "^10 || ^12 || >=14"
      }
    },
    "node_modules/normalize-path": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/normalize-path/-/normalize-path-3.0.0.tgz",
      "integrity": "sha512-6eZs5Ls3WtCisHWp9S2GUy8dqkpGi4BVSz3GaqiE6ezub0512ESztXUwUB6C6IKbQkY2Pnb/mD4WYojCRwcwLA==",
      "dev": true,
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/object-assign": {
      "version": "4.1.1",
      "resolved": "https://registry.npmjs.org/object-assign/-/object-assign-4.1.1.tgz",
      "integrity": "sha512-rJgTQnkUnH1sFw8yT6VSU3zD3sWmu6sZhIseY8VX+GRu3P6F7Fu+JNDoXfklElbLJSnc3FUQHVe4cU5hj+BcUg==",
      "dev": true,
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/object-hash": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/object-hash/-/object-hash-3.0.0.tgz",
      "integrity": "sha512-RSn9F68PjH9HqtltsSnqYC1XXoWe9Bju5+213R98cNGttag9q9yAOTzdbsqvIa7aNm5WffBZFpWYr2aWrklWAw==",
      "dev": true,
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/object-inspect": {
      "version": "1.13.1",
      "resolved": "https://registry.npmjs.org/object-inspect/-/object-inspect-1.13.1.tgz",
      "integrity": "sha512-5qoj1RUiKOMsCCNLV1CBiPYE10sziTsnmNxkAI/rZhiD63CF7IqdFGC/XzjWjpSgLf0LxXX3bDFIh0E18f6UhQ==",
      "dev": true,
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/object-keys": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/object-keys/-/object-keys-1.1.1.tgz",
      "integrity": "sha512-NuAESUOUMrlIXOfHKzD6bpPu3tYt3xvjNdRIQ+FeT0lNb4K8WR70CaDxhuNguS2XG+GjkyMwOzsN5ZktImfhLA==",
      "dev": true,
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/object.assign": {
      "version": "4.1.5",
      "resolved": "https://registry.npmjs.org/object.assign/-/object.assign-4.1.5.tgz",
      "integrity": "sha512-byy+U7gp+FVwmyzKPYhW2h5l3crpmGsxl7X2s8y43IgxvG4g3QZ6CffDtsNQy1WsmZpQbO+ybo0AlW7TY6DcBQ==",
      "dev": true,
      "dependencies": {
        "call-bind": "^1.0.5",
        "define-properties": "^1.2.1",
        "has-symbols": "^1.0.3",
        "object-keys": "^1.1.1"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/object.entries": {
      "version": "1.1.8",
      "resolved": "https://registry.npmjs.org/object.entries/-/object.entries-1.1.8.tgz",
      "integrity": "sha512-cmopxi8VwRIAw/fkijJohSfpef5PdN0pMQJN6VC/ZKvn0LIknWD8KtgY6KlQdEc4tIjcQ3HxSMmnvtzIscdaYQ==",
      "dev": true,
      "dependencies": {
        "call-bind": "^1.0.7",
        "define-properties": "^1.2.1",
        "es-object-atoms": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/object.fromentries": {
      "version": "2.0.8",
      "resolved": "https://registry.npmjs.org/object.fromentries/-/object.fromentries-2.0.8.tgz",
      "integrity": "sha512-k6E21FzySsSK5a21KRADBd/NGneRegFO5pLHfdQLpRDETUNJueLXs3WCzyQ3tFRDYgbq3KHGXfTbi2bs8WQ6rQ==",
      "dev": true,
      "dependencies": {
        "call-bind": "^1.0.7",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.2",
        "es-object-atoms": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/object.groupby": {
      "version": "1.0.3",
      "resolved": "https://registry.npmjs.org/object.groupby/-/object.groupby-1.0.3.tgz",
      "integrity": "sha512-+Lhy3TQTuzXI5hevh8sBGqbmurHbbIjAi0Z4S63nthVLmLxfbj4T54a4CfZrXIrt9iP4mVAPYMo/v99taj3wjQ==",
      "dev": true,
      "dependencies": {
        "call-bind": "^1.0.7",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/object.hasown": {
      "version": "1.1.4",
      "resolved": "https://registry.npmjs.org/object.hasown/-/object.hasown-1.1.4.tgz",
      "integrity": "sha512-FZ9LZt9/RHzGySlBARE3VF+gE26TxR38SdmqOqliuTnl9wrKulaQs+4dee1V+Io8VfxqzAfHu6YuRgUy8OHoTg==",
      "dev": true,
      "dependencies": {
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.2",
        "es-object-atoms": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/object.values": {
      "version": "1.2.0",
      "resolved": "https://registry.npmjs.org/object.values/-/object.values-1.2.0.tgz",
      "integrity": "sha512-yBYjY9QX2hnRmZHAjG/f13MzmBzxzYgQhFrke06TTyKY5zSTEqkOeukBzIdVA3j3ulu8Qa3MbVFShV7T2RmGtQ==",
      "dev": true,
      "dependencies": {
        "call-bind": "^1.0.7",
        "define-properties": "^1.2.1",
        "es-object-atoms": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/once": {
      "version": "1.4.0",
      "resolved": "https://registry.npmjs.org/once/-/once-1.4.0.tgz",
      "integrity": "sha512-lNaJgI+2Q5URQBkccEKHTQOPaXdUxnZZElQTZY0MFUAuaEqe1E+Nyvgdz/aIyNi6Z9MzO5dv1H8n58/GELp3+w==",
      "dev": true,
      "dependencies": {
        "wrappy": "1"
      }
    },
    "node_modules/optionator": {
      "version": "0.9.3",
      "resolved": "https://registry.npmjs.org/optionator/-/optionator-0.9.3.tgz",
      "integrity": "sha512-JjCoypp+jKn1ttEFExxhetCKeJt9zhAgAve5FXHixTvFDW/5aEktX9bufBKLRRMdU7bNtpLfcGu94B3cdEJgjg==",
      "dev": true,
      "dependencies": {
        "@aashutoshrathi/word-wrap": "^1.2.3",
        "deep-is": "^0.1.3",
        "fast-levenshtein": "^2.0.6",
        "levn": "^0.4.1",
        "prelude-ls": "^1.2.1",
        "type-check": "^0.4.0"
      },
      "engines": {
        "node": ">= 0.8.0"
      }
    },
    "node_modules/p-limit": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/p-limit/-/p-limit-3.1.0.tgz",
      "integrity": "sha512-TYOanM3wGwNGsZN2cVTYPArw454xnXj5qmWF1bEoAc4+cU/ol7GVh7odevjp1FNHduHc3KZMcFduxU5Xc6uJRQ==",
      "dev": true,
      "dependencies": {
        "yocto-queue": "^0.1.0"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/p-locate": {
      "version": "5.0.0",
      "resolved": "https://registry.npmjs.org/p-locate/-/p-locate-5.0.0.tgz",
      "integrity": "sha512-LaNjtRWUBY++zB5nE/NwcaoMylSPk+S+ZHNB1TzdbMJMny6dynpAGt7X/tl/QYq3TIeE6nxHppbo2LGymrG5Pw==",
      "dev": true,
      "dependencies": {
        "p-limit": "^3.0.2"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/parent-module": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/parent-module/-/parent-module-1.0.1.tgz",
      "integrity": "sha512-GQ2EWRpQV8/o+Aw8YqtfZZPfNRWZYkbidE9k5rpl/hC3vtHHBfGm2Ifi6qWV+coDGkrUKZAxE3Lot5kcsRlh+g==",
      "dev": true,
      "dependencies": {
        "callsites": "^3.0.0"
      },
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/path-exists": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/path-exists/-/path-exists-4.0.0.tgz",
      "integrity": "sha512-ak9Qy5Q7jYb2Wwcey5Fpvg2KoAc/ZIhLSLOSBmRmygPsGwkVVt0fZa0qrtMz+m6tJTAHfZQ8FnmB4MG4LWy7/w==",
      "dev": true,
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/path-is-absolute": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/path-is-absolute/-/path-is-absolute-1.0.1.tgz",
      "integrity": "sha512-AVbw3UJ2e9bq64vSaS9Am0fje1Pa8pbGqTTsmXfaIiMpnr5DlDhfJOuLj9Sf95ZPVDAUerDfEk88MPmPe7UCQg==",
      "dev": true,
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/path-key": {
      "version": "3.1.1",
      "resolved": "https://registry.npmjs.org/path-key/-/path-key-3.1.1.tgz",
      "integrity": "sha512-ojmeN0qd+y0jszEtoY48r0Peq5dwMEkIlCOu6Q5f41lfkswXuKtYrhgoTpLnyIcHm24Uhqx+5Tqm2InSwLhE6Q==",
      "dev": true,
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/path-parse": {
      "version": "1.0.7",
      "resolved": "https://registry.npmjs.org/path-parse/-/path-parse-1.0.7.tgz",
      "integrity": "sha512-LDJzPVEEEPR+y48z93A0Ed0yXb8pAByGWo/k5YYdYgpY2/2EsOsksJrq7lOHxryrVOn1ejG6oAp8ahvOIQD8sw==",
      "dev": true
    },
    "node_modules/path-scurry": {
      "version": "1.10.2",
      "resolved": "https://registry.npmjs.org/path-scurry/-/path-scurry-1.10.2.tgz",
      "integrity": "sha512-7xTavNy5RQXnsjANvVvMkEjvloOinkAjv/Z6Ildz9v2RinZ4SBKTWFOVRbaF8p0vpHnyjV/UwNDdKuUv6M5qcA==",
      "dev": true,
      "dependencies": {
        "lru-cache": "^10.2.0",
        "minipass": "^5.0.0 || ^6.0.2 || ^7.0.0"
      },
      "engines": {
        "node": ">=16 || 14 >=14.17"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/path-type": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/path-type/-/path-type-4.0.0.tgz",
      "integrity": "sha512-gDKb8aZMDeD/tZWs9P6+q0J9Mwkdl6xMV8TjnGP3qJVJ06bdMgkbBlLU8IdfOsIsFz2BW1rNVT3XuNEl8zPAvw==",
      "dev": true,
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/picocolors": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/picocolors/-/picocolors-1.0.0.tgz",
      "integrity": "sha512-1fygroTLlHu66zi26VoTDv8yRgm0Fccecssto+MhsZ0D/DGW2sm8E8AjW7NU5VVTRt5GxbeZ5qBuJr+HyLYkjQ=="
    },
    "node_modules/picomatch": {
      "version": "2.3.1",
      "resolved": "https://registry.npmjs.org/picomatch/-/picomatch-2.3.1.tgz",
      "integrity": "sha512-JU3teHTNjmE2VCGFzuY8EXzCDVwEqB2a8fsIvwaStHhAWJEeVd1o1QD80CU6+ZdEXXSLbSsuLwJjkCBWqRQUVA==",
      "dev": true,
      "engines": {
        "node": ">=8.6"
      },
      "funding": {
        "url": "https://github.com/sponsors/jonschlinkert"
      }
    },
    "node_modules/pify": {
      "version": "2.3.0",
      "resolved": "https://registry.npmjs.org/pify/-/pify-2.3.0.tgz",
      "integrity": "sha512-udgsAY+fTnvv7kI7aaxbqwWNb0AHiB0qBO89PZKPkoTmGOgdbrHDKD+0B2X4uTfJ/FT1R09r9gTsjUjNJotuog==",
      "dev": true,
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/pirates": {
      "version": "4.0.6",
      "resolved": "https://registry.npmjs.org/pirates/-/pirates-4.0.6.tgz",
      "integrity": "sha512-saLsH7WeYYPiD25LDuLRRY/i+6HaPYr6G1OUlN39otzkSTxKnubR9RTxS3/Kk50s1g2JTgFwWQDQyplC5/SHZg==",
      "dev": true,
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/possible-typed-array-names": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/possible-typed-array-names/-/possible-typed-array-names-1.0.0.tgz",
      "integrity": "sha512-d7Uw+eZoloe0EHDIYoe+bQ5WXnGMOpmiZFTuMWCwpjzzkL2nTjcKiAk4hh8TjnGye2TwWOk3UXucZ+3rbmBa8Q==",
      "dev": true,
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/postcss": {
      "version": "8.4.38",
      "resolved": "https://registry.npmjs.org/postcss/-/postcss-8.4.38.tgz",
      "integrity": "sha512-Wglpdk03BSfXkHoQa3b/oulrotAkwrlLDRSOb9D0bN86FdRyE9lppSp33aHNPgBa0JKCoB+drFLZkQoRRYae5A==",
      "dev": true,
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/postcss/"
        },
        {
          "type": "tidelift",
          "url": "https://tidelift.com/funding/github/npm/postcss"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "dependencies": {
        "nanoid": "^3.3.7",
        "picocolors": "^1.0.0",
        "source-map-js": "^1.2.0"
      },
      "engines": {
        "node": "^10 || ^12 || >=14"
      }
    },
    "node_modules/postcss-import": {
      "version": "15.1.0",
      "resolved": "https://registry.npmjs.org/postcss-import/-/postcss-import-15.1.0.tgz",
      "integrity": "sha512-hpr+J05B2FVYUAXHeK1YyI267J/dDDhMU6B6civm8hSY1jYJnBXxzKDKDswzJmtLHryrjhnDjqqp/49t8FALew==",
      "dev": true,
      "dependencies": {
        "postcss-value-parser": "^4.0.0",
        "read-cache": "^1.0.0",
        "resolve": "^1.1.7"
      },
      "engines": {
        "node": ">=14.0.0"
      },
      "peerDependencies": {
        "postcss": "^8.0.0"
      }
    },
    "node_modules/postcss-js": {
      "version": "4.0.1",
      "resolved": "https://registry.npmjs.org/postcss-js/-/postcss-js-4.0.1.tgz",
      "integrity": "sha512-dDLF8pEO191hJMtlHFPRa8xsizHaM82MLfNkUHdUtVEV3tgTp5oj+8qbEqYM57SLfc74KSbw//4SeJma2LRVIw==",
      "dev": true,
      "dependencies": {
        "camelcase-css": "^2.0.1"
      },
      "engines": {
        "node": "^12 || ^14 || >= 16"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/postcss/"
      },
      "peerDependencies": {
        "postcss": "^8.4.21"
      }
    },
    "node_modules/postcss-load-config": {
      "version": "4.0.2",
      "resolved": "https://registry.npmjs.org/postcss-load-config/-/postcss-load-config-4.0.2.tgz",
      "integrity": "sha512-bSVhyJGL00wMVoPUzAVAnbEoWyqRxkjv64tUl427SKnPrENtq6hJwUojroMz2VB+Q1edmi4IfrAPpami5VVgMQ==",
      "dev": true,
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/postcss/"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "dependencies": {
        "lilconfig": "^3.0.0",
        "yaml": "^2.3.4"
      },
      "engines": {
        "node": ">= 14"
      },
      "peerDependencies": {
        "postcss": ">=8.0.9",
        "ts-node": ">=9.0.0"
      },
      "peerDependenciesMeta": {
        "postcss": {
          "optional": true
        },
        "ts-node": {
          "optional": true
        }
      }
    },
    "node_modules/postcss-load-config/node_modules/lilconfig": {
      "version": "3.1.1",
      "resolved": "https://registry.npmjs.org/lilconfig/-/lilconfig-3.1.1.tgz",
      "integrity": "sha512-O18pf7nyvHTckunPWCV1XUNXU1piu01y2b7ATJ0ppkUkk8ocqVWBrYjJBCwHDjD/ZWcfyrA0P4gKhzWGi5EINQ==",
      "dev": true,
      "engines": {
        "node": ">=14"
      },
      "funding": {
        "url": "https://github.com/sponsors/antonk52"
      }
    },
    "node_modules/postcss-nested": {
      "version": "6.0.1",
      "resolved": "https://registry.npmjs.org/postcss-nested/-/postcss-nested-6.0.1.tgz",
      "integrity": "sha512-mEp4xPMi5bSWiMbsgoPfcP74lsWLHkQbZc3sY+jWYd65CUwXrUaTp0fmNpa01ZcETKlIgUdFN/MpS2xZtqL9dQ==",
      "dev": true,
      "dependencies": {
        "postcss-selector-parser": "^6.0.11"
      },
      "engines": {
        "node": ">=12.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/postcss/"
      },
      "peerDependencies": {
        "postcss": "^8.2.14"
      }
    },
    "node_modules/postcss-selector-parser": {
      "version": "6.0.16",
      "resolved": "https://registry.npmjs.org/postcss-selector-parser/-/postcss-selector-parser-6.0.16.tgz",
      "integrity": "sha512-A0RVJrX+IUkVZbW3ClroRWurercFhieevHB38sr2+l9eUClMqome3LmEmnhlNy+5Mr2EYN6B2Kaw9wYdd+VHiw==",
      "dev": true,
      "dependencies": {
        "cssesc": "^3.0.0",
        "util-deprecate": "^1.0.2"
      },
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/postcss-value-parser": {
      "version": "4.2.0",
      "resolved": "https://registry.npmjs.org/postcss-value-parser/-/postcss-value-parser-4.2.0.tgz",
      "integrity": "sha512-1NNCs6uurfkVbeXG4S8JFT9t19m45ICnif8zWLd5oPSZ50QnwMfK+H3jv408d4jw/7Bttv5axS5IiHoLaVNHeQ==",
      "dev": true
    },
    "node_modules/prelude-ls": {
      "version": "1.2.1",
      "resolved": "https://registry.npmjs.org/prelude-ls/-/prelude-ls-1.2.1.tgz",
      "integrity": "sha512-vkcDPrRZo1QZLbn5RLGPpg/WmIQ65qoWWhcGKf/b5eplkkarX0m9z8ppCat4mlOqUsWpyNuYgO3VRyrYHSzX5g==",
      "dev": true,
      "engines": {
        "node": ">= 0.8.0"
      }
    },
    "node_modules/prop-types": {
      "version": "15.8.1",
      "resolved": "https://registry.npmjs.org/prop-types/-/prop-types-15.8.1.tgz",
      "integrity": "sha512-oj87CgZICdulUohogVAR7AjlC0327U4el4L6eAvOqCeudMDVU0NThNaV+b9Df4dXgSP1gXMTnPdhfe/2qDH5cg==",
      "dev": true,
      "dependencies": {
        "loose-envify": "^1.4.0",
        "object-assign": "^4.1.1",
        "react-is": "^16.13.1"
      }
    },
    "node_modules/punycode": {
      "version": "2.3.1",
      "resolved": "https://registry.npmjs.org/punycode/-/punycode-2.3.1.tgz",
      "integrity": "sha512-vYt7UD1U9Wg6138shLtLOvdAu+8DsC/ilFtEVHcH+wydcSpNE20AfSOduf6MkRFahL5FY7X1oU7nKVZFtfq8Fg==",
      "dev": true,
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/queue-microtask": {
      "version": "1.2.3",
      "resolved": "https://registry.npmjs.org/queue-microtask/-/queue-microtask-1.2.3.tgz",
      "integrity": "sha512-NuaNSa6flKT5JaSYQzJok04JzTL1CA6aGhv5rfLW3PgqA+M2ChpZQnAC8h8i4ZFkBS8X5RqkDBHA7r4hej3K9A==",
      "dev": true,
      "funding": [
        {
          "type": "github",
          "url": "https://github.com/sponsors/feross"
        },
        {
          "type": "patreon",
          "url": "https://www.patreon.com/feross"
        },
        {
          "type": "consulting",
          "url": "https://feross.org/support"
        }
      ]
    },
    "node_modules/react": {
      "version": "18.2.0",
      "resolved": "https://registry.npmjs.org/react/-/react-18.2.0.tgz",
      "integrity": "sha512-/3IjMdb2L9QbBdWiW5e3P2/npwMBaU9mHCSCUzNln0ZCYbcfTsGbTJrU/kGemdH2IWmB2ioZ+zkxtmq6g09fGQ==",
      "dependencies": {
        "loose-envify": "^1.1.0"
      },
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/react-dom": {
      "version": "18.2.0",
      "resolved": "https://registry.npmjs.org/react-dom/-/react-dom-18.2.0.tgz",
      "integrity": "sha512-6IMTriUmvsjHUjNtEDudZfuDQUoWXVxKHhlEGSk81n4YFS+r/Kl99wXiwlVXtPBtJenozv2P+hxDsw9eA7Xo6g==",
      "dependencies": {
        "loose-envify": "^1.1.0",
        "scheduler": "^0.23.0"
      },
      "peerDependencies": {
        "react": "^18.2.0"
      }
    },
    "node_modules/react-is": {
      "version": "16.13.1",
      "resolved": "https://registry.npmjs.org/react-is/-/react-is-16.13.1.tgz",
      "integrity": "sha512-24e6ynE2H+OKt4kqsOvNd8kBpV65zoxbA4BVsEOB3ARVWQki/DHzaUoC5KuON/BiccDaCCTZBuOcfZs70kR8bQ==",
      "dev": true
    },
    "node_modules/read-cache": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/read-cache/-/read-cache-1.0.0.tgz",
      "integrity": "sha512-Owdv/Ft7IjOgm/i0xvNDZ1LrRANRfew4b2prF3OWMQLxLfu3bS8FVhCsrSCMK4lR56Y9ya+AThoTpDCTxCmpRA==",
      "dev": true,
      "dependencies": {
        "pify": "^2.3.0"
      }
    },
    "node_modules/readdirp": {
      "version": "3.6.0",
      "resolved": "https://registry.npmjs.org/readdirp/-/readdirp-3.6.0.tgz",
      "integrity": "sha512-hOS089on8RduqdbhvQ5Z37A0ESjsqz6qnRcffsMU3495FuTdqSm+7bhJ29JvIOsBDEEnan5DPu9t3To9VRlMzA==",
      "dev": true,
      "dependencies": {
        "picomatch": "^2.2.1"
      },
      "engines": {
        "node": ">=8.10.0"
      }
    },
    "node_modules/reflect.getprototypeof": {
      "version": "1.0.6",
      "resolved": "https://registry.npmjs.org/reflect.getprototypeof/-/reflect.getprototypeof-1.0.6.tgz",
      "integrity": "sha512-fmfw4XgoDke3kdI6h4xcUz1dG8uaiv5q9gcEwLS4Pnth2kxT+GZ7YehS1JTMGBQmtV7Y4GFGbs2re2NqhdozUg==",
      "dev": true,
      "dependencies": {
        "call-bind": "^1.0.7",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.1",
        "es-errors": "^1.3.0",
        "get-intrinsic": "^1.2.4",
        "globalthis": "^1.0.3",
        "which-builtin-type": "^1.1.3"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/regenerator-runtime": {
      "version": "0.14.1",
      "resolved": "https://registry.npmjs.org/regenerator-runtime/-/regenerator-runtime-0.14.1.tgz",
      "integrity": "sha512-dYnhHh0nJoMfnkZs6GmmhFknAGRrLznOu5nc9ML+EJxGvrx6H7teuevqVqCuPcPK//3eDrrjQhehXVx9cnkGdw==",
      "dev": true
    },
    "node_modules/regexp.prototype.flags": {
      "version": "1.5.2",
      "resolved": "https://registry.npmjs.org/regexp.prototype.flags/-/regexp.prototype.flags-1.5.2.tgz",
      "integrity": "sha512-NcDiDkTLuPR+++OCKB0nWafEmhg/Da8aUPLPMQbK+bxKKCm1/S5he+AqYa4PlMCVBalb4/yxIRub6qkEx5yJbw==",
      "dev": true,
      "dependencies": {
        "call-bind": "^1.0.6",
        "define-properties": "^1.2.1",
        "es-errors": "^1.3.0",
        "set-function-name": "^2.0.1"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/resolve": {
      "version": "1.22.8",
      "resolved": "https://registry.npmjs.org/resolve/-/resolve-1.22.8.tgz",
      "integrity": "sha512-oKWePCxqpd6FlLvGV1VU0x7bkPmmCNolxzjMf4NczoDnQcIWrAF+cPtZn5i6n+RfD2d9i0tzpKnG6Yk168yIyw==",
      "dev": true,
      "dependencies": {
        "is-core-module": "^2.13.0",
        "path-parse": "^1.0.7",
        "supports-preserve-symlinks-flag": "^1.0.0"
      },
      "bin": {
        "resolve": "bin/resolve"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/resolve-from": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/resolve-from/-/resolve-from-4.0.0.tgz",
      "integrity": "sha512-pb/MYmXstAkysRFx8piNI1tGFNQIFA3vkE3Gq4EuA1dF6gHp/+vgZqsCGJapvy8N3Q+4o7FwvquPJcnZ7RYy4g==",
      "dev": true,
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/resolve-pkg-maps": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/resolve-pkg-maps/-/resolve-pkg-maps-1.0.0.tgz",
      "integrity": "sha512-seS2Tj26TBVOC2NIc2rOe2y2ZO7efxITtLZcGSOnHHNOQ7CkiUBfw0Iw2ck6xkIhPwLhKNLS8BO+hEpngQlqzw==",
      "dev": true,
      "funding": {
        "url": "https://github.com/privatenumber/resolve-pkg-maps?sponsor=1"
      }
    },
    "node_modules/reusify": {
      "version": "1.0.4",
      "resolved": "https://registry.npmjs.org/reusify/-/reusify-1.0.4.tgz",
      "integrity": "sha512-U9nH88a3fc/ekCF1l0/UP1IosiuIjyTh7hBvXVMHYgVcfGvt897Xguj2UOLDeI5BG2m7/uwyaLVT6fbtCwTyzw==",
      "dev": true,
      "engines": {
        "iojs": ">=1.0.0",
        "node": ">=0.10.0"
      }
    },
    "node_modules/rimraf": {
      "version": "3.0.2",
      "resolved": "https://registry.npmjs.org/rimraf/-/rimraf-3.0.2.tgz",
      "integrity": "sha512-JZkJMZkAGFFPP2YqXZXPbMlMBgsxzE8ILs4lMIX/2o0L9UBw9O/Y3o6wFw/i9YLapcUJWwqbi3kdxIPdC62TIA==",
      "dev": true,
      "dependencies": {
        "glob": "^7.1.3"
      },
      "bin": {
        "rimraf": "bin.js"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/rimraf/node_modules/glob": {
      "version": "7.2.3",
      "resolved": "https://registry.npmjs.org/glob/-/glob-7.2.3.tgz",
      "integrity": "sha512-nFR0zLpU2YCaRxwoCJvL6UvCH2JFyFVIvwTLsIf21AuHlMskA1hhTdk+LlYJtOlYt9v6dvszD2BGRqBL+iQK9Q==",
      "dev": true,
      "dependencies": {
        "fs.realpath": "^1.0.0",
        "inflight": "^1.0.4",
        "inherits": "2",
        "minimatch": "^3.1.1",
        "once": "^1.3.0",
        "path-is-absolute": "^1.0.0"
      },
      "engines": {
        "node": "*"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/run-parallel": {
      "version": "1.2.0",
      "resolved": "https://registry.npmjs.org/run-parallel/-/run-parallel-1.2.0.tgz",
      "integrity": "sha512-5l4VyZR86LZ/lDxZTR6jqL8AFE2S0IFLMP26AbjsLVADxHdhB/c0GUsH+y39UfCi3dzz8OlQuPmnaJOMoDHQBA==",
      "dev": true,
      "funding": [
        {
          "type": "github",
          "url": "https://github.com/sponsors/feross"
        },
        {
          "type": "patreon",
          "url": "https://www.patreon.com/feross"
        },
        {
          "type": "consulting",
          "url": "https://feross.org/support"
        }
      ],
      "dependencies": {
        "queue-microtask": "^1.2.2"
      }
    },
    "node_modules/safe-array-concat": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/safe-array-concat/-/safe-array-concat-1.1.2.tgz",
      "integrity": "sha512-vj6RsCsWBCf19jIeHEfkRMw8DPiBb+DMXklQ/1SGDHOMlHdPUkZXFQ2YdplS23zESTijAcurb1aSgJA3AgMu1Q==",
      "dev": true,
      "dependencies": {
        "call-bind": "^1.0.7",
        "get-intrinsic": "^1.2.4",
        "has-symbols": "^1.0.3",
        "isarray": "^2.0.5"
      },
      "engines": {
        "node": ">=0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/safe-regex-test": {
      "version": "1.0.3",
      "resolved": "https://registry.npmjs.org/safe-regex-test/-/safe-regex-test-1.0.3.tgz",
      "integrity": "sha512-CdASjNJPvRa7roO6Ra/gLYBTzYzzPyyBXxIMdGW3USQLyjWEls2RgW5UBTXaQVp+OrpeCK3bLem8smtmheoRuw==",
      "dev": true,
      "dependencies": {
        "call-bind": "^1.0.6",
        "es-errors": "^1.3.0",
        "is-regex": "^1.1.4"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/scheduler": {
      "version": "0.23.0",
      "resolved": "https://registry.npmjs.org/scheduler/-/scheduler-0.23.0.tgz",
      "integrity": "sha512-CtuThmgHNg7zIZWAXi3AsyIzA3n4xx7aNyjwC2VJldO2LMVDhFK+63xGqq6CsJH4rTAt6/M+N4GhZiDYPx9eUw==",
      "dependencies": {
        "loose-envify": "^1.1.0"
      }
    },
    "node_modules/semver": {
      "version": "7.6.0",
      "resolved": "https://registry.npmjs.org/semver/-/semver-7.6.0.tgz",
      "integrity": "sha512-EnwXhrlwXMk9gKu5/flx5sv/an57AkRplG3hTK68W7FRDN+k+OWBj65M7719OkA82XLBxrcX0KSHj+X5COhOVg==",
      "dev": true,
      "dependencies": {
        "lru-cache": "^6.0.0"
      },
      "bin": {
        "semver": "bin/semver.js"
      },
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/semver/node_modules/lru-cache": {
      "version": "6.0.0",
      "resolved": "https://registry.npmjs.org/lru-cache/-/lru-cache-6.0.0.tgz",
      "integrity": "sha512-Jo6dJ04CmSjuznwJSS3pUeWmd/H0ffTlkXXgwZi+eq1UCmqQwCh+eLsYOYCwY991i2Fah4h1BEMCx4qThGbsiA==",
      "dev": true,
      "dependencies": {
        "yallist": "^4.0.0"
      },
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/set-function-length": {
      "version": "1.2.2",
      "resolved": "https://registry.npmjs.org/set-function-length/-/set-function-length-1.2.2.tgz",
      "integrity": "sha512-pgRc4hJ4/sNjWCSS9AmnS40x3bNMDTknHgL5UaMBTMyJnU90EgWh1Rz+MC9eFu4BuN/UwZjKQuY/1v3rM7HMfg==",
      "dev": true,
      "dependencies": {
        "define-data-property": "^1.1.4",
        "es-errors": "^1.3.0",
        "function-bind": "^1.1.2",
        "get-intrinsic": "^1.2.4",
        "gopd": "^1.0.1",
        "has-property-descriptors": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/set-function-name": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/set-function-name/-/set-function-name-2.0.2.tgz",
      "integrity": "sha512-7PGFlmtwsEADb0WYyvCMa1t+yke6daIG4Wirafur5kcf+MhUnPms1UeR0CKQdTZD81yESwMHbtn+TR+dMviakQ==",
      "dev": true,
      "dependencies": {
        "define-data-property": "^1.1.4",
        "es-errors": "^1.3.0",
        "functions-have-names": "^1.2.3",
        "has-property-descriptors": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/shebang-command": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/shebang-command/-/shebang-command-2.0.0.tgz",
      "integrity": "sha512-kHxr2zZpYtdmrN1qDjrrX/Z1rR1kG8Dx+gkpK1G4eXmvXswmcE1hTWBWYUzlraYw1/yZp6YuDY77YtvbN0dmDA==",
      "dev": true,
      "dependencies": {
        "shebang-regex": "^3.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/shebang-regex": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/shebang-regex/-/shebang-regex-3.0.0.tgz",
      "integrity": "sha512-7++dFhtcx3353uBaq8DDR4NuxBetBzC7ZQOhmTQInHEd6bSrXdiEyzCvG07Z44UYdLShWUyXt5M/yhz8ekcb1A==",
      "dev": true,
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/side-channel": {
      "version": "1.0.6",
      "resolved": "https://registry.npmjs.org/side-channel/-/side-channel-1.0.6.tgz",
      "integrity": "sha512-fDW/EZ6Q9RiO8eFG8Hj+7u/oW+XrPTIChwCOM2+th2A6OblDtYYIpve9m+KvI9Z4C9qSEXlaGR6bTEYHReuglA==",
      "dev": true,
      "dependencies": {
        "call-bind": "^1.0.7",
        "es-errors": "^1.3.0",
        "get-intrinsic": "^1.2.4",
        "object-inspect": "^1.13.1"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/signal-exit": {
      "version": "4.1.0",
      "resolved": "https://registry.npmjs.org/signal-exit/-/signal-exit-4.1.0.tgz",
      "integrity": "sha512-bzyZ1e88w9O1iNJbKnOlvYTrWPDl46O1bG0D3XInv+9tkPrxrN8jUUTiFlDkkmKWgn1M6CfIA13SuGqOa9Korw==",
      "dev": true,
      "engines": {
        "node": ">=14"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/slash": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/slash/-/slash-3.0.0.tgz",
      "integrity": "sha512-g9Q1haeby36OSStwb4ntCGGGaKsaVSjQ68fBxoQcutl5fS1vuY18H3wSt3jFyFtrkx+Kz0V1G85A4MyAdDMi2Q==",
      "dev": true,
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/source-map-js": {
      "version": "1.2.0",
      "resolved": "https://registry.npmjs.org/source-map-js/-/source-map-js-1.2.0.tgz",
      "integrity": "sha512-itJW8lvSA0TXEphiRoawsCksnlf8SyvmFzIhltqAHluXd88pkCd+cXJVHTDwdCr0IzwptSm035IHQktUu1QUMg==",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/streamsearch": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/streamsearch/-/streamsearch-1.1.0.tgz",
      "integrity": "sha512-Mcc5wHehp9aXz1ax6bZUyY5afg9u2rv5cqQI3mRrYkGC8rW2hM02jWuwjtL++LS5qinSyhj2QfLyNsuc+VsExg==",
      "engines": {
        "node": ">=10.0.0"
      }
    },
    "node_modules/string-width": {
      "version": "5.1.2",
      "resolved": "https://registry.npmjs.org/string-width/-/string-width-5.1.2.tgz",
      "integrity": "sha512-HnLOCR3vjcY8beoNLtcjZ5/nxn2afmME6lhrDrebokqMap+XbeW8n9TXpPDOqdGK5qcI3oT0GKTW6wC7EMiVqA==",
      "dev": true,
      "dependencies": {
        "eastasianwidth": "^0.2.0",
        "emoji-regex": "^9.2.2",
        "strip-ansi": "^7.0.1"
      },
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/string-width-cjs": {
      "name": "string-width",
      "version": "4.2.3",
      "resolved": "https://registry.npmjs.org/string-width/-/string-width-4.2.3.tgz",
      "integrity": "sha512-wKyQRQpjJ0sIp62ErSZdGsjMJWsap5oRNihHhu6G7JVO/9jIB6UyevL+tXuOqrng8j/cxKTWyWUwvSTriiZz/g==",
      "dev": true,
      "dependencies": {
        "emoji-regex": "^8.0.0",
        "is-fullwidth-code-point": "^3.0.0",
        "strip-ansi": "^6.0.1"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/string-width-cjs/node_modules/emoji-regex": {
      "version": "8.0.0",
      "resolved": "https://registry.npmjs.org/emoji-regex/-/emoji-regex-8.0.0.tgz",
      "integrity": "sha512-MSjYzcWNOA0ewAHpz0MxpYFvwg6yjy1NG3xteoqz644VCo/RPgnr1/GGt+ic3iJTzQ8Eu3TdM14SawnVUmGE6A==",
      "dev": true
    },
    "node_modules/string-width/node_modules/ansi-regex": {
      "version": "6.0.1",
      "resolved": "https://registry.npmjs.org/ansi-regex/-/ansi-regex-6.0.1.tgz",
      "integrity": "sha512-n5M855fKb2SsfMIiFFoVrABHJC8QtHwVx+mHWP3QcEqBHYienj5dHSgjbxtC0WEZXYt4wcD6zrQElDPhFuZgfA==",
      "dev": true,
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/chalk/ansi-regex?sponsor=1"
      }
    },
    "node_modules/string-width/node_modules/strip-ansi": {
      "version": "7.1.0",
      "resolved": "https://registry.npmjs.org/strip-ansi/-/strip-ansi-7.1.0.tgz",
      "integrity": "sha512-iq6eVVI64nQQTRYq2KtEg2d2uU7LElhTJwsH4YzIHZshxlgZms/wIc4VoDQTlG/IvVIrBKG06CrZnp0qv7hkcQ==",
      "dev": true,
      "dependencies": {
        "ansi-regex": "^6.0.1"
      },
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/chalk/strip-ansi?sponsor=1"
      }
    },
    "node_modules/string.prototype.matchall": {
      "version": "4.0.11",
      "resolved": "https://registry.npmjs.org/string.prototype.matchall/-/string.prototype.matchall-4.0.11.tgz",
      "integrity": "sha512-NUdh0aDavY2og7IbBPenWqR9exH+E26Sv8e0/eTe1tltDGZL+GtBkDAnnyBtmekfK6/Dq3MkcGtzXFEd1LQrtg==",
      "dev": true,
      "dependencies": {
        "call-bind": "^1.0.7",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.2",
        "es-errors": "^1.3.0",
        "es-object-atoms": "^1.0.0",
        "get-intrinsic": "^1.2.4",
        "gopd": "^1.0.1",
        "has-symbols": "^1.0.3",
        "internal-slot": "^1.0.7",
        "regexp.prototype.flags": "^1.5.2",
        "set-function-name": "^2.0.2",
        "side-channel": "^1.0.6"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/string.prototype.trim": {
      "version": "1.2.9",
      "resolved": "https://registry.npmjs.org/string.prototype.trim/-/string.prototype.trim-1.2.9.tgz",
      "integrity": "sha512-klHuCNxiMZ8MlsOihJhJEBJAiMVqU3Z2nEXWfWnIqjN0gEFS9J9+IxKozWWtQGcgoa1WUZzLjKPTr4ZHNFTFxw==",
      "dev": true,
      "dependencies": {
        "call-bind": "^1.0.7",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.0",
        "es-object-atoms": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/string.prototype.trimend": {
      "version": "1.0.8",
      "resolved": "https://registry.npmjs.org/string.prototype.trimend/-/string.prototype.trimend-1.0.8.tgz",
      "integrity": "sha512-p73uL5VCHCO2BZZ6krwwQE3kCzM7NKmis8S//xEC6fQonchbum4eP6kR4DLEjQFO3Wnj3Fuo8NM0kOSjVdHjZQ==",
      "dev": true,
      "dependencies": {
        "call-bind": "^1.0.7",
        "define-properties": "^1.2.1",
        "es-object-atoms": "^1.0.0"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/string.prototype.trimstart": {
      "version": "1.0.8",
      "resolved": "https://registry.npmjs.org/string.prototype.trimstart/-/string.prototype.trimstart-1.0.8.tgz",
      "integrity": "sha512-UXSH262CSZY1tfu3G3Secr6uGLCFVPMhIqHjlgCUtCCcgihYc/xKs9djMTMUOb2j1mVSeU8EU6NWc/iQKU6Gfg==",
      "dev": true,
      "dependencies": {
        "call-bind": "^1.0.7",
        "define-properties": "^1.2.1",
        "es-object-atoms": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/strip-ansi": {
      "version": "6.0.1",
      "resolved": "https://registry.npmjs.org/strip-ansi/-/strip-ansi-6.0.1.tgz",
      "integrity": "sha512-Y38VPSHcqkFrCpFnQ9vuSXmquuv5oXOKpGeT6aGrr3o3Gc9AlVa6JBfUSOCnbxGGZF+/0ooI7KrPuUSztUdU5A==",
      "dev": true,
      "dependencies": {
        "ansi-regex": "^5.0.1"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/strip-ansi-cjs": {
      "name": "strip-ansi",
      "version": "6.0.1",
      "resolved": "https://registry.npmjs.org/strip-ansi/-/strip-ansi-6.0.1.tgz",
      "integrity": "sha512-Y38VPSHcqkFrCpFnQ9vuSXmquuv5oXOKpGeT6aGrr3o3Gc9AlVa6JBfUSOCnbxGGZF+/0ooI7KrPuUSztUdU5A==",
      "dev": true,
      "dependencies": {
        "ansi-regex": "^5.0.1"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/strip-bom": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/strip-bom/-/strip-bom-3.0.0.tgz",
      "integrity": "sha512-vavAMRXOgBVNF6nyEEmL3DBK19iRpDcoIwW+swQ+CbGiu7lju6t+JklA1MHweoWtadgt4ISVUsXLyDq34ddcwA==",
      "dev": true,
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/strip-json-comments": {
      "version": "3.1.1",
      "resolved": "https://registry.npmjs.org/strip-json-comments/-/strip-json-comments-3.1.1.tgz",
      "integrity": "sha512-6fPc+R4ihwqP6N/aIv2f1gMH8lOVtWQHoqC4yK6oSDVVocumAsfCqjkXnqiYMhmMwS/mEHLp7Vehlt3ql6lEig==",
      "dev": true,
      "engines": {
        "node": ">=8"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/styled-jsx": {
      "version": "5.1.1",
      "resolved": "https://registry.npmjs.org/styled-jsx/-/styled-jsx-5.1.1.tgz",
      "integrity": "sha512-pW7uC1l4mBZ8ugbiZrcIsiIvVx1UmTfw7UkC3Um2tmfUq9Bhk8IiyEIPl6F8agHgjzku6j0xQEZbfA5uSgSaCw==",
      "dependencies": {
        "client-only": "0.0.1"
      },
      "engines": {
        "node": ">= 12.0.0"
      },
      "peerDependencies": {
        "react": ">= 16.8.0 || 17.x.x || ^18.0.0-0"
      },
      "peerDependenciesMeta": {
        "@babel/core": {
          "optional": true
        },
        "babel-plugin-macros": {
          "optional": true
        }
      }
    },
    "node_modules/sucrase": {
      "version": "3.35.0",
      "resolved": "https://registry.npmjs.org/sucrase/-/sucrase-3.35.0.tgz",
      "integrity": "sha512-8EbVDiu9iN/nESwxeSxDKe0dunta1GOlHufmSSXxMD2z2/tMZpDMpvXQGsc+ajGo8y2uYUmixaSRUc/QPoQ0GA==",
      "dev": true,
      "dependencies": {
        "@jridgewell/gen-mapping": "^0.3.2",
        "commander": "^4.0.0",
        "glob": "^10.3.10",
        "lines-and-columns": "^1.1.6",
        "mz": "^2.7.0",
        "pirates": "^4.0.1",
        "ts-interface-checker": "^0.1.9"
      },
      "bin": {
        "sucrase": "bin/sucrase",
        "sucrase-node": "bin/sucrase-node"
      },
      "engines": {
        "node": ">=16 || 14 >=14.17"
      }
    },
    "node_modules/supports-color": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/supports-color/-/supports-color-7.2.0.tgz",
      "integrity": "sha512-qpCAvRl9stuOHveKsn7HncJRvv501qIacKzQlO/+Lwxc9+0q2wLyv4Dfvt80/DPn2pqOBsJdDiogXGR9+OvwRw==",
      "dev": true,
      "dependencies": {
        "has-flag": "^4.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/supports-preserve-symlinks-flag": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/supports-preserve-symlinks-flag/-/supports-preserve-symlinks-flag-1.0.0.tgz",
      "integrity": "sha512-ot0WnXS9fgdkgIcePe6RHNk1WA8+muPa6cSjeR3V8K27q9BB1rTE3R1p7Hv0z1ZyAc8s6Vvv8DIyWf681MAt0w==",
      "dev": true,
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/tailwindcss": {
      "version": "3.4.3",
      "resolved": "https://registry.npmjs.org/tailwindcss/-/tailwindcss-3.4.3.tgz",
      "integrity": "sha512-U7sxQk/n397Bmx4JHbJx/iSOOv5G+II3f1kpLpY2QeUv5DcPdcTsYLlusZfq1NthHS1c1cZoyFmmkex1rzke0A==",
      "dev": true,
      "dependencies": {
        "@alloc/quick-lru": "^5.2.0",
        "arg": "^5.0.2",
        "chokidar": "^3.5.3",
        "didyoumean": "^1.2.2",
        "dlv": "^1.1.3",
        "fast-glob": "^3.3.0",
        "glob-parent": "^6.0.2",
        "is-glob": "^4.0.3",
        "jiti": "^1.21.0",
        "lilconfig": "^2.1.0",
        "micromatch": "^4.0.5",
        "normalize-path": "^3.0.0",
        "object-hash": "^3.0.0",
        "picocolors": "^1.0.0",
        "postcss": "^8.4.23",
        "postcss-import": "^15.1.0",
        "postcss-js": "^4.0.1",
        "postcss-load-config": "^4.0.1",
        "postcss-nested": "^6.0.1",
        "postcss-selector-parser": "^6.0.11",
        "resolve": "^1.22.2",
        "sucrase": "^3.32.0"
      },
      "bin": {
        "tailwind": "lib/cli.js",
        "tailwindcss": "lib/cli.js"
      },
      "engines": {
        "node": ">=14.0.0"
      }
    },
    "node_modules/tapable": {
      "version": "2.2.1",
      "resolved": "https://registry.npmjs.org/tapable/-/tapable-2.2.1.tgz",
      "integrity": "sha512-GNzQvQTOIP6RyTfE2Qxb8ZVlNmw0n88vp1szwWRimP02mnTsx3Wtn5qRdqY9w2XduFNUgvOwhNnQsjwCp+kqaQ==",
      "dev": true,
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/text-table": {
      "version": "0.2.0",
      "resolved": "https://registry.npmjs.org/text-table/-/text-table-0.2.0.tgz",
      "integrity": "sha512-N+8UisAXDGk8PFXP4HAzVR9nbfmVJ3zYLAWiTIoqC5v5isinhr+r5uaO8+7r3BMfuNIufIsA7RdpVgacC2cSpw==",
      "dev": true
    },
    "node_modules/thenify": {
      "version": "3.3.1",
      "resolved": "https://registry.npmjs.org/thenify/-/thenify-3.3.1.tgz",
      "integrity": "sha512-RVZSIV5IG10Hk3enotrhvz0T9em6cyHBLkH/YAZuKqd8hRkKhSfCGIcP2KUY0EPxndzANBmNllzWPwak+bheSw==",
      "dev": true,
      "dependencies": {
        "any-promise": "^1.0.0"
      }
    },
    "node_modules/thenify-all": {
      "version": "1.6.0",
      "resolved": "https://registry.npmjs.org/thenify-all/-/thenify-all-1.6.0.tgz",
      "integrity": "sha512-RNxQH/qI8/t3thXJDwcstUO4zeqo64+Uy/+sNVRBx4Xn2OX+OZ9oP+iJnNFqplFra2ZUVeKCSa2oVWi3T4uVmA==",
      "dev": true,
      "dependencies": {
        "thenify": ">= 3.1.0 < 4"
      },
      "engines": {
        "node": ">=0.8"
      }
    },
    "node_modules/to-regex-range": {
      "version": "5.0.1",
      "resolved": "https://registry.npmjs.org/to-regex-range/-/to-regex-range-5.0.1.tgz",
      "integrity": "sha512-65P7iz6X5yEr1cwcgvQxbbIw7Uk3gOy5dIdtZ4rDveLqhrdJP+Li/Hx6tyK0NEb+2GCyneCMJiGqrADCSNk8sQ==",
      "dev": true,
      "dependencies": {
        "is-number": "^7.0.0"
      },
      "engines": {
        "node": ">=8.0"
      }
    },
    "node_modules/ts-api-utils": {
      "version": "1.3.0",
      "resolved": "https://registry.npmjs.org/ts-api-utils/-/ts-api-utils-1.3.0.tgz",
      "integrity": "sha512-UQMIo7pb8WRomKR1/+MFVLTroIvDVtMX3K6OUir8ynLyzB8Jeriont2bTAtmNPa1ekAgN7YPDyf6V+ygrdU+eQ==",
      "dev": true,
      "engines": {
        "node": ">=16"
      },
      "peerDependencies": {
        "typescript": ">=4.2.0"
      }
    },
    "node_modules/ts-interface-checker": {
      "version": "0.1.13",
      "resolved": "https://registry.npmjs.org/ts-interface-checker/-/ts-interface-checker-0.1.13.tgz",
      "integrity": "sha512-Y/arvbn+rrz3JCKl9C4kVNfTfSm2/mEp5FSz5EsZSANGPSlQrpRI5M4PKF+mJnE52jOO90PnPSc3Ur3bTQw0gA==",
      "dev": true
    },
    "node_modules/tsconfig-paths": {
      "version": "3.15.0",
      "resolved": "https://registry.npmjs.org/tsconfig-paths/-/tsconfig-paths-3.15.0.tgz",
      "integrity": "sha512-2Ac2RgzDe/cn48GvOe3M+o82pEFewD3UPbyoUHHdKasHwJKjds4fLXWf/Ux5kATBKN20oaFGu+jbElp1pos0mg==",
      "dev": true,
      "dependencies": {
        "@types/json5": "^0.0.29",
        "json5": "^1.0.2",
        "minimist": "^1.2.6",
        "strip-bom": "^3.0.0"
      }
    },
    "node_modules/tslib": {
      "version": "2.6.2",
      "resolved": "https://registry.npmjs.org/tslib/-/tslib-2.6.2.tgz",
      "integrity": "sha512-AEYxH93jGFPn/a2iVAwW87VuUIkR1FVUKB77NwMF7nBTDkDrrT/Hpt/IrCJ0QXhW27jTBDcf5ZY7w6RiqTMw2Q=="
    },
    "node_modules/type-check": {
      "version": "0.4.0",
      "resolved": "https://registry.npmjs.org/type-check/-/type-check-0.4.0.tgz",
      "integrity": "sha512-XleUoc9uwGXqjWwXaUTZAmzMcFZ5858QA2vvx1Ur5xIcixXIP+8LnFDgRplU30us6teqdlskFfu+ae4K79Ooew==",
      "dev": true,
      "dependencies": {
        "prelude-ls": "^1.2.1"
      },
      "engines": {
        "node": ">= 0.8.0"
      }
    },
    "node_modules/type-fest": {
      "version": "0.20.2",
      "resolved": "https://registry.npmjs.org/type-fest/-/type-fest-0.20.2.tgz",
      "integrity": "sha512-Ne+eE4r0/iWnpAxD852z3A+N0Bt5RN//NjJwRd2VFHEmrywxf5vsZlh4R6lixl6B+wz/8d+maTSAkN1FIkI3LQ==",
      "dev": true,
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/typed-array-buffer": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/typed-array-buffer/-/typed-array-buffer-1.0.2.tgz",
      "integrity": "sha512-gEymJYKZtKXzzBzM4jqa9w6Q1Jjm7x2d+sh19AdsD4wqnMPDYyvwpsIc2Q/835kHuo3BEQ7CjelGhfTsoBb2MQ==",
      "dev": true,
      "dependencies": {
        "call-bind": "^1.0.7",
        "es-errors": "^1.3.0",
        "is-typed-array": "^1.1.13"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/typed-array-byte-length": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/typed-array-byte-length/-/typed-array-byte-length-1.0.1.tgz",
      "integrity": "sha512-3iMJ9q0ao7WE9tWcaYKIptkNBuOIcZCCT0d4MRvuuH88fEoEH62IuQe0OtraD3ebQEoTRk8XCBoknUNc1Y67pw==",
      "dev": true,
      "dependencies": {
        "call-bind": "^1.0.7",
        "for-each": "^0.3.3",
        "gopd": "^1.0.1",
        "has-proto": "^1.0.3",
        "is-typed-array": "^1.1.13"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/typed-array-byte-offset": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/typed-array-byte-offset/-/typed-array-byte-offset-1.0.2.tgz",
      "integrity": "sha512-Ous0vodHa56FviZucS2E63zkgtgrACj7omjwd/8lTEMEPFFyjfixMZ1ZXenpgCFBBt4EC1J2XsyVS2gkG0eTFA==",
      "dev": true,
      "dependencies": {
        "available-typed-arrays": "^1.0.7",
        "call-bind": "^1.0.7",
        "for-each": "^0.3.3",
        "gopd": "^1.0.1",
        "has-proto": "^1.0.3",
        "is-typed-array": "^1.1.13"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/typed-array-length": {
      "version": "1.0.6",
      "resolved": "https://registry.npmjs.org/typed-array-length/-/typed-array-length-1.0.6.tgz",
      "integrity": "sha512-/OxDN6OtAk5KBpGb28T+HZc2M+ADtvRxXrKKbUwtsLgdoxgX13hyy7ek6bFRl5+aBs2yZzB0c4CnQfAtVypW/g==",
      "dev": true,
      "dependencies": {
        "call-bind": "^1.0.7",
        "for-each": "^0.3.3",
        "gopd": "^1.0.1",
        "has-proto": "^1.0.3",
        "is-typed-array": "^1.1.13",
        "possible-typed-array-names": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/typescript": {
      "version": "5.4.5",
      "resolved": "https://registry.npmjs.org/typescript/-/typescript-5.4.5.tgz",
      "integrity": "sha512-vcI4UpRgg81oIRUFwR0WSIHKt11nJ7SAVlYNIu+QpqeyXP+gpQJy/Z4+F0aGxSE4MqwjyXvW/TzgkLAx2AGHwQ==",
      "dev": true,
      "bin": {
        "tsc": "bin/tsc",
        "tsserver": "bin/tsserver"
      },
      "engines": {
        "node": ">=14.17"
      }
    },
    "node_modules/unbox-primitive": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/unbox-primitive/-/unbox-primitive-1.0.2.tgz",
      "integrity": "sha512-61pPlCD9h51VoreyJ0BReideM3MDKMKnh6+V9L08331ipq6Q8OFXZYiqP6n/tbHx4s5I9uRhcye6BrbkizkBDw==",
      "dev": true,
      "dependencies": {
        "call-bind": "^1.0.2",
        "has-bigints": "^1.0.2",
        "has-symbols": "^1.0.3",
        "which-boxed-primitive": "^1.0.2"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/undici-types": {
      "version": "5.26.5",
      "resolved": "https://registry.npmjs.org/undici-types/-/undici-types-5.26.5.tgz",
      "integrity": "sha512-JlCMO+ehdEIKqlFxk6IfVoAUVmgz7cU7zD/h9XZ0qzeosSHmUJVOzSQvvYSYWXkFXC+IfLKSIffhv0sVZup6pA==",
      "dev": true
    },
    "node_modules/uri-js": {
      "version": "4.4.1",
      "resolved": "https://registry.npmjs.org/uri-js/-/uri-js-4.4.1.tgz",
      "integrity": "sha512-7rKUyy33Q1yc98pQ1DAmLtwX109F7TIfWlW1Ydo8Wl1ii1SeHieeh0HHfPeL2fMXK6z0s8ecKs9frCuLJvndBg==",
      "dev": true,
      "dependencies": {
        "punycode": "^2.1.0"
      }
    },
    "node_modules/util-deprecate": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/util-deprecate/-/util-deprecate-1.0.2.tgz",
      "integrity": "sha512-EPD5q1uXyFxJpCrLnCc1nHnq3gOa6DZBocAIiI2TaSCA7VCJ1UJDMagCzIkXNsUYfD1daK//LTEQ8xiIbrHtcw==",
      "dev": true
    },
    "node_modules/which": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/which/-/which-2.0.2.tgz",
      "integrity": "sha512-BLI3Tl1TW3Pvl70l3yq3Y64i+awpwXqsGBYWkkqMtnbXgrMD+yj7rhW0kuEDxzJaYXGjEW5ogapKNMEKNMjibA==",
      "dev": true,
      "dependencies": {
        "isexe": "^2.0.0"
      },
      "bin": {
        "node-which": "bin/node-which"
      },
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/which-boxed-primitive": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/which-boxed-primitive/-/which-boxed-primitive-1.0.2.tgz",
      "integrity": "sha512-bwZdv0AKLpplFY2KZRX6TvyuN7ojjr7lwkg6ml0roIy9YeuSr7JS372qlNW18UQYzgYK9ziGcerWqZOmEn9VNg==",
      "dev": true,
      "dependencies": {
        "is-bigint": "^1.0.1",
        "is-boolean-object": "^1.1.0",
        "is-number-object": "^1.0.4",
        "is-string": "^1.0.5",
        "is-symbol": "^1.0.3"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/which-builtin-type": {
      "version": "1.1.3",
      "resolved": "https://registry.npmjs.org/which-builtin-type/-/which-builtin-type-1.1.3.tgz",
      "integrity": "sha512-YmjsSMDBYsM1CaFiayOVT06+KJeXf0o5M/CAd4o1lTadFAtacTUM49zoYxr/oroopFDfhvN6iEcBxUyc3gvKmw==",
      "dev": true,
      "dependencies": {
        "function.prototype.name": "^1.1.5",
        "has-tostringtag": "^1.0.0",
        "is-async-function": "^2.0.0",
        "is-date-object": "^1.0.5",
        "is-finalizationregistry": "^1.0.2",
        "is-generator-function": "^1.0.10",
        "is-regex": "^1.1.4",
        "is-weakref": "^1.0.2",
        "isarray": "^2.0.5",
        "which-boxed-primitive": "^1.0.2",
        "which-collection": "^1.0.1",
        "which-typed-array": "^1.1.9"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/which-collection": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/which-collection/-/which-collection-1.0.2.tgz",
      "integrity": "sha512-K4jVyjnBdgvc86Y6BkaLZEN933SwYOuBFkdmBu9ZfkcAbdVbpITnDmjvZ/aQjRXQrv5EPkTnD1s39GiiqbngCw==",
      "dev": true,
      "dependencies": {
        "is-map": "^2.0.3",
        "is-set": "^2.0.3",
        "is-weakmap": "^2.0.2",
        "is-weakset": "^2.0.3"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/which-typed-array": {
      "version": "1.1.15",
      "resolved": "https://registry.npmjs.org/which-typed-array/-/which-typed-array-1.1.15.tgz",
      "integrity": "sha512-oV0jmFtUky6CXfkqehVvBP/LSWJ2sy4vWMioiENyJLePrBO/yKyV9OyJySfAKosh+RYkIl5zJCNZ8/4JncrpdA==",
      "dev": true,
      "dependencies": {
        "available-typed-arrays": "^1.0.7",
        "call-bind": "^1.0.7",
        "for-each": "^0.3.3",
        "gopd": "^1.0.1",
        "has-tostringtag": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/wrap-ansi": {
      "version": "8.1.0",
      "resolved": "https://registry.npmjs.org/wrap-ansi/-/wrap-ansi-8.1.0.tgz",
      "integrity": "sha512-si7QWI6zUMq56bESFvagtmzMdGOtoxfR+Sez11Mobfc7tm+VkUckk9bW2UeffTGVUbOksxmSw0AA2gs8g71NCQ==",
      "dev": true,
      "dependencies": {
        "ansi-styles": "^6.1.0",
        "string-width": "^5.0.1",
        "strip-ansi": "^7.0.1"
      },
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/chalk/wrap-ansi?sponsor=1"
      }
    },
    "node_modules/wrap-ansi-cjs": {
      "name": "wrap-ansi",
      "version": "7.0.0",
      "resolved": "https://registry.npmjs.org/wrap-ansi/-/wrap-ansi-7.0.0.tgz",
      "integrity": "sha512-YVGIj2kamLSTxw6NsZjoBxfSwsn0ycdesmc4p+Q21c5zPuZ1pl+NfxVdxPtdHvmNVOQ6XSYG4AUtyt/Fi7D16Q==",
      "dev": true,
      "dependencies": {
        "ansi-styles": "^4.0.0",
        "string-width": "^4.1.0",
        "strip-ansi": "^6.0.0"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/chalk/wrap-ansi?sponsor=1"
      }
    },
    "node_modules/wrap-ansi-cjs/node_modules/emoji-regex": {
      "version": "8.0.0",
      "resolved": "https://registry.npmjs.org/emoji-regex/-/emoji-regex-8.0.0.tgz",
      "integrity": "sha512-MSjYzcWNOA0ewAHpz0MxpYFvwg6yjy1NG3xteoqz644VCo/RPgnr1/GGt+ic3iJTzQ8Eu3TdM14SawnVUmGE6A==",
      "dev": true
    },
    "node_modules/wrap-ansi-cjs/node_modules/string-width": {
      "version": "4.2.3",
      "resolved": "https://registry.npmjs.org/string-width/-/string-width-4.2.3.tgz",
      "integrity": "sha512-wKyQRQpjJ0sIp62ErSZdGsjMJWsap5oRNihHhu6G7JVO/9jIB6UyevL+tXuOqrng8j/cxKTWyWUwvSTriiZz/g==",
      "dev": true,
      "dependencies": {
        "emoji-regex": "^8.0.0",
        "is-fullwidth-code-point": "^3.0.0",
        "strip-ansi": "^6.0.1"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/wrap-ansi/node_modules/ansi-regex": {
      "version": "6.0.1",
      "resolved": "https://registry.npmjs.org/ansi-regex/-/ansi-regex-6.0.1.tgz",
      "integrity": "sha512-n5M855fKb2SsfMIiFFoVrABHJC8QtHwVx+mHWP3QcEqBHYienj5dHSgjbxtC0WEZXYt4wcD6zrQElDPhFuZgfA==",
      "dev": true,
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/chalk/ansi-regex?sponsor=1"
      }
    },
    "node_modules/wrap-ansi/node_modules/ansi-styles": {
      "version": "6.2.1",
      "resolved": "https://registry.npmjs.org/ansi-styles/-/ansi-styles-6.2.1.tgz",
      "integrity": "sha512-bN798gFfQX+viw3R7yrGWRqnrN2oRkEkUjjl4JNn4E8GxxbjtG3FbrEIIY3l8/hrwUwIeCZvi4QuOTP4MErVug==",
      "dev": true,
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/chalk/ansi-styles?sponsor=1"
      }
    },
    "node_modules/wrap-ansi/node_modules/strip-ansi": {
      "version": "7.1.0",
      "resolved": "https://registry.npmjs.org/strip-ansi/-/strip-ansi-7.1.0.tgz",
      "integrity": "sha512-iq6eVVI64nQQTRYq2KtEg2d2uU7LElhTJwsH4YzIHZshxlgZms/wIc4VoDQTlG/IvVIrBKG06CrZnp0qv7hkcQ==",
      "dev": true,
      "dependencies": {
        "ansi-regex": "^6.0.1"
      },
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/chalk/strip-ansi?sponsor=1"
      }
    },
    "node_modules/wrappy": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/wrappy/-/wrappy-1.0.2.tgz",
      "integrity": "sha512-l4Sp/DRseor9wL6EvV2+TuQn63dMkPjZ/sp9XkghTEbV9KlPS1xUsZ3u7/IQO4wxtcFB4bgpQPRcR3QCvezPcQ==",
      "dev": true
    },
    "node_modules/yallist": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/yallist/-/yallist-4.0.0.tgz",
      "integrity": "sha512-3wdGidZyq5PB084XLES5TpOSRA3wjXAlIWMhum2kRcv/41Sn2emQ0dycQW4uZXLejwKvg6EsvbdlVL+FYEct7A==",
      "dev": true
    },
    "node_modules/yaml": {
      "version": "2.4.1",
      "resolved": "https://registry.npmjs.org/yaml/-/yaml-2.4.1.tgz",
      "integrity": "sha512-pIXzoImaqmfOrL7teGUBt/T7ZDnyeGBWyXQBvOVhLkWLN37GXv8NMLK406UY6dS51JfcQHsmcW5cJ441bHg6Lg==",
      "dev": true,
      "bin": {
        "yaml": "bin.mjs"
      },
      "engines": {
        "node": ">= 14"
      }
    },
    "node_modules/yocto-queue": {
      "version": "0.1.0",
      "resolved": "https://registry.npmjs.org/yocto-queue/-/yocto-queue-0.1.0.tgz",
      "integrity": "sha512-rVksvsnNCdJ/ohGc6xgPwyN8eheCxsiLM8mxuE/t/mOVqJewPuO1miLpTHQiRgTKCLexL4MeAFVagts7HmNZ2Q==",
      "dev": true,
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    }
  }
}

</game/frontend/package-lock.json>

<game/frontend/package.json>
{
  "name": "game",
  "version": "0.1.0",
  "private": true,
  "scripts": {
    "dev": "next dev",
    "build": "next build",
    "start": "next start",
    "lint": "next lint"
  },
  "dependencies": {
    "@radix-ui/react-alert-dialog": "^1.0.5",
    "@radix-ui/react-aspect-ratio": "^1.0.3",
    "@radix-ui/react-avatar": "^1.0.4",
    "@radix-ui/react-dialog": "^1.0.5",
    "@radix-ui/react-dropdown-menu": "^2.0.6",
    "@radix-ui/react-icons": "^1.3.0",
    "@radix-ui/react-label": "^2.0.2",
    "@radix-ui/react-slot": "^1.0.2",
    "@radix-ui/react-toast": "^1.1.5",
    "class-variance-authority": "^0.7.0",
    "clsx": "^2.1.0",
    "framer-motion": "^11.2.4",
    "lucide-react": "^0.372.0",
    "next": "14.2.2",
    "react": "^18",
    "react-dom": "^18",
    "socket.io-client": "^4.7.5",
    "tailwind-merge": "^2.3.0",
    "tailwindcss-animate": "^1.0.7"
  },
  "devDependencies": {
    "typescript": "^5",
    "@types/node": "^20",
    "@types/react": "^18",
    "@types/react-dom": "^18",
    "postcss": "^8",
    "tailwindcss": "^3.4.1",
    "eslint": "^8",
    "eslint-config-next": "14.2.2"
  }
}

</game/frontend/package.json>

<game/frontend/public/research-paper-content.json>
{
    "abstract": "This paper explores the intersection of artificial intelligence (AI) and sustainability, examining how AI can be leveraged to address pressing environmental challenges. We investigate the potential of AI-powered solutions in areas such as renewable energy optimization, smart city planning, and waste management. Through a comprehensive literature review and case studies, we highlight the opportunities and challenges associated with integrating AI into sustainable development initiatives. The findings of this study provide valuable insights for policymakers, researchers, and practitioners seeking to harness the power of AI for a more sustainable future.",
    "sections": [
      {
        "title": "Introduction",
        "content": "In the face of pressing environmental challenges, such as climate change, resource depletion, and environmental degradation, the need for sustainable solutions has never been more urgent. Artificial intelligence (AI) has emerged as a promising technology that can play a crucial role in addressing these challenges and driving sustainable development. This paper explores the intersection of AI and sustainability, examining how AI-powered solutions can be leveraged to optimize renewable energy systems, enhance smart city planning, and improve waste management and recycling processes.",
        "image": {
          "alt": "Renewable energy optimization",
          "src": "/images/renewable-energy-optimization.jpg"
        }
      },
      {
        "title": "AI and Renewable Energy Optimization",
        "content": "One of the key areas where AI can contribute to sustainability is in the optimization of renewable energy systems. AI algorithms can be used to predict energy demand, forecast weather patterns, and optimize the operation of renewable energy generation and storage systems. This can lead to more efficient utilization of renewable resources, reduced energy waste, and improved grid stability.",
        "image": {
          "alt": "AI-powered renewable energy optimization in action",
          "src": "/placeholder.svg"
        }
      },
      {
        "title": "AI-Powered Smart City Planning",
        "content": "AI can also play a crucial role in the development of smart cities, where technology is used to optimize urban infrastructure and services. AI-powered solutions can be used for traffic management, energy distribution, waste management, and urban planning, leading to more efficient and sustainable cities.",
        "image": {
          "alt": "AI-powered smart city planning",
          "src": "/placeholder.svg"
        }
      },
      {
        "title": "AI in Waste Management and Recycling",
        "content": "AI can also be leveraged to improve waste management and recycling processes. AI-powered systems can be used for waste sorting, contamination detection, and optimization of recycling logistics, leading to higher recycling rates and reduced waste sent to landfills.",
        "image": {
          "alt": "AI-powered waste management and recycling",
          "src": "/images/ai-waste-management.jpg"
        }
      },
      {
        "title": "Challenges and Limitations",
        "content": "While the potential of AI for sustainability is significant, there are also challenges and limitations that must be addressed. These include issues related to data availability, algorithm bias, energy consumption of AI systems, and the need for interdisciplinary collaboration to fully realize the benefits of AI-powered sustainable solutions."
      },
      {
        "title": "Conclusion",
        "content": "In conclusion, this paper has demonstrated the significant potential of AI to contribute to sustainable development. By leveraging AI-powered solutions in areas such as renewable energy optimization, smart city planning, and waste management, we can make significant strides towards a more sustainable future. However, it is crucial to address the challenges and limitations associated with the integration of AI into sustainable initiatives. Through continued research, collaboration, and responsible deployment of AI technologies, we can harness the power of this transformative technology to create a more sustainable and resilient world."
      }
    ]
  }
  
</game/frontend/public/research-paper-content.json>

<game/frontend/README.md>
## Getting Started

> Please note that the frontend here contains placeholder text and not the actual OMNI-EPIC website.  
> Please see [https://omni-epic.vercel.app/](https://omni-epic.vercel.app/) for the actual OMNI-EPIC website.

### Backend
In order to run the game from the root of the repository run:
```bash
cd omni_epic/
python -m game.backend.app
```

Open [http://localhost:3005](http://localhost:3005) with your browser to see the backend result.

### Frontend

Ensure that you have NodeJS installed(https://nodejs.org/en/download/)  
Ensure that you have bun installed as well(https://bun.sh)  

In order to get the packages run
```bash
cd omni_epic/game/frontend/
bun install
```

In order to run the package 
```bash
cd omni_epic/game/frontend
npm run dev
# or
bun run dev
```

Open [http://localhost:3000](http://localhost:3000) with your browser to see the frontend result.

To edit the main page, edit /public/research-paper-content.json and the changes will be reflected in the GUI.

### Changing ports
For backend:  
In omni_epic/game/backend/app.py: `absl_app.run(lambda argv: socketio.run(app, host='0.0.0.0', port=3005))`  

For frontend:  
In omni_epic/game/frontend/.env: `NEXT_PUBLIC_API_URL=http://localhost:3005` (this should point to the backend port)  
In omni_epic/game/frontend/package.json: `"dev": "next dev"` to `"dev": "next dev -p 4000"`  

</game/frontend/README.md>

<game/frontend/src/app/globals.css>
@tailwind base;
  @tailwind components;
  @tailwind utilities;
  
</game/frontend/src/app/globals.css>

<game/frontend/src/app/KeyIdentifier.tsx>
"use client"
import { Connected } from '@/components/ui/connected/connected';
import { NotConnected } from '@/components/ui/connected/notconnected';
import React, { useEffect, useState } from 'react';
import { io, Socket } from 'socket.io-client';
import { Button } from "@/components/ui/button"
import { ToastAction } from "@/components/ui/toast"
import { useToast } from "@/components/ui/use-toast"
import { ToastDemo } from '@/components/ui/connected/toast';
import { EnvDescriptionEvent } from '../../types/socket_types';
import { ResetAlertDialog } from '@/components/ui/next_level/button_level';
export function SocketIdentifier() {
  const { toast } = useToast()
  const [connected, setConnected] = useState(false);
  const [levelFinished, setLevelFinishedToast] = useState(false); // State to track if the next level toast has been shown
  const [newSocket, setSocket] = useState<Socket | null>(null);
const [nextLevel, setNextLevelToastShown] = useState(false);
  // let socket: Socket;
  // useEffect(() => {
  //   // This side effect reacts to the change in level completion status.
  //   if (nextLevel) {
  //     // Show the toast for level completion.
  //     toast({
  //       title: "You've finished the first level!",
  //       duration: 900000, // 15 minutes or any desired duration
  //       description: 'You have reached the next level. Prepare for new challenges!',
  //       action: (
  //         <ToastAction altText="Dismiss">Dismiss</ToastAction>
  //       ),
  //     });
  //   }
  // }, [nextLevel, toast]);
  useEffect(() => {
    // This side effect reacts to the change in level completion status.
    if (levelFinished) {
      // Show the toast for level completion.
      toast({
        title: "You've finished the first level!",
        duration:3000, // 15 minutes or any desired duration
        description: 'You have reached the next level. Prepare for new challenges!',
        action: (
          <ToastAction altText="Dismiss">Dismiss</ToastAction>
        ),
      });
    }
  }, [levelFinished, toast]);
  useEffect(() => {

    const socket = io(process.env.NEXT_PUBLIC_API_URL!);
    setSocket(socket);
    
    // socket = io(process.env.NEXT_PUBLIC_API_URL!, {
    //   // Add any options here
    // });
    console.log(process.env.NEXT_PUBLIC_API_URL!);
    // socket.on('connect', () => {
    //   console.log('Connected to Socket.IO server');
    //   setConnected(true);
    //   // Show the toast notification on connect
    //   toast({
    //     title: 'Socket Connection Established',
    //     description: 'You are now connected to the server.',
    //     action: (
    //       <ToastAction altText="See connection details">Details</ToastAction>
    //     ),
    //   });
    // });
    socket.on('connect', () => {
      console.log('Connected to Socket.IO server');
      setConnected(true);
    });
    socket.on('disconnect', () => {
      console.log('Disconnected from Socket.IO server');
      setConnected(false);
    });
    socket.on('env_description', (data: EnvDescriptionEvent) => {
      toast({
        className: 'text-4xl ',
        title: 'Instructions for the current level:',
        description: <div>{data.description.split('\n').map(
          (line, index) => (
            <div key={index}>{line}<br/></div>
          )
        )}</div>,
        duration: 40000,
        action: (
          <ToastAction altText="View details" >Close</ToastAction>
        ),
      });
    });
    socket.on('reset_message',()=>{
      setLevelFinishedToast(false);
    })
    socket.on('level_complete', () => {
      console.log('Level completed')
      // Show a toast notification about starting the next level
      // console.log(levelFinished)
      // if (!levelFinished) {
      //   toast({
      //     title: 'Next Level!',
      //     duration:900000,
      //     description: 'You have reached the next level. Prepare for new challenges!',
      //     action: (
      //       <ToastAction altText="View level details">Level Details</ToastAction>
      //     ),
      //   });
      //   // Mark the toast as shown
        setLevelFinishedToast(true);
      // }


 

    });

    socket.on('next_level', () => {
      // console.log('Next level message received')
      // Show a toast notification about starting the next level
      // console.log(levelFinished)
      // if (!levelFinished) {
      //   toast({
      //     title: 'Next Level!',
      //     duration:900000,
      //     description: 'You have reached the next level. Prepare for new challenges!',
      //     action: (
      //       <ToastAction altText="View level details">Level Details</ToastAction>
      //     ),
      //   });
      //   // Mark the toast as shown
        setNextLevelToastShown(true);
      // }


 

    });




    const handleKeyDown = (event: KeyboardEvent) => {
      let action;
      switch (event.key) {
        case 'w':
        case 'ArrowUp':
          action = 1; // Go forward
          break;

        case 's':
        case 'ArrowDown':
          action = 2; // Go backward
          break;

        case 'a':
        case 'ArrowLeft':
          action = 3; // Rotate counterclockwise
          break;

        case 'd':
        case 'ArrowRight':
          action = 4; // Rotate clockwise
          break;

        case 'm':
        case 'Spacebar':
          action = 5; // Jump
          break;

        default:
          return;
      }
      if (connected && action !== undefined) {
        socket.emit('action', { action });
      }
    };

    window.addEventListener('keydown', handleKeyDown);

    return () => {
      socket.off('connect');
      socket.off('disconnect');
      socket.off('level_complete');
      socket.off('env_description'); // Clean up the listener
      socket.close();
      window.removeEventListener('keydown', handleKeyDown);
    };
  }, [connected, toast]); // Include 'toast' in the dependency array to ensure it's captured by useEffect
  const handleNextLevel = () => {
    newSocket?.emit('next_level');
  };

  const handleReset = () => {
    // setLevelFinishedToast(false);
    newSocket?.emit('reset');
 
  };
  return (
    <div className="flex flex-col items-stretch space-y-2">
      {/* <ToastDemo></ToastDemo> */}
      <div className="min-w-full">
        {connected ? <Connected></Connected> : <NotConnected></NotConnected>}
      </div>
      <Button onClick={handleNextLevel} className="w-full" >Next Level</Button>

      <div className="min-w-full">
        <ResetAlertDialog onConfirm={handleReset}></ResetAlertDialog>
      </div>

      {/* <button onClick={handleReset}>Reset Level</button> */}
      {/* {levelFinished ? <div>Level completed</div> : <div>Level not completed</div>} */}
    </div>
  );
}
</game/frontend/src/app/KeyIdentifier.tsx>

<game/frontend/src/app/layout.tsx>
import type { Metadata } from "next";
import { Inter } from "next/font/google";
import "./globals.css";
import { Toaster } from "@/components/ui/toaster"
const inter = Inter({ subsets: ["latin"] });

export const metadata: Metadata = {
  title: "Create Next App",
  description: "Generated by create next app",
};

export default function RootLayout({
  children,
}: Readonly<{
  children: React.ReactNode;
}>) {
  return (
    <html lang="en">
      <body className={inter.className}>
      <main>{children}</main>
        
      <Toaster /></body>
   
    </html>
  );
}

</game/frontend/src/app/layout.tsx>

<game/frontend/src/app/leaderboard/page.tsx>
import { LeaderBoard } from "@/components/leader-board";

export default function MainLeaderBoardPage(){
    return (
        <div>
          <LeaderBoard/>
        </div>
    )
}
</game/frontend/src/app/leaderboard/page.tsx>

<game/frontend/src/app/page.tsx>
import { AcademicPage } from "@/components/academic_page_v2/acad-page_2";
import { HeaderComponent } from "@/components/header-component";
import { HomePage } from "@/components/home-page";
import { Button } from "@/components/ui/button";
import Link from "next/link"
import { SheetTrigger, SheetContent, Sheet } from "@/components/ui/sheet"
import { Label } from "@/components/ui/label"
import { DropdownMenuTrigger, DropdownMenuRadioItem, DropdownMenuRadioGroup, DropdownMenuContent, DropdownMenu } from "@/components/ui/dropdown-menu"
import { TableHead, TableRow, TableHeader, TableCell, TableBody, Table } from "@/components/ui/table"
import { AvatarImage, AvatarFallback, Avatar } from "@/components/ui/avatar"
import { MenuIcon, TrophyIcon } from "@/components/leader-board";


export default function Home() {
  return (
 <div>
    <header className="flex h-16 items-center justify-between px-4 md:px-6 border-b">
        <Link className="flex items-center gap-2" href="/">
          <TrophyIcon className="h-6 w-6" />
          <span className="font-bold">omni_epic</span>
        </Link>
        <Sheet>
          <SheetTrigger asChild>
            <Button size="icon" variant="outline">
              <MenuIcon className="h-6 w-6" />
              <span className="sr-only">Toggle navigation menu</span>
            </Button>
          </SheetTrigger>
          <SheetContent side="right">
            <div className="grid gap-4 p-4">
              <Link href="/">Home</Link>
              <Link href="/leaderboard">Leaderboard</Link>
              <Link href="/about">About</Link>
              <Link href="#">Contact</Link>
            </div>
          </SheetContent>
        </Sheet>
      </header>
  <section className="bg-gray-100 dark:bg-gray-800 py-12 md:py-20">
        {/* <div className="container">
          <div className="max-w-3xl mx-auto space-y-6 text-center">
            <h1 className="text-3xl md:text-4xl font-bold tracking-tight">
             OMNI EPIC
              <sup>1</sup>
            </h1>
            <div className="text-gray-500 dark:text-gray-400 space-x-4">
              <span>Name 1</span>
              <span>Name 2</span>
            </div>
            <p className="text-gray-500 dark:text-gray-400">
              Published in NeurIPS 2024
            </p>
          </div>
        </div> */}
        <HeaderComponent></HeaderComponent>
      </section>
  <HomePage></HomePage>
  <div className="p-32"></div>
  <AcademicPage></AcademicPage>
 </div>
 
    );
}

</game/frontend/src/app/page.tsx>

<game/frontend/src/components/academic-page.tsx>
"use client"

// to use client for this page to ensure that it can do async loads off JSON's for Static site generation 

export function AcademicPage() {
  return (
    <>
      
      <section className="container py-12 md:py-20">
        <div className="max-w-3xl mx-auto space-y-8">
          <div>
            <h2 className="text-2xl font-bold mb-4">Abstract</h2>
            <p className="text-gray-500 dark:text-gray-400 leading-relaxed">
              This paper explores the intersection of artificial intelligence (AI) and sustainability, examining how AI
              can be leveraged to address pressing environmental challenges. We investigate the potential of AI-powered
              solutions in areas such as renewable energy optimization, smart city planning, and waste management.
              Through a comprehensive literature review and case studies, we highlight the opportunities and challenges
              associated with integrating AI into sustainable development initiatives. The findings of this study
              provide valuable insights for policymakers, researchers, and practitioners seeking to harness the power of
              AI for a more sustainable future.
            </p>
          </div>
          <div>
            <h2 className="text-2xl font-bold mb-4">Table of Contents</h2>
            <ol className="list-decimal pl-6 space-y-2 text-gray-500 dark:text-gray-400">
              <li>Introduction</li>
              <li>AI and Renewable Energy Optimization</li>
              <li>AI-Powered Smart City Planning</li>
              <li>AI in Waste Management and Recycling</li>
              <li>Challenges and Limitations</li>
              <li>Conclusion</li>
            </ol>
          </div>
          <div>
            <h2 className="text-2xl font-bold mb-4">Introduction</h2>
            <p className="text-gray-500 dark:text-gray-400 leading-relaxed">
              In the face of pressing environmental challenges, such as climate change, resource depletion, and
              environmental degradation, the need for sustainable solutions has never been more urgent. Artificial
              intelligence (AI) has emerged as a promising technology that can play a crucial role in addressing these
              challenges and driving sustainable development. This paper explores the intersection of AI and
              sustainability, examining how AI-powered solutions can be leveraged to optimize renewable energy systems,
              enhance smart city planning, and improve waste management and recycling processes.
            </p>
            <div className="mt-4">
              <img
                alt="Renewable energy optimization"
                className="rounded-lg"
                height={450}
                src="/placeholder.svg"
                style={{
                  aspectRatio: "800/450",
                  objectFit: "cover",
                }}
                width={800}
              />
              <p className="text-sm text-gray-500 dark:text-gray-400 mt-2">
                AI-powered solutions for renewable energy optimization
              </p>
            </div>
          </div>
          <div>
            <h2 className="text-2xl font-bold mb-4">AI and Renewable Energy Optimization</h2>
            <p className="text-gray-500 dark:text-gray-400 leading-relaxed">
              One of the key areas where AI can contribute to sustainability is in the optimization of renewable energy
              systems. AI algorithms can be used to predict energy demand, forecast weather patterns, and optimize the
              operation of renewable energy generation and storage systems. This can lead to more efficient utilization
              of renewable resources, reduced energy waste, and improved grid stability.
              <sup>2</sup>
            </p>
            <div className="mt-4">
              <p className="text-sm text-gray-500 dark:text-gray-400 mt-2">
                AI-powered renewable energy optimization in action
              </p>
            </div>
          </div>
          <div>
            <h2 className="text-2xl font-bold mb-4">AI-Powered Smart City Planning</h2>
            <p className="text-gray-500 dark:text-gray-400 leading-relaxed">
              AI can also play a crucial role in the development of smart cities, where technology is used to optimize
              urban infrastructure and services. AI-powered solutions can be used for traffic management, energy
              distribution, waste management, and urban planning, leading to more efficient and sustainable cities.
              <sup>3</sup>
            </p>
            <div className="mt-4">
              <img
                alt="Smart city planning"
                className="rounded-lg"
                height={450}
                src="/placeholder.svg"
                style={{
                  aspectRatio: "800/450",
                  objectFit: "cover",
                }}
                width={800}
              />
              <p className="text-sm text-gray-500 dark:text-gray-400 mt-2">AI-powered smart city planning</p>
            </div>
          </div>
          <div>
            <h2 className="text-2xl font-bold mb-4">AI in Waste Management and Recycling</h2>
            <p className="text-gray-500 dark:text-gray-400 leading-relaxed">
              AI can also be leveraged to improve waste management and recycling processes. AI-powered systems can be
              used for waste sorting, contamination detection, and optimization of recycling logistics, leading to
              higher recycling rates and reduced waste sent to landfills.
              <sup>4</sup>
            </p>
            <div className="mt-4">
              <p className="text-sm text-gray-500 dark:text-gray-400 mt-2">AI-powered waste management and recycling</p>
            </div>
          </div>
          <div>
            <h2 className="text-2xl font-bold mb-4">Challenges and Limitations</h2>
            <p className="text-gray-500 dark:text-gray-400 leading-relaxed">
              While the potential of AI for sustainability is significant, there are also challenges and limitations
              that must be addressed. These include issues related to data availability, algorithm bias, energy
              consumption of AI systems, and the need for interdisciplinary collaboration to fully realize the benefits
              of AI-powered sustainable solutions.
              <sup>5</sup>
            </p>
          </div>
          <div>
            <h2 className="text-2xl font-bold mb-4">Conclusion</h2>
            <p className="text-gray-500 dark:text-gray-400 leading-relaxed">
              In conclusion, this paper has demonstrated the significant potential of AI to contribute to sustainable
              development. By leveraging AI-powered solutions in areas such as renewable energy optimization, smart city
              planning, and waste management, we can make significant strides towards a more sustainable future.
              However, it is crucial to address the challenges and limitations associated with the integration of AI
              into sustainable initiatives. Through continued research, collaboration, and responsible deployment of AI
              technologies, we can harness the power of this transformative technology to create a more sustainable and
              resilient world.
            </p>
          </div>
        </div>
      </section>
    </>
  )
}

</game/frontend/src/components/academic-page.tsx>

<game/frontend/src/components/academic_page_v2/acad-page_2.tsx>
"use client"
import React, { useState, useEffect } from 'react';
// Interfaces for the academic content
interface AcademicContent {
    abstract: string;
    sections: Section[];
  }
  
  interface Section {
    title: string;
    content: string;
    image?: {
      alt: string;
      src: string;
    };
  }
  
export function AcademicPage() {
  const [data, setData] = useState<AcademicContent | null>(null);

  useEffect(() => {
    // Fetching the data from a local JSON file
    fetch('research-paper-content.json')
      .then(response => response.json())
      .then(setData)
      .catch(console.error); // Handle errors appropriately in real applications
  }, []);

  if (!data) {
    return <div>Loading...</div>; // Or any other loading state representation
  }

  return (
    <>
      <section className="container py-12 md:py-20">
        <div className="max-w-3xl mx-auto space-y-8">
          <div>
            <h2 className="text-2xl font-bold mb-4">Abstract</h2>
            <p className="text-gray-500 dark:text-gray-400 leading-relaxed">
              {data.abstract}
            </p>
          </div>
          {data.sections.map((section, index) => (
            <div key={index}>
              <h2 className="text-2xl font-bold mb-4">{section.title}</h2>
              <p className="text-gray-500 dark:text-gray-400 leading-relaxed">
                {section.content}
              </p>
              {section.image && (
                <div className="mt-4">
                  <img
                    alt={section.image.alt}
                    className="rounded-lg"
                    style={{
                      aspectRatio: "800/450",
                      objectFit: "cover",
                    }}
                    src={section.image.src}
                    width={800}
                    height={450}
                  />
                  <p className="text-sm text-gray-500 dark:text-gray-400 mt-2">
                    {section.image.alt}
                  </p>
                </div>
              )}
            </div>
          ))}
        </div>
      </section>
    </>
  );
}

</game/frontend/src/components/academic_page_v2/acad-page_2.tsx>

<game/frontend/src/components/canvas.tsx>
"use client"
import React, { useEffect, useRef } from 'react';

export function CanvasVideoPlayer({ src }:any) {
  const canvasRef = useRef(null);
  const imageRef = useRef(new Image());

  useEffect(() => {
    const canvas = canvasRef.current;
    const context = canvas.getContext('2d');
    const image = imageRef.current;

    const fetchStream = async () => {
      const response = await fetch(src);
      const reader = response.body.getReader();
      console.log(reader);
      let receivedLength = 0;
      let chunks = []; // Array of received binary chunks (comprises the body)
      while(true) {
        const {done, value} = await reader.read();
        if (done) {
          break;
        }
        chunks.push(value);
        receivedLength += value.length;

        const blob = new Blob(chunks, {type: "image/jpeg"});
        image.src = URL.createObjectURL(blob);
        
        // Clear the canvas and draw the new frame
        context.clearRect(0, 0, canvas.width, canvas.height);
        context.drawImage(image, 0, 0, canvas.width, canvas.height);
        
        chunks = []; // Clear the chunks for the next frame
      }
    };

    fetchStream();
  }, [src]);

  return <canvas ref={canvasRef} className="bg-black" width="640" height="480"></canvas>;
};

</game/frontend/src/components/canvas.tsx>

<game/frontend/src/components/header-component.tsx>
"use client"
import { motion } from 'framer-motion';
import { Button } from "@/components/ui/button"
const animationVariants = {
  hidden: { opacity: 0, y: 20 },
  visible: { opacity: 1, y: 0 },
};

const icons = [
  { IconComponent: FileTextIcon, label: 'Paper' },
  { IconComponent: XIcon, label: 'arXiv' },
  { IconComponent: VideoIcon, label: 'Video' },
  { IconComponent: CodeIcon, label: 'Code' },
  { IconComponent: DatabaseIcon, label: 'Data' },
];

export function HeaderComponent() {
  return (
    <div className="max-w-4xl mx-auto space-y-6">
    <motion.h1
      className="text-5xl font-bold leading-tight text-center"
      initial="hidden"
      animate="visible"
      variants={animationVariants}
      transition={{ duration: 0.5 }}
    >
      OMNI EPIC
    </motion.h1>
    <div className="flex flex-col items-center space-y-4">
      <motion.p
        className="text-lg"
        initial="hidden"
        animate="visible"
        variants={animationVariants}
        transition={{ duration: 0.5, delay: 0.3 }}
      >
        Travis Scott
        <sup>1</sup>, Kanye West
        <sup>2</sup>, Kim Kardashian
        <sup>2</sup>, Tim Cook
        <sup>2</sup>,
        <br />
        Sam Altman
        <sup>2</sup>, Steve Jobs
        <sup>1,2</sup>, Kirby
        <sup>2</sup>
      </motion.p>
      <motion.p
        className="text-lg"
        initial="hidden"
        animate="visible"
        variants={animationVariants}
        transition={{ duration: 0.5, delay: 0.6 }}
      >
        <sup>1</sup>
        University of British Columbia, <sup>2</sup>
        Imperial College London
      </motion.p>
      <div className="flex flex-wrap justify-center gap-4">
        {icons.map((icon, index) => (
          <motion.div
            key={icon.label}
            initial="hidden"
            animate="visible"
            variants={animationVariants}
            transition={{ duration: 0.5, delay: 0.9 + index * 0.2 }}
          >
            <Button className="bg-black text-white py-2 px-4 rounded-full inline-flex items-center">
              <icon.IconComponent className="mr-2" />
              {icon.label}
            </Button>
          </motion.div>
        ))}
      </div>
    </div>
  </div>
  )
}

function ArchiveXIcon(props:any) {
  return (
    <svg
      {...props}
      xmlns="http://www.w3.org/2000/svg"
      width="24"
      height="24"
      viewBox="0 0 24 24"
      fill="none"
      stroke="currentColor"
      strokeWidth="2"
      strokeLinecap="round"
      strokeLinejoin="round"
    >
      <rect width="20" height="5" x="2" y="3" rx="1" />
      <path d="M4 8v11a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8" />
      <path d="m9.5 17 5-5" />
      <path d="m9.5 12 5 5" />
    </svg>
  )
}


function CodeIcon(props:any) {
  return (
    <svg
      {...props}
      xmlns="http://www.w3.org/2000/svg"
      width="24"
      height="24"
      viewBox="0 0 24 24"
      fill="none"
      stroke="currentColor"
      strokeWidth="2"
      strokeLinecap="round"
      strokeLinejoin="round"
    >
      <polyline points="16 18 22 12 16 6" />
      <polyline points="8 6 2 12 8 18" />
    </svg>
  )
}


function DatabaseIcon(props:any) {
  return (
    <svg
      {...props}
      xmlns="http://www.w3.org/2000/svg"
      width="24"
      height="24"
      viewBox="0 0 24 24"
      fill="none"
      stroke="currentColor"
      strokeWidth="2"
      strokeLinecap="round"
      strokeLinejoin="round"
    >
      <ellipse cx="12" cy="5" rx="9" ry="3" />
      <path d="M3 5V19A9 3 0 0 0 21 19V5" />
      <path d="M3 12A9 3 0 0 0 21 12" />
    </svg>
  )
}


function FileTextIcon(props:any) {
  return (
    <svg
      {...props}
      xmlns="http://www.w3.org/2000/svg"
      width="24"
      height="24"
      viewBox="0 0 24 24"
      fill="none"
      stroke="currentColor"
      strokeWidth="2"
      strokeLinecap="round"
      strokeLinejoin="round"
    >
      <path d="M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7Z" />
      <path d="M14 2v4a2 2 0 0 0 2 2h4" />
      <path d="M10 9H8" />
      <path d="M16 13H8" />
      <path d="M16 17H8" />
    </svg>
  )
}




function VideoIcon(props:any) {
  return (
    <svg
      {...props}
      xmlns="http://www.w3.org/2000/svg"
      width="24"
      height="24"
      viewBox="0 0 24 24"
      fill="none"
      stroke="currentColor"
      strokeWidth="2"
      strokeLinecap="round"
      strokeLinejoin="round"
    >
      <path d="m16 13 5.223 3.482a.5.5 0 0 0 .777-.416V7.87a.5.5 0 0 0-.752-.432L16 10.5" />
      <rect x="2" y="6" width="14" height="12" rx="2" />
    </svg>
  )
}


function XIcon(props:any) {
  return (
    <svg
      {...props}
      xmlns="http://www.w3.org/2000/svg"
      width="24"
      height="24"
      viewBox="0 0 24 24"
      fill="none"
      stroke="currentColor"
      strokeWidth="2"
      strokeLinecap="round"
      strokeLinejoin="round"
    >
      <path d="M18 6 6 18" />
      <path d="m6 6 12 12" />
    </svg>
  )
}
</game/frontend/src/components/header-component.tsx>

<game/frontend/src/components/home-page.tsx>
import { SocketIdentifier } from "@/app/KeyIdentifier";
import Link from "next/link";

export function HomePage() {
  return (
    <div className="flex flex-col h-screen w-full">
      {/* <div className="flex w-full shrink-0 items-center px-4 border-b border-gray-200 dark:border-gray-800">
        <Link className="flex shrink-0 items-center space-x-2 text-lg font-semibold" href="/">
          omni_epic
        </Link>
      </div> */}
      <main className="flex flex-1 w-full flex-col items-center justify-center p-4">
        <div className="flex w-full max-w-7xl flex-col items-center justify-center gap-4">
          <div className="aspect-[16/9] w-full overflow-hidden rounded-lg shadow-lg">
            {/* <video className="w-full h-full object-cover rounded-md bg-gray-100 dark:bg-gray-800" controls> */}
            <img src="http://localhost:3005/video_feed" alt="Game Stream"  className="w-full h-full border-rad object-cover rounded-md bg-gray-100 dark:bg-gray-800" />
              Your browser does not support the video tag.
            {/* </video> */}
          
          </div>
          <SocketIdentifier></SocketIdentifier>
          {/* <div className="grid w-full gap-4">
            <h2 className="text-3xl font-bold">Try to beat the leaderboard</h2> */}
            {/* <h3 className="text-2xl font-medium">The keys that you can use are WASD</h3> */}
          {/* </div> */}
        </div>
      </main>
   
    </div>
  )
}
</game/frontend/src/components/home-page.tsx>

<game/frontend/src/components/leader-board.tsx>

import Link from "next/link"
import { Button } from "@/components/ui/button"
import { SheetTrigger, SheetContent, Sheet } from "@/components/ui/sheet"
import { Label } from "@/components/ui/label"
import { DropdownMenuTrigger, DropdownMenuRadioItem, DropdownMenuRadioGroup, DropdownMenuContent, DropdownMenu } from "@/components/ui/dropdown-menu"
import { TableHead, TableRow, TableHeader, TableCell, TableBody, Table } from "@/components/ui/table"
import { AvatarImage, AvatarFallback, Avatar } from "@/components/ui/avatar"

export function LeaderBoard() {
  return (
    <>
      <header className="flex h-16 items-center justify-between px-4 md:px-6 border-b">
        <Link className="flex items-center gap-2" href="/">
          <TrophyIcon className="h-6 w-6" />
          <span className="font-bold">OMNI EPIC Leaderboard</span>
        </Link>
        <Sheet>
          <SheetTrigger asChild>
            <Button size="icon" variant="outline">
              <MenuIcon className="h-6 w-6" />
              <span className="sr-only">Toggle navigation menu</span>
            </Button>
          </SheetTrigger>
          <SheetContent side="right">
            <div className="grid gap-4 p-4">
              <Link href="/">Home</Link>
              <Link href="/leaderboard">Leaderboard</Link>
              <Link href="/about">About</Link>
              <Link href="/contact">Contact</Link>
            </div>
          </SheetContent>
        </Sheet>
      </header>
      <main className="container px-4 md:px-6 py-8">
        <div className="flex flex-col gap-6">
          <div className="flex items-center justify-between">
            <h1 className="text-2xl font-bold">Leaderboard</h1>
            <div className="flex items-center gap-2">
              <Label className="text-sm" htmlFor="sort">
                Sort by:
              </Label>
              <DropdownMenu>
                <DropdownMenuTrigger asChild>
                  <Button size="sm" variant="outline">
                    <ArrowUpDownIcon className="h-4 w-4 mr-2" />
                    Score
                  </Button>
                </DropdownMenuTrigger>
                <DropdownMenuContent align="end" className="w-40">
                  <DropdownMenuRadioGroup value="score">
                    <DropdownMenuRadioItem value="score">Score</DropdownMenuRadioItem>
                    <DropdownMenuRadioItem value="rank">Rank</DropdownMenuRadioItem>
                    <DropdownMenuRadioItem value="name">Name</DropdownMenuRadioItem>
                  </DropdownMenuRadioGroup>
                </DropdownMenuContent>
              </DropdownMenu>
            </div>
          </div>
          <Table>
            <TableHeader>
              <TableRow>
                <TableHead className="w-[80px]">Rank</TableHead>
                <TableHead>Player</TableHead>
                <TableHead className="text-right">Score</TableHead>
                <TableHead className="text-right">Wins</TableHead>
                <TableHead className="text-right">Losses</TableHead>
              </TableRow>
            </TableHeader>
            <TableBody>
              <TableRow>
                <TableCell className="font-medium">1</TableCell>
                <TableCell>
                  <div className="flex items-center gap-2">
                    <Avatar>
                      <AvatarImage alt="Player 1" src="/placeholder-avatar.jpg" />
                      <AvatarFallback>P1</AvatarFallback>
                    </Avatar>
                    <span>Player 1</span>
                  </div>
                </TableCell>
                <TableCell className="text-right">12,345</TableCell>
                <TableCell className="text-right">100</TableCell>
                <TableCell className="text-right">25</TableCell>
              </TableRow>
              <TableRow>
                <TableCell className="font-medium">2</TableCell>
                <TableCell>
                  <div className="flex items-center gap-2">
                    <Avatar>
                      <AvatarImage alt="Player 2" src="/placeholder-avatar.jpg" />
                      <AvatarFallback>P2</AvatarFallback>
                    </Avatar>
                    <span>Player 2</span>
                  </div>
                </TableCell>
                <TableCell className="text-right">11,987</TableCell>
                <TableCell className="text-right">95</TableCell>
                <TableCell className="text-right">30</TableCell>
              </TableRow>
              <TableRow>
                <TableCell className="font-medium">3</TableCell>
                <TableCell>
                  <div className="flex items-center gap-2">
                    <Avatar>
                      <AvatarImage alt="Player 3" src="/placeholder-avatar.jpg" />
                      <AvatarFallback>P3</AvatarFallback>
                    </Avatar>
                    <span>Player 3</span>
                  </div>
                </TableCell>
                <TableCell className="text-right">10,654</TableCell>
                <TableCell className="text-right">90</TableCell>
                <TableCell className="text-right">35</TableCell>
              </TableRow>
              <TableRow>
                <TableCell className="font-medium">4</TableCell>
                <TableCell>
                  <div className="flex items-center gap-2">
                    <Avatar>
                      <AvatarImage alt="Player 4" src="/placeholder-avatar.jpg" />
                      <AvatarFallback>P4</AvatarFallback>
                    </Avatar>
                    <span>Player 4</span>
                  </div>
                </TableCell>
                <TableCell className="text-right">9,876</TableCell>
                <TableCell className="text-right">85</TableCell>
                <TableCell className="text-right">40</TableCell>
              </TableRow>
              <TableRow>
                <TableCell className="font-medium">5</TableCell>
                <TableCell>
                  <div className="flex items-center gap-2">
                    <Avatar>
                      <AvatarImage alt="Player 5" src="/placeholder-avatar.jpg" />
                      <AvatarFallback>P5</AvatarFallback>
                    </Avatar>
                    <span>Player 5</span>
                  </div>
                </TableCell>
                <TableCell className="text-right">8,765</TableCell>
                <TableCell className="text-right">80</TableCell>
                <TableCell className="text-right">45</TableCell>
              </TableRow>
            </TableBody>
          </Table>
        </div>
      </main>
    </>
  )
}

function ArrowUpDownIcon(props) {
  return (
    <svg
      {...props}
      xmlns="http://www.w3.org/2000/svg"
      width="24"
      height="24"
      viewBox="0 0 24 24"
      fill="none"
      stroke="currentColor"
      strokeWidth="2"
      strokeLinecap="round"
      strokeLinejoin="round"
    >
      <path d="m21 16-4 4-4-4" />
      <path d="M17 20V4" />
      <path d="m3 8 4-4 4 4" />
      <path d="M7 4v16" />
    </svg>
  )
}


export function MenuIcon(props:any) {
  return (
    <svg
      {...props}
      xmlns="http://www.w3.org/2000/svg"
      width="24"
      height="24"
      viewBox="0 0 24 24"
      fill="none"
      stroke="currentColor"
      strokeWidth="2"
      strokeLinecap="round"
      strokeLinejoin="round"
    >
      <line x1="4" x2="20" y1="12" y2="12" />
      <line x1="4" x2="20" y1="6" y2="6" />
      <line x1="4" x2="20" y1="18" y2="18" />
    </svg>
  )
}


export function TrophyIcon(props:any) {
  return (
    <svg
      {...props}
      xmlns="http://www.w3.org/2000/svg"
      width="24"
      height="24"
      viewBox="0 0 24 24"
      fill="none"
      stroke="currentColor"
      strokeWidth="2"
      strokeLinecap="round"
      strokeLinejoin="round"
    >
      <path d="M6 9H4.5a2.5 2.5 0 0 1 0-5H6" />
      <path d="M18 9h1.5a2.5 2.5 0 0 0 0-5H18" />
      <path d="M4 22h16" />
      <path d="M10 14.66V17c0 .55-.47.98-.97 1.21C7.85 18.75 7 20.24 7 22" />
      <path d="M14 14.66V17c0 .55.47.98.97 1.21C16.15 18.75 17 20.24 17 22" />
      <path d="M18 2H6v7a6 6 0 0 0 12 0V2Z" />
    </svg>
  )
}

</game/frontend/src/components/leader-board.tsx>

<game/frontend/src/components/ui/alert-dialog.tsx>
"use client"

import * as React from "react"
import * as AlertDialogPrimitive from "@radix-ui/react-alert-dialog"

import { cn } from "@/lib/utils"
import { buttonVariants } from "@/components/ui/button"

const AlertDialog = AlertDialogPrimitive.Root

const AlertDialogTrigger = AlertDialogPrimitive.Trigger

const AlertDialogPortal = AlertDialogPrimitive.Portal

const AlertDialogOverlay = React.forwardRef<
  React.ElementRef<typeof AlertDialogPrimitive.Overlay>,
  React.ComponentPropsWithoutRef<typeof AlertDialogPrimitive.Overlay>
>(({ className, ...props }, ref) => (
  <AlertDialogPrimitive.Overlay
    className={cn(
      "fixed inset-0 z-50 bg-black/80  data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0",
      className
    )}
    {...props}
    ref={ref}
  />
))
AlertDialogOverlay.displayName = AlertDialogPrimitive.Overlay.displayName

const AlertDialogContent = React.forwardRef<
  React.ElementRef<typeof AlertDialogPrimitive.Content>,
  React.ComponentPropsWithoutRef<typeof AlertDialogPrimitive.Content>
>(({ className, ...props }, ref) => (
  <AlertDialogPortal>
    <AlertDialogOverlay />
    <AlertDialogPrimitive.Content
      ref={ref}
      className={cn(
        "fixed left-[50%] top-[50%] z-50 grid w-full max-w-lg translate-x-[-50%] translate-y-[-50%] gap-4 border border-slate-200 bg-white p-6 shadow-lg duration-200 data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0 data-[state=closed]:zoom-out-95 data-[state=open]:zoom-in-95 data-[state=closed]:slide-out-to-left-1/2 data-[state=closed]:slide-out-to-top-[48%] data-[state=open]:slide-in-from-left-1/2 data-[state=open]:slide-in-from-top-[48%] sm:rounded-lg dark:border-slate-800 dark:bg-slate-950",
        className
      )}
      {...props}
    />
  </AlertDialogPortal>
))
AlertDialogContent.displayName = AlertDialogPrimitive.Content.displayName

const AlertDialogHeader = ({
  className,
  ...props
}: React.HTMLAttributes<HTMLDivElement>) => (
  <div
    className={cn(
      "flex flex-col space-y-2 text-center sm:text-left",
      className
    )}
    {...props}
  />
)
AlertDialogHeader.displayName = "AlertDialogHeader"

const AlertDialogFooter = ({
  className,
  ...props
}: React.HTMLAttributes<HTMLDivElement>) => (
  <div
    className={cn(
      "flex flex-col-reverse sm:flex-row sm:justify-end sm:space-x-2",
      className
    )}
    {...props}
  />
)
AlertDialogFooter.displayName = "AlertDialogFooter"

const AlertDialogTitle = React.forwardRef<
  React.ElementRef<typeof AlertDialogPrimitive.Title>,
  React.ComponentPropsWithoutRef<typeof AlertDialogPrimitive.Title>
>(({ className, ...props }, ref) => (
  <AlertDialogPrimitive.Title
    ref={ref}
    className={cn("text-lg font-semibold", className)}
    {...props}
  />
))
AlertDialogTitle.displayName = AlertDialogPrimitive.Title.displayName

const AlertDialogDescription = React.forwardRef<
  React.ElementRef<typeof AlertDialogPrimitive.Description>,
  React.ComponentPropsWithoutRef<typeof AlertDialogPrimitive.Description>
>(({ className, ...props }, ref) => (
  <AlertDialogPrimitive.Description
    ref={ref}
    className={cn("text-sm text-slate-500 dark:text-slate-400", className)}
    {...props}
  />
))
AlertDialogDescription.displayName =
  AlertDialogPrimitive.Description.displayName

const AlertDialogAction = React.forwardRef<
  React.ElementRef<typeof AlertDialogPrimitive.Action>,
  React.ComponentPropsWithoutRef<typeof AlertDialogPrimitive.Action>
>(({ className, ...props }, ref) => (
  <AlertDialogPrimitive.Action
    ref={ref}
    className={cn(buttonVariants(), className)}
    {...props}
  />
))
AlertDialogAction.displayName = AlertDialogPrimitive.Action.displayName

const AlertDialogCancel = React.forwardRef<
  React.ElementRef<typeof AlertDialogPrimitive.Cancel>,
  React.ComponentPropsWithoutRef<typeof AlertDialogPrimitive.Cancel>
>(({ className, ...props }, ref) => (
  <AlertDialogPrimitive.Cancel
    ref={ref}
    className={cn(
      buttonVariants({ variant: "outline" }),
      "mt-2 sm:mt-0",
      className
    )}
    {...props}
  />
))
AlertDialogCancel.displayName = AlertDialogPrimitive.Cancel.displayName

export {
  AlertDialog,
  AlertDialogPortal,
  AlertDialogOverlay,
  AlertDialogTrigger,
  AlertDialogContent,
  AlertDialogHeader,
  AlertDialogFooter,
  AlertDialogTitle,
  AlertDialogDescription,
  AlertDialogAction,
  AlertDialogCancel,
}

</game/frontend/src/components/ui/alert-dialog.tsx>

<game/frontend/src/components/ui/alert.tsx>
import * as React from "react"
import { cva, type VariantProps } from "class-variance-authority"

import { cn } from "@/lib/utils"

const alertVariants = cva(
  "relative w-full rounded-lg border border-gray-200 p-4 [&>svg~*]:pl-7 [&>svg+div]:translate-y-[-3px] [&>svg]:absolute [&>svg]:left-4 [&>svg]:top-4 [&>svg]:text-gray-950 dark:border-gray-800 dark:[&>svg]:text-gray-50",
  {
    variants: {
      variant: {
        default: "bg-white text-gray-950 dark:bg-gray-950 dark:text-gray-50",
        destructive:
          "border-red-500/50 text-red-500 dark:border-red-500 [&>svg]:text-red-500 dark:border-red-900/50 dark:text-red-900 dark:dark:border-red-900 dark:[&>svg]:text-red-900",
      },
    },
    defaultVariants: {
      variant: "default",
    },
  }
)

const Alert = React.forwardRef<
  HTMLDivElement,
  React.HTMLAttributes<HTMLDivElement> & VariantProps<typeof alertVariants>
>(({ className, variant, ...props }, ref) => (
  <div
    ref={ref}
    role="alert"
    className={cn(alertVariants({ variant }), className)}
    {...props}
  />
))
Alert.displayName = "Alert"

const AlertTitle = React.forwardRef<
  HTMLParagraphElement,
  React.HTMLAttributes<HTMLHeadingElement>
>(({ className, ...props }, ref) => (
  <h5
    ref={ref}
    className={cn("mb-1 font-medium leading-none tracking-tight", className)}
    {...props}
  />
))
AlertTitle.displayName = "AlertTitle"

const AlertDescription = React.forwardRef<
  HTMLParagraphElement,
  React.HTMLAttributes<HTMLParagraphElement>
>(({ className, ...props }, ref) => (
  <div
    ref={ref}
    className={cn("text-sm [&_p]:leading-relaxed", className)}
    {...props}
  />
))
AlertDescription.displayName = "AlertDescription"

export { Alert, AlertTitle, AlertDescription }

</game/frontend/src/components/ui/alert.tsx>

<game/frontend/src/components/ui/aspect-ratio.tsx>
"use client"

import * as AspectRatioPrimitive from "@radix-ui/react-aspect-ratio"

const AspectRatio = AspectRatioPrimitive.Root

export { AspectRatio }

</game/frontend/src/components/ui/aspect-ratio.tsx>

<game/frontend/src/components/ui/avatar.tsx>
"use client"

import * as React from "react"
import * as AvatarPrimitive from "@radix-ui/react-avatar"

import { cn } from "@/lib/utils"

const Avatar = React.forwardRef<
  React.ElementRef<typeof AvatarPrimitive.Root>,
  React.ComponentPropsWithoutRef<typeof AvatarPrimitive.Root>
>(({ className, ...props }, ref) => (
  <AvatarPrimitive.Root
    ref={ref}
    className={cn(
      "relative flex h-10 w-10 shrink-0 overflow-hidden rounded-full",
      className
    )}
    {...props}
  />
))
Avatar.displayName = AvatarPrimitive.Root.displayName

const AvatarImage = React.forwardRef<
  React.ElementRef<typeof AvatarPrimitive.Image>,
  React.ComponentPropsWithoutRef<typeof AvatarPrimitive.Image>
>(({ className, ...props }, ref) => (
  <AvatarPrimitive.Image
    ref={ref}
    className={cn("aspect-square h-full w-full", className)}
    {...props}
  />
))
AvatarImage.displayName = AvatarPrimitive.Image.displayName

const AvatarFallback = React.forwardRef<
  React.ElementRef<typeof AvatarPrimitive.Fallback>,
  React.ComponentPropsWithoutRef<typeof AvatarPrimitive.Fallback>
>(({ className, ...props }, ref) => (
  <AvatarPrimitive.Fallback
    ref={ref}
    className={cn(
      "flex h-full w-full items-center justify-center rounded-full bg-slate-100 dark:bg-slate-800",
      className
    )}
    {...props}
  />
))
AvatarFallback.displayName = AvatarPrimitive.Fallback.displayName

export { Avatar, AvatarImage, AvatarFallback }

</game/frontend/src/components/ui/avatar.tsx>

<game/frontend/src/components/ui/button.tsx>
import * as React from "react"
import { Slot } from "@radix-ui/react-slot"
import { cva, type VariantProps } from "class-variance-authority"

import { cn } from "@/lib/utils"

const buttonVariants = cva(
  "inline-flex items-center justify-center whitespace-nowrap rounded-md text-sm font-medium ring-offset-white transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-slate-950 focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 dark:ring-offset-slate-950 dark:focus-visible:ring-slate-300",
  {
    variants: {
      variant: {
        default: "bg-slate-900 text-slate-50 hover:bg-slate-900/90 dark:bg-slate-50 dark:text-slate-900 dark:hover:bg-slate-50/90",
        destructive:
          "bg-red-500 text-slate-50 hover:bg-red-500/90 dark:bg-red-900 dark:text-slate-50 dark:hover:bg-red-900/90",
        outline:
          "border border-slate-200 bg-white hover:bg-slate-100 hover:text-slate-900 dark:border-slate-800 dark:bg-slate-950 dark:hover:bg-slate-800 dark:hover:text-slate-50",
        secondary:
          "bg-slate-100 text-slate-900 hover:bg-slate-100/80 dark:bg-slate-800 dark:text-slate-50 dark:hover:bg-slate-800/80",
        ghost: "hover:bg-slate-100 hover:text-slate-900 dark:hover:bg-slate-800 dark:hover:text-slate-50",
        link: "text-slate-900 underline-offset-4 hover:underline dark:text-slate-50",
      },
      size: {
        default: "h-10 px-4 py-2",
        sm: "h-9 rounded-md px-3",
        lg: "h-11 rounded-md px-8",
        icon: "h-10 w-10",
      },
    },
    defaultVariants: {
      variant: "default",
      size: "default",
    },
  }
)

export interface ButtonProps
  extends React.ButtonHTMLAttributes<HTMLButtonElement>,
    VariantProps<typeof buttonVariants> {
  asChild?: boolean
}

const Button = React.forwardRef<HTMLButtonElement, ButtonProps>(
  ({ className, variant, size, asChild = false, ...props }, ref) => {
    const Comp = asChild ? Slot : "button"
    return (
      <Comp
        className={cn(buttonVariants({ variant, size, className }))}
        ref={ref}
        {...props}
      />
    )
  }
)
Button.displayName = "Button"

export { Button, buttonVariants }

</game/frontend/src/components/ui/button.tsx>

<game/frontend/src/components/ui/connected/connected.tsx>
import { LinkNone2Icon} from "@radix-ui/react-icons"

import {
  Alert,
  AlertDescription,
  AlertTitle,
} from "@/components/ui/alert"

export function Connected() {
  return (
    <Alert className="w-full">
    
      <LinkNone2Icon className="h-4 w-4" />
      <AlertTitle>      <div style={{color: 'green'}}>Connected</div></AlertTitle>
      {/* <AlertDescription>
      <div style={{color: 'green'}}>Connected</div>
      </AlertDescription> */}

    </Alert>
  )
}

</game/frontend/src/components/ui/connected/connected.tsx>

<game/frontend/src/components/ui/connected/notconnected.tsx>
import { LinkBreak2Icon} from "@radix-ui/react-icons"

import {
  Alert,
  AlertDescription,
  AlertTitle,
} from "@/components/ui/alert"

export function NotConnected() {
  return (
    <Alert>
      <LinkBreak2Icon className="h-4 w-4" />
      <AlertTitle>   <div style={{color: 'red'}}>Not connected</div></AlertTitle>
      {/* <AlertDescription>
      <div style={{color: 'green'}}>Connected</div>
      </AlertDescription> */}

    </Alert>
  )
}

</game/frontend/src/components/ui/connected/notconnected.tsx>

<game/frontend/src/components/ui/connected/toast.tsx>
"use client"

import { Button } from "@/components/ui/button"
import { ToastAction } from "@/components/ui/toast"
import { useToast } from "@/components/ui/use-toast"

export function ToastDemo() {
  const { toast } = useToast()

  return (
    <Button
      variant="outline"
      onClick={() => {
        toast({
          title: "Scheduled: Catch up ",
          description: "Friday, February 10, 2023 at 5:57 PM",
          action: (
            <ToastAction altText="Goto schedule to undo">Undo</ToastAction>
          ),
        })
      }}
    >
      Add to calendar
    </Button>
  )
}

</game/frontend/src/components/ui/connected/toast.tsx>

<game/frontend/src/components/ui/dropdown-menu.tsx>
"use client"

import * as React from "react"
import * as DropdownMenuPrimitive from "@radix-ui/react-dropdown-menu"
import { Check, ChevronRight, Circle } from "lucide-react"

import { cn } from "@/lib/utils"

const DropdownMenu = DropdownMenuPrimitive.Root

const DropdownMenuTrigger = DropdownMenuPrimitive.Trigger

const DropdownMenuGroup = DropdownMenuPrimitive.Group

const DropdownMenuPortal = DropdownMenuPrimitive.Portal

const DropdownMenuSub = DropdownMenuPrimitive.Sub

const DropdownMenuRadioGroup = DropdownMenuPrimitive.RadioGroup

const DropdownMenuSubTrigger = React.forwardRef<
  React.ElementRef<typeof DropdownMenuPrimitive.SubTrigger>,
  React.ComponentPropsWithoutRef<typeof DropdownMenuPrimitive.SubTrigger> & {
    inset?: boolean
  }
>(({ className, inset, children, ...props }, ref) => (
  <DropdownMenuPrimitive.SubTrigger
    ref={ref}
    className={cn(
      "flex cursor-default select-none items-center rounded-sm px-2 py-1.5 text-sm outline-none focus:bg-slate-100 data-[state=open]:bg-slate-100 dark:focus:bg-slate-800 dark:data-[state=open]:bg-slate-800",
      inset && "pl-8",
      className
    )}
    {...props}
  >
    {children}
    <ChevronRight className="ml-auto h-4 w-4" />
  </DropdownMenuPrimitive.SubTrigger>
))
DropdownMenuSubTrigger.displayName =
  DropdownMenuPrimitive.SubTrigger.displayName

const DropdownMenuSubContent = React.forwardRef<
  React.ElementRef<typeof DropdownMenuPrimitive.SubContent>,
  React.ComponentPropsWithoutRef<typeof DropdownMenuPrimitive.SubContent>
>(({ className, ...props }, ref) => (
  <DropdownMenuPrimitive.SubContent
    ref={ref}
    className={cn(
      "z-50 min-w-[8rem] overflow-hidden rounded-md border border-slate-200 bg-white p-1 text-slate-950 shadow-lg data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0 data-[state=closed]:zoom-out-95 data-[state=open]:zoom-in-95 data-[side=bottom]:slide-in-from-top-2 data-[side=left]:slide-in-from-right-2 data-[side=right]:slide-in-from-left-2 data-[side=top]:slide-in-from-bottom-2 dark:border-slate-800 dark:bg-slate-950 dark:text-slate-50",
      className
    )}
    {...props}
  />
))
DropdownMenuSubContent.displayName =
  DropdownMenuPrimitive.SubContent.displayName

const DropdownMenuContent = React.forwardRef<
  React.ElementRef<typeof DropdownMenuPrimitive.Content>,
  React.ComponentPropsWithoutRef<typeof DropdownMenuPrimitive.Content>
>(({ className, sideOffset = 4, ...props }, ref) => (
  <DropdownMenuPrimitive.Portal>
    <DropdownMenuPrimitive.Content
      ref={ref}
      sideOffset={sideOffset}
      className={cn(
        "z-50 min-w-[8rem] overflow-hidden rounded-md border border-slate-200 bg-white p-1 text-slate-950 shadow-md data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0 data-[state=closed]:zoom-out-95 data-[state=open]:zoom-in-95 data-[side=bottom]:slide-in-from-top-2 data-[side=left]:slide-in-from-right-2 data-[side=right]:slide-in-from-left-2 data-[side=top]:slide-in-from-bottom-2 dark:border-slate-800 dark:bg-slate-950 dark:text-slate-50",
        className
      )}
      {...props}
    />
  </DropdownMenuPrimitive.Portal>
))
DropdownMenuContent.displayName = DropdownMenuPrimitive.Content.displayName

const DropdownMenuItem = React.forwardRef<
  React.ElementRef<typeof DropdownMenuPrimitive.Item>,
  React.ComponentPropsWithoutRef<typeof DropdownMenuPrimitive.Item> & {
    inset?: boolean
  }
>(({ className, inset, ...props }, ref) => (
  <DropdownMenuPrimitive.Item
    ref={ref}
    className={cn(
      "relative flex cursor-default select-none items-center rounded-sm px-2 py-1.5 text-sm outline-none transition-colors focus:bg-slate-100 focus:text-slate-900 data-[disabled]:pointer-events-none data-[disabled]:opacity-50 dark:focus:bg-slate-800 dark:focus:text-slate-50",
      inset && "pl-8",
      className
    )}
    {...props}
  />
))
DropdownMenuItem.displayName = DropdownMenuPrimitive.Item.displayName

const DropdownMenuCheckboxItem = React.forwardRef<
  React.ElementRef<typeof DropdownMenuPrimitive.CheckboxItem>,
  React.ComponentPropsWithoutRef<typeof DropdownMenuPrimitive.CheckboxItem>
>(({ className, children, checked, ...props }, ref) => (
  <DropdownMenuPrimitive.CheckboxItem
    ref={ref}
    className={cn(
      "relative flex cursor-default select-none items-center rounded-sm py-1.5 pl-8 pr-2 text-sm outline-none transition-colors focus:bg-slate-100 focus:text-slate-900 data-[disabled]:pointer-events-none data-[disabled]:opacity-50 dark:focus:bg-slate-800 dark:focus:text-slate-50",
      className
    )}
    checked={checked}
    {...props}
  >
    <span className="absolute left-2 flex h-3.5 w-3.5 items-center justify-center">
      <DropdownMenuPrimitive.ItemIndicator>
        <Check className="h-4 w-4" />
      </DropdownMenuPrimitive.ItemIndicator>
    </span>
    {children}
  </DropdownMenuPrimitive.CheckboxItem>
))
DropdownMenuCheckboxItem.displayName =
  DropdownMenuPrimitive.CheckboxItem.displayName

const DropdownMenuRadioItem = React.forwardRef<
  React.ElementRef<typeof DropdownMenuPrimitive.RadioItem>,
  React.ComponentPropsWithoutRef<typeof DropdownMenuPrimitive.RadioItem>
>(({ className, children, ...props }, ref) => (
  <DropdownMenuPrimitive.RadioItem
    ref={ref}
    className={cn(
      "relative flex cursor-default select-none items-center rounded-sm py-1.5 pl-8 pr-2 text-sm outline-none transition-colors focus:bg-slate-100 focus:text-slate-900 data-[disabled]:pointer-events-none data-[disabled]:opacity-50 dark:focus:bg-slate-800 dark:focus:text-slate-50",
      className
    )}
    {...props}
  >
    <span className="absolute left-2 flex h-3.5 w-3.5 items-center justify-center">
      <DropdownMenuPrimitive.ItemIndicator>
        <Circle className="h-2 w-2 fill-current" />
      </DropdownMenuPrimitive.ItemIndicator>
    </span>
    {children}
  </DropdownMenuPrimitive.RadioItem>
))
DropdownMenuRadioItem.displayName = DropdownMenuPrimitive.RadioItem.displayName

const DropdownMenuLabel = React.forwardRef<
  React.ElementRef<typeof DropdownMenuPrimitive.Label>,
  React.ComponentPropsWithoutRef<typeof DropdownMenuPrimitive.Label> & {
    inset?: boolean
  }
>(({ className, inset, ...props }, ref) => (
  <DropdownMenuPrimitive.Label
    ref={ref}
    className={cn(
      "px-2 py-1.5 text-sm font-semibold",
      inset && "pl-8",
      className
    )}
    {...props}
  />
))
DropdownMenuLabel.displayName = DropdownMenuPrimitive.Label.displayName

const DropdownMenuSeparator = React.forwardRef<
  React.ElementRef<typeof DropdownMenuPrimitive.Separator>,
  React.ComponentPropsWithoutRef<typeof DropdownMenuPrimitive.Separator>
>(({ className, ...props }, ref) => (
  <DropdownMenuPrimitive.Separator
    ref={ref}
    className={cn("-mx-1 my-1 h-px bg-slate-100 dark:bg-slate-800", className)}
    {...props}
  />
))
DropdownMenuSeparator.displayName = DropdownMenuPrimitive.Separator.displayName

const DropdownMenuShortcut = ({
  className,
  ...props
}: React.HTMLAttributes<HTMLSpanElement>) => {
  return (
    <span
      className={cn("ml-auto text-xs tracking-widest opacity-60", className)}
      {...props}
    />
  )
}
DropdownMenuShortcut.displayName = "DropdownMenuShortcut"

export {
  DropdownMenu,
  DropdownMenuTrigger,
  DropdownMenuContent,
  DropdownMenuItem,
  DropdownMenuCheckboxItem,
  DropdownMenuRadioItem,
  DropdownMenuLabel,
  DropdownMenuSeparator,
  DropdownMenuShortcut,
  DropdownMenuGroup,
  DropdownMenuPortal,
  DropdownMenuSub,
  DropdownMenuSubContent,
  DropdownMenuSubTrigger,
  DropdownMenuRadioGroup,
}

</game/frontend/src/components/ui/dropdown-menu.tsx>

<game/frontend/src/components/ui/label.tsx>
"use client"

import * as React from "react"
import * as LabelPrimitive from "@radix-ui/react-label"
import { cva, type VariantProps } from "class-variance-authority"

import { cn } from "@/lib/utils"

const labelVariants = cva(
  "text-sm font-medium leading-none peer-disabled:cursor-not-allowed peer-disabled:opacity-70"
)

const Label = React.forwardRef<
  React.ElementRef<typeof LabelPrimitive.Root>,
  React.ComponentPropsWithoutRef<typeof LabelPrimitive.Root> &
    VariantProps<typeof labelVariants>
>(({ className, ...props }, ref) => (
  <LabelPrimitive.Root
    ref={ref}
    className={cn(labelVariants(), className)}
    {...props}
  />
))
Label.displayName = LabelPrimitive.Root.displayName

export { Label }

</game/frontend/src/components/ui/label.tsx>

<game/frontend/src/components/ui/next_level/button_level.tsx>
import {
    AlertDialog,
    AlertDialogAction,
    AlertDialogCancel,
    AlertDialogContent,
    AlertDialogDescription,
    AlertDialogFooter,
    AlertDialogHeader,
    AlertDialogTitle,
    AlertDialogTrigger,
  } from "@/components/ui/alert-dialog";
  import { Button } from "@/components/ui/button";
  
  // Accept a prop for the action to perform
  export function ResetAlertDialog({ onConfirm }:{onConfirm: () => any}) {
    return (
      <AlertDialog>
        <AlertDialogTrigger asChild>
          <Button className="w-full" variant="outline">Reset Level</Button>
        </AlertDialogTrigger>
        <AlertDialogContent>
          <AlertDialogHeader>
            <AlertDialogTitle>Are you absolutely sure?</AlertDialogTitle>
            <AlertDialogDescription>
              This action will reset the current level and cannot be undone.
            </AlertDialogDescription>
          </AlertDialogHeader>
          <AlertDialogFooter>
            <AlertDialogCancel>Cancel</AlertDialogCancel>
            {/* Use the onConfirm prop when the action button is clicked */}
            <AlertDialogAction onClick={onConfirm}>Reset Level</AlertDialogAction>
          </AlertDialogFooter>
        </AlertDialogContent>
      </AlertDialog>
    );
  }
  
</game/frontend/src/components/ui/next_level/button_level.tsx>

<game/frontend/src/components/ui/sheet.tsx>
"use client"

import * as React from "react"
import * as SheetPrimitive from "@radix-ui/react-dialog"
import { cva, type VariantProps } from "class-variance-authority"
import { X } from "lucide-react"

import { cn } from "@/lib/utils"

const Sheet = SheetPrimitive.Root

const SheetTrigger = SheetPrimitive.Trigger

const SheetClose = SheetPrimitive.Close

const SheetPortal = SheetPrimitive.Portal

const SheetOverlay = React.forwardRef<
  React.ElementRef<typeof SheetPrimitive.Overlay>,
  React.ComponentPropsWithoutRef<typeof SheetPrimitive.Overlay>
>(({ className, ...props }, ref) => (
  <SheetPrimitive.Overlay
    className={cn(
      "fixed inset-0 z-50 bg-black/80  data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0",
      className
    )}
    {...props}
    ref={ref}
  />
))
SheetOverlay.displayName = SheetPrimitive.Overlay.displayName

const sheetVariants = cva(
  "fixed z-50 gap-4 bg-white p-6 shadow-lg transition ease-in-out data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:duration-300 data-[state=open]:duration-500 dark:bg-slate-950",
  {
    variants: {
      side: {
        top: "inset-x-0 top-0 border-b data-[state=closed]:slide-out-to-top data-[state=open]:slide-in-from-top",
        bottom:
          "inset-x-0 bottom-0 border-t data-[state=closed]:slide-out-to-bottom data-[state=open]:slide-in-from-bottom",
        left: "inset-y-0 left-0 h-full w-3/4 border-r data-[state=closed]:slide-out-to-left data-[state=open]:slide-in-from-left sm:max-w-sm",
        right:
          "inset-y-0 right-0 h-full w-3/4  border-l data-[state=closed]:slide-out-to-right data-[state=open]:slide-in-from-right sm:max-w-sm",
      },
    },
    defaultVariants: {
      side: "right",
    },
  }
)

interface SheetContentProps
  extends React.ComponentPropsWithoutRef<typeof SheetPrimitive.Content>,
    VariantProps<typeof sheetVariants> {}

const SheetContent = React.forwardRef<
  React.ElementRef<typeof SheetPrimitive.Content>,
  SheetContentProps
>(({ side = "right", className, children, ...props }, ref) => (
  <SheetPortal>
    <SheetOverlay />
    <SheetPrimitive.Content
      ref={ref}
      className={cn(sheetVariants({ side }), className)}
      {...props}
    >
      {children}
      <SheetPrimitive.Close className="absolute right-4 top-4 rounded-sm opacity-70 ring-offset-white transition-opacity hover:opacity-100 focus:outline-none focus:ring-2 focus:ring-slate-950 focus:ring-offset-2 disabled:pointer-events-none data-[state=open]:bg-slate-100 dark:ring-offset-slate-950 dark:focus:ring-slate-300 dark:data-[state=open]:bg-slate-800">
        <X className="h-4 w-4" />
        <span className="sr-only">Close</span>
      </SheetPrimitive.Close>
    </SheetPrimitive.Content>
  </SheetPortal>
))
SheetContent.displayName = SheetPrimitive.Content.displayName

const SheetHeader = ({
  className,
  ...props
}: React.HTMLAttributes<HTMLDivElement>) => (
  <div
    className={cn(
      "flex flex-col space-y-2 text-center sm:text-left",
      className
    )}
    {...props}
  />
)
SheetHeader.displayName = "SheetHeader"

const SheetFooter = ({
  className,
  ...props
}: React.HTMLAttributes<HTMLDivElement>) => (
  <div
    className={cn(
      "flex flex-col-reverse sm:flex-row sm:justify-end sm:space-x-2",
      className
    )}
    {...props}
  />
)
SheetFooter.displayName = "SheetFooter"

const SheetTitle = React.forwardRef<
  React.ElementRef<typeof SheetPrimitive.Title>,
  React.ComponentPropsWithoutRef<typeof SheetPrimitive.Title>
>(({ className, ...props }, ref) => (
  <SheetPrimitive.Title
    ref={ref}
    className={cn("text-lg font-semibold text-slate-950 dark:text-slate-50", className)}
    {...props}
  />
))
SheetTitle.displayName = SheetPrimitive.Title.displayName

const SheetDescription = React.forwardRef<
  React.ElementRef<typeof SheetPrimitive.Description>,
  React.ComponentPropsWithoutRef<typeof SheetPrimitive.Description>
>(({ className, ...props }, ref) => (
  <SheetPrimitive.Description
    ref={ref}
    className={cn("text-sm text-slate-500 dark:text-slate-400", className)}
    {...props}
  />
))
SheetDescription.displayName = SheetPrimitive.Description.displayName

export {
  Sheet,
  SheetPortal,
  SheetOverlay,
  SheetTrigger,
  SheetClose,
  SheetContent,
  SheetHeader,
  SheetFooter,
  SheetTitle,
  SheetDescription,
}

</game/frontend/src/components/ui/sheet.tsx>

<game/frontend/src/components/ui/table.tsx>
import * as React from "react"

import { cn } from "@/lib/utils"

const Table = React.forwardRef<
  HTMLTableElement,
  React.HTMLAttributes<HTMLTableElement>
>(({ className, ...props }, ref) => (
  <div className="relative w-full overflow-auto">
    <table
      ref={ref}
      className={cn("w-full caption-bottom text-sm", className)}
      {...props}
    />
  </div>
))
Table.displayName = "Table"

const TableHeader = React.forwardRef<
  HTMLTableSectionElement,
  React.HTMLAttributes<HTMLTableSectionElement>
>(({ className, ...props }, ref) => (
  <thead ref={ref} className={cn("[&_tr]:border-b", className)} {...props} />
))
TableHeader.displayName = "TableHeader"

const TableBody = React.forwardRef<
  HTMLTableSectionElement,
  React.HTMLAttributes<HTMLTableSectionElement>
>(({ className, ...props }, ref) => (
  <tbody
    ref={ref}
    className={cn("[&_tr:last-child]:border-0", className)}
    {...props}
  />
))
TableBody.displayName = "TableBody"

const TableFooter = React.forwardRef<
  HTMLTableSectionElement,
  React.HTMLAttributes<HTMLTableSectionElement>
>(({ className, ...props }, ref) => (
  <tfoot
    ref={ref}
    className={cn(
      "border-t bg-slate-100/50 font-medium [&>tr]:last:border-b-0 dark:bg-slate-800/50",
      className
    )}
    {...props}
  />
))
TableFooter.displayName = "TableFooter"

const TableRow = React.forwardRef<
  HTMLTableRowElement,
  React.HTMLAttributes<HTMLTableRowElement>
>(({ className, ...props }, ref) => (
  <tr
    ref={ref}
    className={cn(
      "border-b transition-colors hover:bg-slate-100/50 data-[state=selected]:bg-slate-100 dark:hover:bg-slate-800/50 dark:data-[state=selected]:bg-slate-800",
      className
    )}
    {...props}
  />
))
TableRow.displayName = "TableRow"

const TableHead = React.forwardRef<
  HTMLTableCellElement,
  React.ThHTMLAttributes<HTMLTableCellElement>
>(({ className, ...props }, ref) => (
  <th
    ref={ref}
    className={cn(
      "h-12 px-4 text-left align-middle font-medium text-slate-500 [&:has([role=checkbox])]:pr-0 dark:text-slate-400",
      className
    )}
    {...props}
  />
))
TableHead.displayName = "TableHead"

const TableCell = React.forwardRef<
  HTMLTableCellElement,
  React.TdHTMLAttributes<HTMLTableCellElement>
>(({ className, ...props }, ref) => (
  <td
    ref={ref}
    className={cn("p-4 align-middle [&:has([role=checkbox])]:pr-0", className)}
    {...props}
  />
))
TableCell.displayName = "TableCell"

const TableCaption = React.forwardRef<
  HTMLTableCaptionElement,
  React.HTMLAttributes<HTMLTableCaptionElement>
>(({ className, ...props }, ref) => (
  <caption
    ref={ref}
    className={cn("mt-4 text-sm text-slate-500 dark:text-slate-400", className)}
    {...props}
  />
))
TableCaption.displayName = "TableCaption"

export {
  Table,
  TableHeader,
  TableBody,
  TableFooter,
  TableHead,
  TableRow,
  TableCell,
  TableCaption,
}

</game/frontend/src/components/ui/table.tsx>

<game/frontend/src/components/ui/toast.tsx>
"use client"

import * as React from "react"
import * as ToastPrimitives from "@radix-ui/react-toast"
import { cva, type VariantProps } from "class-variance-authority"
import { X } from "lucide-react"

import { cn } from "@/lib/utils"

const ToastProvider = ToastPrimitives.Provider

const ToastViewport = React.forwardRef<
  React.ElementRef<typeof ToastPrimitives.Viewport>,
  React.ComponentPropsWithoutRef<typeof ToastPrimitives.Viewport>
>(({ className, ...props }, ref) => (
  <ToastPrimitives.Viewport
    ref={ref}
    className={cn(
      "fixed top-0 z-[100] flex max-h-screen w-full flex-col-reverse p-4 sm:bottom-0 sm:right-0 sm:top-auto sm:flex-col md:max-w-[420px]",
      className
    )}
    {...props}
  />
))
ToastViewport.displayName = ToastPrimitives.Viewport.displayName

const toastVariants = cva(
  "group pointer-events-auto relative flex w-full items-center justify-between space-x-4 overflow-hidden rounded-md border border-slate-200 p-6 pr-8 shadow-lg transition-all data-[swipe=cancel]:translate-x-0 data-[swipe=end]:translate-x-[var(--radix-toast-swipe-end-x)] data-[swipe=move]:translate-x-[var(--radix-toast-swipe-move-x)] data-[swipe=move]:transition-none data-[state=open]:animate-in data-[state=closed]:animate-out data-[swipe=end]:animate-out data-[state=closed]:fade-out-80 data-[state=closed]:slide-out-to-right-full data-[state=open]:slide-in-from-top-full data-[state=open]:sm:slide-in-from-bottom-full dark:border-slate-800",
  {
    variants: {
      variant: {
        default: "border bg-white text-slate-950 dark:bg-slate-950 dark:text-slate-50",
        destructive:
          "destructive group border-red-500 bg-red-500 text-slate-50 dark:border-red-900 dark:bg-red-900 dark:text-slate-50",
      },
    },
    defaultVariants: {
      variant: "default",
    },
  }
)

const Toast = React.forwardRef<
  React.ElementRef<typeof ToastPrimitives.Root>,
  React.ComponentPropsWithoutRef<typeof ToastPrimitives.Root> &
    VariantProps<typeof toastVariants>
>(({ className, variant, ...props }, ref) => {
  return (
    <ToastPrimitives.Root
      ref={ref}
      className={cn(toastVariants({ variant }), className)}
      {...props}
    />
  )
})
Toast.displayName = ToastPrimitives.Root.displayName

const ToastAction = React.forwardRef<
  React.ElementRef<typeof ToastPrimitives.Action>,
  React.ComponentPropsWithoutRef<typeof ToastPrimitives.Action>
>(({ className, ...props }, ref) => (
  <ToastPrimitives.Action
    ref={ref}
    className={cn(
      "inline-flex h-8 shrink-0 items-center justify-center rounded-md border border-slate-200 bg-transparent px-3 text-sm font-medium ring-offset-white transition-colors hover:bg-slate-100 focus:outline-none focus:ring-2 focus:ring-slate-950 focus:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 group-[.destructive]:border-slate-100/40 group-[.destructive]:hover:border-red-500/30 group-[.destructive]:hover:bg-red-500 group-[.destructive]:hover:text-slate-50 group-[.destructive]:focus:ring-red-500 dark:border-slate-800 dark:ring-offset-slate-950 dark:hover:bg-slate-800 dark:focus:ring-slate-300 dark:group-[.destructive]:border-slate-800/40 dark:group-[.destructive]:hover:border-red-900/30 dark:group-[.destructive]:hover:bg-red-900 dark:group-[.destructive]:hover:text-slate-50 dark:group-[.destructive]:focus:ring-red-900",
      className
    )}
    {...props}
  />
))
ToastAction.displayName = ToastPrimitives.Action.displayName

const ToastClose = React.forwardRef<
  React.ElementRef<typeof ToastPrimitives.Close>,
  React.ComponentPropsWithoutRef<typeof ToastPrimitives.Close>
>(({ className, ...props }, ref) => (
  <ToastPrimitives.Close
    ref={ref}
    className={cn(
      "absolute right-2 top-2 rounded-md p-1 text-slate-950/50 opacity-0 transition-opacity hover:text-slate-950 focus:opacity-100 focus:outline-none focus:ring-2 group-hover:opacity-100 group-[.destructive]:text-red-300 group-[.destructive]:hover:text-red-50 group-[.destructive]:focus:ring-red-400 group-[.destructive]:focus:ring-offset-red-600 dark:text-slate-50/50 dark:hover:text-slate-50",
      className
    )}
    toast-close=""
    {...props}
  >
    <X className="h-4 w-4" />
  </ToastPrimitives.Close>
))
ToastClose.displayName = ToastPrimitives.Close.displayName

const ToastTitle = React.forwardRef<
  React.ElementRef<typeof ToastPrimitives.Title>,
  React.ComponentPropsWithoutRef<typeof ToastPrimitives.Title>
>(({ className, ...props }, ref) => (
  <ToastPrimitives.Title
    ref={ref}
    className={cn("text-sm font-semibold", className)}
    {...props}
  />
))
ToastTitle.displayName = ToastPrimitives.Title.displayName

const ToastDescription = React.forwardRef<
  React.ElementRef<typeof ToastPrimitives.Description>,
  React.ComponentPropsWithoutRef<typeof ToastPrimitives.Description>
>(({ className, ...props }, ref) => (
  <ToastPrimitives.Description
    ref={ref}
    className={cn("text-sm opacity-90", className)}
    {...props}
  />
))
ToastDescription.displayName = ToastPrimitives.Description.displayName

type ToastProps = React.ComponentPropsWithoutRef<typeof Toast>

type ToastActionElement = React.ReactElement<typeof ToastAction>

export {
  type ToastProps,
  type ToastActionElement,
  ToastProvider,
  ToastViewport,
  Toast,
  ToastTitle,
  ToastDescription,
  ToastClose,
  ToastAction,
}

</game/frontend/src/components/ui/toast.tsx>

<game/frontend/src/components/ui/toaster.tsx>
"use client"

import {
  Toast,
  ToastClose,
  ToastDescription,
  ToastProvider,
  ToastTitle,
  ToastViewport,
} from "@/components/ui/toast"
import { useToast } from "@/components/ui/use-toast"

export function Toaster() {
  const { toasts } = useToast()

  return (
    <ToastProvider>
      {toasts.map(function ({ id, title, description, action, ...props }) {
        return (
          <Toast key={id} {...props}>
            <div className="grid gap-1">
              {title && <ToastTitle>{title}</ToastTitle>}
              {description && (
                <ToastDescription>{description}</ToastDescription>
              )}
            </div>
            {action}
            <ToastClose />
          </Toast>
        )
      })}
      <ToastViewport />
    </ToastProvider>
  )
}

</game/frontend/src/components/ui/toaster.tsx>

<game/frontend/src/components/ui/use-toast.ts>
"use client"

// Inspired by react-hot-toast library
import * as React from "react"

import type {
  ToastActionElement,
  ToastProps,
} from "@/components/ui/toast"

const TOAST_LIMIT = 1
const TOAST_REMOVE_DELAY = 1000000

type ToasterToast = ToastProps & {
  id: string
  title?: React.ReactNode
  description?: React.ReactNode
  action?: ToastActionElement
}

const actionTypes = {
  ADD_TOAST: "ADD_TOAST",
  UPDATE_TOAST: "UPDATE_TOAST",
  DISMISS_TOAST: "DISMISS_TOAST",
  REMOVE_TOAST: "REMOVE_TOAST",
} as const

let count = 0

function genId() {
  count = (count + 1) % Number.MAX_SAFE_INTEGER
  return count.toString()
}

type ActionType = typeof actionTypes

type Action =
  | {
      type: ActionType["ADD_TOAST"]
      toast: ToasterToast
    }
  | {
      type: ActionType["UPDATE_TOAST"]
      toast: Partial<ToasterToast>
    }
  | {
      type: ActionType["DISMISS_TOAST"]
      toastId?: ToasterToast["id"]
    }
  | {
      type: ActionType["REMOVE_TOAST"]
      toastId?: ToasterToast["id"]
    }

interface State {
  toasts: ToasterToast[]
}

const toastTimeouts = new Map<string, ReturnType<typeof setTimeout>>()

const addToRemoveQueue = (toastId: string) => {
  if (toastTimeouts.has(toastId)) {
    return
  }

  const timeout = setTimeout(() => {
    toastTimeouts.delete(toastId)
    dispatch({
      type: "REMOVE_TOAST",
      toastId: toastId,
    })
  }, TOAST_REMOVE_DELAY)

  toastTimeouts.set(toastId, timeout)
}

export const reducer = (state: State, action: Action): State => {
  switch (action.type) {
    case "ADD_TOAST":
      return {
        ...state,
        toasts: [action.toast, ...state.toasts].slice(0, TOAST_LIMIT),
      }

    case "UPDATE_TOAST":
      return {
        ...state,
        toasts: state.toasts.map((t) =>
          t.id === action.toast.id ? { ...t, ...action.toast } : t
        ),
      }

    case "DISMISS_TOAST": {
      const { toastId } = action

      // ! Side effects ! - This could be extracted into a dismissToast() action,
      // but I'll keep it here for simplicity
      if (toastId) {
        addToRemoveQueue(toastId)
      } else {
        state.toasts.forEach((toast) => {
          addToRemoveQueue(toast.id)
        })
      }

      return {
        ...state,
        toasts: state.toasts.map((t) =>
          t.id === toastId || toastId === undefined
            ? {
                ...t,
                open: false,
              }
            : t
        ),
      }
    }
    case "REMOVE_TOAST":
      if (action.toastId === undefined) {
        return {
          ...state,
          toasts: [],
        }
      }
      return {
        ...state,
        toasts: state.toasts.filter((t) => t.id !== action.toastId),
      }
  }
}

const listeners: Array<(state: State) => void> = []

let memoryState: State = { toasts: [] }

function dispatch(action: Action) {
  memoryState = reducer(memoryState, action)
  listeners.forEach((listener) => {
    listener(memoryState)
  })
}

type Toast = Omit<ToasterToast, "id">

function toast({ ...props }: Toast) {
  const id = genId()

  const update = (props: ToasterToast) =>
    dispatch({
      type: "UPDATE_TOAST",
      toast: { ...props, id },
    })
  const dismiss = () => dispatch({ type: "DISMISS_TOAST", toastId: id })

  dispatch({
    type: "ADD_TOAST",
    toast: {
      ...props,
      id,
      open: true,
      onOpenChange: (open) => {
        if (!open) dismiss()
      },
    },
  })

  return {
    id: id,
    dismiss,
    update,
  }
}

function useToast() {
  const [state, setState] = React.useState<State>(memoryState)

  React.useEffect(() => {
    listeners.push(setState)
    return () => {
      const index = listeners.indexOf(setState)
      if (index > -1) {
        listeners.splice(index, 1)
      }
    }
  }, [state])

  return {
    ...state,
    toast,
    dismiss: (toastId?: string) => dispatch({ type: "DISMISS_TOAST", toastId }),
  }
}

export { useToast, toast }

</game/frontend/src/components/ui/use-toast.ts>

<game/frontend/tailwind.config.ts>
import type { Config } from "tailwindcss"
const { fontFamily } = require("tailwindcss/defaultTheme")
const config = {
  darkMode: ["class"],
  content: [
    './pages/**/*.{ts,tsx}',
    './components/**/*.{ts,tsx}',
    './app/**/*.{ts,tsx}',
    './src/**/*.{ts,tsx}',
  ],
  prefix: "",
  theme: {
    container: {
      center: true,
      padding: "2rem",
      screens: {
        "2xl": "1400px",
      },
    },
    extend: {
      keyframes: {
        "accordion-down": {
          from: { height: "0" },
          to: { height: "var(--radix-accordion-content-height)" },
        },
        "accordion-up": {
          from: { height: "var(--radix-accordion-content-height)" },
          to: { height: "0" },
        },
      },
      animation: {
        "accordion-down": "accordion-down 0.2s ease-out",
        "accordion-up": "accordion-up 0.2s ease-out",
      },
    },
  },
  plugins: [require("tailwindcss-animate")],
} satisfies Config

export default config
</game/frontend/tailwind.config.ts>

<game/frontend/tsconfig.json>
{
  "compilerOptions": {
    "lib": ["dom", "dom.iterable", "esnext"],
    "allowJs": true,
    "skipLibCheck": true,
    "strict": true,
    "noEmit": true,
    "esModuleInterop": true,
    "module": "esnext",
    "moduleResolution": "bundler",
    "resolveJsonModule": true,
    "isolatedModules": true,
    "jsx": "preserve",
    "incremental": true,
    "plugins": [
      {
        "name": "next"
      }
    ],
    "paths": {
      "@/*": ["./src/*"]
    }
  },
  "include": ["next-env.d.ts", "**/*.ts", "**/*.tsx", ".next/types/**/*.ts"],
  "exclude": ["node_modules"]
}

</game/frontend/tsconfig.json>

<game/frontend/types/socket_types.tsx>
// .types/SocketEvents.ts

export interface EnvDescriptionEvent {
    description: string;
  }
  
</game/frontend/types/socket_types.tsx>

<game/frontend/utils/socket.js>
import io from 'socket.io-client';
let socket;

export const initSocket = () => {
  // Ensures a single socket connection is maintained
  if (!socket) {
    socket = io(process.env.NEXT_PUBLIC_API_URL, {
      // Add any options here
    });
    console.log('Connecting to Socket.IO server...');
  }
  return socket;
};

</game/frontend/utils/socket.js>

<main_dreamer.py>
import warnings
from functools import partial as bind

import dreamerv3
import embodied

import hydra
from omegaconf import OmegaConf, DictConfig

warnings.filterwarnings('ignore', '.*truncated to dtype int32.*')


@hydra.main(version_base=None, config_path="configs/dreamer/", config_name="dreamer_xxs")
def main_dreamer(config: DictConfig) -> None:
	config = embodied.Config(OmegaConf.to_container(config))
	config, _ = embodied.Flags(config).parse_known()

	def make_logger(config):
		logdir = embodied.Path(config.logdir)
		logger_list = [
			embodied.logger.TerminalOutput(),
			embodied.logger.JSONLOutput(logdir, 'metrics.jsonl'),
		]
		if config.wandb:
			logger_list.append(embodied.logger.WandBOutput(logdir, config=config))
		return embodied.Logger(embodied.Counter(), logger_list)

	def make_env(config, env_id=0):
		from embodied.envs.pybullet import PyBullet
		env = PyBullet(config.env.path, vision=config.env.vision, size=config.env.size, use_depth=config.env.use_depth, fov=config.env.fov)
		env = dreamerv3.wrap_env(env, config)
		return env

	def make_replay(config):
		return embodied.replay.Replay(
				length=config.batch_length,
				capacity=config.replay.size,
				directory=embodied.Path(config.logdir) / 'replay',
				online=config.replay.online,
		)

	def make_agent(config):
		env = make_env(config)
		agent = dreamerv3.Agent(env.obs_space, env.act_space, config)
		env.close()
		return agent

	args = embodied.Config(
			**config.run,
			logdir=config.logdir,
			batch_size=config.batch_size,
			batch_length=config.batch_length,
			batch_length_eval=config.batch_length_eval,
			replay_context=config.replay_context,
	)

	embodied.run.train(
			bind(make_agent, config),
			bind(make_replay, config),
			bind(make_env, config),
			bind(make_logger, config),
			args,
	)


if __name__ == "__main__":
	main_dreamer()

</main_dreamer.py>

<main_omni_epic.py>
import copy
import os
import math
import numpy as np
import re
import json
import hydra
from omegaconf import DictConfig

from omni_epic.robots import robot_dict
from omni_epic.core.fm import FM
from main_dreamer import main_dreamer
from run_utils import (
	get_images_from_video,
	save_images,
	encode_image,
	get_task_success_from_folder,
	parse_task_desc_from_env_code,
)
from rag_utils import get_similar_codepaths


def init_archive(archive_from_ckpt):
	archive_codepaths = []  # tasks that were successfully generated and trained
	archive_failedgens = []  # tasks that failed to generate compilable code
	archive_failedint = []  # tasks that failed interestingness eval
	archive_failedtrain = []  # tasks that failed to train a successful agent
	if len(archive_from_ckpt) > 0:
		# Initialize archive from checkpoint
		with open(archive_from_ckpt, 'r') as f:
			content = f.read()
			json_str = re.split('(?<=})\n(?={)', content)[-1]
			json_obj = json.loads(json_str)
			archive_codepaths = json_obj["codepaths"]
			archive_failedgens = json_obj["failedgens"]
			archive_failedint = json_obj["failedint"]
			archive_failedtrain = json_obj["failedtrain"]
	return archive_codepaths, archive_failedgens, archive_failedint, archive_failedtrain


@hydra.main(version_base=None, config_path="configs/", config_name="omni_epic")
def main(config: DictConfig):
	robot = config.robot
	robot_desc = robot_dict[robot]["robot_desc"]
	task_key_base = 'task'
	add_examples = config.add_examples

	# Create archive
	task_descs_init = robot_dict[robot]["task_descs_init"]
	archive_codepaths, archive_failedgens, archive_failedint, archive_failedtrain = init_archive(config.archive_from_ckpt)
	init_archive_size = len(task_descs_init)
	prev_num_iterations = len(archive_codepaths) + len(archive_failedgens) + len(archive_failedint) + len(archive_failedtrain)

	# Configs for each component
	config_task_generator = config.task_generator
	config_env_generator = config.environment_generator
	config_moi = config.model_of_interestingness
	config_success_detector = config.success_detector
	config_dreamer = config.dreamer
	config_task_iterator = config.task_iterator
	if config_success_detector.use_vision:
		config_task_iterator = config.task_iterator_vision
	num_steps_per_task = config.dreamer.run.steps

	# FM instance for each component
	fm_task_generator = FM(config_task_generator)
	fm_env_generator = FM(config_env_generator)
	fm_moi = FM(config_moi)
	fm_success_detector = FM(config_success_detector)
	fm_task_iterator = FM(config_task_iterator)

	# Variables to keep track of the iteration
	iterate_same_task = False
	iterate_same_task_count = 0
	iterations_spent_on_init_tasks = 0  # iterations spent on generating tasks from task_descs_init this run
	taskgen_choose_probs = np.ones(len(archive_codepaths))  # probability of choosing a task from the archive
	stop_iteration = False  # stop iterations, only used when config.iterate_until_success_gen is True

	# Override kwargs
	override_vars = config.override_vars
	taskgen_choose_probs = override_vars.get('taskgen_choose_probs', taskgen_choose_probs)
	taskgen_choose_probs = np.array(taskgen_choose_probs)
	iterate_same_task = override_vars.get('iterate_same_task', iterate_same_task)
	task_desc = override_vars.get('task_description', None)
	task_envpath = override_vars.get('task_envpath', None)

	prev_taskgen_choose_probs = copy.copy(taskgen_choose_probs)
	for iteration in range(config.iterations):
		if stop_iteration:
			break
		# Variables to keep track of the iteration
		iteration += prev_num_iterations  # add the number of iterations from the previous run
		task_key = f'{task_key_base}_{iteration}'
		task_dir = os.path.join(config.logdir, f'{task_key}')
		metadata = {}

		taskgen_example_paths = copy.copy(archive_codepaths)
		if iteration < len(task_descs_init):
			# First few iterations used to create tasks from seeded task descriptions
			task_desc = task_descs_init[iteration]
			taskgen_completion = fm_env_generator.query_env_code(robot, task_desc)
			metadata["init_task_desc"] = task_desc
			iterations_spent_on_init_tasks += 1
		elif iterate_same_task:
			# Iterate on the same task
			if not config.use_archive:
				taskgen_example_paths = []
			elif config_task_iterator.num_examples > 0 and len(archive_codepaths) > config_task_iterator.num_examples:
				# Find similar codepaths to the current task
				taskgen_example_paths, _ = get_similar_codepaths(
					task_envpath,
					archive_codepaths,
					num_returns=config_task_iterator.num_examples,
					embedding_method=config.embedding_method,
				)
			if config_success_detector.use_vision:
				# With vision
				taskgen_completion = fm_task_iterator.reflect_task_with_vision(
					robot,
					task_envpath,
					taskgen_example_paths,
					success_reasoning, input_image,  # should have been initialized in the previous iteration
					add_examples=add_examples,
				)
			else:
				# Wtihout vision
				taskgen_completion = fm_task_iterator.reflect_task(
					robot,
					task_envpath,
					taskgen_example_paths,
					add_examples=add_examples,
				)
			try:  # Get new task description if generated, otherwise use the previous one
				task_desc = parse_task_desc_from_env_code(taskgen_completion)
			except:
				pass
			iterate_same_task = False
			iterate_same_task_count += 1
			metadata["taskit_from_paths"] = [task_envpath]
			metadata["taskit_example_paths"] = taskgen_example_paths
			metadata["iterate_same_task_count"] = iterate_same_task_count
		else:
			if not config.use_archive:
				taskgen_example_paths = []
				taskgen_failed_paths = []
				taskgen_add_example_paths = []
			else:
				# Using prior knowledge that seeded task descs are very diverse, so adaptive num_examples
				num_examples = config_task_generator.num_examples
				num_examples = min(num_examples, max(math.ceil((iteration+1-init_archive_size) / init_archive_size), 1))
				num_examples_total = num_examples + config_task_generator.num_add_examples
				taskgen_add_example_paths = []
				# Choose examples to be fed into the prompt to generate the next task
				probs = taskgen_choose_probs if np.any(taskgen_choose_probs) else np.ones(len(archive_codepaths))
				probs /= np.sum(probs)
				chosen_idx = np.random.choice(len(archive_codepaths), p=probs)
				chosen_codepath = archive_codepaths[chosen_idx]
				if config_task_generator.num_examples > 0 and len(archive_codepaths) > num_examples:
					taskgen_example_paths, taskgen_example_indices = get_similar_codepaths(
						chosen_codepath,
						archive_codepaths,
						num_returns=num_examples_total,
						embedding_method=config.embedding_method,
					)
					prev_taskgen_choose_probs = copy.copy(taskgen_choose_probs)
					taskgen_choose_probs += 1  # Update counters for choosing examples
					taskgen_choose_probs[taskgen_example_indices] = 0
					taskgen_add_example_paths = taskgen_example_paths[num_examples:]
					taskgen_example_paths = taskgen_example_paths[:num_examples]
				# Choose failed examples to be fed into the prompt to generate the next task
				taskgen_failed_paths = copy.copy(archive_failedtrain)
				num_failed_examples = config_task_generator.num_failed_examples
				if num_failed_examples > 0 and len(archive_failedtrain) > num_failed_examples:
					taskgen_failed_paths, _ = get_similar_codepaths(
						chosen_codepath,
						archive_failedtrain,
						num_returns=num_failed_examples,
						embedding_method=config.embedding_method,
					)

			# Generate the next task
			metadata["taskgen_example_paths"] = taskgen_example_paths
			metadata["taskgen_failed_paths"] = taskgen_failed_paths
			metadata["taskgen_add_example_paths"] = taskgen_add_example_paths

			# Get the next task description
			task_desc = fm_task_generator.get_next_task_desc(
				robot,
				taskgen_example_paths,
				taskgen_failed_paths,
				add_examples=True,
			)

			# Query environment code
			taskgen_completion = fm_env_generator.query_env_code(robot, task_desc, add_examples=add_examples, env_paths_other=taskgen_example_paths + taskgen_add_example_paths)

		# Iterate on compilation errors for a max number of gens
		gen_num = fm_env_generator.iterate_on_errors(
			robot,
			task_desc,
			taskgen_completion,
			task_dir,
			add_examples=add_examples,
			env_paths_other=taskgen_example_paths,
			iteration_max=config.error_max_iterations,
		)

		# If generation was successful
		if gen_num >= 0:
			# Save the generated task envpath
			task_envpath = os.path.abspath(os.path.join(task_dir, f'env_{gen_num}.py'))
			metadata['envpath'] = task_envpath

			# Evaluate interestingness of the generated task
			if config.use_archive and config.enable_moi and len(archive_codepaths) > iterations_spent_on_init_tasks:
				# Evaluate whether the generated task is interesting by comparing with N most similar tasks
				moi_example_paths = copy.copy(archive_codepaths)
				if config_moi.num_examples > 0 and len(moi_example_paths) > config_moi.num_examples:
					moi_example_paths, _ = get_similar_codepaths(
						task_envpath,
						archive_codepaths,
						num_returns=config_moi.num_examples,
						embedding_method=config.embedding_method,
					)
				_, is_interesting = fm_moi.query_interestingness(
					robot_desc, task_envpath, moi_example_paths,
				)
				metadata['moi_example_paths'] = moi_example_paths
				metadata['is_interesting'] = is_interesting
			else:
				# Assume generated task is interesting
				is_interesting = True

			if is_interesting:
				if config.train_agent:
					# Train agent on the generated task
					dreamer_dir = os.path.join(task_dir, 'dreamer/')
					config_dreamer.logdir = dreamer_dir
					config_dreamer.env.path = task_envpath
					# If archive is not empty
					# and not first few iterations used to create tasks from seeded task descriptions
					if config.train_from_ckpt and len(archive_codepaths) > 0  \
						and not iteration < len(task_descs_init):
						ckpt_paths, _ = get_similar_codepaths(
							task_envpath,
							archive_codepaths,
							num_returns=1,
							embedding_method=config.embedding_method,
						)
						ckpt_path = ckpt_paths[0]
						ckpt_dir = os.path.join(os.path.dirname(ckpt_path), 'dreamer/')
						config_dreamer.run.from_checkpoint = os.path.join(ckpt_dir, 'checkpoint.ckpt')
						with open(os.path.join(ckpt_dir, 'metrics.jsonl'), 'r') as f:
							for line in f:
								ckpt_steps = json.loads(line)['step']
						config_dreamer.run.steps = ckpt_steps + num_steps_per_task
						metadata['train_from_ckpt'] = config_dreamer.run.from_checkpoint

					# Run Dreamer
					main_dreamer(config_dreamer)

					# Evaluate if the trained agent has successfully completed the task
					render_dir = os.path.join(dreamer_dir, 'eval')
					if config.enable_sd and config_success_detector.use_vision:
						# Use VLM to evaluate task success
						imagedir = os.path.join(task_dir, 'input_images/')
						video_files = [f for f in os.listdir(render_dir) if f.endswith('.mp4') and f.startswith('render')]
						video_file = os.path.join(render_dir, video_files[0])
						images = get_images_from_video(video_file)
						save_images(images, imagedir)
						input_image = encode_image(os.path.join(imagedir, "concat_image.png"))
						_, task_success, success_reasoning = fm_success_detector.query_success_with_vision(
							robot, robot_desc, task_desc, task_envpath, input_image,
						)
					elif config.enable_sd and not config_success_detector.use_vision:
						# Get task success from saved files
						task_success = get_task_success_from_folder(render_dir)
					else:
						task_success = True
				else:
					# Do not train agent and assume the task has succeeded
					task_success = True

				# If task is successful, add task to archive, else iterate on the same task
				metadata['task_success'] = task_success
				if task_success:
					# Add task to the archive
					archive_codepaths.append(task_envpath)
					iterate_same_task_count = 0
					taskgen_choose_probs = np.append(taskgen_choose_probs, 0)
					prev_taskgen_choose_probs = copy.copy(taskgen_choose_probs)
					if config.iterate_until_success_gen:
						stop_iteration = True
				else:
					# Iterate on the same task the next iteration
					if iterate_same_task_count < config_task_iterator.max_iterations:
						iterate_same_task = True
					else:
						iterate_same_task_count = 0
					archive_failedtrain.append(task_envpath)

			else:
				# If task is not interesting, add the task to the reject archive
				archive_failedint.append(task_envpath)
		else:
			# If generation failed, add the task to the reject archive
			archive_failedgens.append(task_dir)
			taskgen_choose_probs = prev_taskgen_choose_probs  # Reset taskgen_choose_probs

		# Save metadata about the task
		with open(os.path.join(task_dir, 'metadata.json'), 'w') as f:
			json.dump(metadata, f, indent=4)

		# Save the archive
		with open(os.path.join(config.logdir, 'archive.jsonl'), 'a') as f:
			f.write(json.dumps({
				'codepaths': archive_codepaths,
				'failedgens': archive_failedgens,
				'failedint': archive_failedint,
				'failedtrain': archive_failedtrain,
			}, indent=4) + '\n')

	return {
		'taskgen_choose_probs': taskgen_choose_probs,
	}


if __name__ == "__main__":
	main()

</main_omni_epic.py>

<omni_epic/core/fm.py>
import ast
import os
import traceback
import logging
from time import sleep
import re
from textwrap import indent, dedent
import base64
from io import BytesIO
from PIL import Image
import mediapy

from openai import OpenAI
from openai import RateLimitError, APIConnectionError
import anthropic
import google.generativeai as genai

from embodied.envs.pybullet import PyBullet
from omni_epic.core import prompts, ParseError
from omni_epic.robots import robot_dict
from omni_epic.envs import EnvironmentError, test_env_halts, test_env
logger = logging.getLogger(__name__)


class FM:

	def __init__(self, config):
		self._config = config
		self._client_name = self._config.client
		self._model = self._config.model
		self._client = self._create_client(self._client_name, self._model)

	def _create_client(self, client_name, model):
		if client_name == "openai":
			return OpenAI()
		elif client_name == "anthropic":
			return anthropic.Anthropic()
		elif client_name == "google":
			return genai.GenerativeModel(model)

	def _create_prompt_multimodal(self, prompt, input_images):
		client_name = self._client_name
		prompt = prompt.strip()
		if client_name == "openai":
			new_prompt = [
				{
					"type": "image_url",
					"image_url": {
						"url": f"data:image/png;base64,{xs}",
						# "detail": "low",
					}
				} for xs in input_images
			]
			new_prompt.append({"type": "text", "text": prompt})
		elif client_name == "anthropic":
			new_prompt = [
				{
					"type": "image",
					"source": {
						"type": "base64",
						"media_type": "image/png",
						"data": xs,
					},
				} for xs in input_images
			]
			new_prompt.append({"type": "text", "text": prompt})
		elif client_name == "google":
			new_prompt = [Image.open(BytesIO(base64.b64decode(xs))) for xs in input_images]
			new_prompt.append(prompt)
		return new_prompt

	def _chat_completion(self, system_prompt, user_prompt):
		while True:
			try:
				if self._client_name == "openai":
					completion = self._client.chat.completions.create(
						messages=[
							{"role": "system", "content": system_prompt},
							{"role": "user", "content": user_prompt},
						],
						model=self._model,
						max_tokens=self._config.max_tokens,
						temperature=self._config.temperature,
					).choices[0].message.content
				elif self._client_name == "anthropic":
					completion = self._client.messages.create(
						system=system_prompt,
						messages=[
							{"role": "user", "content": user_prompt},
						],
						model=self._model,
						max_tokens=self._config.max_tokens,
						temperature=self._config.temperature,
					).content[0].text
				elif self._client_name == "google":
					# NOTE: have to use this complicated multiprocessing thing so that training with JAX runs after using the gemini API.
					from multiprocessing import Process, Queue

					def generate_content(q, user_prompt, system_prompt, client, config):
						user_prompt = user_prompt if isinstance(user_prompt, list) else [user_prompt]
						completion = client.generate_content(
							contents=[f"System prompt: {system_prompt}", *user_prompt],
							generation_config=genai.types.GenerationConfig(
								max_output_tokens=config.max_tokens,
								temperature=config.temperature,
							)
						).text
						q.put(completion)

					q = Queue()
					p = Process(target=generate_content, args=(q, user_prompt, system_prompt, self._client, self._config))
					p.start()
					p.join()  # Wait for the process to finish
					completion = q.get()  # Get the result from the queue
				# Log completion
				completion = completion.strip()
				logger.info({"system_prompt": system_prompt, "user_prompt": user_prompt, "completion": completion})
				return completion
			except (RateLimitError, APIConnectionError, Exception) as e:
				logger.info(f"API got error {e}. Retrying after 10 seconds.")
				sleep(10)

	def wrap_string(self, string):
		"""Wrap string in triple quotes."""
		return f"\"\"\"\n{string}\n\"\"\""

	def wrap_code(self, code):
		"""Wrap code in a python block."""
		return f"```python\n{code}\n```"

	def filter_error(self, error):
		error = error.strip()
		lines = []
		for line in error.splitlines():
			if set(line) == {'^', ' '}:
				pass
			else:
				lines.append(line)
		return '\n'.join(lines)

	def get_env_code(self, env_path):
		"""Get environment code from env_path."""
		env_code = open(env_path).read()
		env_code_wrapped = self.wrap_code(env_code.strip())
		return env_code_wrapped

	def get_env_codes(self, env_paths):
		"""Get environment codes from env_paths."""
		env_codes = [self.get_env_code(env_path) for env_path in env_paths]
		env_codes = "\n\n".join(env_codes)
		return env_codes

	def get_env_codes_example(self, robot):
		"""Get few-shot environment code examples for a given robot."""
		env_paths_example = robot_dict[robot]["env_paths_example"]
		return self.get_env_codes(env_paths_example)

	def parse_env_code(self, completion):
		"""Parse the environment code from the completion."""
		match = re.search(r"Environment code:\s*```python\s*(.*?)\s*```", completion, re.DOTALL | re.IGNORECASE)

		if match:
			env_code = match.group(1).strip()
			return env_code
		else:
			raise ParseError("No environment code found in your response. Please follow the desired format.")

	def parse_next_task_desc(self, completion):
		"""Parse the next task description from the completion."""
		match = re.search(r"Next task description:\s*\"\"\"(.*)\"\"\"", completion, re.DOTALL | re.IGNORECASE)

		if match:
			next_task_desc = dedent(match.group(1)).strip()
			return next_task_desc
		else:
			raise ParseError("No next task description found in your response. Please follow the desired format.")

	def parse_success(self, completion):
		"""Parse the task success from the completion."""
		match = re.search(r"Did the robot solve the task\?:\s*(.*?)$", completion, re.MULTILINE | re.IGNORECASE)

		if match:
			task_success = match.group(1).strip()
			task_success = task_success.split(" ")[0].lower()  # if there are words after the answer
			return "yes" in task_success  # handle the case where there are punctuations
		else:
			raise ParseError("No task success/failure evaluation found in your response. Please follow the desired format.")

	def parse_success_reasoning(self, completion):
		"""Parse the task success reasoning from the completion."""
		match = re.search(r"Reasoning for task success/failure:\s*(.*?)\s*Did the robot solve the task\?:", completion, re.DOTALL | re.IGNORECASE)

		if match:
			task_success_reasoning = match.group(1).strip()
			return task_success_reasoning
		else:
			raise ParseError("No task success/failure reasoning found in your response. Please follow the desired format.")

	def parse_interestingness(self, completion):
		"""Parse the interestingness from the completion."""
		match = re.search(r"Is the new task interesting\?:\s*(.*?)$", completion, re.MULTILINE | re.IGNORECASE)

		if match:
			is_interesting = match.group(1).strip()
			is_interesting = is_interesting.split(" ")[0].lower()  # if there are words after the answer
			return "yes" in is_interesting
		else:
			raise ParseError("No task interestingness evaluation found in your response. Please follow the desired format.")

	def query_env_code(self, robot, task_desc, add_examples=True, env_paths_other=[]):
		"""Query environment code for the given task description."""
		# Create prompts
		robot_desc = robot_dict[robot]["robot_desc"]
		task_desc_wrapped = self.wrap_string(task_desc)
		env_codes_example = [self.get_env_codes_example(robot)] if add_examples else []
		env_code_others = [self.get_env_codes(env_paths_other)] if env_paths_other else []
		env_codes_example = "\n\n".join(env_codes_example + env_code_others)

		system_prompt = prompts.query_env_code.system_prompt.format(ROBOT_DESC=robot_desc)
		user_prompt = prompts.query_env_code.user_prompt.format(ENV_CODES_EXAMPLE=env_codes_example, TASK_DESC=task_desc_wrapped)

		# Prompt FM
		logger.info(f"Query environment code.\nTask description:\n{task_desc_wrapped}")
		completion = self._chat_completion(system_prompt, user_prompt)
		return completion

	def reflect_error(self, robot, env_code, error, add_examples=True, env_paths_other=[]):
		"""Reflect on environment code error."""
		# Create prompts
		robot_desc = robot_dict[robot]["robot_desc"]
		env_code_wrapped = self.wrap_code(env_code)
		error_wrapped = self.wrap_string(error)
		env_codes_example = [self.get_env_codes_example(robot)] if add_examples else []
		env_codes_other = [self.get_env_codes(env_paths_other)] if env_paths_other else []
		env_codes_example = "\n\n".join(env_codes_example + env_codes_other)

		system_prompt = prompts.reflect_error.system_prompt.format(ROBOT_DESC=robot_desc)
		user_prompt = prompts.reflect_error.user_prompt.format(
			ENV_CODES_EXAMPLE=env_codes_example,
			ENV_CODE=env_code_wrapped,
			ERROR=error_wrapped,
		)

		# Prompt FM
		logger.info(f"Reflect on error for environment code.\nError:\n{error}")
		completion = self._chat_completion(system_prompt, user_prompt)
		return completion

	def iterate_on_errors(self, robot, task_desc, completion, task_path, add_examples=True, env_paths_other=[], iteration_max=5):
		os.makedirs(task_path, exist_ok=True)
		iteration = 0
		while iteration <= iteration_max:
			try:
				# Parse environment code
				env_code = self.parse_env_code(completion)

				# Save environment code before replacing docstring because it can raise an error if code is incorrect
				env_path = os.path.join(task_path, f"env_{iteration}.py")
				with open(env_path, "w") as f:
					f.write(env_code)

				# Replace docstring
				env_code = update_env_docstring(env_code, task_desc)

				# Save environment code
				env_path = os.path.join(task_path, f"env_{iteration}.py")
				with open(env_path, "w") as f:
					f.write(env_code)

				# Test if environment halts
				test_env_halts(env_path, timeout=10.)

				# Test environment
				test_env(env_path)
			except ParseError as e:
				env_code = str(None)
				error = str(e) + f"\n\"\"\"\n\nTask description:\n\"\"\"{task_desc}"
			except EnvironmentError as e:
				error = str(e)
			except Exception:
				error = traceback.format_exc()
				error = self.filter_error(error)
			else:
				logger.info(f"Generate environment code, iteration {iteration}: SUCESS")

				# Visualize environment
				env = PyBullet(env_path=env_path, vision=False)._env
				renders, renders3p = env.visualize()
				env.close()
				mediapy.write_video(os.path.join(task_path, "render.mp4"), renders)
				mediapy.write_video(os.path.join(task_path, "render3p.mp4"), renders3p)

				return iteration
			logger.info(f"Generate environment code, iteration {iteration}: ERROR")

			# Reflect on error
			completion = self.reflect_error(robot, env_code, error, add_examples=add_examples, env_paths_other=env_paths_other)
			iteration += 1
		return -1

	def generate_env_code(self, robot, task_desc, task_path, add_examples=True, env_paths_other=[], iteration_max=5):
		"""Generate environment code for the given task description."""
		# Query environment code
		completion = self.query_env_code(robot, task_desc)

		# Iterate on errors
		iteration = self.iterate_on_errors(
			robot, task_desc,
			completion,
			task_path,
			add_examples=add_examples,
			env_paths_other=env_paths_other,
			iteration_max=iteration_max
		)

		return iteration

	def reflect_task(self, robot, env_path, env_paths_other, add_examples=True):
		"""Reflect on task."""
		# Create prompts
		robot_desc = robot_dict[robot]["robot_desc"]
		env_code_wrapped = self.get_env_code(env_path)
		env_codes_example = [self.get_env_codes_example(robot)] if add_examples else []
		env_codes_other = [self.get_env_codes(env_paths_other)] if env_paths_other else []
		env_codes_example = "\n\n".join(env_codes_example + env_codes_other)

		system_prompt = prompts.reflect_task.system_prompt.format(ROBOT_DESC=robot_desc)
		user_prompt = prompts.reflect_task.user_prompt.format(
			ENV_CODES_EXAMPLE=env_codes_example,
			ENV_CODE=env_code_wrapped,
		)

		# Prompt FM
		logger.info(f"Reflect on task.")
		completion = self._chat_completion(system_prompt, user_prompt)
		return completion

	def reflect_task_with_vision(self, robot, env_path, env_paths_other, failure_reasoning, input_image, add_examples=True):
		"""Reflect on task with vision."""
		# Create prompts
		robot_desc = robot_dict[robot]["robot_desc"]
		env_code_wrapped = self.get_env_code(env_path)
		env_codes_example = [self.get_env_codes_example(robot)] if add_examples else []
		env_codes_other = [self.get_env_codes(env_paths_other)] if env_paths_other else []
		env_codes_example = "\n\n".join(env_codes_example + env_codes_other)
		input_image = input_image if isinstance(input_image, list) else [input_image]

		# Build prompts
		system_prompt = prompts.reflect_task_with_vision.system_prompt.format(ROBOT_DESC=robot_desc)
		user_prompt = prompts.reflect_task_with_vision.user_prompt.format(
			ENV_CODES_EXAMPLE=env_codes_example,
			ENV_CODE=env_code_wrapped,
			FAILURE_REASONING=failure_reasoning,
		)

		# Add input image to user prompt
		user_prompt = self._create_prompt_multimodal(user_prompt, input_image)

		# Prompt FM
		logger.info(f"Reflect on task with vision.")
		completion = self._chat_completion(system_prompt, user_prompt)
		return completion

	def get_next_task_desc(self, robot, env_paths_learned, env_paths_failed, add_examples=True):
		"""Get the next task."""
		# Create prompts
		robot_desc = robot_dict[robot]["robot_desc"]
		env_codes_example = self.get_env_codes_example(robot) if add_examples else "None"
		env_codes_learned = self.get_env_codes(env_paths_learned)
		env_codes_learned = "None" if env_codes_learned == "" else env_codes_learned
		env_codes_failed = self.get_env_codes(env_paths_failed)
		env_codes_failed = "None" if env_codes_failed == "" else env_codes_failed

		if self._config.enable_moi:
			system_prompt = prompts.query_next_task_desc.system_prompt
			user_prompt = prompts.query_next_task_desc.user_prompt
		else:
			system_prompt = prompts.query_next_task_desc_no_moi.system_prompt
			user_prompt = prompts.query_next_task_desc_no_moi.user_prompt
		system_prompt = system_prompt.format(ROBOT_DESC=robot_desc)
		user_prompt = user_prompt.format(ENV_CODES_EXAMPLE=env_codes_example, ENV_CODES_LEARNED=env_codes_learned, ENV_CODES_FAILED=env_codes_failed)

		# Prompt FM
		logger.info(f"Query next task description.")
		completion = self._chat_completion(system_prompt, user_prompt)

		# Parse next task description
		try:
			next_task_desc = self.parse_next_task_desc(completion)
		except ParseError as e:
			logger.info(f"Querying next task:\nError:\n{e}")
			return self.get_next_task_desc(robot, env_paths_learned, env_paths_failed)
		else:
			return next_task_desc

	def query_success_with_vision(
			self,
			robot, robot_desc,
			task_desc, task_codepath,
			input_image,
	):
		"""Evaluate the success of the task using vision input.

		Args:
			robot: Robot name.
			robot_desc: Robot description.
			task_desc: Task description.
			task_codepath: Task codepath.
			input_image: Input image. Can be one image or a list of images.

		Returns:
			completion: Completion text generated by FM.
			task_success: Task success/failure indicator.
			success_reasoning: Reasoning for task success/failure.
		"""
		# Process inputs
		task_desc = self.wrap_string(task_desc)
		env_code = self.get_env_codes([task_codepath])
		input_image = input_image if isinstance(input_image, list) else [input_image]

		# Build prompts
		system_prompt = prompts.query_success.system_prompt.format(ROBOT_DESC=robot_desc)
		user_prompt = prompts.query_success.user_prompt.format(ENV_CODE=env_code)
		user_prompt = self._create_prompt_multimodal(user_prompt, input_image)

		# Prompt FM
		system_prompt = system_prompt.strip()
		completion = self._chat_completion(system_prompt, user_prompt)

		# Parse success detection
		try:
			task_success = self.parse_success(completion)
		except Exception as e:
			logger.info(f"Error: {e} Trying again.")
			return self.query_success_with_vision(
				robot, robot_desc,
				task_desc, task_codepath,
				input_image,
			)

		# Parse success reasoning
		try:
			task_success_reasoning = self.parse_success_reasoning(completion)
		except Exception as e:
			logger.info(f"Error: {e} Trying again.")
			return self.query_success_with_vision(
				robot, robot_desc,
				task_desc, task_codepath,
				input_image,
			)

		return completion, task_success, task_success_reasoning

	def query_interestingness(self, robot_desc, query_codepath, compare_codepaths):
		"""Evaluate if the generated task is interesting by comparing with the given tasks.

		Args:
			robot_desc: Robot description.
			query_codepath: Query codepath.
			compare_codepaths: Compare codepaths.

		Returns:
			completion: Completion text generated by FM.
			is_interesting: Task interestingness indicator.
		"""
		# Process inputs
		target_code = self.get_env_codes([query_codepath])
		compare_codes = self.get_env_codes(compare_codepaths)

		# Build prompts
		system_prompt = prompts.query_interestingness.system_prompt.format(ROBOT_DESC=robot_desc)
		user_prompt = prompts.query_interestingness.user_prompt.format(ENV_CODES_EXAMPLE=compare_codes, ENV_CODE=target_code)

		# Query FM
		system_prompt = system_prompt.strip()
		user_prompt = user_prompt.strip()
		completion = self._chat_completion(system_prompt, user_prompt)

		# Parse interestingness
		try:
			is_interesting = self.parse_interestingness(completion)
		except Exception as e:
			logger.info(f"Error: {e} Trying again.")
			return self.query_interestingness(query_codepath, compare_codepaths)

		return completion, is_interesting


def update_env_docstring(env_code, task_desc):
	"""
	Modifies or adds a docstring to the class `Env` in the given env_code.
	
	Args:
	env_code (str): The environment code containing class `Env`.
	new_docstring (str): The new docstring to insert for the class 'Env'.
	
	Returns:
	str: The modified env_code if the class 'Env' is found, or unchanged code otherwise.
	"""
	indentation = re.search(r'\n([ \t]+)def get_task_rewards', env_code, re.DOTALL).group(1)
	task_desc_wrapped = '\n' + indent(task_desc, indentation) + '\n' + indentation

	class DocstringUpdater(ast.NodeTransformer):
		"""
		AST Node Transformer to update or add docstrings to the specified class 'Env'.
		"""
		def visit_ClassDef(self, node):
			if node.name == "Env":
				if not ast.get_docstring(node):
					# If no docstring, add one
					node.body.insert(0, ast.Expr(value=ast.Constant(value=task_desc_wrapped)))
				else:
					# Replace the existing docstring
					for i, n in enumerate(node.body):
						if isinstance(n, ast.Expr) and isinstance(n.value, (ast.Constant, ast.Constant)):
							node.body[i] = ast.Expr(value=ast.Constant(value=task_desc_wrapped))
							break
				return node
			return node

	# Parse the original code into an AST
	tree = ast.parse(env_code)

	# Modify the AST
	transformer = DocstringUpdater()
	modified_tree = transformer.visit(tree)

	# Convert the modified AST back to source code using ast.unparse
	modified_env_code = ast.unparse(modified_tree)

	return modified_env_code

</omni_epic/core/fm.py>

<omni_epic/core/prompts/query_env_code.py>
system_prompt = """
You are an expert in Python programming and reinforcement learning. Your goal is to implement an environment in PyBullet specifically designed to train a robot for a given task. You will be provided with the task description and with pairs of task description and environment code. Your objective is to write environment code that rigorously aligns with the task description, helping the robot learn the task as effectively as possible.

Instructions:
- Write code without using placeholders.
- Don't change the import statements.
- For each object, always define its size first, and ensure the object's initial position is set relative to the platform it starts on or any other object, as demonstrated in the provided environment code examples. For example, if an object is initialized on the ground, define its position as: [self.platform_position[0], self.platform_position[1], self.platform_position[2] + self.platform_size[2] / 2 + self.object_size[2] / 2].
- Ensure the robot's initial position is set relative to the platform it starts on, as demonstrated in the provided environment code examples. For example, if the robot starts on a platform, its initial position should be set to [self.platform_position[0], self.platform_position[1], self.platform_position[2] + self.platform_size[2] / 2 + self.robot.links["base"].position_init[2]].
- Implement the methods `Env.reset()`, `Env.step()`, `Env.get_task_rewards()`, `Env.get_terminated()`, `Env.get_success()`. You can implement additional methods if needed.
- `Env.get_task_rewards()` returns a dictionary with the different reward components to help the robot learn the task. You should implement dense reward components that are easy to optimize and defined in the range -10. to 10.
- `Env.get_terminated()` returns a boolean that indicates whether the episode is terminated.
- `Env.get_success()` returns a boolean that indicates whether the task is successfully completed.
- If the task involves a target zone, make sure that the collision of the target zone is set to False.
- If the task involves navigating a terrain with obstacles, make sure that the robot cannot go around the obstacles. Add wall or boundary objects to prevent the robot from going around the obstacles.

Robot description:
{ROBOT_DESC}

Desired format:
Environment code:
```python
<environment code>
```
""".strip()

user_prompt = """
Pairs of task description and environment code:
{ENV_CODES_EXAMPLE}

Task description:
{TASK_DESC}
""".strip()

</omni_epic/core/prompts/query_env_code.py>

<omni_epic/core/prompts/query_interestingness.py>
system_prompt = """
You are an expert in curriculum learning and reinforcement learning. Your goal is to help a robot master a diverse set of interesting tasks in simulation using PyBullet. You will be provided with a list of old tasks and with a new task. Your objective is to determine whether the new task is interesting or not.

The new task can be considered interesting if one of the following is true, the new task is:
- Novel compared to the old tasks, to build a diverse skill set.
- Creative or surprising.
- Fun or engaging to watch.
- Not too easy for the robot to learn given its current skill set, progressing toward more complex challenges.
- Useful according to humans, making it worth learning.

Robot description:
{ROBOT_DESC}

Desired format:
Reasoning for why the new task is interesting or not:
<reasoning>

Is the new task interesting?:
<Yes/No>
""".strip()

user_prompt = """
Old tasks:
{ENV_CODES_EXAMPLE}

New task:
{ENV_CODE}
""".strip()

</omni_epic/core/prompts/query_interestingness.py>

<omni_epic/core/prompts/query_next_task_desc.py>
system_prompt = """
You are an expert in curriculum learning and reinforcement learning. Your goal is to help a robot master a diverse set of interesting tasks in simulation using PyBullet. You will be provided with the list of tasks that the robot has successfully learned, along with their corresponding environment code, and the list of tasks that the robot has attempted but failed to learn, along with their corresponding environment code. Your objective is to decide the next task for the robot, selecting one that is learnable, interesting and novel.

Instructions:
- The next task should be learnable:
    - Not too difficult for the robot to learn given its current skill set.
    - Don't suggest a task that builds on a past failed task.
    - Realistic for the robot based on its description.
    - Possible to complete in simulation in PyBullet.
- The next task should be interesting:
    - Novel and creative compared to the tasks the robot has already learned.
    - Useful according to humans, making it worth learning.
    - Design rich environments with a large number of diverse objects and terrains, and with a clear task for the robot to execute.
    - The task should be fun or engaging to watch. You can draw inspiration from real-world tasks or video games. Be creative!
- Be specific in the task description:
    - State clearly what the task of the robot is.
    - Define clearly what the success condition is.
    - Define clearly what are the different reward and penalty components.
    - Define clearly what the termination conditions are. If the reward components include a survival reward, ensure the episode only terminates when the agent fails the task.
- The task should not take too long to complete.
- The robot can push objects around but lacks the ability to grab, pick up, carry, or stack objects. Don't suggest tasks that involve these skills.
- Don't suggest tasks that require the robot to navigate through a maze.
- If the task involves navigating a terrain with obstacles, make sure that the robot can not go around the obstacles.
- If the task involves a target zone, make sure that the collision of the target zone is set to False.
- Return only the task description, not the environment code.
- Ensure that the designs pose no harm to humans and align with human values and ethics.

Robot description:
{ROBOT_DESC}

Desired format:
Reasoning for what the next task should be:
<reasoning>

Next task description:
\"\"\"
<task description>
\"\"\"
""".strip()

user_prompt = """
Environment code examples:
{ENV_CODES_EXAMPLE}

Learned tasks and environment code:
{ENV_CODES_LEARNED}

Failed tasks and environment code:
{ENV_CODES_FAILED}
""".strip()

</omni_epic/core/prompts/query_next_task_desc.py>

<omni_epic/core/prompts/query_next_task_desc_no_moi.py>
system_prompt = """
You are an expert in curriculum learning and reinforcement learning. Your goal is to help a robot master a set of tasks in simulation using PyBullet. You will be provided with the list of tasks that the robot has successfully learned, along with their corresponding environment code, and the list of tasks that the robot has attempted but failed to learn, along with their corresponding environment code. Your objective is to decide the next task for the robot, selecting one that will maximize learning effectiveness based on its past successes and failures.

Instructions:
- The next task should be learnable:
    - Not too difficult for the robot to learn given its current skill set.
    - Don't suggest a task that builds on a past failed task.
    - Realistic for the robot based on its description.
    - Possible to complete in simulation in PyBullet.
- Be specific in the task description:
    - State clearly what the task of the robot is.
    - Define clearly what the success condition is.
    - Define clearly what are the different reward and penalty components.
    - Define clearly what the termination conditions are. If the reward components include a survival reward, ensure the episode only terminates when the agent fails the task.
- The task should not take too long to complete.
- The robot can push objects around but lacks the ability to grab, pick up, carry, or stack objects. Don't suggest tasks that involve these skills.
- Don't suggest tasks that require the robot to navigate through a maze.
- If the task involves navigating a terrain with obstacles, make sure that the robot cannot go around the obstacles.
- If the task involves a target zone, make sure that the collision of the target zone is set to False.
- Return only the task description, not the environment code.
- Ensure that the designs pose no harm to humans and align with human values and ethics.

Robot description:
{ROBOT_DESC}

Desired format:
Reasoning for what the next task should be:
<reasoning>

Next task description:
\"\"\"
<task description>
\"\"\"
""".strip()

user_prompt = """
Environment code examples:
{ENV_CODES_EXAMPLE}

Learned tasks and environment code:
{ENV_CODES_LEARNED}

Failed tasks and environment code:
{ENV_CODES_FAILED}
""".strip()

</omni_epic/core/prompts/query_next_task_desc_no_moi.py>

<omni_epic/core/prompts/query_success.py>
system_prompt = """
You are an expert in Python programming and reinforcement learning. Your goal is to evaluate if a robot has solved a task. You will be provided with the task description, the corresponding environment code and an image containing snapshots of the robot attempting to complete the task. Your objective is to describe the image, reason about whether the task has been completed and determine if the robot has solved the task.

Instructions:
- In the description of the image, describe the environment and the behavior of the robot.
- In the reasoning, analyze if the environment corresponds to the task description and if the behavior of the robot meets the requirements for task success.
- The task is considered failed if the environment is constructed in a way that makes solving the task impossible.
- If you are unsure, make an educated guess and always provide an answer.
- If you are unsure, say that it has failed.

Robot description:
{ROBOT_DESC}

Desired format:
Description of the image:
<image description>

Reasoning for task success/failure:
<reasoning>

Did the robot solve the task?:
<Yes/No>
""".strip()

user_prompt = """
Task description and environment code:
{ENV_CODE}
""".strip()

</omni_epic/core/prompts/query_success.py>

<omni_epic/core/prompts/reflect_error.py>
system_prompt = """
You are an expert in Python programming and reinforcement learning. Your goal is to implement an environment in PyBullet specifically designed to train a robot for a given task. You will be provided with environment code examples, with an environment code that returns an error when executed and with the specific error that was encountered. Your objective is to reason about the error and provide a new, improved environment code with no error.

Instructions:
- Write code without using placeholders.
- Don't change the import statements.
- For each object, always define its size first, and ensure the object's initial position is set relative to the platform it starts on or any other object, as demonstrated in the provided environment code examples. For example, if an object is initialized on the ground, define its position as: [self.platform_position[0], self.platform_position[1], self.platform_position[2] + self.platform_size[2] / 2 + self.object_size[2] / 2].
- Ensure the robot's initial position is set relative to the platform it starts on, as demonstrated in the provided environment code examples. For example, if the robot starts on a platform, its initial position should be set to [self.platform_position[0], self.platform_position[1], self.platform_position[2] + self.platform_size[2] / 2 + self.robot.links["base"].position_init[2]].
- Implement the methods `Env.reset()`, `Env.step()`, `Env.get_task_rewards()`, `Env.get_terminated()`, `Env.get_success()`. You can implement additional methods if needed.
- `Env.get_task_rewards()` returns a dictionary with the different reward components to help the robot learn the task. You should implement dense reward components that are easy to optimize and defined in the range -10. to 10.
- `Env.get_terminated()` returns a boolean that indicates whether the episode is terminated.
- `Env.get_success()` returns a boolean that indicates whether the task is successfully completed.

Robot description:
{ROBOT_DESC}

Desired format:
How to solve the error:
<reasoning>

Environment code:
```python
<environment code>
```
""".strip()

user_prompt = """
Environment code examples:
{ENV_CODES_EXAMPLE}

Environment code with error:
{ENV_CODE}

Error:
{ERROR}
""".strip()

</omni_epic/core/prompts/reflect_error.py>

<omni_epic/core/prompts/reflect_task.py>
system_prompt = """
You are an expert in Python programming and reinforcement learning. Your goal is to improve an environment in PyBullet specifically designed to train a robot for a given task. The robot has been trained in the environment, but has not been able to complete the task. You will be provided with environment code examples and with the current environment code that fails to properly train the agent on the given task. Your objective is to reason about what might be causing the agent to fail and provide a new, improved environment code that will help the agent learn the task more effectively.

Instructions:
- Write code without using placeholders.
- Don't change the import statements.
- Reason about why the robot has not been able to complete the task in the current environment.
    - Check `Env.get_task_rewards` to ensure that the rewards are guiding the robot to learn the task. The rewards should be dense and easy to optimize. For example, if the task is to reach a goal, the environment should reward progress towards the goal, rather than just rewarding reaching the goal.
    - Check `Env.get_terminated` to ensure that the logic is correct.
    - Check `Env.get_success` to ensure that the logic is correct.
    - Check `Env.reset` to ensure that the initial positions of the robot and the objects are correct.
    - Check `Env.step` to ensure that the logic of the environment is correct.
    - Additionally, you can simplify the task by removing any complexity.
- If the task involves navigating a terrain with obstacles, make sure that the robot cannot go around the obstacles.

Robot description:
{ROBOT_DESC}

Desired format:
Reasoning for why the agent fails to complete the task:
<reasoning>

Reasoning for code improvement:
<reasoning>

New environment code:
```python
<environment code>
```
""".strip()

user_prompt = """
Environment code examples:
{ENV_CODES_EXAMPLE}

Environment code failing to train the agent:
{ENV_CODE}
""".strip()

</omni_epic/core/prompts/reflect_task.py>

<omni_epic/core/prompts/reflect_task_with_vision.py>
system_prompt = """
You are an expert assistant in reinforcement learning environment design and PyBullet. Your goal is to teach a robot to complete diverse tasks. To achieve this, you generate creative and diverse environments that are easy for reinforcement learning agents to learn, based on their current skills (which you will be informed about). You ensure that the designs pose no harm to humans and align with human values and ethics. The robot is capable of moving objects through interaction, but it lacks the ability to grab them. Therefore, please avoid suggesting tasks that involve grabbing, such as picking up, carrying, or stacking objects. You write code without syntax errors and always think through and document your implementation carefully. The overall goal is to create a series of different challenges to train the robot in a wide array of fun and interesting tasks, thereby developing skills that humans recognize as useful, interesting, diverse, and challenging (all while making the challenges at each stage not too difficult given the robot's current skill set). We want to start with simple tasks and progress to a vast variety of engaging and complex challenges.

Robot description:
{ROBOT_DESC}
""".strip()

user_prompt = """
You are provided with examples of task descriptions and their corresponding environment code. For a given task description, you are also provided with the previously generated environment code, an image containing snapshots taken about every second that show what the robot looks like in the environment after attempting to learn the task, and the reason for task failure. You should reason about how to write a new environment code to better help the agent learn the given task.

Examples:
{ENV_CODES_EXAMPLE}

Environment code:
{ENV_CODE}

Reasoning for task failure:
{FAILURE_REASONING}

Please follow these criteria:
- If you are reusing code from above, rewrite the code in the generated code block. The generated code block should be self-contained and should not reference any external code.
- The return values for `Env.step()` are `(observation, reward, terminated, truncated, info)`.
- Always rewrite the functions `Env.get_task_rewards()`, `Env.get_terminated()`, `Env.get_success()`. You can also add other functions if needed. `Env.get_task_rewards()` returns a dictionary of the different reward components for the task at the current time step. `Env.get_terminated()` returns a boolean that indicates whether the episode is terminated. `Env.get_success()` returns a boolean that indicates whether the task is successfully completed.
- Always include all necessary details and functionalities in the code to fully implement the environment, without using placeholders.

The task has not yet been achieved. Reflect on why the agent might not have learned the task yet, and discuss how the code could be modified to better facilitate the agent's learning. Then, write the new `Env` environment code for the same task in a Python code block.

You should only respond in the format as described below:
RESPONSE FORMAT:
Reasoning for why the agent failed: ...
Reasoning for code modification: ...
New environment code:
```python
...
```
""".strip()

</omni_epic/core/prompts/reflect_task_with_vision.py>

<omni_epic/core/prompts/__init__.py>
from omni_epic.core.prompts import query_env_code
from omni_epic.core.prompts import query_next_task_desc
from omni_epic.core.prompts import query_next_task_desc_no_moi
from omni_epic.core.prompts import query_interestingness
from omni_epic.core.prompts import query_success
from omni_epic.core.prompts import reflect_error
from omni_epic.core.prompts import reflect_task
from omni_epic.core.prompts import reflect_task_with_vision

</omni_epic/core/prompts/__init__.py>

<omni_epic/core/__init__.py>
class ParseError(Exception):
    pass

</omni_epic/core/__init__.py>

<omni_epic/envs/ant/balance_board.py>
import numpy as np
from omni_epic.envs.ant.base import AntEnv


class Env(AntEnv):
    """
    Balance on a board placed on top of a rolling cylinder.

    Description:
    - A cylinder (radius 0.5 m and height 2 m) is placed on the ground and can roll along the y-axis.
    - A board (length 3 m, width 2 m and thickness 0.05 m) is placed on top of the cylinder.
    The robot is initialized on top of the board facing toward the positive x-axis.
    The task of the robot is to stand on the board and keep its balance on the board while the cylinder moves underneath.

    Success:
    The task is completed if the robot remains standing on the board for more than 10 s.

    Rewards:
    The robot is rewarded for remaining on the board.

    Termination:
    The task terminates if the robot falls of the board.
    """

    def __init__(self):
        super().__init__()

        # Init ground
        self.ground_size = [10., 10., 10.]
        self.ground_position = [0., 0., 0.]
        self.ground_id = self.create_box(mass=0., half_extents=[self.ground_size[0] / 2, self.ground_size[1] / 2, self.ground_size[2] / 2], position=self.ground_position, color=[0.5, 0.5, 0.5, 1.])
        self._p.changeDynamics(bodyUniqueId=self.ground_id, linkIndex=-1, lateralFriction=0.8, restitution=0.5)

        # Init cylinder
        self.cylinder_radius = 0.5
        self.cylinder_height = 2.
        self.cylinder_position_init = [self.ground_position[0], self.ground_position[1], self.ground_position[2] + self.ground_size[2] / 2 + self.cylinder_radius]
        self.cylinder_orientation_init = self._p.getQuaternionFromEuler(eulerAngles=[0., np.pi / 2, 0.])  # roll along y-axis
        self.cylinder_id = self.create_cylinder(mass=10., radius=self.cylinder_radius, height=self.cylinder_height, position=self.cylinder_position_init, orientation=self.cylinder_orientation_init, color=[0., 0., 1., 1.]) 
        self._p.changeDynamics(bodyUniqueId=self.cylinder_id, linkIndex=-1, lateralFriction=0.8, restitution=0.5)

        # Init board
        self.board_size = [2., 3., 0.05]
        self.board_position_init = [self.cylinder_position_init[0], self.cylinder_position_init[1], self.cylinder_position_init[2] + self.cylinder_radius + self.board_size[2] / 2]  # Init board above cylinder
        self.board_id = self.create_box(mass=10., half_extents=[self.board_size[0] / 2, self.board_size[1] / 2, self.board_size[2] / 2], position=self.board_position_init, color=[1., 0., 0., 1.])
        self._p.changeDynamics(bodyUniqueId=self.board_id, linkIndex=-1, lateralFriction=0.8, restitution=0.5)

    def create_box(self, mass, half_extents, position, color):
        collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents)
        visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents, rgbaColor=color)
        return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position)

    def create_cylinder(self, mass, radius, height, position, orientation, color):
        collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_CYLINDER, radius=radius, height=height)
        visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_CYLINDER, radius=radius, length=height, rgbaColor=color)
        return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position, baseOrientation=orientation)

    def reset(self):
        observation = super().reset()

        # Reset time
        self.time = 0.

        # Reset cylinder position
        self._p.resetBasePositionAndOrientation(self.cylinder_id, self.cylinder_position_init, self.cylinder_orientation_init)

        # Reset board position
        self._p.resetBasePositionAndOrientation(self.board_id, self.board_position_init, [0., 0., 0., 1.])

        # Reset robot position
        self._p.resetBasePositionAndOrientation(self.robot.robot_id, [self.board_position_init[0], self.board_position_init[1], self.board_position_init[2] + self.board_size[2] / 2 + self.robot.links["base"].position_init[2]], self.robot.links["base"].orientation_init)

        return observation

    def step(self, action):
        observation, reward, terminated, truncated, info = super().step(action)

        # Increase time
        self.time += self.dt

        return observation, reward, terminated, truncated, info

    def get_task_rewards(self, action):
        # On board
        on_board = 1. if self.robot.links["base"].position[2] > self.board_position_init[2] + self.board_size[2] / 2 else -1.
        return {"on_board": on_board}

    def get_terminated(self, action):
        # Terminate if not on board
        is_on_board = self.robot.links["base"].position[2] > self.board_position_init[2] + self.board_size[2] / 2
        return not is_on_board

    def get_success(self):
        # Success if on board after 10. s
        on_board = self.time >= 10. and self.robot.links["base"].position[2] > self.board_position_init[2] + self.board_size[2] / 2
        return on_board

</omni_epic/envs/ant/balance_board.py>

<omni_epic/envs/ant/base.py>
from omni_epic.envs.base import Env
from omni_epic.robots.ant import AntRobot


class AntEnv(Env):
	dt = 0.0165

	def __init__(self):
		# Init world
		super().__init__()

		# Init robot
		self.robot = AntRobot(self._p)

		self.action_space = self.robot.action_space
		self.observation_space = self.robot.observation_space

	def get_truncated(self, action):
		return False

</omni_epic/envs/ant/base.py>

<omni_epic/envs/ant/cross_bridge.py>
import numpy as np
from omni_epic.envs.ant.base import AntEnv


class Env(AntEnv):
    """
    Cross a pride-colored bridge to reach a platform.

    Description:
    - A start platform and an end platform (each 3 m in size and 0.5 m in thickness) are placed 30 m apart.
    - The two platforms are connected by a bridge (2 m wide) divided in multiple segments. Each segment has a different color corresponding to the pride colors.
    The robot is initialized on the start platform.
    The task of the robot is to cross the bridge to reach the end platform as fast as possible.

    Success:
    The task is successfully completed when the robot reaches the end platform.

    Rewards:
    To help the robot complete the task:
    - The robot receives a reward for each time step it remains standing on the bridge or platforms, encouraging steady progress.
    - The robot is rewarded based on how much it reduces the distance to the end platform, incentivizing swift movement towards the goal.

    Termination:
    The task terminates immediately if the robot falls off the start platform, any segment of the bridge, or the end platform.
    """

    def __init__(self):
        super().__init__()

        # Init start platform
        self.platform_size = [3., 3., 0.5]
        self.platform_start_position = [0., 0., 0.]
        self.platform_end_position = [self.platform_start_position[0] + 30., self.platform_start_position[1], self.platform_start_position[2]]
        self.platform_start_id = self.create_box(mass=0., half_extents=[self.platform_size[0] / 2, self.platform_size[1] / 2, self.platform_size[2] / 2], position=self.platform_start_position, color=[0.8, 0.8, 0.8, 1.])
        self.platform_end_id = self.create_box(mass=0., half_extents=[self.platform_size[0] / 2, self.platform_size[1] / 2, self.platform_size[2] / 2], position=self.platform_end_position, color=[0.8, 0.8, 0.8, 1.])

        # Init bridge
        self.bridge_length = self.platform_end_position[0] - self.platform_start_position[0] - self.platform_size[0]
        self.bridge_width = 2.
        pride_colors = [
            [1.0, 0.0, 0.0, 1.],  # Red
            [1.0, 0.5, 0.0, 1.],  # Orange
            [1.0, 1.0, 0.0, 1.],  # Yellow
            [0.0, 0.5, 0.0, 1.],  # Green
            [0.0, 0.0, 1.0, 1.],  # Blue
            [0.7, 0.0, 1.0, 1.],  # Violet
        ]

        # Segment length
        num_colors = len(pride_colors)
        segment_size = self.bridge_length / num_colors

        # Create segments
        for i, color in enumerate(pride_colors):
            segment_id = self.create_box(mass=0., half_extents=[segment_size / 2, self.bridge_width / 2, self.platform_size[2] / 2], position=[self.platform_start_position[0] + self.platform_size[0] / 2 + segment_size / 2 + i * segment_size, self.platform_start_position[1], self.platform_start_position[2]], color=color)
            self._p.changeDynamics(bodyUniqueId=segment_id, linkIndex=-1, lateralFriction=0.8, restitution=0.5)

    def create_box(self, mass, half_extents, position, color):
        collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents)
        visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents, rgbaColor=color)
        return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position)

    def get_object_position(self, object_id):
        return np.asarray(self._p.getBasePositionAndOrientation(object_id)[0])

    def get_distance_to_object(self, object_id):
        object_position = self.get_object_position(object_id)
        robot_position = self.robot.links["base"].position
        return np.linalg.norm(object_position[:2] - robot_position[:2])

    def reset(self):
        observation = super().reset()

        # Reset robot position on start platform
        self._p.resetBasePositionAndOrientation(self.robot.robot_id, [self.platform_start_position[0], self.platform_start_position[1], self.platform_start_position[2] + self.platform_size[2] / 2 + self.robot.links["base"].position_init[2]], self.robot.links["base"].orientation_init)

        return observation

    def step(self, action):
        # Before taking action
        self.distance_to_platform_end = self.get_distance_to_object(self.platform_end_id)

        observation, reward, terminated, truncated, info = super().step(action)

        return observation, reward, terminated, truncated, info

    def get_task_rewards(self, action):
        # After taking action
        new_distance_to_platform_end = self.get_distance_to_object(self.platform_end_id)

        # Standing
        contact_points = self._p.getContactPoints(bodyA=self.robot.robot_id, linkIndexA=self.robot.links["base"].index)
        standing = 1. if len(contact_points) == 0 else -1.

        # Reach end platform
        reach_platform_end = (self.distance_to_platform_end - new_distance_to_platform_end) / self.dt

        return {"standing": standing, "reach_platform_end": reach_platform_end}

    def get_terminated(self, action):
        # Terminate if fall off
        return self.robot.links["base"].position[2] < self.platform_start_position[2]

    def get_success(self):
        # Success if reach end platform
        is_on_platform_end = self.get_distance_to_object(self.platform_end_id) < self.platform_size[2] / 2
        return is_on_platform_end

</omni_epic/envs/ant/cross_bridge.py>

<omni_epic/envs/ant/cross_lava.py>
import numpy as np
from omni_epic.envs.r2d2.base import R2D2Env


class Env(R2D2Env):
    """
    Cross over lava on a boat to reach a target zone.

    Description:
    - The lava is simulated with an orange, 10 x 10 m heightfield.
    - There are two platforms on either side of the lava, each measuring 5 x 10 m. One serves as the start platform and the other as the end platform.
    - The boat is a box with dimensions 3 meters in length, 2 meters in width, and 0.2 meters in height. It is initialized next to the start platform at a random y-position.
    - The boat has a button that, when pressed, activates the boat to move over the lava at a speed of 3 meters per second.
    - The end platform has a target zone indicated by a green, transparent sphere.
    The robot's task is to jump onto the boat from the start platform, press the button to activate the boat, and travel across the lava to reach the end platform. The robot must then enter the target zone to complete the task.

    Success:
    The task is successfully completed when the robot enters the target zone on the end platform.

    Rewards:
    To guide the robot to complete the task:
    - The robot receives a reward for each time step it remains active and does not fall off or touch the lava.
    - The robot is rewarded for making progress towards pressing the button on the boat.
    - Additional rewards are given for progressing towards the target zone, with a significant bonus for entering the target zone.

    Termination:
    The task terminates immediately if the robot falls off the platform or the boat, or if it touches the simulated lava.
    """

    def __init__(self):
        super().__init__()

        # Init lava
        self.lava_size = [10., 10.]
        self.lava_height = 0.1
        self.lava_position = [0., 0., 0.]
        self.lava_id = self.create_heightfield(
            size=self.lava_size,
            height_max=self.lava_height,  # create small bumps to create a fluid-like surface
            position=self.lava_position,
            resolution=20,  # number of points per meter
            repeats=2,
        )
        self._p.changeVisualShape(objectUniqueId=self.lava_id, linkIndex=-1, rgbaColor=[1., 0.3, 0.1, 1.])  # change to lava color

        # Init platforms
        self.platform_size = [5., self.lava_size[1], 1.]
        self.platform_start_position = [self.lava_position[0] - self.lava_size[0] / 2 - self.platform_size[0] / 2, self.lava_position[1], self.lava_position[2]]
        self.platform_end_position = [self.lava_position[0] + self.lava_size[0] / 2 + self.platform_size[0] / 2, self.lava_position[1], self.lava_position[2]]
        self.platform_start_id = self.create_box(mass=0., half_extents=[self.platform_size[0] / 2, self.platform_size[1] / 2, self.platform_size[2] / 2], position=self.platform_start_position, color=[0.3, 0.3, 0.3, 1.])
        self.platform_end_id = self.create_box(mass=0., half_extents=[self.platform_size[0] / 2, self.platform_size[1] / 2, self.platform_size[2] / 2], position=self.platform_end_position, color=[0.3, 0.3, 0.3, 1.])
        self._p.changeDynamics(bodyUniqueId=self.platform_start_id, linkIndex=-1, lateralFriction=0.8, restitution=0.5)
        self._p.changeDynamics(bodyUniqueId=self.platform_end_id, linkIndex=-1, lateralFriction=0.8, restitution=0.5)

        # Init boat
        self.boat_size = [3., 2., 0.2]
        self.boat_position_init = [self.lava_position[0] - self.lava_size[0] / 2 + self.boat_size[0] / 2, self.lava_position[1], self.boat_size[2] / 2]
        self.boat_speed = 3.
        self.boat_id = self.create_box(mass=0., half_extents=[self.boat_size[0] / 2, self.boat_size[1] / 2, self.boat_size[2] / 2], position=self.boat_position_init, color=[0.8, 0.8, 0.8, 1.])
        self._p.changeDynamics(bodyUniqueId=self.boat_id, linkIndex=-1, lateralFriction=0.8, restitution=0.5)

        # Init button
        self.button_radius = 0.25
        self.button_height = 0.25
        self.button_position_init = [self.boat_position_init[0] + self.boat_size[0] / 4, self.lava_position[1], self.boat_position_init[2] + self.boat_size[2] / 2 + self.button_height / 2]  # put button on the right side of the boat
        self.button_id = self.create_cylinder(mass=0., radius=self.button_radius, height=self.button_height, position=self.button_position_init, color=[0., 0.5, 0., 1.])

        # Init target zone
        self.target_zone_radius = 1.5
        self.target_zone_id = self.create_sphere(mass=0., radius=self.target_zone_radius, collision=False, position=[self.platform_end_position[0], self.platform_end_position[1], self.platform_end_position[2] + self.platform_size[2] / 2], color=[0., 1., 0., 0.5])

        self.objects_on_boat = [self.button_id]

    def create_box(self, mass, half_extents, position, color):
        collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents)
        visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents, rgbaColor=color)
        return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position)

    def create_cylinder(self, mass, radius, height, position, color):
        collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_CYLINDER, radius=radius, height=height)
        visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_CYLINDER, radius=radius, length=height, rgbaColor=color)
        return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position)

    def create_sphere(self, mass, radius, collision, position, color):
        if collision:
            collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_SPHERE, radius=radius)
            visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_SPHERE, radius=radius, rgbaColor=color)
            return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position)
        else:
            visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_SPHERE, radius=radius, rgbaColor=color)
            return self._p.createMultiBody(baseMass=mass, baseVisualShapeIndex=visual_shape_id, basePosition=position)

    def create_heightfield(self, size, height_max, position, resolution, repeats=2):
        heightfield_data = np.random.uniform(low=0., high=height_max, size=(int(size[0] * resolution / repeats), int(size[1] * resolution / repeats)))
        heightfield_data = np.repeat(np.repeat(heightfield_data, repeats, axis=0), repeats, axis=1)
        mesh_scale = [1/resolution, 1/resolution, 1.]
        heightfield_collision_shape_id = self._p.createCollisionShape(
            shapeType=self._p.GEOM_HEIGHTFIELD,
            meshScale=mesh_scale,
            heightfieldData=heightfield_data.reshape(-1),
            numHeightfieldRows=heightfield_data.shape[0],
            numHeightfieldColumns=heightfield_data.shape[1],
        )
        return self._p.createMultiBody(baseMass=0., baseCollisionShapeIndex=heightfield_collision_shape_id, basePosition=[position[0], position[1], position[2] + mesh_scale[2] * height_max / 2])

    def get_object_position(self, object_id):
        return np.asarray(self._p.getBasePositionAndOrientation(object_id)[0])

    def get_distance_to_object(self, object_id):
        object_position = self.get_object_position(object_id)
        robot_position = self.robot.links["base"].position
        return np.linalg.norm(object_position[:2] - robot_position[:2])

    def reset(self):
        observation = super().reset()

        # Reset boat position
        boat_y_init = np.random.uniform(low=-self.lava_size[1] / 2 + self.boat_size[1] / 2, high=self.lava_size[1] / 2 - self.boat_size[1] / 2)  # randomize y position
        self._p.resetBasePositionAndOrientation(self.boat_id, [self.boat_position_init[0], boat_y_init, self.boat_position_init[2]], [0., 0., 0., 1.])

        # Reset button position
        self._p.resetBasePositionAndOrientation(self.button_id, [self.button_position_init[0], boat_y_init, self.button_position_init[2]], [0., 0., 0., 1.])

        # Reset target zone
        target_zone_y = np.random.uniform(low=-self.lava_size[1] / 2 + self.target_zone_radius, high=self.lava_size[1] / 2 - self.target_zone_radius)  # randomize y position
        self.target_zone_position = [self.platform_end_position[0], target_zone_y, self.platform_end_position[2] + self.platform_size[2] / 2]
        self._p.resetBasePositionAndOrientation(self.target_zone_id, self.target_zone_position, [0., 0., 0., 1.])

        # Reset robot position
        self._p.resetBasePositionAndOrientation(self.robot.robot_id, [self.platform_start_position[0], self.platform_start_position[1], self.platform_start_position[2] + self.platform_size[2] / 2 + self.robot.links["base"].position_init[2]], self.robot.links["base"].orientation_init)

        return observation

    def step(self, action):
        # Before taking action
        self.distance_to_button = self.get_distance_to_object(self.button_id)
        self.distance_to_target_zone = self.get_distance_to_object(self.target_zone_id)
        self.has_touched_platform_end = len(self._p.getContactPoints(bodyA=self.robot.robot_id, bodyB=self.platform_end_id)) > 0

        observation, reward, terminated, truncated, info = super().step(action)

        # Check if button is pressed
        contact_points = self._p.getContactPoints(bodyA=self.robot.robot_id, bodyB=self.button_id)
        button_pressed = len(contact_points) > 0

        if button_pressed:
            # Move boat and everything on boat forward
            for body_id in [self.boat_id] + self.objects_on_boat:
                body_position = self.get_object_position(body_id)
                new_object_position = body_position + np.array([self.boat_speed * self.dt, 0., 0.])
                self._p.resetBasePositionAndOrientation(body_id, new_object_position, [0., 0., 0., 1.])

        return observation, reward, terminated, truncated, info

    def get_task_rewards(self, action):
        # After taking action
        new_distance_to_button = self.get_distance_to_object(self.button_id)
        new_distance_to_target_zone = self.get_distance_to_object(self.target_zone_id)

        # Standing
        contact_points = self._p.getContactPoints(bodyA=self.robot.robot_id, linkIndexA=self.robot.links["base"].index)
        standing = 1. if len(contact_points) == 0 else -1.

        # Reach button
        reach_button = (self.distance_to_button - new_distance_to_button) / self.dt

        # Reach target zone
        reach_target_zone = (self.distance_to_target_zone - new_distance_to_target_zone) / self.dt
        if self.distance_to_target_zone < self.target_zone_radius:
            reach_target_zone += 5.

        return {"standing": standing, "reach_button": reach_button, "reach_target_zone": reach_target_zone}

    def get_terminated(self, action):
        # Terminate if not standing
        contact_points = self._p.getContactPoints(bodyA=self.robot.robot_id, linkIndexA=self.robot.links["base"].index)
        is_standing = len(contact_points) == 0

        # Terminate if touch lava
        contact_points = self._p.getContactPoints(bodyA=self.robot.robot_id, bodyB=self.lava_id)
        is_touching_lava = len(contact_points) > 0

        # Terminate if fall off
        is_fall_off = self.robot.links["base"].position[2] < self.platform_start_position[2]
        return not is_standing or is_touching_lava or is_fall_off

    def get_success(self):
        # Success if stand in the target zone
        distance_to_target_zone = self.get_distance_to_object(self.target_zone_id)
        return distance_to_target_zone < self.target_zone_radius

</omni_epic/envs/ant/cross_lava.py>

<omni_epic/envs/ant/go_down_stairs.py>
import numpy as np
from omni_epic.envs.ant.base import AntEnv


class Env(AntEnv):
    """
    Descend a series of stairs to reach the ground.

    Description:
    - The environment consists of a ground platform (1000 m x 10 m x 10 m) and a set of 10 steps.
    - Each step has dimensions of 1 m in length, 10 m in width, and 0.2 m in height.
    - The steps are positioned to form a descending staircase starting from an initial height, with each subsequent step lower than the previous one.
    The robot is initialized at the top of the stairs.

    Success:
    The task is completed when the robot successfully descends the stairs and touches the ground platform.

    Rewards:
    The help the robot complete the task:
    - The robot is rewarded for standing at each time step.
    - The robot is rewarded for forward velocity, incentivizing it to move down the stairs.

    Termination:
    The task terminates immediately if the robot falls off the stairs or the ground platform.
    """

    def __init__(self):
        super().__init__()

        # Init ground
        self.ground_size = [1000., 10., 10.]
        self.ground_position = [0., 0., 0.]
        self.ground_id = self.create_box(mass=0., half_extents=[self.ground_size[0] / 2, self.ground_size[1] / 2, self.ground_size[2] / 2], position=self.ground_position, color=[0.5, 0.5, 0.5, 1.])
        self._p.changeDynamics(bodyUniqueId=self.ground_id, linkIndex=-1, lateralFriction=0.8, restitution=0.5)

        # Init stairs
        self.num_steps = 10
        self.step_size = [1.0, 10., 0.2]
        self.step_position_init = [self.ground_position[0], self.ground_position[1], self.ground_position[2] + self.ground_size[2] / 2 + self.num_steps * self.step_size[2]]
        self.create_stairs_down(step_size=self.step_size, step_position_init=self.step_position_init, num_steps=self.num_steps)

    def create_box(self, mass, half_extents, position, color):
        collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents)
        visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents, rgbaColor=color)
        return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position)

    def create_stairs_down(self, step_size, step_position_init, num_steps):
        color_1 = np.array([1., 0., 0.])
        color_2 = np.array([0., 0., 1.])
        for i in range(num_steps):
            step_position = [step_position_init[0] + i * step_size[0], step_position_init[1], step_position_init[2] - i * step_size[2]]
            interpolation = i / (num_steps - 1)
            step_color = (1 - interpolation) * color_1 + interpolation * color_2  # shade steps for visualization
            self.create_box(mass=0., half_extents=[step_size[0] / 2, step_size[1] / 2, step_size[2] / 2], position=step_position, color=np.append(step_color, 1.))

    def reset(self):
        observation = super().reset()

        # Reset robot position at the top of the stairs
        self._p.resetBasePositionAndOrientation(self.robot.robot_id, [self.step_position_init[0], self.step_position_init[1], self.step_position_init[2] + self.step_size[2] / 2 + self.robot.links["base"].position_init[2]], self.robot.links["base"].orientation_init)

        return observation

    def step(self, action):
        # Before taking action
        self.position = self.robot.links["base"].position

        observation, reward, terminated, truncated, info = super().step(action)

        return observation, reward, terminated, truncated, info

    def get_task_rewards(self, action):
        # After taking action
        new_position = self.robot.links["base"].position

        # Standing
        contact_points = self._p.getContactPoints(bodyA=self.robot.robot_id, linkIndexA=self.robot.links["base"].index)
        standing = 1. if len(contact_points) == 0 else -1.

        # Forward velocity
        forward_velocity = (new_position[0] - self.position[0]) / self.dt

        return {"standing": standing, "forward_velocity": forward_velocity}

    def get_terminated(self, action):
        # Terminate if not standing
        contact_points = self._p.getContactPoints(bodyA=self.robot.robot_id, linkIndexA=self.robot.links["base"].index)
        is_standing = len(contact_points) == 0

        # Terminate if fall off
        is_fall_off = self.robot.links["base"].position[2] < self.ground_position[2]
        return not is_standing or is_fall_off

    def get_success(self):
        # Success if reach end stairs and touch ground
        contact_points = self._p.getContactPoints(bodyA=self.robot.robot_id, bodyB=self.ground_id)
        is_on_ground = len(contact_points) > 0
        return is_on_ground

</omni_epic/envs/ant/go_down_stairs.py>

<omni_epic/envs/ant/go_forward.py>
import numpy as np
from omni_epic.envs.ant.base import AntEnv


class Env(AntEnv):
    """
    Go forward.

    Description:
    The robot is standing on a flat ground represented by a box.
    The task of the robot is to go forward as fast as possible.

    Success:
    The task is completed if the robot runs forward for 10 meters.

    Rewards:
    The help the robot complete the task:
    - The robot is rewarded for standing at each time step.
    - The robot is rewarded for forward velocity, incentivizing it to move forward quickly.

    Termination:
    The task terminates if the robot falls.
    """

    def __init__(self):
        super().__init__()

        # Init ground
        self.ground_size = [1000., 1000., 10.]
        self.ground_position = [0., 0., 0.]
        self.ground_id = self.create_box(mass=0., half_extents=[self.ground_size[0] / 2, self.ground_size[1] / 2, self.ground_size[2] / 2], position=self.ground_position, color=[0.5, 0.5, 0.5, 1.])
        self._p.changeDynamics(bodyUniqueId=self.ground_id, linkIndex=-1, lateralFriction=0.8, restitution=0.5)

    def create_box(self, mass, half_extents, position, color):
        collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents)
        visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents, rgbaColor=color)
        return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position)

    def reset(self):
        observation = super().reset()

        # Reset robot position
        self._p.resetBasePositionAndOrientation(self.robot.robot_id, [self.ground_position[0], self.ground_position[1], self.ground_position[2] + self.ground_size[2] / 2 + self.robot.links["base"].position_init[2]], self.robot.links["base"].orientation_init)

        return observation

    def step(self, action):
        # Before taking action
        self.position = self.robot.links["base"].position

        observation, reward, terminated, truncated, info = super().step(action)

        return observation, reward, terminated, truncated, info

    def get_task_rewards(self, action):
        # After taking action
        new_position = self.robot.links["base"].position

        # Standing
        contact_points = self._p.getContactPoints(bodyA=self.robot.robot_id, linkIndexA=self.robot.links["base"].index)
        standing = 1. if len(contact_points) == 0 else -1.

        # Forward velocity
        forward_velocity = (new_position[0] - self.position[0]) / self.dt

        return {"standing": standing, "forward_velocity": forward_velocity}

    def get_terminated(self, action):
        # Terminate if not standing
        contact_points = self._p.getContactPoints(bodyA=self.robot.robot_id, linkIndexA=self.robot.links["base"].index)
        is_standing = len(contact_points) == 0
        return not is_standing

    def get_success(self):
        # Success if run forward for 10 meters
        return self.robot.links["base"].position[0] > 10.

</omni_epic/envs/ant/go_forward.py>

<omni_epic/envs/ant/go_to_box.py>
import numpy as np
from omni_epic.envs.ant.base import AntEnv


class Env(AntEnv):
    """
    Reach a box.

    Description:
    - The environment consists of a large flat ground measuring 1000 x 1000 x 10 meters.
    - A box with dimensions 1 x 1 x 1 meter is placed randomly on the ground in a radius of 25 m around the robot. To avoid collisions, the box cannot spawn in a radius of 2 m around the robot.
    - The robot is initialized at a fixed position on the ground.
    The task of the robot is to reach and touch the box.

    Success:
    The task is completed if the robot makes contact with the box.

    Rewards:
    The help the robot complete the task:
    - The robot is rewarded for standing at each time step.
    - The robot is rewarded for moving closer to the box.

    Termination:
    The task terminates if the robot falls.
    """

    def __init__(self):
        super().__init__()

        # Init ground
        self.ground_size = [1000., 1000., 10.]
        self.ground_position = [0., 0., 0.]
        self.ground_id = self.create_box(mass=0., half_extents=[self.ground_size[0] / 2, self.ground_size[1] / 2, self.ground_size[2] / 2], position=self.ground_position, color=[0.5, 0.5, 0.5, 1.])
        self._p.changeDynamics(bodyUniqueId=self.ground_id, linkIndex=-1, lateralFriction=0.8, restitution=0.5)

        # Init box
        self.box_size = [1., 1., 1.]
        self.box_id = self.create_box(mass=1., half_extents=[self.box_size[0] / 2, self.box_size[1] / 2, self.box_size[2] / 2], position=[0., 0., 0.], color=[1., 0., 0., 1.])

        # Starting position of the robot
        self.robot_position_init = [self.ground_position[0], self.ground_position[1], self.ground_position[2] + self.ground_size[2] / 2 + self.robot.links["base"].position_init[2]]

    def create_box(self, mass, half_extents, position, color):
        collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents)
        visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents, rgbaColor=color)
        return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position)

    def get_object_position(self, object_id):
        return np.asarray(self._p.getBasePositionAndOrientation(object_id)[0])

    def get_distance_to_object(self, object_id):
        object_position = self.get_object_position(object_id)
        robot_position = self.robot.links["base"].position
        return np.linalg.norm(object_position[:2] - robot_position[:2])

    def reset(self):
        observation = super().reset()

        # Reset robot position on ground
        self._p.resetBasePositionAndOrientation(self.robot.robot_id, self.robot_position_init, self.robot.links["base"].orientation_init)

        # Reset box position
        angle = np.random.uniform(0., 2 * np.pi)
        radius = np.random.uniform(2., 25.)
        self._p.resetBasePositionAndOrientation(self.box_id, [self.robot_position_init[0] + radius * np.cos(angle), self.robot_position_init[1] + radius * np.sin(angle), self.ground_position[2] + self.ground_size[2] / 2 + self.box_size[2] / 2], [0., 0., 0., 1.])

        return observation

    def step(self, action):
        # Before taking action
        self.distance_to_box = self.get_distance_to_object(self.box_id)

        observation, reward, terminated, truncated, info = super().step(action)

        return observation, reward, terminated, truncated, info

    def get_task_rewards(self, action):
        # After taking action
        new_distance_to_box = self.get_distance_to_object(self.box_id)

        # Standing
        contact_points = self._p.getContactPoints(bodyA=self.robot.robot_id, linkIndexA=self.robot.links["base"].index)
        objects_in_contact = {contact_point[2] for contact_point in contact_points}
        standing = 1. if self.ground_id not in objects_in_contact else -1.

        # Reach box
        reach_box = (self.distance_to_box - new_distance_to_box) / self.dt

        return {"standing": standing, "reach_box": reach_box}

    def get_terminated(self, action):
        # Terminate if not standing
        contact_points = self._p.getContactPoints(bodyA=self.robot.robot_id, linkIndexA=self.robot.links["base"].index)
        objects_in_contact = {contact_point[2] for contact_point in contact_points}
        is_standing = self.ground_id not in objects_in_contact  # allow body to touch box
        return not is_standing

    def get_success(self):
        # Success if touch box
        contact_points_box = self._p.getContactPoints(bodyA=self.robot.robot_id, bodyB=self.box_id)
        is_touching_box = len(contact_points_box) > 0
        return is_touching_box

</omni_epic/envs/ant/go_to_box.py>

<omni_epic/envs/ant/kick_ball.py>
import numpy as np
from omni_epic.envs.ant.base import AntEnv


class Env(AntEnv):
    """
    Kick a ball.

    Description:
    - The environment consists of a large flat ground measuring 1000 x 1000 x 10 meters.
    - A ball with a radius of 0.5 meters is placed randomly on the ground.
    - The robot is initialized at a fixed position on the ground.
    - The task of the robot is to move across the ground, reach the ball, and kick it as far away as possible.

    Success:
    The task is successfully completed if the robot kicks the ball so that it moves more than 10 meters away from its initial position.

    Rewards:
    To help the robot complete the task:
    - The robot is rewarded for standing.
    - The robot is rewarded for decreasing its distance to the ball.
    - The robot is rewarded for increasing the velocity of the ball to guide the robot to kick the ball.

    Termination:
    The task terminates if the robot falls.
    """

    def __init__(self):
        super().__init__()

        # Init ground
        self.ground_size = [1000., 1000., 10.]
        self.ground_position = [0., 0., 0.]
        self.ground_id = self.create_box(mass=0., half_extents=[self.ground_size[0] / 2, self.ground_size[1] / 2, self.ground_size[2] / 2], position=self.ground_position, color=[0.5, 0.5, 0.5, 1.])
        self._p.changeDynamics(bodyUniqueId=self.ground_id, linkIndex=-1, lateralFriction=0.8, restitution=0.5)

        # Init ball
        self.ball_radius = 0.5
        self.ball_id = self.create_sphere(mass=1., radius=self.ball_radius, position=[0., 0., 0.], color=[1., 0., 0., 1.])

        # Starting position of the robot
        self.robot_position_init = [self.ground_position[0], self.ground_position[1], self.ground_position[2] + self.ground_size[2] / 2 + self.robot.links["base"].position_init[2]]

    def create_box(self, mass, half_extents, position, color):
        collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents)
        visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents, rgbaColor=color)
        return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position)

    def create_sphere(self, mass, radius, position, color):
        collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_SPHERE, radius=radius)
        visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_SPHERE, radius=radius, rgbaColor=color)
        return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position)

    def get_object_position(self, object_id):
        return np.asarray(self._p.getBasePositionAndOrientation(object_id)[0])

    def get_distance_to_object(self, object_id):
        object_position = self.get_object_position(object_id)
        robot_position = self.robot.links["base"].position
        return np.linalg.norm(object_position[:2] - robot_position[:2])

    def reset(self):
        observation = super().reset()

        # Reset robot position on ground
        self._p.resetBasePositionAndOrientation(self.robot.robot_id, self.robot_position_init, self.robot.links["base"].orientation_init)

        # Reset ball position
        ball_y_init = np.random.uniform(self.robot_position_init[1] - 2., self.robot_position_init[1] + 2.)
        self._p.resetBasePositionAndOrientation(self.ball_id, [self.robot_position_init[0] + 5., ball_y_init, self.ground_position[2] + self.ground_size[2] / 2 + self.ball_radius], [0., 0., 0., 1.])

        return observation

    def step(self, action):
        # Before taking action
        self.distance_to_ball = self.get_distance_to_object(self.ball_id)
        self.ball_position = self.get_object_position(self.ball_id)

        observation, reward, terminated, truncated, info = super().step(action)

        return observation, reward, terminated, truncated, info

    def get_task_rewards(self, action):
        # After taking action
        new_distance_to_ball = self.get_distance_to_object(self.ball_id)
        new_ball_position = self.get_object_position(self.ball_id) 

        # Standing
        contact_points = self._p.getContactPoints(bodyA=self.robot.robot_id, linkIndexA=self.robot.links["base"].index)
        objects_in_contact = {contact_point[2] for contact_point in contact_points}
        standing = 1. if self.ground_id not in objects_in_contact else -1.

        # Reach ball
        reach_ball = (self.distance_to_ball - new_distance_to_ball) / self.dt

        # Velocity of ball
        ball_velocity = np.linalg.norm(new_ball_position - self.ball_position) / self.dt

        return {"standing": standing, "reach_ball": reach_ball, "ball_velocity": ball_velocity}

    def get_terminated(self, action):
        # Terminate if not standing
        contact_points = self._p.getContactPoints(bodyA=self.robot.robot_id, linkIndexA=self.robot.links["base"].index)
        objects_in_contact = {contact_point[2] for contact_point in contact_points}
        is_standing = self.ground_id not in objects_in_contact  # allow body to touch ball
        return not is_standing

    def get_success(self):
        # Success if kick ball 10 meters away from origin
        ball_distance_to_origin = np.linalg.norm(self.get_object_position(self.ball_id))
        return ball_distance_to_origin > 10.

</omni_epic/envs/ant/kick_ball.py>

<omni_epic/envs/ant/maze.py>
import numpy as np
from omni_epic.envs.ant.base import AntEnv


class Env(AntEnv):
    """
    Navigate through a maze to reach the end position.

    Description:
    - The environment consists of a large flat ground measuring 1000 x 1000 x 10 m.
    - A maze is constructed on the ground using walls of height 1 meter and scale 3 m per cell.
    - The maze is represented by a 2D array where 0 indicates an empty space, 1 indicates a wall, 2 indicates the start position, and 3 indicates the end position.
    - The robot is initialized at the start position in the maze.
    - The task of the robot is to navigate through the maze and reach the end position.

    Success:
    The task is completed if the robot reaches the end position in the maze.

    Rewards:
    To guide the robot to complete the task:
    - The robot receives a reward at each time step for survival.
    - The robot is rewarded for making progress towards the end position in the maze.

    Termination:
    The task terminates if the robot falls.
    """

    def __init__(self):
        super().__init__()

        # Init ground
        self.ground_size = [1000., 1000., 10.]
        self.ground_position = [0., 0., 0.]
        self.ground_id = self.create_box(mass=0., half_extents=[self.ground_size[0] / 2, self.ground_size[1] / 2, self.ground_size[2] / 2], position=self.ground_position, color=[0.5, 0.5, 0.5, 1.])
        self._p.changeDynamics(bodyUniqueId=self.ground_id, linkIndex=-1, lateralFriction=0.8, restitution=0.5)

        # Init maze - 0 is empty, 1 is wall, 2 is start, 3 is end
        self.maze_height = 1.
        self.maze_scale = 3.
        maze = np.array([
            [1, 1, 1, 3, 1, 1],
            [1, 0, 0, 0, 0, 1],
            [1, 0, 1, 1, 0, 1],
            [2, 0, 0, 0, 0, 1],
            [1, 1, 1, 1, 1, 1],
        ])
        for index, value in np.ndenumerate(maze):
                if value == 1:
                    self.create_box(0., half_extents=[self.maze_scale / 2, self.maze_scale / 2, self.maze_height / 2], position=[self.maze_scale * index[1], -self.maze_scale * index[0], self.ground_position[2] + self.ground_size[2] / 2 + self.maze_height / 2], color=[0.2, 0.2, 0.2, 1])

        # Get start and end position
        start_position_index = np.squeeze(np.argwhere(maze == 2))
        self.start_position = self.maze_scale * np.array([start_position_index[1], -start_position_index[0]])
        end_position_index = np.squeeze(np.argwhere(maze == 3))
        self.end_position = self.maze_scale * np.array([end_position_index[1], -end_position_index[0]])

    def create_box(self, mass, half_extents, position, color):
        collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents)
        visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents, rgbaColor=color)
        return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position)

    def reset(self):
        observation = super().reset()

        # Reset robot position at start position
        self._p.resetBasePositionAndOrientation(self.robot.robot_id, [self.start_position[0], self.start_position[1], self.ground_position[2] + self.ground_size[2] / 2 + self.robot.links["base"].position_init[2]], self.robot.links["base"].orientation_init)

        return observation

    def step(self, action):
        # Before taking action
        self.position = self.robot.links["base"].position
        self.distance_to_end = np.linalg.norm(self.position[:2] - self.end_position)

        observation, reward, terminated, truncated, info = super().step(action)

        return observation, reward, terminated, truncated, info

    def get_task_rewards(self, action):
        # After taking action
        new_position = self.robot.links["base"].position
        new_distance_to_end = np.linalg.norm(new_position[:2] - self.end_position)

        # Standing
        contact_points = self._p.getContactPoints(bodyA=self.robot.robot_id, linkIndexA=self.robot.links["base"].index)
        objects_in_contact = {contact_point[2] for contact_point in contact_points}
        standing = 1. if self.ground_id not in objects_in_contact else -1.

        # Progress in the maze
        maze_progress = (self.distance_to_end - new_distance_to_end) / self.dt

        return {"standing": standing, "maze_progress": maze_progress}

    def get_terminated(self, action):
        # Terminate if not standing
        contact_points = self._p.getContactPoints(bodyA=self.robot.robot_id, linkIndexA=self.robot.links["base"].index)
        objects_in_contact = {contact_point[2] for contact_point in contact_points}
        is_standing = self.ground_id not in objects_in_contact  # allow body to touch walls
        return not is_standing

    def get_success(self):
        # Success if reach end of maze
        return np.linalg.norm(self.robot.links["base"].position[:2] - self.end_position) < self.maze_scale

</omni_epic/envs/ant/maze.py>

<omni_epic/envs/ant/open_door.py>
import numpy as np
from omni_epic.envs.ant.base import AntEnv


class Env(AntEnv):
    """
    Activate a lever to open a door and move through the door.

    Description:
    - The environment consists of a large platform measuring 1000 x 10 x 0.1 meters.
    - The robot is initialized at a fixed position on the platform.
    - A door with dimensions 0.5 x 2 x 2 meters is placed on the platform, 5 m away from the robot, initially closed.
    - The door is flanked by walls to prevent the robot from bypassing it.
    - A lever is placed on the platform, 2 meters to the left of the door.
    - The task of the robot is to move to the lever, activate it to open the door, and then pass through the door.

    Success:
    The task is successfully completed if the robot passes through the door and moves more than 10 m beyond the initial position.

    Rewards:
    To guide the robot to complete the task:
    - The robot receives a survival reward at each time step.
    - The robot is rewarded for decreasing its distance to the lever.
    - The robot receives a bonus rewards for activating the lever to open the door.
    - Once the door is open, the robot is rewarded for moving forward.

    Termination:
    The task terminates immediately if the robot falls off the stairs or the ground platform.
    """

    def __init__(self):
        super().__init__()

        self.robot_position_init = [0., 0., 0.]

        # Init platform
        self.platform_size = [1000., 10., 0.1]
        self.platform_position = [self.robot_position_init[0] + self.platform_size[0] / 2 - 2., self.robot_position_init[1], self.robot_position_init[2] - self.platform_size[2] / 2]  # offset by 2 m to avoid off-edge or on-edge placement
        self.platform_id = self.create_box(mass=0., half_extents=[self.platform_size[0] / 2, self.platform_size[1] / 2, self.platform_size[2] / 2], position=self.platform_position, color=[0.5, 0.5, 0.5, 1.])
        self._p.changeDynamics(bodyUniqueId=self.platform_id, linkIndex=-1, lateralFriction=0.8, restitution=0.5)

        # Init door
        self.door_size = [0.5, 2., 2.]
        self.door_position_init = [self.robot_position_init[0] + 5., self.platform_position[1], self.platform_position[2] + self.platform_size[2] / 2 + self.door_size[2] / 2]
        self.door_id = self.create_box(mass=0., half_extents=[self.door_size[0] / 2, self.door_size[1] / 2, self.door_size[2] / 2], position=self.door_position_init, color=[1., 0., 0., 1.])
        self.door_open = False

        # Init wall
        self.wall_size = [self.door_size[0], (self.platform_size[1] - self.door_size[1]) / 2, self.door_size[2]]  # walls plus door span the full platform to prevent robot to go around
        self.create_box(mass=0., half_extents=[self.wall_size[0] / 2, self.wall_size[1] / 2, self.wall_size[2] / 2], position=[self.door_position_init[0], self.door_position_init[1] + self.door_size[1] / 2 + self.wall_size[1] / 2, self.platform_position[2] + self.platform_size[2] / 2 + self.wall_size[2] / 2], color=[0., 0., 1., 1.])  # left section
        self.create_box(mass=0., half_extents=[self.wall_size[0] / 2, self.wall_size[1] / 2, self.wall_size[2] / 2], position=[self.door_position_init[0], self.door_position_init[1] - self.door_size[1] / 2 - self.wall_size[1] / 2, self.platform_position[2] + self.platform_size[2] / 2 + self.wall_size[2] / 2], color=[0., 0., 1., 1.])  # right section

        # Init lever
        self.lever_radius = 0.05
        self.lever_height = 0.5
        lever_position = [self.door_position_init[0] - 2., self.door_size[1], self.platform_position[2] + self.platform_size[2] / 2 + self.lever_height / 2]  # two meters to the left of the door on the platform
        self.lever_id = self.create_cylinder(mass=0., radius=self.lever_radius, height=self.lever_height, position=lever_position, color=[0.5, 0.25, 0., 1.])

    def create_box(self, mass, half_extents, position, color):
        collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents)
        visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents, rgbaColor=color)
        return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position)

    def create_cylinder(self, mass, radius, height, position, color):
        collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_CYLINDER, radius=radius, height=height)
        visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_CYLINDER, radius=radius, length=height, rgbaColor=color)
        return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position)

    def get_object_position(self, object_id):
        return np.asarray(self._p.getBasePositionAndOrientation(object_id)[0])

    def get_distance_to_object(self, object_id):
        object_position = self.get_object_position(object_id)
        robot_position = self.robot.links["base"].position
        return np.linalg.norm(object_position[:2] - robot_position[:2])

    def reset(self):
        observation = super().reset()

        # Reset door
        self.door_open = False
        self._p.resetBasePositionAndOrientation(self.door_id, self.door_position_init, [0., 0., 0., 1.])

        # Reset robot position
        self._p.resetBasePositionAndOrientation(self.robot.robot_id, [self.robot_position_init[0], self.robot_position_init[1], self.robot_position_init[2] + self.robot.links["base"].position_init[2]], self.robot.links["base"].orientation_init)

        return observation

    def step(self, action):
        # Before taking action
        self.position = self.robot.links["base"].position
        self.distance_to_lever = self.get_distance_to_object(self.lever_id)

        observation, reward, terminated, truncated, info = super().step(action)

        contact_points = self._p.getContactPoints(bodyA=self.robot.robot_id, bodyB=self.lever_id)
        if len(contact_points) > 0 and not self.door_open:
            self.door_open = True
            self._p.resetBasePositionAndOrientation(self.door_id, [self.door_position_init[0], self.door_position_init[1] + self.door_size[1], self.door_position_init[2]], [0., 0., 0., 1.])

        return observation, reward, terminated, truncated, info

    def get_task_rewards(self, action):
        # After taking action
        new_position = self.robot.links["base"].position
        new_distance_to_lever = self.get_distance_to_object(self.lever_id)

        # Standing
        contact_points = self._p.getContactPoints(bodyA=self.robot.robot_id, linkIndexA=self.robot.links["base"].index)
        standing = 1. if len(contact_points) == 0 else -1.

        # Reach lever
        if not self.door_open and len(self._p.getContactPoints(bodyA=self.robot.robot_id, bodyB=self.lever_id)) == 0:
            reach_lever = (self.distance_to_lever - new_distance_to_lever) / self.dt
        elif not self.door_open and len(self._p.getContactPoints(bodyA=self.robot.robot_id, bodyB=self.lever_id)) > 0:
            reach_lever = 10.
        else:
            reach_lever = 0.

        # Forward velocity
        if self.door_open:
            forward_velocity = (new_position[0] - self.position[0]) / self.dt
        else:
            forward_velocity = 0.

        return {"standing": standing, "reach_lever": reach_lever, "forward_velocity": forward_velocity}

    def get_terminated(self, action):
        # Terminate if not standing
        contact_points = self._p.getContactPoints(bodyA=self.robot.robot_id, linkIndexA=self.robot.links["base"].index)
        is_standing = len(contact_points) == 0

        # Terminate if fall off
        is_fall_off = self.robot.links["base"].position[2] < self.platform_position[2]
        return not is_standing or is_fall_off

    def get_success(self):
        # Success if pass through door
        return self.robot.links["base"].position[0] > 10.

</omni_epic/envs/ant/open_door.py>

<omni_epic/envs/ant/walk_on_cylinder.py>
import numpy as np
from omni_epic.envs.ant.base import AntEnv


class Env(AntEnv):
    """
    Go forward on top of a rolling cylinder.

    Description:
    - The environment consists of a large flat ground measuring 1000 x 1000 x 10 m.
    - A cylinder with a radius of 2 m and a height of 3 m is placed on the ground and can roll along the x-axis.
    - The cylinder's initial position is at the center of the ground, and it is oriented to roll along the x-axis.
    - The robot is initialized on top of the cylinder.
    - The task of the robot is to go forward while balancing on top of the rolling cylinder.

    Success:
    The task is completed if the robot rolls more than 5 m forward without falling off.

    Rewards:
    To guide the robot to complete the task:
    - The robot receives a reward for each time step it remains balanced on the cylinder.
    - The robot receives a reward for forward velocity along the x-axis.

    Termination:
    The task terminates immediately if the is not standing on the cylinder or if the robot falls off the cylinder.
    """

    def __init__(self):
        super().__init__()

        # Init ground
        self.ground_size = [1000., 1000., 10.]
        self.ground_position = [0., 0., 0.]
        self.ground_id = self.create_box(mass=0., half_extents=[self.ground_size[0] / 2, self.ground_size[1] / 2, self.ground_size[2] / 2], position=self.ground_position, color=[0.5, 0.5, 0.5, 1.])
        self._p.changeDynamics(bodyUniqueId=self.ground_id, linkIndex=-1, lateralFriction=0.8, restitution=0.5)

        # Init cylinder
        self.cylinder_radius = 2.
        self.cylinder_height = 3.
        self.cylinder_position_init = [self.ground_position[0], self.ground_position[1], self.ground_position[2] + self.ground_size[2] / 2 + self.cylinder_radius]
        self.cylinder_orientation_init = self._p.getQuaternionFromEuler(eulerAngles=[np.pi / 2, 0., 0.])  # roll along x-axis
        self.cylinder_id = self.create_cylinder(mass=25., radius=self.cylinder_radius, height=self.cylinder_height, position=self.cylinder_position_init, orientation=self.cylinder_orientation_init, color=[0., 0., 1., 1.]) 
        self._p.changeDynamics(bodyUniqueId=self.cylinder_id, linkIndex=-1, lateralFriction=0.8, restitution=0.5)

    def create_box(self, mass, half_extents, position, color):
        collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents)
        visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents, rgbaColor=color)
        return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position)

    def create_cylinder(self, mass, radius, height, position, orientation, color):
        collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_CYLINDER, radius=radius, height=height)
        visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_CYLINDER, radius=radius, length=height, rgbaColor=color)
        return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position, baseOrientation=orientation)

    def reset(self):
        observation = super().reset()

        # Reset cylinder position
        self._p.resetBasePositionAndOrientation(self.cylinder_id, self.cylinder_position_init, self.cylinder_orientation_init)

        # Reset robot position on the top of cylinder
        self._p.resetBasePositionAndOrientation(self.robot.robot_id, [self.cylinder_position_init[0], self.cylinder_position_init[1], self.cylinder_position_init[2] + self.cylinder_radius + self.robot.links["base"].position_init[2]], self.robot.links["base"].orientation_init)

        return observation

    def step(self, action):
        # Before taking action
        self.position = self.robot.links["base"].position

        observation, reward, terminated, truncated, info = super().step(action)

        return observation, reward, terminated, truncated, info

    def get_task_rewards(self, action):
        # After taking action
        new_position = self.robot.links["base"].position

        # Standing
        contact_points = self._p.getContactPoints(bodyA=self.robot.robot_id, linkIndexA=self.robot.links["base"].index)
        objects_in_contact = {contact_point[2] for contact_point in contact_points}
        standing = 1. if self.cylinder_id not in objects_in_contact else -1.

        # Forward velocity
        forward_velocity = (new_position[0] - self.position[0]) / self.dt

        return {"standing": standing, "forward_velocity": forward_velocity}

    def get_terminated(self, action):
        # Terminate if not standing
        contact_points = self._p.getContactPoints(bodyA=self.robot.robot_id, linkIndexA=self.robot.links["base"].index, bodyB=self.cylinder_id)
        is_standing = len(contact_points) == 0

        # Terminate if not on cylinder
        is_on_cylinder = self.robot.links["base"].position[2] > self.cylinder_position_init[2] + self.cylinder_radius
        return not is_standing or not is_on_cylinder

    def get_success(self):
        # Success if rolled on cylinder
        return self.robot.links["base"].position[0] > 5.

</omni_epic/envs/ant/walk_on_cylinder.py>

<omni_epic/envs/base.py>
import importlib

import numpy as np
from scipy.spatial.transform import Rotation
import gym
import pybullet
from pybullet_utils import bullet_client
import pybullet_data

from omni_epic.robots.base import Robot, angle_between_vectors_2d


class Env(gym.Env):
	dt: float
	robot: Robot

	def __init__(self):
		self._p = bullet_client.BulletClient(connection_mode=pybullet.DIRECT)

		# Load EGL renderer plugin
		self._p.setAdditionalSearchPath(pybullet_data.getDataPath())
		egl = importlib.util.find_spec("eglRenderer")
		self._p.loadPlugin(egl.origin, "_eglRendererPlugin")

		# Init world
		self._init()

	def _init(self):
		# Set additional search path
		self._p.setAdditionalSearchPath("/workspace/src/omni_epic/envs/assets")

		# Reset simulation
		self._p.resetSimulation()

		# Set simulation parameters
		self._p.setGravity(0, 0, -9.8)
		self._p.setDefaultContactERP(0.9)
		self._p.setPhysicsEngineParameter(
			fixedTimeStep=self.dt,
			numSolverIterations=5,
			numSubSteps=4,
			deterministicOverlappingPairs=1,
		)

	def reset(self, seed=None, options=None):
		# Reset simulation
		super().reset(seed=seed)
		self.robot.reset(seed=seed)

		# Get observation
		return self.robot.get_observation()

	def step(self, action):
		# Step simulation
		self.robot.apply_action(action)
		self._p.stepSimulation()
		self.robot.update()

		# Get observation, reward, terminated and truncated
		observation = self.robot.get_observation()
		reward = self.get_reward(action)
		terminated = self.get_terminated(action)
		truncated = self.get_truncated(action)

		return observation, reward, terminated, truncated, {}

	def get_reward(self, action):
		task_rewards = self.get_task_rewards(action)
		robot_rewards = self.robot.get_rewards(action)
		return sum(task_rewards.values()) + sum(robot_rewards.values())

	def get_task_rewards(self, action):
		raise NotImplementedError

	def get_terminated(self, action):
		raise NotImplementedError

	def get_truncated(self, action):
		raise NotImplementedError

	def get_success(self):
		raise NotImplementedError

	def get_render_config(self):
		"""Get render config."""
		# Get AABB of robot
		aabb_min, aabb_max = self._p.getAABB(self.robot.robot_id)
		aabb_max = np.array(aabb_max)
		aabb_min = np.array(aabb_min)

		# Iterate over the rest of the bodies
		for body_id in range(self._p.getNumBodies()):
			# Skip robot id
			if body_id == self.robot.robot_id:
				continue
			try:
				# Get AABB of object
				obj_aabb_min, obj_aabb_max = self._p.getAABB(body_id)
				obj_aabb_max = np.array(obj_aabb_max)
				obj_aabb_min = np.array(obj_aabb_min)
				# If object is greater than a certain size, skip
				if np.linalg.norm(obj_aabb_max - obj_aabb_min) > 30.0:
					continue
				# Update AABB
				aabb_min = np.minimum(aabb_min, obj_aabb_min)
				aabb_max = np.maximum(aabb_max, obj_aabb_max)
			except:
				continue

		# Calculate render configs
		camera_target_position = (aabb_min + aabb_max) / 2
		distance = max([abs(x - y) for x, y in zip(camera_target_position, aabb_max)])
		return {
			"fov": 90,
			"camera_target_position": camera_target_position,
			"distance": distance + 0.5,
		}

	def render(self, height=720, width=1280, fov=60., camera_target_position=None, distance=10., yaw=0.):
		if camera_target_position is None:
			camera_target_position = self.robot.links["base"].position
		view_matrix = self._p.computeViewMatrixFromYawPitchRoll(
			cameraTargetPosition=camera_target_position,
			distance=distance,
			yaw=yaw,
			pitch=-30.,
			roll=0.,
			upAxisIndex=2,
		)
		proj_matrix = self._p.computeProjectionMatrixFOV(
			fov=fov,
			aspect=width / height,
			nearVal=0.01,
			farVal=100.0,
		)
		(_, _, rgba, _, _) = self._p.getCameraImage(
			width=width,
			height=height,
			viewMatrix=view_matrix,
			projectionMatrix=proj_matrix,
			renderer=pybullet.ER_BULLET_HARDWARE_OPENGL,
			flags=pybullet.ER_NO_SEGMENTATION_MASK,
		)
		return rgba[..., :3]

	def render3p(self, height=720, width=1280, fov=60., distance=5.):
		base_rotation_init = Rotation.from_quat(self.robot.links["base"].orientation_init)
		base_rotation = Rotation.from_quat(self.robot.links["base"].orientation)
		base_rotation_relative = base_rotation * base_rotation_init.inv()
		forward_vector = base_rotation_relative.apply(np.array([1., 0., 0.]))
		angle = angle_between_vectors_2d(forward_vector[:2], np.array([1., 0.]))
		view_matrix = self._p.computeViewMatrixFromYawPitchRoll(
			cameraTargetPosition=self.robot.links["base"].position + np.array([0., 0., 1.]),
			distance=distance,
			yaw=-np.degrees(angle) - 90.,
			pitch=-20.,
			roll=0.,
			upAxisIndex=2,
		)
		proj_matrix = self._p.computeProjectionMatrixFOV(
			fov=fov,
			aspect=width / height,
			nearVal=0.01,
			farVal=100.0,
		)
		(_, _, rgba, _, _) = self._p.getCameraImage(
			width=width,
			height=height,
			viewMatrix=view_matrix,
			projectionMatrix=proj_matrix,
			renderer=pybullet.ER_BULLET_HARDWARE_OPENGL,
			flags=pybullet.ER_NO_SEGMENTATION_MASK,
		)
		return rgba[..., :3]

	def close(self):
		self._p.disconnect()

	def is_robot_colliding(self):
		contact_points = self._p.getContactPoints(self.robot.robot_id)
		return len(contact_points) > 0

	def is_robot_falling(self):
		linear_velocity, _ = self._p.getBaseVelocity(self.robot.robot_id)
		return linear_velocity[2] < -5.

	def is_object_colliding(self):
		for body_id in range(self._p.getNumBodies()):
			# Skip robot id
			if body_id == self.robot.robot_id:
				continue
			# Check if object is exploding
			linear_velocity, _ = self._p.getBaseVelocity(body_id)
			if np.linalg.norm(linear_velocity) > 20.:
				return True
		return False

	def visualize(self):
		self.reset()
		render_config = self.get_render_config()
		renders = []
		renders3p = []
		renders.append(self.render(**render_config))
		renders3p.append(self.render3p())
		for _ in range(200):
			self.step(self.action_space.sample())
			renders.append(self.render(**render_config))
			renders3p.append(self.render3p())
		return renders, renders3p

</omni_epic/envs/base.py>

<omni_epic/envs/humanoid/balance_board.py>
import numpy as np
from omni_epic.envs.humanoid.base import HumanoidEnv


class Env(HumanoidEnv):
    """
    Balance on a board placed on top of a rolling cylinder.

    Description:
    - A cylinder (radius 0.25 m and height 1 m) is placed on the ground and can roll along the y-axis.
    - A board (length 1 m, width 0.25 m and thickness 0.05 m) is placed on top of the cylinder.
    The robot is initialized on top of the board facing toward the positive x-axis.
    The task of the robot is to stand on the board and keep its balance on the board while the cylinder moves underneath.

    Success:
    The task is completed if the robot remains standing on the board for more than 10 s.

    Rewards:
    The robot is rewarded for remaining on the board.

    Termination:
    The task terminates if the robot falls of the board.
    """

    def __init__(self):
        super().__init__()

        # Init ground
        self.ground_size = [10., 10., 10.]
        self.ground_position = [0., 0., 0.]
        self.ground_id = self.create_box(mass=0., half_extents=[self.ground_size[0] / 2, self.ground_size[1] / 2, self.ground_size[2] / 2], position=self.ground_position, color=[0.5, 0.5, 0.5, 1.])
        self._p.changeDynamics(bodyUniqueId=self.ground_id, linkIndex=-1, lateralFriction=0.8, restitution=0.5)

        # Init cylinder
        self.cylinder_radius = 0.25
        self.cylinder_height = 1.
        self.cylinder_position_init = [self.ground_position[0], self.ground_position[1], self.ground_position[2] + self.ground_size[2] / 2 + self.cylinder_radius]
        self.cylinder_orientation_init = self._p.getQuaternionFromEuler(eulerAngles=[0., np.pi / 2, 0.])  # roll along y-axis
        self.cylinder_id = self.create_cylinder(mass=10., radius=self.cylinder_radius, height=self.cylinder_height, position=self.cylinder_position_init, orientation=self.cylinder_orientation_init, color=[0., 0., 1., 1.]) 
        self._p.changeDynamics(bodyUniqueId=self.cylinder_id, linkIndex=-1, lateralFriction=0.8, restitution=0.5)

        # Init board
        self.board_size = [0.25, 1., 0.05]
        self.board_position_init = [self.cylinder_position_init[0], self.cylinder_position_init[1], self.cylinder_position_init[2] + self.cylinder_radius + self.board_size[2] / 2]  # Init board above cylinder
        self.board_id = self.create_box(mass=10., half_extents=[self.board_size[0] / 2, self.board_size[1] / 2, self.board_size[2] / 2], position=self.board_position_init, color=[1., 0., 0., 1.])
        self._p.changeDynamics(bodyUniqueId=self.board_id, linkIndex=-1, lateralFriction=0.8, restitution=0.5)

    def create_box(self, mass, half_extents, position, color):
        collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents)
        visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents, rgbaColor=color)
        return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position)

    def create_cylinder(self, mass, radius, height, position, orientation, color):
        collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_CYLINDER, radius=radius, height=height)
        visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_CYLINDER, radius=radius, length=height, rgbaColor=color)
        return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position, baseOrientation=orientation)

    def reset(self):
        observation = super().reset()

        # Reset time
        self.time = 0.

        # Reset cylinder position
        self._p.resetBasePositionAndOrientation(self.cylinder_id, self.cylinder_position_init, self.cylinder_orientation_init)

        # Reset board position
        self._p.resetBasePositionAndOrientation(self.board_id, self.board_position_init, [0., 0., 0., 1.])

        # Reset robot position
        self._p.resetBasePositionAndOrientation(self.robot.robot_id, [self.board_position_init[0], self.board_position_init[1], self.board_position_init[2] + self.board_size[2] / 2 + self.robot.links["base"].position_init[2]], self.robot.links["base"].orientation_init)

        return observation

    def step(self, action):
        observation, reward, terminated, truncated, info = super().step(action)

        # Increase time
        self.time += self.dt

        return observation, reward, terminated, truncated, info

    def get_task_rewards(self, action):
        # On board
        on_board = 1. if self.robot.links["base"].position[2] > self.board_position_init[2] + self.board_size[2] / 2 else -1.
        return {"on_board": on_board}

    def get_terminated(self, action):
        # Terminate if not on board
        is_on_board = self.robot.links["base"].position[2] > self.board_position_init[2] + self.board_size[2] / 2
        return not is_on_board

    def get_success(self):
        # Success if on board after 10. s
        on_board = self.time >= 10. and self.robot.links["base"].position[2] > self.board_position_init[2] + self.board_size[2] / 2
        return on_board

</omni_epic/envs/humanoid/balance_board.py>

<omni_epic/envs/humanoid/base.py>
from omni_epic.envs.base import Env
from omni_epic.robots.humanoid import HumanoidRobot


class HumanoidEnv(Env):
	dt = 0.0165

	def __init__(self):
		# Init world
		super().__init__()

		# Init robot
		self.robot = HumanoidRobot(self._p)

		self.action_space = self.robot.action_space
		self.observation_space = self.robot.observation_space

	def get_truncated(self, action):
		return False

</omni_epic/envs/humanoid/base.py>

<omni_epic/envs/humanoid/cross_bridge.py>
import numpy as np
from omni_epic.envs.humanoid.base import HumanoidEnv


class Env(HumanoidEnv):
    """
    Cross a pride-colored bridge to reach a platform.

    Description:
    - A start platform and an end platform (each 3 m in size and 0.5 m in thickness) are placed 30 m apart.
    - The two platforms are connected by a bridge (1 m wide) divided in multiple segments. Each segment has a different color corresponding to the pride colors.
    The robot is initialized on the start platform.
    The task of the robot is to cross the bridge to reach the end platform as fast as possible.

    Success:
    The task is successfully completed when the robot reaches the end platform.

    Rewards:
    To help the robot complete the task:
    - The robot receives a reward for each time step it remains standing on the bridge or platforms, encouraging steady progress.
    - The robot is rewarded based on how much it reduces the distance to the end platform, incentivizing swift movement towards the goal.

    Termination:
    The task terminates immediately if the robot falls off the start platform, any segment of the bridge, or the end platform.
    """

    def __init__(self):
        super().__init__()

        # Init start platform
        self.platform_size = [3., 3., 0.5]
        self.platform_start_position = [0., 0., 0.]
        self.platform_end_position = [self.platform_start_position[0] + 30., self.platform_start_position[1], self.platform_start_position[2]]
        self.platform_start_id = self.create_box(mass=0., half_extents=[self.platform_size[0] / 2, self.platform_size[1] / 2, self.platform_size[2] / 2], position=self.platform_start_position, color=[0.8, 0.8, 0.8, 1.])
        self.platform_end_id = self.create_box(mass=0., half_extents=[self.platform_size[0] / 2, self.platform_size[1] / 2, self.platform_size[2] / 2], position=self.platform_end_position, color=[0.8, 0.8, 0.8, 1.])

        # Init bridge
        self.bridge_length = self.platform_end_position[0] - self.platform_start_position[0] - self.platform_size[0]
        self.bridge_width = 1.
        pride_colors = [
            [1.0, 0.0, 0.0, 1.],  # Red
            [1.0, 0.5, 0.0, 1.],  # Orange
            [1.0, 1.0, 0.0, 1.],  # Yellow
            [0.0, 0.5, 0.0, 1.],  # Green
            [0.0, 0.0, 1.0, 1.],  # Blue
            [0.7, 0.0, 1.0, 1.],  # Violet
        ]

        # Segment length
        num_colors = len(pride_colors)
        segment_size = self.bridge_length / num_colors

        # Create segments
        for i, color in enumerate(pride_colors):
            segment_id = self.create_box(mass=0., half_extents=[segment_size / 2, self.bridge_width / 2, self.platform_size[2] / 2], position=[self.platform_start_position[0] + self.platform_size[0] / 2 + segment_size / 2 + i * segment_size, self.platform_start_position[1], self.platform_start_position[2]], color=color)
            self._p.changeDynamics(bodyUniqueId=segment_id, linkIndex=-1, lateralFriction=0.8, restitution=0.5)

    def create_box(self, mass, half_extents, position, color):
        collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents)
        visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents, rgbaColor=color)
        return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position)

    def get_object_position(self, object_id):
        return np.asarray(self._p.getBasePositionAndOrientation(object_id)[0])

    def get_distance_to_object(self, object_id):
        object_position = self.get_object_position(object_id)
        robot_position = self.robot.links["base"].position
        return np.linalg.norm(object_position[:2] - robot_position[:2])

    def reset(self):
        observation = super().reset()

        # Reset robot position on start platform
        self._p.resetBasePositionAndOrientation(self.robot.robot_id, [self.platform_start_position[0], self.platform_start_position[1], self.platform_start_position[2] + self.platform_size[2] / 2 + self.robot.links["base"].position_init[2]], self.robot.links["base"].orientation_init)

        return observation

    def step(self, action):
        # Before taking action
        self.distance_to_platform_end = self.get_distance_to_object(self.platform_end_id)

        observation, reward, terminated, truncated, info = super().step(action)

        return observation, reward, terminated, truncated, info

    def get_task_rewards(self, action):
        # After taking action
        new_distance_to_platform_end = self.get_distance_to_object(self.platform_end_id)

        # Standing
        contact_points = self._p.getContactPoints(bodyA=self.robot.robot_id)
        objects_in_contact = {contact_point[2] for contact_point in contact_points if contact_point[2] != self.robot.robot_id and contact_point[3] not in {self.robot.links["left_foot"].index, self.robot.links["right_foot"].index}}
        standing = 2. if len(objects_in_contact) == 0 else -1.

        # Reach end platform
        reach_platform_end = (self.distance_to_platform_end - new_distance_to_platform_end) / self.dt

        return {"standing": standing, "reach_platform_end": reach_platform_end}

    def get_terminated(self, action):
        # Terminate if not standing
        contact_points = self._p.getContactPoints(bodyA=self.robot.robot_id)
        objects_in_contact = {contact_point[2] for contact_point in contact_points if contact_point[2] != self.robot.robot_id and contact_point[3] not in {self.robot.links["left_foot"].index, self.robot.links["right_foot"].index}}
        is_standing = len(objects_in_contact) == 0

        # Terminate if fall off
        is_fall_off = self.robot.links["base"].position[2] < self.platform_start_position[2]
        return not is_standing or is_fall_off

    def get_success(self):
        # Success if reach end platform
        is_on_platform_end = self.get_distance_to_object(self.platform_end_id) < self.platform_size[2] / 2
        return is_on_platform_end

</omni_epic/envs/humanoid/cross_bridge.py>

<omni_epic/envs/humanoid/cross_lava.py>
import numpy as np
from omni_epic.envs.humanoid.base import HumanoidEnv


class Env(HumanoidEnv):
    """
    Cross over lava on a boat to reach a target zone.

    Description:
    - The lava is simulated with an orange, 10 x 10 m heightfield.
    - There are two platforms on either side of the lava, each measuring 5 x 10 m. One serves as the start platform and the other as the end platform.
    - The boat is a box with dimensions 3 meters in length, 2 meters in width, and 0.2 meters in height. It is initialized next to the start platform at a random y-position.
    - The boat has a button that, when pressed, activates the boat to move over the lava at a speed of 3 meters per second.
    - The end platform has a target zone indicated by a green, transparent sphere.
    The robot's task is to jump onto the boat from the start platform, press the button to activate the boat, and travel across the lava to reach the end platform. The robot must then enter the target zone to complete the task.

    Success:
    The task is successfully completed when the robot enters the target zone on the end platform.

    Rewards:
    To guide the robot to complete the task:
    - The robot receives a reward for each time step it remains active and does not fall off or touch the lava.
    - The robot is rewarded for making progress towards pressing the button on the boat.
    - Additional rewards are given for progressing towards the target zone, with a significant bonus for entering the target zone.

    Termination:
    The task terminates immediately if the robot falls off the platform or the boat, or if it touches the simulated lava.
    """

    def __init__(self):
        super().__init__()

        # Init lava
        self.lava_size = [10., 5.]
        self.lava_height = 0.1
        self.lava_position = [0., 0., 0.]
        self.lava_id = self.create_heightfield(
            size=self.lava_size,
            height_max=self.lava_height,  # create small bumps to create a fluid-like surface
            position=self.lava_position,
            resolution=20,  # number of points per meter
            repeats=2,  # repeats
        )
        self._p.changeVisualShape(objectUniqueId=self.lava_id, linkIndex=-1, rgbaColor=[1., 0.3, 0.1, 1.])  # change to lava color

        # Init platforms
        self.platform_size = [5., self.lava_size[1], 1.]
        self.platform_start_position_init = [self.lava_position[0] - self.lava_size[0] / 2 - self.platform_size[0] / 2, self.lava_position[1], self.lava_position[2]]
        self.platform_end_position_init = [self.lava_position[0] + self.lava_size[0] / 2 + self.platform_size[0] / 2, self.lava_position[1], self.lava_position[2]]
        self.platform_start_id = self.create_box(mass=0., half_extents=[self.platform_size[0] / 2, self.lava_size[1] / 2, self.platform_size[2] / 2], position=self.platform_start_position_init, rgba_color=[0.3, 0.3, 0.3, 1.])
        self.platform_end_id = self.create_box(mass=0., half_extents=[self.platform_size[0] / 2, self.lava_size[1] / 2, self.platform_size[2] / 2], position=self.platform_end_position_init, rgba_color=[0.3, 0.3, 0.3, 1.])

        # Init boat
        self.boat_size = [3., 2., 0.2]
        self.boat_position_init = [self.lava_position[0] - self.lava_size[0] / 2 + self.boat_size[0] / 2, self.lava_position[1], self.boat_size[2] / 2]
        self.boat_speed = 3.
        self.boat_id = self.create_box(mass=0., half_extents=[self.boat_size[0] / 2, self.boat_size[1] / 2, self.boat_size[2] / 2], position=self.boat_position_init, rgba_color=[0.8, 0.8, 0.8, 1.])

        # Init button
        self.button_radius = 0.25
        self.button_height = 0.25
        self.button_position_init = [self.boat_position_init[0] + self.boat_size[0] / 4, self.lava_position[1], self.boat_position_init[2] + self.boat_size[2] / 2 + self.button_height / 2]  # put button on the right side of the boat
        self.button_id = self.create_cylinder(mass=0., radius=self.button_radius, height=self.button_height, position=self.button_position_init, orientation=[0., 0., 0., 1.], rgba_color=[0., 0.5, 0., 1.])

        self.objects_on_boat = [self.button_id]

    def create_box(self, mass, half_extents, position, rgba_color):
        collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents)
        visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents, rgbaColor=rgba_color)
        return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position)

    def create_cylinder(self, mass, radius, height, position, orientation, rgba_color):
        collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_CYLINDER, radius=radius, height=height)
        visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_CYLINDER, radius=radius, length=height, rgbaColor=rgba_color)
        return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position, baseOrientation=orientation)

    def create_heightfield(self, size, height_max, position, resolution, repeats=2):
        heightfield_data = np.random.uniform(low=0., high=height_max, size=(int(size[0] * resolution / repeats), int(size[1] * resolution / repeats)))
        heightfield_data = np.repeat(np.repeat(heightfield_data, repeats, axis=0), repeats, axis=1)
        mesh_scale = [1/resolution, 1/resolution, 1.]
        heightfield_collision_shape_id = self._p.createCollisionShape(
            shapeType=self._p.GEOM_HEIGHTFIELD,
            meshScale=mesh_scale,
            heightfieldData=heightfield_data.reshape(-1),
            numHeightfieldRows=heightfield_data.shape[0],
            numHeightfieldColumns=heightfield_data.shape[1],
        )
        return self._p.createMultiBody(baseMass=0., baseCollisionShapeIndex=heightfield_collision_shape_id, basePosition=[position[0], position[1], position[2] + mesh_scale[2] * height_max / 2])

    def get_center_of_mass(self):
        return np.asarray([link.mass * link.position for link in self.robot.links.values()]).sum(axis=0)/self.robot.mass

    def get_object_position(self, object_id):
        return np.asarray(self._p.getBasePositionAndOrientation(object_id)[0])

    def get_distance_to_object(self, object_id):
        object_position = self.get_object_position(object_id)
        robot_position = self.robot.links["base"].position
        return np.linalg.norm(object_position[:2] - robot_position[:2])

    def reset(self):
        observation = super().reset()

        # Reset boat position
        boat_y_init = np.random.uniform(low=-self.lava_size[1] / 2 + self.boat_size[1] / 2, high=self.lava_size[1] / 2 - self.boat_size[1] / 2)  # randomize y position
        self._p.resetBasePositionAndOrientation(self.boat_id, [self.boat_position_init[0], boat_y_init, self.boat_position_init[2]], [0., 0., 0., 1.])

        # Reset button position
        self._p.resetBasePositionAndOrientation(self.button_id, [self.button_position_init[0], boat_y_init, self.button_position_init[2]], [0., 0., 0., 1.])

        # Reset robot position
        self._p.resetBasePositionAndOrientation(
            self.robot.robot_id,
            [self.platform_start_position_init[0], self.platform_start_position_init[1], self.platform_start_position_init[2] + self.platform_size[2] / 2 + self.robot.links["base"].position_init[2]],
            self.robot.links["base"].orientation_init,
        )

        return observation

    def step(self, action):
        # Distance to button before taking action
        self.distance_to_button = self.get_distance_to_object(self.button_id)

        # Center of mass before taking action
        self.center_of_mass = self.get_center_of_mass()

        observation, reward, terminated, truncated, info = super().step(action)

        # Check if button is pressed
        contact_points = self._p.getContactPoints(bodyA=self.robot.robot_id, bodyB=self.button_id)
        button_pressed = len(contact_points) > 0

        if button_pressed:
            # Move boat forward
            boat_position = self.get_object_position(self.boat_id)
            new_boat_position = boat_position + np.array([self.boat_speed * self.dt, 0., 0.])
            self._p.resetBasePositionAndOrientation(self.boat_id, new_boat_position, [0., 0., 0., 1.])

            # Move everything on boat forward
            for object_id in self.objects_on_boat:
                object_position = self.get_object_position(object_id)
                new_object_position = object_position + np.array([self.boat_speed * self.dt, 0., 0.])
                self._p.resetBasePositionAndOrientation(object_id, new_object_position, [0., 0., 0., 1.])

        return observation, reward, terminated, truncated, info

    def get_task_rewards(self, action):
        # Standing
        contact_points = self._p.getContactPoints(bodyA=self.robot.robot_id)
        objects_in_contact = {contact_point[2] for contact_point in contact_points if contact_point[2] != self.robot.robot_id and contact_point[3] not in {self.robot.links["left_foot"].index, self.robot.links["right_foot"].index}}
        standing = 2. if len(objects_in_contact) == 0 else -1.

        # Reach button
        new_distance_to_button = self.get_distance_to_object(self.button_id)  # Distance to button after taking action
        reach_button = (self.distance_to_button - new_distance_to_button) / self.dt

        # Forward velocity
        new_center_of_mass = self.get_center_of_mass()  # Center of mass after taking action
        forward_velocity = (new_center_of_mass[0] - self.center_of_mass[0]) / self.dt

        return {"standing": standing, "reach_button": reach_button, "forward_velocity": forward_velocity}

    def get_terminated(self, action):
        # Terminate if not standing
        contact_points = self._p.getContactPoints(bodyA=self.robot.robot_id)
        objects_in_contact = {contact_point[2] for contact_point in contact_points if contact_point[2] != self.robot.robot_id and contact_point[3] not in {self.robot.links["left_foot"].index, self.robot.links["right_foot"].index}}
        is_standing = len(objects_in_contact) == 0

        # Terminate if touch lava
        contact_points = self._p.getContactPoints(bodyA=self.robot.robot_id, bodyB=self.lava_id)
        is_touching_lava = len(contact_points) > 0

        # Terminate if fall off
        is_fall_off = self.robot.links["base"].position[2] < self.platform_start_position_init[2]
        return not is_standing or is_touching_lava or is_fall_off

    def get_success(self):
        # Success if cross lava and touched the end platform
        contact_points = self._p.getContactPoints(bodyA=self.robot.robot_id, bodyB=self.platform_end_id)
        return len(contact_points) > 0

</omni_epic/envs/humanoid/cross_lava.py>

<omni_epic/envs/humanoid/go_down_stairs.py>
import numpy as np
from omni_epic.envs.humanoid.base import HumanoidEnv


class Env(HumanoidEnv):
    """
    Descend a series of stairs to reach the ground.

    Description:
    - The environment consists of a ground platform (1000 m x 10 m x 10 m) and a set of 10 steps.
    - Each step has dimensions of 1 m in length, 10 m in width, and 0.2 m in height.
    - The steps are positioned to form a descending staircase starting from an initial height, with each subsequent step lower than the previous one.
    The robot is initialized at the top of the stairs.

    Success:
    The task is completed when the robot successfully descends the stairs and touches the ground platform.

    Rewards:
    The help the robot complete the task:
    - The robot is rewarded for standing at each time step.
    - The robot is rewarded for forward velocity, incentivizing it to move down the stairs.

    Termination:
    The task terminates immediately if the robot falls off the stairs or the ground platform.
    """

    def __init__(self):
        super().__init__()

        # Init ground
        self.ground_size = [1000., 10., 10.]
        self.ground_position = [0., 0., 0.]
        self.ground_id = self.create_box(mass=0., half_extents=[self.ground_size[0] / 2, self.ground_size[1] / 2, self.ground_size[2] / 2], position=self.ground_position, color=[0.5, 0.5, 0.5, 1.])
        self._p.changeDynamics(bodyUniqueId=self.ground_id, linkIndex=-1, lateralFriction=0.8, restitution=0.5)

        # Init stairs
        self.num_steps = 10
        self.step_size = [1.0, 10., 0.2]
        self.step_position_init = [self.ground_position[0], self.ground_position[1], self.ground_position[2] + self.ground_size[2] / 2 + self.num_steps * self.step_size[2]]
        self.create_stairs_down(step_size=self.step_size, step_position_init=self.step_position_init, num_steps=self.num_steps)

    def create_box(self, mass, half_extents, position, color):
        collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents)
        visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents, rgbaColor=color)
        return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position)

    def create_stairs_down(self, step_size, step_position_init, num_steps):
        color_1 = np.array([1., 0., 0.])
        color_2 = np.array([0., 0., 1.])
        for i in range(num_steps):
            step_position = [step_position_init[0] + i * step_size[0], step_position_init[1], step_position_init[2] - i * step_size[2]]
            interpolation = i / (num_steps - 1)
            step_color = (1 - interpolation) * color_1 + interpolation * color_2  # shade steps for visualization
            self.create_box(mass=0., half_extents=[step_size[0] / 2, step_size[1] / 2, step_size[2] / 2], position=step_position, color=np.append(step_color, 1.))

    def reset(self):
        observation = super().reset()

        # Reset robot position at the top of the stairs
        self._p.resetBasePositionAndOrientation(self.robot.robot_id, [self.step_position_init[0], self.step_position_init[1], self.step_position_init[2] + self.step_size[2] / 2 + self.robot.links["base"].position_init[2]], self.robot.links["base"].orientation_init)

        return observation

    def step(self, action):
        # Before taking action
        self.position = self.robot.links["base"].position

        observation, reward, terminated, truncated, info = super().step(action)

        return observation, reward, terminated, truncated, info

    def get_task_rewards(self, action):
        # After taking action
        new_position = self.robot.links["base"].position

        # Standing
        contact_points = self._p.getContactPoints(bodyA=self.robot.robot_id)
        objects_in_contact = {contact_point[2] for contact_point in contact_points if contact_point[2] != self.robot.robot_id and contact_point[3] not in {self.robot.links["left_foot"].index, self.robot.links["right_foot"].index}}
        standing = 2. if len(objects_in_contact) == 0 else -1.

        # Forward velocity
        forward_velocity = (new_position[0] - self.position[0]) / self.dt

        return {"standing": standing, "forward_velocity": forward_velocity}

    def get_terminated(self, action):
        # Terminate if not standing
        contact_points = self._p.getContactPoints(bodyA=self.robot.robot_id)
        objects_in_contact = {contact_point[2] for contact_point in contact_points if contact_point[2] != self.robot.robot_id and contact_point[3] not in {self.robot.links["left_foot"].index, self.robot.links["right_foot"].index}}
        is_standing = len(objects_in_contact) == 0

        # Terminate if fall off
        is_fall_off = self.robot.links["base"].position[2] < self.ground_position[2]
        return not is_standing or is_fall_off

    def get_success(self):
        # Success if reach end stairs and touch ground
        contact_points = self._p.getContactPoints(bodyA=self.robot.robot_id, bodyB=self.ground_id)
        is_on_ground = len(contact_points) > 0
        return is_on_ground

</omni_epic/envs/humanoid/go_down_stairs.py>

<omni_epic/envs/humanoid/go_forward.py>
import numpy as np
from omni_epic.envs.humanoid.base import HumanoidEnv


class Env(HumanoidEnv):
    """
    Go forward.

    Description:
    The robot is standing on a flat ground represented by a box.
    The task of the robot is to go forward as fast as possible.

    Success:
    The task is completed if the robot runs forward for 10 meters.

    Rewards:
    The help the robot complete the task:
    - The robot is rewarded for standing at each time step.
    - The robot is rewarded for forward velocity, incentivizing it to move forward quickly.

    Termination:
    The task terminates if the robot falls.
    """

    def __init__(self):
        super().__init__()

        # Init ground
        self.ground_size = [1000., 1000., 10.]
        self.ground_position = [0., 0., 0.]
        self.ground_id = self.create_box(mass=0., half_extents=[self.ground_size[0] / 2, self.ground_size[1] / 2, self.ground_size[2] / 2], position=self.ground_position, color=[0.5, 0.5, 0.5, 1.])
        self._p.changeDynamics(bodyUniqueId=self.ground_id, linkIndex=-1, lateralFriction=0.8, restitution=0.5)

    def create_box(self, mass, half_extents, position, color):
        collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents)
        visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents, rgbaColor=color)
        return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position)

    def reset(self):
        observation = super().reset()

        # Reset robot position
        self._p.resetBasePositionAndOrientation(self.robot.robot_id, [self.ground_position[0], self.ground_position[1], self.ground_position[2] + self.ground_size[2] / 2 + self.robot.links["base"].position_init[2]], self.robot.links["base"].orientation_init)

        return observation

    def step(self, action):
        # Before taking action
        self.position = self.robot.links["base"].position

        observation, reward, terminated, truncated, info = super().step(action)

        return observation, reward, terminated, truncated, info

    def get_task_rewards(self, action):
        # After taking action
        new_position = self.robot.links["base"].position

        # Standing
        contact_points = self._p.getContactPoints(bodyA=self.robot.robot_id, bodyB=self.ground_id)
        objects_in_contact = {contact_point[2] for contact_point in contact_points if contact_point[3] not in {self.robot.links["left_foot"].index, self.robot.links["right_foot"].index}}
        standing = 2. if len(objects_in_contact) == 0 else -1.

        # Forward velocity
        forward_velocity = (new_position[0] - self.position[0]) / self.dt

        return {"standing": standing, "forward_velocity": forward_velocity}

    def get_terminated(self, action):
        # Terminate if not standing
        contact_points = self._p.getContactPoints(bodyA=self.robot.robot_id, bodyB=self.ground_id)
        objects_in_contact = {contact_point[2] for contact_point in contact_points if contact_point[3] not in {self.robot.links["left_foot"].index, self.robot.links["right_foot"].index}}
        is_standing = len(objects_in_contact) == 0
        return not is_standing

    def get_success(self):
        # Success if run forward for 10 meters
        return self.robot.links["base"].position[0] > 10.

</omni_epic/envs/humanoid/go_forward.py>

<omni_epic/envs/humanoid/go_to_box.py>
import numpy as np
from omni_epic.envs.humanoid.base import HumanoidEnv


class Env(HumanoidEnv):
    """
    Reach a box.

    Description:
    - The environment consists of a large flat ground measuring 1000 x 1000 x 10 meters.
    - A box with dimensions 1 x 1 x 1 meter is placed randomly on the ground in a radius of 25 m around the robot. To avoid collisions, the box cannot spawn in a radius of 2 m around the robot.
    - The robot is initialized at a fixed position on the ground.
    The task of the robot is to reach and touch the box.

    Success:
    The task is completed if the robot makes contact with the box.

    Rewards:
    The help the robot complete the task:
    - The robot is rewarded for standing at each time step.
    - The robot is rewarded for moving closer to the box.

    Termination:
    The task terminates if the robot falls.
    """

    def __init__(self):
        super().__init__()

        # Init ground
        self.ground_size = [1000., 1000., 10.]
        self.ground_position = [0., 0., 0.]
        self.ground_id = self.create_box(mass=0., half_extents=[self.ground_size[0] / 2, self.ground_size[1] / 2, self.ground_size[2] / 2], position=self.ground_position, color=[0.5, 0.5, 0.5, 1.])
        self._p.changeDynamics(bodyUniqueId=self.ground_id, linkIndex=-1, lateralFriction=0.8, restitution=0.5)

        # Init box
        self.box_size = [1., 1., 1.]
        self.box_id = self.create_box(mass=1., half_extents=[self.box_size[0] / 2, self.box_size[1] / 2, self.box_size[2] / 2], position=[0., 0., 0.], color=[1., 0., 0., 1.])

        # Starting position of the robot
        self.robot_position_init = [self.ground_position[0], self.ground_position[1], self.ground_position[2] + self.ground_size[2] / 2 + self.robot.links["base"].position_init[2]]

    def create_box(self, mass, half_extents, position, color):
        collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents)
        visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents, rgbaColor=color)
        return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position)

    def get_object_position(self, object_id):
        return np.asarray(self._p.getBasePositionAndOrientation(object_id)[0])

    def get_distance_to_object(self, object_id):
        object_position = self.get_object_position(object_id)
        robot_position = self.robot.links["base"].position
        return np.linalg.norm(object_position[:2] - robot_position[:2])

    def reset(self):
        observation = super().reset()

        # Reset robot position on ground
        self._p.resetBasePositionAndOrientation(self.robot.robot_id, self.robot_position_init, self.robot.links["base"].orientation_init)

        # Reset box position
        angle = np.random.uniform(0., 2 * np.pi)
        radius = np.random.uniform(2., 25.)
        self._p.resetBasePositionAndOrientation(self.box_id, [self.robot_position_init[0] + radius * np.cos(angle), self.robot_position_init[1] + radius * np.sin(angle), self.ground_position[2] + self.ground_size[2] / 2 + self.box_size[2] / 2], [0., 0., 0., 1.])

        return observation

    def step(self, action):
        # Before taking action
        self.distance_to_box = self.get_distance_to_object(self.box_id)

        observation, reward, terminated, truncated, info = super().step(action)

        return observation, reward, terminated, truncated, info

    def get_task_rewards(self, action):
        # After taking action
        new_distance_to_box = self.get_distance_to_object(self.box_id)

        # Standing
        contact_points = self._p.getContactPoints(bodyA=self.robot.robot_id)
        objects_in_contact = {contact_point[2] for contact_point in contact_points if contact_point[2] != self.robot.robot_id and contact_point[3] not in {self.robot.links["left_foot"].index, self.robot.links["right_foot"].index}}
        standing = 2. if self.ground_id not in objects_in_contact else -1.

        # Reach box
        reach_box = (self.distance_to_box - new_distance_to_box) / self.dt

        return {"standing": standing, "reach_box": reach_box}

    def get_terminated(self, action):
        # Terminate if not standing
        contact_points = self._p.getContactPoints(bodyA=self.robot.robot_id)
        objects_in_contact = {contact_point[2] for contact_point in contact_points if contact_point[2] != self.robot.robot_id and contact_point[3] not in {self.robot.links["left_foot"].index, self.robot.links["right_foot"].index}}
        is_standing = self.ground_id not in objects_in_contact
        return not is_standing

    def get_success(self):
        # Success if touch box
        contact_points_box = self._p.getContactPoints(bodyA=self.robot.robot_id, bodyB=self.box_id)
        is_touching_box = len(contact_points_box) > 0
        return is_touching_box

</omni_epic/envs/humanoid/go_to_box.py>

<omni_epic/envs/humanoid/kick_ball.py>
import numpy as np
from omni_epic.envs.humanoid.base import HumanoidEnv


class Env(HumanoidEnv):
    """
    Kick a ball.

    Description:
    - The environment consists of a large flat ground measuring 1000 x 1000 x 10 meters.
    - A ball with a radius of 0.5 meters is placed randomly on the ground.
    - The robot is initialized at a fixed position on the ground.
    - The task of the robot is to move across the ground, reach the ball, and kick it as far away as possible.

    Success:
    The task is successfully completed if the robot kicks the ball so that it moves more than 10 meters away from its initial position.

    Rewards:
    To help the robot complete the task:
    - The robot is rewarded for standing.
    - The robot is rewarded for decreasing its distance to the ball.
    - The robot is rewarded for increasing the velocity of the ball to guide the robot to kick the ball.

    Termination:
    The task terminates if the robot falls.
    """

    def __init__(self):
        super().__init__()

        # Init ground
        self.ground_size = [1000., 1000., 10.]
        self.ground_position = [0., 0., 0.]
        self.ground_id = self.create_box(mass=0., half_extents=[self.ground_size[0] / 2, self.ground_size[1] / 2, self.ground_size[2] / 2], position=self.ground_position, color=[0.5, 0.5, 0.5, 1.])
        self._p.changeDynamics(bodyUniqueId=self.ground_id, linkIndex=-1, lateralFriction=0.8, restitution=0.5)

        # Init ball
        self.ball_radius = 0.5
        self.ball_id = self.create_sphere(mass=1., radius=self.ball_radius, position=[0., 0., 0.], color=[1., 0., 0., 1.])

        # Starting position of the robot
        self.robot_position_init = [self.ground_position[0], self.ground_position[1], self.ground_position[2] + self.ground_size[2] / 2 + self.robot.links["base"].position_init[2]]

    def create_box(self, mass, half_extents, position, color):
        collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents)
        visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents, rgbaColor=color)
        return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position)

    def create_sphere(self, mass, radius, position, color):
        collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_SPHERE, radius=radius)
        visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_SPHERE, radius=radius, rgbaColor=color)
        return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position)

    def get_object_position(self, object_id):
        return np.asarray(self._p.getBasePositionAndOrientation(object_id)[0])

    def get_distance_to_object(self, object_id):
        object_position = self.get_object_position(object_id)
        robot_position = self.robot.links["base"].position
        return np.linalg.norm(object_position[:2] - robot_position[:2])

    def reset(self):
        observation = super().reset()

        # Reset robot position on ground
        self._p.resetBasePositionAndOrientation(self.robot.robot_id, self.robot_position_init, self.robot.links["base"].orientation_init)

        # Reset ball position
        ball_y_init = np.random.uniform(self.robot_position_init[1] - 2., self.robot_position_init[1] + 2.)
        self._p.resetBasePositionAndOrientation(self.ball_id, [self.robot_position_init[0] + 5., ball_y_init, self.ground_position[2] + self.ground_size[2] / 2 + self.ball_radius], [0., 0., 0., 1.])

        return observation

    def step(self, action):
        # Before taking action
        self.distance_to_ball = self.get_distance_to_object(self.ball_id)
        self.ball_position = self.get_object_position(self.ball_id)

        observation, reward, terminated, truncated, info = super().step(action)

        return observation, reward, terminated, truncated, info

    def get_task_rewards(self, action):
        # After taking action
        new_distance_to_ball = self.get_distance_to_object(self.ball_id)
        new_ball_position = self.get_object_position(self.ball_id) 

        # Standing
        contact_points = self._p.getContactPoints(bodyA=self.robot.robot_id)
        objects_in_contact = {contact_point[2] for contact_point in contact_points if contact_point[2] != self.robot.robot_id and contact_point[3] not in {self.robot.links["left_foot"].index, self.robot.links["right_foot"].index}}
        standing = 2. if self.ground_id not in objects_in_contact else -1.

        # Reach ball
        reach_ball = (self.distance_to_ball - new_distance_to_ball) / self.dt

        # Velocity of ball
        ball_velocity = np.linalg.norm(new_ball_position - self.ball_position) / self.dt

        return {"standing": standing, "reach_ball": reach_ball, "ball_velocity": ball_velocity}

    def get_terminated(self, action):
        # Terminate if not standing
        contact_points = self._p.getContactPoints(bodyA=self.robot.robot_id)
        objects_in_contact = {contact_point[2] for contact_point in contact_points if contact_point[2] != self.robot.robot_id and contact_point[3] not in {self.robot.links["left_foot"].index, self.robot.links["right_foot"].index}}
        is_standing = self.ground_id not in objects_in_contact  # allow body to touch ball
        return not is_standing

    def get_success(self):
        # Success if kick ball 10 meters away from origin
        ball_distance_to_origin = np.linalg.norm(self.get_object_position(self.ball_id))
        return ball_distance_to_origin > 10.

</omni_epic/envs/humanoid/kick_ball.py>

<omni_epic/envs/humanoid/maze.py>
import numpy as np
from omni_epic.envs.humanoid.base import HumanoidEnv


class Env(HumanoidEnv):
    """
    Navigate through a maze to reach the end position.

    Description:
    - The environment consists of a large flat ground measuring 1000 x 1000 x 10 m.
    - A maze is constructed on the ground using walls of height 1 meter and scale 2 m per cell.
    - The maze is represented by a 2D array where 0 indicates an empty space, 1 indicates a wall, 2 indicates the start position, and 3 indicates the end position.
    - The robot is initialized at the start position in the maze.
    - The task of the robot is to navigate through the maze and reach the end position.

    Success:
    The task is completed if the robot reaches the end position in the maze.

    Rewards:
    To guide the robot to complete the task:
    - The robot receives a reward at each time step for survival.
    - The robot is rewarded for making progress towards the end position in the maze.

    Termination:
    The task terminates if the robot falls.
    """

    def __init__(self):
        super().__init__()

        # Init ground
        self.ground_size = [1000., 1000., 10.]
        self.ground_position = [0., 0., 0.]
        self.ground_id = self.create_box(mass=0., half_extents=[self.ground_size[0] / 2, self.ground_size[1] / 2, self.ground_size[2] / 2], position=self.ground_position, color=[0.5, 0.5, 0.5, 1.])
        self._p.changeDynamics(bodyUniqueId=self.ground_id, linkIndex=-1, lateralFriction=0.8, restitution=0.5)

        # Init maze - 0 is empty, 1 is wall, 2 is start, 3 is end
        self.maze_height = 1.
        self.maze_scale = 2.
        maze = np.array([
            [1, 1, 1, 3, 1, 1],
            [1, 0, 0, 0, 0, 1],
            [1, 0, 1, 1, 0, 1],
            [2, 0, 0, 0, 0, 1],
            [1, 1, 1, 1, 1, 1],
        ])
        for index, value in np.ndenumerate(maze):
                if value == 1:
                    self.create_box(0., half_extents=[self.maze_scale / 2, self.maze_scale / 2, self.maze_height / 2], position=[self.maze_scale * index[1], -self.maze_scale * index[0], self.ground_position[2] + self.ground_size[2] / 2 + self.maze_height / 2], color=[0.2, 0.2, 0.2, 1])

        # Get start and end position
        start_position_index = np.squeeze(np.argwhere(maze == 2))
        self.start_position = self.maze_scale * np.array([start_position_index[1], -start_position_index[0]])
        end_position_index = np.squeeze(np.argwhere(maze == 3))
        self.end_position = self.maze_scale * np.array([end_position_index[1], -end_position_index[0]])

    def create_box(self, mass, half_extents, position, color):
        collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents)
        visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents, rgbaColor=color)
        return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position)

    def reset(self):
        observation = super().reset()

        # Reset robot position at start position
        self._p.resetBasePositionAndOrientation(self.robot.robot_id, [self.start_position[0], self.start_position[1], self.ground_position[2] + self.ground_size[2] / 2 + self.robot.links["base"].position_init[2]], self.robot.links["base"].orientation_init)

        return observation

    def step(self, action):
        # Before taking action
        self.position = self.robot.links["base"].position
        self.distance_to_end = np.linalg.norm(self.position[:2] - self.end_position)

        observation, reward, terminated, truncated, info = super().step(action)

        return observation, reward, terminated, truncated, info

    def get_task_rewards(self, action):
        # After taking action
        new_position = self.robot.links["base"].position
        new_distance_to_end = np.linalg.norm(new_position[:2] - self.end_position)

        # Standing
        contact_points = self._p.getContactPoints(bodyA=self.robot.robot_id)
        objects_in_contact = {contact_point[2] for contact_point in contact_points if contact_point[2] != self.robot.robot_id and contact_point[3] not in {self.robot.links["left_foot"].index, self.robot.links["right_foot"].index}}
        standing = 2. if self.ground_id not in objects_in_contact else -1.

        # Progress in the maze
        maze_progress = (self.distance_to_end - new_distance_to_end) / self.dt

        return {"standing": standing, "maze_progress": maze_progress}

    def get_terminated(self, action):
        # Terminate if not standing
        contact_points = self._p.getContactPoints(bodyA=self.robot.robot_id)
        objects_in_contact = {contact_point[2] for contact_point in contact_points if contact_point[2] != self.robot.robot_id and contact_point[3] not in {self.robot.links["left_foot"].index, self.robot.links["right_foot"].index}}
        is_standing = self.ground_id not in objects_in_contact
        return not is_standing

    def get_success(self):
        # Success if reach end of maze
        return np.linalg.norm(self.robot.links["base"].position[:2] - self.end_position) < self.maze_scale

</omni_epic/envs/humanoid/maze.py>

<omni_epic/envs/humanoid/open_door.py>
import numpy as np
from omni_epic.envs.humanoid.base import HumanoidEnv


class Env(HumanoidEnv):
    """
    Activate a lever to open a door and move through the door.

    Description:
    - The environment consists of a large platform measuring 1000 x 10 x 0.1 meters.
    - The robot is initialized at a fixed position on the platform.
    - A door with dimensions 0.5 x 2 x 2 meters is placed on the platform, 5 m away from the robot, initially closed.
    - The door is flanked by walls to prevent the robot from bypassing it.
    - A lever is placed on the platform, 2 meters to the left of the door.
    - The task of the robot is to move to the lever, activate it to open the door, and then pass through the door.

    Success:
    The task is successfully completed if the robot passes through the door and moves more than 10 m beyond the initial position.

    Rewards:
    To guide the robot to complete the task:
    - The robot receives a survival reward at each time step.
    - The robot is rewarded for decreasing its distance to the lever.
    - The robot receives a bonus rewards for activating the lever to open the door.
    - Once the door is open, the robot is rewarded for moving forward.

    Termination:
    The task terminates immediately if the robot falls off the stairs or the ground platform.
    """

    def __init__(self):
        super().__init__()

        self.robot_position_init = [0., 0., 0.]

        # Init platform
        self.platform_size = [1000., 10., 0.1]
        self.platform_position = [self.robot_position_init[0] + self.platform_size[0] / 2 - 2., self.robot_position_init[1], self.robot_position_init[2] - self.platform_size[2] / 2]  # offset by 2 m to avoid off-edge or on-edge placement
        self.platform_id = self.create_box(mass=0., half_extents=[self.platform_size[0] / 2, self.platform_size[1] / 2, self.platform_size[2] / 2], position=self.platform_position, color=[0.5, 0.5, 0.5, 1.])
        self._p.changeDynamics(bodyUniqueId=self.platform_id, linkIndex=-1, lateralFriction=0.8, restitution=0.5)

        # Init door
        self.door_size = [0.5, 2., 2.]
        self.door_position_init = [self.robot_position_init[0] + 5., self.platform_position[1], self.platform_position[2] + self.platform_size[2] / 2 + self.door_size[2] / 2]
        self.door_id = self.create_box(mass=0., half_extents=[self.door_size[0] / 2, self.door_size[1] / 2, self.door_size[2] / 2], position=self.door_position_init, color=[1., 0., 0., 1.])
        self.door_open = False

        # Init wall
        self.wall_size = [self.door_size[0], (self.platform_size[1] - self.door_size[1]) / 2, self.door_size[2]]  # walls plus door span the full platform to prevent robot to go around
        self.create_box(mass=0., half_extents=[self.wall_size[0] / 2, self.wall_size[1] / 2, self.wall_size[2] / 2], position=[self.door_position_init[0], self.door_position_init[1] + self.door_size[1] / 2 + self.wall_size[1] / 2, self.platform_position[2] + self.platform_size[2] / 2 + self.wall_size[2] / 2], color=[0., 0., 1., 1.])  # left section
        self.create_box(mass=0., half_extents=[self.wall_size[0] / 2, self.wall_size[1] / 2, self.wall_size[2] / 2], position=[self.door_position_init[0], self.door_position_init[1] - self.door_size[1] / 2 - self.wall_size[1] / 2, self.platform_position[2] + self.platform_size[2] / 2 + self.wall_size[2] / 2], color=[0., 0., 1., 1.])  # right section

        # Init lever
        self.lever_radius = 0.05
        self.lever_height = 0.5
        lever_position = [self.door_position_init[0] - 2., self.door_size[1], self.platform_position[2] + self.platform_size[2] / 2 + self.lever_height / 2]  # two meters to the left of the door on the platform
        self.lever_id = self.create_cylinder(mass=0., radius=self.lever_radius, height=self.lever_height, position=lever_position, color=[0.5, 0.25, 0., 1.])

    def create_box(self, mass, half_extents, position, color):
        collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents)
        visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents, rgbaColor=color)
        return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position)

    def create_cylinder(self, mass, radius, height, position, color):
        collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_CYLINDER, radius=radius, height=height)
        visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_CYLINDER, radius=radius, length=height, rgbaColor=color)
        return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position)

    def get_object_position(self, object_id):
        return np.asarray(self._p.getBasePositionAndOrientation(object_id)[0])

    def get_distance_to_object(self, object_id):
        object_position = self.get_object_position(object_id)
        robot_position = self.robot.links["base"].position
        return np.linalg.norm(object_position[:2] - robot_position[:2])

    def reset(self):
        observation = super().reset()

        # Reset door
        self.door_open = False
        self._p.resetBasePositionAndOrientation(self.door_id, self.door_position_init, [0., 0., 0., 1.])

        # Reset robot position
        self._p.resetBasePositionAndOrientation(self.robot.robot_id, [self.robot_position_init[0], self.robot_position_init[1], self.robot_position_init[2] + self.robot.links["base"].position_init[2]], self.robot.links["base"].orientation_init)

        return observation

    def step(self, action):
        # Before taking action
        self.position = self.robot.links["base"].position
        self.distance_to_lever = self.get_distance_to_object(self.lever_id)

        observation, reward, terminated, truncated, info = super().step(action)

        contact_points = self._p.getContactPoints(bodyA=self.robot.robot_id, bodyB=self.lever_id)
        if len(contact_points) > 0 and not self.door_open:
            self.door_open = True
            self._p.resetBasePositionAndOrientation(self.door_id, [self.door_position_init[0], self.door_position_init[1] + self.door_size[1], self.door_position_init[2]], [0., 0., 0., 1.])

        return observation, reward, terminated, truncated, info

    def get_task_rewards(self, action):
        # After taking action
        new_position = self.robot.links["base"].position
        new_distance_to_lever = self.get_distance_to_object(self.lever_id)

        # Standing
        contact_points = self._p.getContactPoints(bodyA=self.robot.robot_id, bodyB=self.platform_id)
        objects_in_contact = {contact_point[2] for contact_point in contact_points if contact_point[3] not in {self.robot.links["left_foot"].index, self.robot.links["right_foot"].index}}
        standing = 2. if len(objects_in_contact) == 0 else -1.

        # Reach lever
        if not self.door_open and len(self._p.getContactPoints(bodyA=self.robot.robot_id, bodyB=self.lever_id)) == 0:
            reach_lever = (self.distance_to_lever - new_distance_to_lever) / self.dt
        elif not self.door_open and len(self._p.getContactPoints(bodyA=self.robot.robot_id, bodyB=self.lever_id)) > 0:
            reach_lever = 10.
        else:
            reach_lever = 0.

        # Forward velocity
        if self.door_open:
            forward_velocity = (new_position[0] - self.position[0]) / self.dt
        else:
            forward_velocity = 0.

        return {"standing": standing, "reach_lever": reach_lever, "forward_velocity": forward_velocity}

    def get_terminated(self, action):
        # Terminate if not standing
        contact_points = self._p.getContactPoints(bodyA=self.robot.robot_id, bodyB=self.platform_id)
        objects_in_contact = {contact_point[2] for contact_point in contact_points if contact_point[3] not in {self.robot.links["left_foot"].index, self.robot.links["right_foot"].index}}
        is_standing = len(objects_in_contact) == 0

        # Terminate if fall off
        is_fall_off = self.robot.links["base"].position[2] < self.platform_position[2]
        return not is_standing or is_fall_off

    def get_success(self):
        # Success if pass through door
        return self.robot.links["base"].position[0] > 10.

</omni_epic/envs/humanoid/open_door.py>

<omni_epic/envs/humanoid/walk_on_cylinder.py>
import numpy as np
from omni_epic.envs.humanoid.base import HumanoidEnv


class Env(HumanoidEnv):
    """
    Go forward on top of a rolling cylinder.

    Description:
    - The environment consists of a large flat ground measuring 1000 x 1000 x 10 m.
    - A cylinder with a radius of 2 m and a height of 3 m is placed on the ground and can roll along the x-axis.
    - The cylinder's initial position is at the center of the ground, and it is oriented to roll along the x-axis.
    - The robot is initialized on top of the cylinder.
    - The task of the robot is to go forward while balancing on top of the rolling cylinder.

    Success:
    The task is completed if the robot rolls more than 5 m forward without falling off.

    Rewards:
    To guide the robot to complete the task:
    - The robot receives a reward for each time step it remains balanced on the cylinder.
    - The robot receives a reward for forward velocity along the x-axis.

    Termination:
    The task terminates immediately if the is not standing on the cylinder or if the robot falls off the cylinder.
    """

    def __init__(self):
        super().__init__()

        # Init ground
        self.ground_size = [1000., 1000., 10.]
        self.ground_position = [0., 0., 0.]
        self.ground_id = self.create_box(mass=0., half_extents=[self.ground_size[0] / 2, self.ground_size[1] / 2, self.ground_size[2] / 2], position=self.ground_position, color=[0.5, 0.5, 0.5, 1.])
        self._p.changeDynamics(bodyUniqueId=self.ground_id, linkIndex=-1, lateralFriction=0.8, restitution=0.5)

        # Init cylinder
        self.cylinder_radius = 2.
        self.cylinder_height = 3.
        self.cylinder_position_init = [self.ground_position[0], self.ground_position[1], self.ground_position[2] + self.ground_size[2] / 2 + self.cylinder_radius]
        self.cylinder_orientation_init = self._p.getQuaternionFromEuler(eulerAngles=[np.pi / 2, 0., 0.])  # roll along x-axis
        self.cylinder_id = self.create_cylinder(mass=25., radius=self.cylinder_radius, height=self.cylinder_height, position=self.cylinder_position_init, orientation=self.cylinder_orientation_init, color=[0., 0., 1., 1.]) 
        self._p.changeDynamics(bodyUniqueId=self.cylinder_id, linkIndex=-1, lateralFriction=0.8, restitution=0.5)

    def create_box(self, mass, half_extents, position, color):
        collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents)
        visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents, rgbaColor=color)
        return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position)

    def create_cylinder(self, mass, radius, height, position, orientation, color):
        collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_CYLINDER, radius=radius, height=height)
        visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_CYLINDER, radius=radius, length=height, rgbaColor=color)
        return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position, baseOrientation=orientation)

    def reset(self):
        observation = super().reset()

        # Reset cylinder position
        self._p.resetBasePositionAndOrientation(self.cylinder_id, self.cylinder_position_init, self.cylinder_orientation_init)

        # Reset robot position on the top of cylinder
        self._p.resetBasePositionAndOrientation(self.robot.robot_id, [self.cylinder_position_init[0], self.cylinder_position_init[1], self.cylinder_position_init[2] + self.cylinder_radius + self.robot.links["base"].position_init[2]], self.robot.links["base"].orientation_init)

        return observation

    def step(self, action):
        # Before taking action
        self.position = self.robot.links["base"].position

        observation, reward, terminated, truncated, info = super().step(action)

        return observation, reward, terminated, truncated, info

    def get_task_rewards(self, action):
        # After taking action
        new_position = self.robot.links["base"].position

        # Standing
        contact_points = self._p.getContactPoints(bodyA=self.robot.robot_id, bodyB=self.cylinder_id)
        objects_in_contact = {contact_point[2] for contact_point in contact_points if contact_point[3] not in {self.robot.links["left_foot"].index, self.robot.links["right_foot"].index}}
        standing = 2. if len(objects_in_contact) == 0 else -1.

        # Forward velocity
        forward_velocity = (new_position[0] - self.position[0]) / self.dt

        return {"standing": standing, "forward_velocity": forward_velocity}

    def get_terminated(self, action):
        # Terminate if not standing
        contact_points = self._p.getContactPoints(bodyA=self.robot.robot_id, bodyB=self.cylinder_id)
        objects_in_contact = {contact_point[2] for contact_point in contact_points if contact_point[3] not in {self.robot.links["left_foot"].index, self.robot.links["right_foot"].index}}
        is_standing = len(objects_in_contact) == 0

        # Terminate if not on cylinder or not standing
        is_on_cylinder = self.robot.links["base"].position[2] > 2 * self.cylinder_radius

        return not is_standing or not is_on_cylinder

    def get_success(self):
        # Success if rolled on cylinder
        return self.robot.links["base"].position[0] > 5.

</omni_epic/envs/humanoid/walk_on_cylinder.py>

<omni_epic/envs/r2d2/balance_board.py>
import numpy as np
from omni_epic.envs.r2d2.base import R2D2Env


class Env(R2D2Env):
    """
    Balance on a board placed on top of a rolling cylinder.

    Description:
    - A cylinder (radius 0.5 m and height 1 m) is placed on the ground and can roll along the y-axis.
    - A board (length 3 m, width 2 m and thickness 0.05 m) is placed on top of the cylinder.
    The robot is initialized on top of the board facing toward the positive x-axis.
    The task of the robot is to stand on the board and keep its balance on the board while the cylinder moves underneath.

    Success:
    The task is completed if the robot remains standing on the board for more than 10 s.

    Rewards:
    The robot is rewarded for remaining on the board.

    Termination:
    The task terminates if the robot falls of the board.
    """

    def __init__(self):
        super().__init__()

        # Init ground
        self.ground_size = [10., 10., 10.]
        self.ground_position = [0., 0., 0.]
        self.ground_id = self.create_box(mass=0., half_extents=[self.ground_size[0] / 2, self.ground_size[1] / 2, self.ground_size[2] / 2], position=self.ground_position, color=[0.5, 0.5, 0.5, 1.])
        self._p.changeDynamics(bodyUniqueId=self.ground_id, linkIndex=-1, lateralFriction=0.8, restitution=0.5)

        # Init cylinder
        self.cylinder_radius = 0.5
        self.cylinder_height = 1.
        self.cylinder_position_init = [self.ground_position[0], self.ground_position[1], self.ground_position[2] + self.ground_size[2] / 2 + self.cylinder_radius]
        self.cylinder_orientation_init = self._p.getQuaternionFromEuler(eulerAngles=[0., np.pi / 2, 0.])  # roll along y-axis
        self.cylinder_id = self.create_cylinder(mass=10., radius=self.cylinder_radius, height=self.cylinder_height, position=self.cylinder_position_init, orientation=self.cylinder_orientation_init, color=[0., 0., 1., 1.]) 
        self._p.changeDynamics(bodyUniqueId=self.cylinder_id, linkIndex=-1, lateralFriction=0.8, restitution=0.5)

        # Init board
        self.board_size = [2., 3., 0.05]
        self.board_position_init = [self.cylinder_position_init[0], self.cylinder_position_init[1], self.cylinder_position_init[2] + self.cylinder_radius + self.board_size[2] / 2]  # Init board above cylinder
        self.board_id = self.create_box(mass=10., half_extents=[self.board_size[0] / 2, self.board_size[1] / 2, self.board_size[2] / 2], position=self.board_position_init, color=[1., 0., 0., 1.])
        self._p.changeDynamics(bodyUniqueId=self.board_id, linkIndex=-1, lateralFriction=0.8, restitution=0.5)

    def create_box(self, mass, half_extents, position, color):
        collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents)
        visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents, rgbaColor=color)
        return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position)

    def create_cylinder(self, mass, radius, height, position, orientation, color):
        collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_CYLINDER, radius=radius, height=height)
        visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_CYLINDER, radius=radius, length=height, rgbaColor=color)
        return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position, baseOrientation=orientation)

    def reset(self):
        observation = super().reset()

        # Reset time
        self.time = 0.

        # Reset cylinder position
        self._p.resetBasePositionAndOrientation(self.cylinder_id, self.cylinder_position_init, self.cylinder_orientation_init)

        # Reset board position
        self._p.resetBasePositionAndOrientation(self.board_id, self.board_position_init, [0., 0., 0., 1.])

        # Reset robot position
        self._p.resetBasePositionAndOrientation(self.robot.robot_id, [self.board_position_init[0], self.board_position_init[1], self.board_position_init[2] + self.board_size[2] / 2 + self.robot.links["base"].position_init[2]], self.robot.links["base"].orientation_init)

        return observation

    def step(self, action):
        observation, reward, terminated, truncated, info = super().step(action)

        # Increase time
        self.time += self.dt

        return observation, reward, terminated, truncated, info

    def get_task_rewards(self, action):
        # On board
        on_board = 1. if self.robot.links["base"].position[2] > self.board_position_init[2] + self.board_size[2] / 2 else -1.
        return {"on_board": on_board}

    def get_terminated(self, action):
        # Terminate if not on board
        is_on_board = self.robot.links["base"].position[2] > self.board_position_init[2] + self.board_size[2] / 2
        return not is_on_board

    def get_success(self):
        # Success if on board after 10. s
        on_board = self.time >= 10. and self.robot.links["base"].position[2] > self.board_position_init[2] + self.board_size[2] / 2
        return on_board

</omni_epic/envs/r2d2/balance_board.py>

<omni_epic/envs/r2d2/base.py>
from omni_epic.envs.base import Env
from omni_epic.robots.r2d2 import R2D2Robot


class R2D2Env(Env):
	dt = 0.0165

	def __init__(self):
		# Init world
		super().__init__()

		# Init robot
		self.robot = R2D2Robot(self._p)

		self.action_space = self.robot.action_space
		self.observation_space = self.robot.observation_space

	def get_truncated(self, action):
		return False

</omni_epic/envs/r2d2/base.py>

<omni_epic/envs/r2d2/cross_bridge.py>
import numpy as np
from omni_epic.envs.r2d2.base import R2D2Env


class Env(R2D2Env):
    """
    Cross a pride-colored bridge to reach a platform.

    Description:
    - A start platform and an end platform (each 3 m in size and 0.5 m in thickness) are placed 30 m apart.
    - The two platforms are connected by a bridge (2 m wide) divided in multiple segments. Each segment has a different color corresponding to the pride colors.
    The robot is initialized on the start platform.
    The task of the robot is to cross the bridge to reach the end platform as fast as possible.

    Success:
    The task is successfully completed when the robot reaches the end platform.

    Rewards:
    To help the robot complete the task:
    - The robot receives a reward for each time step it remains on the bridge or platforms, encouraging steady progress.
    - The robot is rewarded based on how much it reduces the distance to the end platform, incentivizing swift movement towards the goal.

    Termination:
    The task terminates immediately if the robot falls off the start platform, any segment of the bridge, or the end platform.
    """

    def __init__(self):
        super().__init__()

        # Init start platform
        self.platform_size = [3., 3., 0.5]
        self.platform_start_position = [0., 0., 0.]
        self.platform_end_position = [self.platform_start_position[0] + 30., self.platform_start_position[1], self.platform_start_position[2]]
        self.platform_start_id = self.create_box(mass=0., half_extents=[self.platform_size[0] / 2, self.platform_size[1] / 2, self.platform_size[2] / 2], position=self.platform_start_position, color=[0.8, 0.8, 0.8, 1.])
        self.platform_end_id = self.create_box(mass=0., half_extents=[self.platform_size[0] / 2, self.platform_size[1] / 2, self.platform_size[2] / 2], position=self.platform_end_position, color=[0.8, 0.8, 0.8, 1.])

        # Init bridge
        self.bridge_length = self.platform_end_position[0] - self.platform_start_position[0] - self.platform_size[0]
        self.bridge_width = 2.
        pride_colors = [
            [1.0, 0.0, 0.0, 1.],  # Red
            [1.0, 0.5, 0.0, 1.],  # Orange
            [1.0, 1.0, 0.0, 1.],  # Yellow
            [0.0, 0.5, 0.0, 1.],  # Green
            [0.0, 0.0, 1.0, 1.],  # Blue
            [0.7, 0.0, 1.0, 1.],  # Violet
        ]

        # Segment length
        num_colors = len(pride_colors)
        segment_size = self.bridge_length / num_colors

        # Create segments
        for i, color in enumerate(pride_colors):
            segment_id = self.create_box(mass=0., half_extents=[segment_size / 2, self.bridge_width / 2, self.platform_size[2] / 2], position=[self.platform_start_position[0] + self.platform_size[0] / 2 + segment_size / 2 + i * segment_size, self.platform_start_position[1], self.platform_start_position[2]], color=color)
            self._p.changeDynamics(bodyUniqueId=segment_id, linkIndex=-1, lateralFriction=0.8, restitution=0.5)

    def create_box(self, mass, half_extents, position, color):
        collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents)
        visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents, rgbaColor=color)
        return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position)

    def get_object_position(self, object_id):
        return np.asarray(self._p.getBasePositionAndOrientation(object_id)[0])

    def get_distance_to_object(self, object_id):
        object_position = self.get_object_position(object_id)
        robot_position = self.robot.links["base"].position
        return np.linalg.norm(object_position[:2] - robot_position[:2])

    def reset(self):
        observation = super().reset()

        # Reset robot position on start platform
        self._p.resetBasePositionAndOrientation(self.robot.robot_id, [self.platform_start_position[0], self.platform_start_position[1], self.platform_start_position[2] + self.platform_size[2] / 2 + self.robot.links["base"].position_init[2]], self.robot.links["base"].orientation_init)

        return observation

    def step(self, action):
        # Before taking action
        self.distance_to_platform_end = self.get_distance_to_object(self.platform_end_id)

        observation, reward, terminated, truncated, info = super().step(action)

        return observation, reward, terminated, truncated, info

    def get_task_rewards(self, action):
        # After taking action
        new_distance_to_platform_end = self.get_distance_to_object(self.platform_end_id)

        # Survival
        survival = 1.

        # Reach end platform
        reach_platform_end = (self.distance_to_platform_end - new_distance_to_platform_end) / self.dt

        return {"survival": survival, "reach_platform_end": reach_platform_end}

    def get_terminated(self, action):
        # Terminate if fall off
        return self.robot.links["base"].position[2] < self.platform_start_position[2]

    def get_success(self):
        # Success if reach end platform
        is_on_platform_end = self.get_distance_to_object(self.platform_end_id) < self.platform_size[2] / 2
        return is_on_platform_end

</omni_epic/envs/r2d2/cross_bridge.py>

<omni_epic/envs/r2d2/cross_lava.py>
import numpy as np
from omni_epic.envs.r2d2.base import R2D2Env


class Env(R2D2Env):
    """
    Cross over lava on a boat to reach a target zone.

    Description:
    - The lava is simulated with an orange, 10 x 10 m heightfield.
    - There are two platforms on either side of the lava, each measuring 5 x 10 m. One serves as the start platform and the other as the end platform.
    - The boat is a box with dimensions 3 meters in length, 2 meters in width, and 0.2 meters in height. It is initialized next to the start platform at a random y-position.
    - The boat has a button that, when pressed, activates the boat to move over the lava at a speed of 3 meters per second.
    - The end platform has a target zone indicated by a green, transparent sphere.
    The robot's task is to jump onto the boat from the start platform, press the button to activate the boat, and travel across the lava to reach the end platform. The robot must then enter the target zone to complete the task.

    Success:
    The task is successfully completed when the robot enters the target zone on the end platform.

    Rewards:
    To guide the robot to complete the task:
    - The robot receives a reward for each time step it remains active and does not fall off or touch the lava.
    - The robot is rewarded for making progress towards pressing the button on the boat.
    - Additional rewards are given for progressing towards the target zone, with a significant bonus for entering the target zone.

    Termination:
    The task terminates immediately if the robot falls off the platform or the boat, or if it touches the simulated lava.
    """

    def __init__(self):
        super().__init__()

        # Init lava
        self.lava_size = [10., 10.]
        self.lava_height = 0.1
        self.lava_position = [0., 0., 0.]
        self.lava_id = self.create_heightfield(
            size=self.lava_size,
            height_max=self.lava_height,  # create small bumps to create a fluid-like surface
            position=self.lava_position,
            resolution=20,  # number of points per meter
            repeats=2,
        )
        self._p.changeVisualShape(objectUniqueId=self.lava_id, linkIndex=-1, rgbaColor=[1., 0.3, 0.1, 1.])  # change to lava color

        # Init platforms
        self.platform_size = [5., self.lava_size[1], 1.]
        self.platform_start_position = [self.lava_position[0] - self.lava_size[0] / 2 - self.platform_size[0] / 2, self.lava_position[1], self.lava_position[2]]
        self.platform_end_position = [self.lava_position[0] + self.lava_size[0] / 2 + self.platform_size[0] / 2, self.lava_position[1], self.lava_position[2]]
        self.platform_start_id = self.create_box(mass=0., half_extents=[self.platform_size[0] / 2, self.platform_size[1] / 2, self.platform_size[2] / 2], position=self.platform_start_position, color=[0.3, 0.3, 0.3, 1.])
        self.platform_end_id = self.create_box(mass=0., half_extents=[self.platform_size[0] / 2, self.platform_size[1] / 2, self.platform_size[2] / 2], position=self.platform_end_position, color=[0.3, 0.3, 0.3, 1.])
        self._p.changeDynamics(bodyUniqueId=self.platform_start_id, linkIndex=-1, lateralFriction=0.8, restitution=0.5)
        self._p.changeDynamics(bodyUniqueId=self.platform_end_id, linkIndex=-1, lateralFriction=0.8, restitution=0.5)

        # Init boat
        self.boat_size = [3., 2., 0.2]
        self.boat_position_init = [self.lava_position[0] - self.lava_size[0] / 2 + self.boat_size[0] / 2, self.lava_position[1], self.boat_size[2] / 2]
        self.boat_speed = 3.
        self.boat_id = self.create_box(mass=0., half_extents=[self.boat_size[0] / 2, self.boat_size[1] / 2, self.boat_size[2] / 2], position=self.boat_position_init, color=[0.8, 0.8, 0.8, 1.])
        self._p.changeDynamics(bodyUniqueId=self.boat_id, linkIndex=-1, lateralFriction=0.8, restitution=0.5)

        # Init button
        self.button_radius = 0.25
        self.button_height = 0.25
        self.button_position_init = [self.boat_position_init[0] + self.boat_size[0] / 4, self.lava_position[1], self.boat_position_init[2] + self.boat_size[2] / 2 + self.button_height / 2]  # put button on the right side of the boat
        self.button_id = self.create_cylinder(mass=0., radius=self.button_radius, height=self.button_height, position=self.button_position_init, color=[0., 0.5, 0., 1.])

        # Init target zone
        self.target_zone_radius = 1.5
        self.target_zone_id = self.create_sphere(mass=0., radius=self.target_zone_radius, collision=False, position=[self.platform_end_position[0], self.platform_end_position[1], self.platform_end_position[2] + self.platform_size[2] / 2], color=[0., 1., 0., 0.5])

        self.objects_on_boat = [self.button_id]

    def create_box(self, mass, half_extents, position, color):
        collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents)
        visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents, rgbaColor=color)
        return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position)

    def create_cylinder(self, mass, radius, height, position, color):
        collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_CYLINDER, radius=radius, height=height)
        visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_CYLINDER, radius=radius, length=height, rgbaColor=color)
        return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position)

    def create_sphere(self, mass, radius, collision, position, color):
        if collision:
            collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_SPHERE, radius=radius)
            visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_SPHERE, radius=radius, rgbaColor=color)
            return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position)
        else:
            visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_SPHERE, radius=radius, rgbaColor=color)
            return self._p.createMultiBody(baseMass=mass, baseVisualShapeIndex=visual_shape_id, basePosition=position)

    def create_heightfield(self, size, height_max, position, resolution, repeats=2):
        heightfield_data = np.random.uniform(low=0., high=height_max, size=(int(size[0] * resolution / repeats), int(size[1] * resolution / repeats)))
        heightfield_data = np.repeat(np.repeat(heightfield_data, repeats, axis=0), repeats, axis=1)
        mesh_scale = [1/resolution, 1/resolution, 1.]
        heightfield_collision_shape_id = self._p.createCollisionShape(
            shapeType=self._p.GEOM_HEIGHTFIELD,
            meshScale=mesh_scale,
            heightfieldData=heightfield_data.reshape(-1),
            numHeightfieldRows=heightfield_data.shape[0],
            numHeightfieldColumns=heightfield_data.shape[1],
        )
        return self._p.createMultiBody(baseMass=0., baseCollisionShapeIndex=heightfield_collision_shape_id, basePosition=[position[0], position[1], position[2] + mesh_scale[2] * height_max / 2])

    def get_object_position(self, object_id):
        return np.asarray(self._p.getBasePositionAndOrientation(object_id)[0])

    def get_distance_to_object(self, object_id):
        object_position = self.get_object_position(object_id)
        robot_position = self.robot.links["base"].position
        return np.linalg.norm(object_position[:2] - robot_position[:2])

    def reset(self):
        observation = super().reset()

        # Reset boat position
        boat_y_init = np.random.uniform(low=-self.lava_size[1] / 2 + self.boat_size[1] / 2, high=self.lava_size[1] / 2 - self.boat_size[1] / 2)  # randomize y position
        self._p.resetBasePositionAndOrientation(self.boat_id, [self.boat_position_init[0], boat_y_init, self.boat_position_init[2]], [0., 0., 0., 1.])

        # Reset button position
        self._p.resetBasePositionAndOrientation(self.button_id, [self.button_position_init[0], boat_y_init, self.button_position_init[2]], [0., 0., 0., 1.])

        # Reset target zone
        target_zone_y = np.random.uniform(low=-self.lava_size[1] / 2 + self.target_zone_radius, high=self.lava_size[1] / 2 - self.target_zone_radius)  # randomize y position
        self.target_zone_position = [self.platform_end_position[0], target_zone_y, self.platform_end_position[2] + self.platform_size[2] / 2]
        self._p.resetBasePositionAndOrientation(self.target_zone_id, self.target_zone_position, [0., 0., 0., 1.])

        # Reset robot position
        self._p.resetBasePositionAndOrientation(self.robot.robot_id, [self.platform_start_position[0], self.platform_start_position[1], self.platform_start_position[2] + self.platform_size[2] / 2 + self.robot.links["base"].position_init[2]], self.robot.links["base"].orientation_init)

        return observation

    def step(self, action):
        # Before taking action
        self.distance_to_button = self.get_distance_to_object(self.button_id)
        self.distance_to_target_zone = self.get_distance_to_object(self.target_zone_id)
        self.has_touched_platform_end = len(self._p.getContactPoints(bodyA=self.robot.robot_id, bodyB=self.platform_end_id)) > 0

        observation, reward, terminated, truncated, info = super().step(action)

        # Check if button is pressed
        contact_points = self._p.getContactPoints(bodyA=self.robot.robot_id, bodyB=self.button_id)
        button_pressed = len(contact_points) > 0

        if button_pressed:
            # Move boat and everything on boat forward
            for body_id in [self.boat_id] + self.objects_on_boat:
                body_position = self.get_object_position(body_id)
                new_object_position = body_position + np.array([self.boat_speed * self.dt, 0., 0.])
                self._p.resetBasePositionAndOrientation(body_id, new_object_position, [0., 0., 0., 1.])

        return observation, reward, terminated, truncated, info

    def get_task_rewards(self, action):
        # After taking action
        new_distance_to_button = self.get_distance_to_object(self.button_id)
        new_distance_to_target_zone = self.get_distance_to_object(self.target_zone_id)

        # Survival
        survival = 1.

        # Reach button
        reach_button = (self.distance_to_button - new_distance_to_button) / self.dt

        # Reach target zone
        reach_target_zone = (self.distance_to_target_zone - new_distance_to_target_zone) / self.dt
        if self.distance_to_target_zone < self.target_zone_radius:
            reach_target_zone += 5.

        return {"survival": survival, "reach_button": reach_button, "reach_target_zone": reach_target_zone}

    def get_terminated(self, action):
        # Terminate if touch lava
        contact_points = self._p.getContactPoints(bodyA=self.robot.robot_id, bodyB=self.lava_id)
        is_touching_lava = len(contact_points) > 0

        # Terminate if fall off
        is_fall_off = self.robot.links["base"].position[2] < self.platform_start_position[2]
        return is_touching_lava or is_fall_off

    def get_success(self):
        # Success if stand in the target zone
        distance_to_target_zone = self.get_distance_to_object(self.target_zone_id)
        return distance_to_target_zone < self.target_zone_radius

</omni_epic/envs/r2d2/cross_lava.py>

<omni_epic/envs/r2d2/go_down_stairs.py>
import numpy as np
from omni_epic.envs.r2d2.base import R2D2Env


class Env(R2D2Env):
    """
    Descend a series of stairs to reach the ground.

    Description:
    - The environment consists of a ground platform (1000 m x 10 m x 10 m) and a set of 10 steps.
    - Each step has dimensions of 1 m in length, 10 m in width, and 0.2 m in height.
    - The steps are positioned to form a descending staircase starting from an initial height, with each subsequent step lower than the previous one.
    The robot is initialized at the top of the stairs.

    Success:
    The task is completed when the robot successfully descends the stairs and touches the ground platform.

    Rewards:
    The help the robot complete the task:
    - The robot is rewarded for survival at each time step.
    - The robot is rewarded for forward velocity, incentivizing it to move down the stairs.

    Termination:
    The task terminates immediately if the robot falls off the stairs or the ground platform.
    """

    def __init__(self):
        super().__init__()

        # Init ground
        self.ground_size = [1000., 10., 10.]
        self.ground_position = [0., 0., 0.]
        self.ground_id = self.create_box(mass=0., half_extents=[self.ground_size[0] / 2, self.ground_size[1] / 2, self.ground_size[2] / 2], position=self.ground_position, color=[0.5, 0.5, 0.5, 1.])
        self._p.changeDynamics(bodyUniqueId=self.ground_id, linkIndex=-1, lateralFriction=0.8, restitution=0.5)

        # Init stairs
        self.num_steps = 10
        self.step_size = [1.0, 10., 0.2]
        self.step_position_init = [self.ground_position[0], self.ground_position[1], self.ground_position[2] + self.ground_size[2] / 2 + self.num_steps * self.step_size[2]]
        self.create_stairs_down(step_size=self.step_size, step_position_init=self.step_position_init, num_steps=self.num_steps)

    def create_box(self, mass, half_extents, position, color):
        collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents)
        visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents, rgbaColor=color)
        return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position)

    def create_stairs_down(self, step_size, step_position_init, num_steps):
        color_1 = np.array([1., 0., 0.])
        color_2 = np.array([0., 0., 1.])
        for i in range(num_steps):
            step_position = [step_position_init[0] + i * step_size[0], step_position_init[1], step_position_init[2] - i * step_size[2]]
            interpolation = i / (num_steps - 1)
            step_color = (1 - interpolation) * color_1 + interpolation * color_2  # shade steps for visualization
            self.create_box(mass=0., half_extents=[step_size[0] / 2, step_size[1] / 2, step_size[2] / 2], position=step_position, color=np.append(step_color, 1.))

    def reset(self):
        observation = super().reset()

        # Reset robot position at the top of the stairs
        self._p.resetBasePositionAndOrientation(self.robot.robot_id, [self.step_position_init[0], self.step_position_init[1], self.step_position_init[2] + self.step_size[2] / 2 + self.robot.links["base"].position_init[2]], self.robot.links["base"].orientation_init)

        return observation

    def step(self, action):
        # Before taking action
        self.position = self.robot.links["base"].position

        observation, reward, terminated, truncated, info = super().step(action)

        return observation, reward, terminated, truncated, info

    def get_task_rewards(self, action):
        # After taking action
        new_position = self.robot.links["base"].position

        # Survival
        survival = 1.

        # Forward velocity
        forward_velocity = (new_position[0] - self.position[0]) / self.dt

        return {"survival": survival, "forward_velocity": forward_velocity}

    def get_terminated(self, action):
        # Terminate if fall off
        return self.robot.links["base"].position[2] < self.ground_position[2]

    def get_success(self):
        # Success if reach end stairs and touch ground
        contact_points = self._p.getContactPoints(bodyA=self.robot.robot_id, bodyB=self.ground_id)
        is_on_ground = len(contact_points) > 0
        return is_on_ground

</omni_epic/envs/r2d2/go_down_stairs.py>

<omni_epic/envs/r2d2/go_forward.py>
import numpy as np
from omni_epic.envs.r2d2.base import R2D2Env


class Env(R2D2Env):
    """
    Go forward.

    Description:
    The robot is standing on a flat ground represented by a box.
    The task of the robot is to go forward as fast as possible.

    Success:
    The task is completed if the robot runs forward for 10 meters.

    Rewards:
    The help the robot complete the task:
    - The robot is rewarded for survival at each time step.
    - The robot is rewarded for forward velocity, incentivizing it to move forward quickly.

    Termination:
    None.
    """

    def __init__(self):
        super().__init__()

        # Init ground
        self.ground_size = [1000., 1000., 10.]
        self.ground_position = [0., 0., 0.]
        self.ground_id = self.create_box(mass=0., half_extents=[self.ground_size[0] / 2, self.ground_size[1] / 2, self.ground_size[2] / 2], position=self.ground_position, color=[0.5, 0.5, 0.5, 1.])
        self._p.changeDynamics(bodyUniqueId=self.ground_id, linkIndex=-1, lateralFriction=0.8, restitution=0.5)

    def create_box(self, mass, half_extents, position, color):
        collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents)
        visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents, rgbaColor=color)
        return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position)

    def reset(self):
        observation = super().reset()

        # Reset robot position
        self._p.resetBasePositionAndOrientation(self.robot.robot_id, [self.ground_position[0], self.ground_position[1], self.ground_position[2] + self.ground_size[2] / 2 + self.robot.links["base"].position_init[2]], self.robot.links["base"].orientation_init)

        return observation

    def step(self, action):
        # Before taking action
        self.position = self.robot.links["base"].position

        observation, reward, terminated, truncated, info = super().step(action)

        return observation, reward, terminated, truncated, info

    def get_task_rewards(self, action):
        # After taking action
        new_position = self.robot.links["base"].position

        # Survival
        survival = 1.

        # Forward velocity
        forward_velocity = (new_position[0] - self.position[0]) / self.dt

        return {"survival": survival, "forward_velocity": forward_velocity}

    def get_terminated(self, action):
        # No termination
        return False

    def get_success(self):
        # Success if run forward for 10 meters
        return self.robot.links["base"].position[0] > 10.

</omni_epic/envs/r2d2/go_forward.py>

<omni_epic/envs/r2d2/go_to_box.py>
import numpy as np
from omni_epic.envs.r2d2.base import R2D2Env


class Env(R2D2Env):
    """
    Reach a box.

    Description:
    - The environment consists of a large flat ground measuring 1000 x 1000 x 10 meters.
    - A box with dimensions 1 x 1 x 1 meter is placed randomly on the ground in a radius of 25 m around the robot. To avoid collisions, the box cannot spawn in a radius of 2 m around the robot.
    - The robot is initialized at a fixed position on the ground.
    The task of the robot is to reach and touch the box.

    Success:
    The task is completed if the robot makes contact with the box.

    Rewards:
    To help the robot complete the task:
    - The robot is rewarded for survival.
    - The robot is rewarded for moving closer to the box.

    Termination:
    None.
    """

    def __init__(self):
        super().__init__()

        # Init ground
        self.ground_size = [1000., 1000., 10.]
        self.ground_position = [0., 0., 0.]
        self.ground_id = self.create_box(mass=0., half_extents=[self.ground_size[0] / 2, self.ground_size[1] / 2, self.ground_size[2] / 2], position=self.ground_position, color=[0.5, 0.5, 0.5, 1.])
        self._p.changeDynamics(bodyUniqueId=self.ground_id, linkIndex=-1, lateralFriction=0.8, restitution=0.5)

        # Init box
        self.box_size = [1., 1., 1.]
        self.box_id = self.create_box(mass=1., half_extents=[self.box_size[0] / 2, self.box_size[1] / 2, self.box_size[2] / 2], position=[0., 0., 0.], color=[1., 0., 0., 1.])

        # Starting position of the robot
        self.robot_position_init = [self.ground_position[0], self.ground_position[1], self.ground_position[2] + self.ground_size[2] / 2 + self.robot.links["base"].position_init[2]]

    def create_box(self, mass, half_extents, position, color):
        collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents)
        visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents, rgbaColor=color)
        return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position)

    def get_object_position(self, object_id):
        return np.asarray(self._p.getBasePositionAndOrientation(object_id)[0])

    def get_distance_to_object(self, object_id):
        object_position = self.get_object_position(object_id)
        robot_position = self.robot.links["base"].position
        return np.linalg.norm(object_position[:2] - robot_position[:2])

    def reset(self):
        observation = super().reset()

        # Reset robot position on ground
        self._p.resetBasePositionAndOrientation(self.robot.robot_id, self.robot_position_init, self.robot.links["base"].orientation_init)

        # Reset box position
        angle = np.random.uniform(0., 2 * np.pi)
        radius = np.random.uniform(2., 25.)
        self._p.resetBasePositionAndOrientation(self.box_id, [self.robot_position_init[0] + radius * np.cos(angle), self.robot_position_init[1] + radius * np.sin(angle), self.ground_position[2] + self.ground_size[2] / 2 + self.box_size[2] / 2], [0., 0., 0., 1.])

        return observation

    def step(self, action):
        # Before taking action
        self.distance_to_box = self.get_distance_to_object(self.box_id)

        observation, reward, terminated, truncated, info = super().step(action)

        return observation, reward, terminated, truncated, info

    def get_task_rewards(self, action):
        # After taking action
        new_distance_to_box = self.get_distance_to_object(self.box_id)

        # Survival
        survival = 1.

        # Reach box
        reach_box = (self.distance_to_box - new_distance_to_box) / self.dt

        return {"survival": survival, "reach_box": reach_box}

    def get_terminated(self, action):
        # No termination
        return False

    def get_success(self):
        # Success if touch box
        contact_points_box = self._p.getContactPoints(bodyA=self.robot.robot_id, bodyB=self.box_id)
        is_touching_box = len(contact_points_box) > 0
        return is_touching_box

</omni_epic/envs/r2d2/go_to_box.py>

<omni_epic/envs/r2d2/kick_ball.py>
import numpy as np
from omni_epic.envs.r2d2.base import R2D2Env


class Env(R2D2Env):
    """
    Kick a ball.

    Description:
    - The environment consists of a large flat ground measuring 1000 x 1000 x 10 meters.
    - A ball with a radius of 0.5 meters is placed randomly on the ground.
    - The robot is initialized at a fixed position on the ground.
    - The task of the robot is to move across the ground, reach the ball, and kick it as far away as possible.

    Success:
    The task is successfully completed if the robot kicks the ball so that it moves more than 10 meters away from its initial position.

    Rewards:
    To help the robot complete the task:
    - The robot is rewarded for survival.
    - The robot is rewarded for decreasing its distance to the ball.
    - The robot is rewarded for increasing the velocity of the ball to guide the robot to kick the ball.

    Termination:
    The task does not have a specific termination condition.
    """

    def __init__(self):
        super().__init__()

        # Init ground
        self.ground_size = [1000., 1000., 10.]
        self.ground_position = [0., 0., 0.]
        self.ground_id = self.create_box(mass=0., half_extents=[self.ground_size[0] / 2, self.ground_size[1] / 2, self.ground_size[2] / 2], position=self.ground_position, color=[0.5, 0.5, 0.5, 1.])
        self._p.changeDynamics(bodyUniqueId=self.ground_id, linkIndex=-1, lateralFriction=0.8, restitution=0.5)

        # Init ball
        self.ball_radius = 0.5
        self.ball_id = self.create_sphere(mass=1., radius=self.ball_radius, position=[0., 0., 0.], color=[1., 0., 0., 1.])

        # Starting position of the robot
        self.robot_position_init = [self.ground_position[0], self.ground_position[1], self.ground_position[2] + self.ground_size[2] / 2 + self.robot.links["base"].position_init[2]]

    def create_box(self, mass, half_extents, position, color):
        collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents)
        visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents, rgbaColor=color)
        return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position)

    def create_sphere(self, mass, radius, position, color):
        collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_SPHERE, radius=radius)
        visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_SPHERE, radius=radius, rgbaColor=color)
        return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position)

    def get_object_position(self, object_id):
        return np.asarray(self._p.getBasePositionAndOrientation(object_id)[0])

    def get_distance_to_object(self, object_id):
        object_position = self.get_object_position(object_id)
        robot_position = self.robot.links["base"].position
        return np.linalg.norm(object_position[:2] - robot_position[:2])

    def reset(self):
        observation = super().reset()

        # Reset robot position on ground
        self._p.resetBasePositionAndOrientation(self.robot.robot_id, self.robot_position_init, self.robot.links["base"].orientation_init)

        # Reset ball position
        ball_y_init = np.random.uniform(self.robot_position_init[1] - 2., self.robot_position_init[1] + 2.)
        self._p.resetBasePositionAndOrientation(self.ball_id, [self.robot_position_init[0] + 5., ball_y_init, self.ground_position[2] + self.ground_size[2] / 2 + self.ball_radius], [0., 0., 0., 1.])

        return observation

    def step(self, action):
        # Before taking action
        self.distance_to_ball = self.get_distance_to_object(self.ball_id)
        self.ball_position = self.get_object_position(self.ball_id)

        observation, reward, terminated, truncated, info = super().step(action)

        return observation, reward, terminated, truncated, info

    def get_task_rewards(self, action):
        # After taking action
        new_distance_to_ball = self.get_distance_to_object(self.ball_id)
        new_ball_position = self.get_object_position(self.ball_id) 

        # Survival
        survival = 1.

        # Reach ball
        reach_ball = (self.distance_to_ball - new_distance_to_ball) / self.dt

        # Velocity of ball
        ball_velocity = np.linalg.norm(new_ball_position - self.ball_position) / self.dt

        return {"survival": survival, "reach_ball": reach_ball, "ball_velocity": ball_velocity}

    def get_terminated(self, action):
        # No termination
        return False

    def get_success(self):
        # Success if kick ball 10 meters away from origin
        ball_distance_to_origin = np.linalg.norm(self.get_object_position(self.ball_id))
        return ball_distance_to_origin > 10.

</omni_epic/envs/r2d2/kick_ball.py>

<omni_epic/envs/r2d2/maze.py>
import numpy as np
from omni_epic.envs.r2d2.base import R2D2Env


class Env(R2D2Env):
    """
    Navigate through a maze to reach the end position.

    Description:
    - The environment consists of a large flat ground measuring 1000 x 1000 x 10 m.
    - A maze is constructed on the ground using walls of height 1 meter and scale 3 m per cell.
    - The maze is represented by a 2D array where 0 indicates an empty space, 1 indicates a wall, 2 indicates the start position, and 3 indicates the end position.
    - The robot is initialized at the start position in the maze.
    - The task of the robot is to navigate through the maze and reach the end position.

    Success:
    The task is completed if the robot reaches the end position in the maze.

    Rewards:
    To guide the robot to complete the task:
    - The robot receives a reward at each time step for survival.
    - The robot is rewarded for making progress towards the end position in the maze.

    Termination:
    The task does not have a specific termination condition and continues until the robot successfully reaches the end position.
    """

    def __init__(self):
        super().__init__()

        # Init ground
        self.ground_size = [1000., 1000., 10.]
        self.ground_position = [0., 0., 0.]
        self.ground_id = self.create_box(mass=0., half_extents=[self.ground_size[0] / 2, self.ground_size[1] / 2, self.ground_size[2] / 2], position=self.ground_position, color=[0.5, 0.5, 0.5, 1.])
        self._p.changeDynamics(bodyUniqueId=self.ground_id, linkIndex=-1, lateralFriction=0.8, restitution=0.5)

        # Init maze - 0 is empty, 1 is wall, 2 is start, 3 is end
        self.maze_height = 1.
        self.maze_scale = 3.
        maze = np.array([
            [1, 1, 1, 3, 1, 1],
            [1, 0, 0, 0, 0, 1],
            [1, 0, 1, 1, 0, 1],
            [2, 0, 0, 0, 0, 1],
            [1, 1, 1, 1, 1, 1],
        ])
        for index, value in np.ndenumerate(maze):
                if value == 1:
                    self.create_box(0., half_extents=[self.maze_scale / 2, self.maze_scale / 2, self.maze_height / 2], position=[self.maze_scale * index[1], -self.maze_scale * index[0], self.ground_position[2] + self.ground_size[2] / 2 + self.maze_height / 2], color=[0.2, 0.2, 0.2, 1])

        # Get start and end position
        start_position_index = np.squeeze(np.argwhere(maze == 2))
        self.start_position = self.maze_scale * np.array([start_position_index[1], -start_position_index[0]])
        end_position_index = np.squeeze(np.argwhere(maze == 3))
        self.end_position = self.maze_scale * np.array([end_position_index[1], -end_position_index[0]])

    def create_box(self, mass, half_extents, position, color):
        collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents)
        visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents, rgbaColor=color)
        return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position)

    def reset(self):
        observation = super().reset()

        # Reset robot position at start position
        self._p.resetBasePositionAndOrientation(self.robot.robot_id, [self.start_position[0], self.start_position[1], self.ground_position[2] + self.ground_size[2] / 2 + self.robot.links["base"].position_init[2]], self.robot.links["base"].orientation_init)

        return observation

    def step(self, action):
        # Before taking action
        self.position = self.robot.links["base"].position
        self.distance_to_end = np.linalg.norm(self.position[:2] - self.end_position)

        observation, reward, terminated, truncated, info = super().step(action)

        return observation, reward, terminated, truncated, info

    def get_task_rewards(self, action):
        # After taking action
        new_position = self.robot.links["base"].position
        new_distance_to_end = np.linalg.norm(new_position[:2] - self.end_position)

        # Survival
        survival = 1.

        # Progress in the maze
        maze_progress = (self.distance_to_end - new_distance_to_end) / self.dt

        return {"survival": survival, "maze_progress": maze_progress}

    def get_terminated(self, action):
        # No termination
        return False

    def get_success(self):
        # Success if reach end of maze
        return np.linalg.norm(self.robot.links["base"].position[:2] - self.end_position) < self.maze_scale

</omni_epic/envs/r2d2/maze.py>

<omni_epic/envs/r2d2/open_door.py>
import numpy as np
from omni_epic.envs.r2d2.base import R2D2Env


class Env(R2D2Env):
    """
    Activate a lever to open a door and move through the door.

    Description:
    - The environment consists of a large platform measuring 1000 x 10 x 0.1 meters.
    - The robot is initialized at a fixed position on the platform.
    - A door with dimensions 0.5 x 2 x 2 meters is placed on the platform, 5 m away from the robot, initially closed.
    - The door is flanked by walls to prevent the robot from bypassing it.
    - A lever is placed on the platform, 2 meters to the left of the door.
    - The task of the robot is to move to the lever, activate it to open the door, and then pass through the door.

    Success:
    The task is successfully completed if the robot passes through the door and moves more than 10 m beyond the initial position.

    Rewards:
    To guide the robot to complete the task:
    - The robot receives a survival reward at each time step.
    - The robot is rewarded for decreasing its distance to the lever.
    - The robot receives a bonus rewards for activating the lever to open the door.
    - Once the door is open, the robot is rewarded for moving forward.

    Termination:
    The task terminates immediately if the robot falls off the stairs or the ground platform.
    """

    def __init__(self):
        super().__init__()

        self.robot_position_init = [0., 0., 0.]

        # Init platform
        self.platform_size = [1000., 10., 0.1]
        self.platform_position = [self.robot_position_init[0] + self.platform_size[0] / 2 - 2., self.robot_position_init[1], self.robot_position_init[2] - self.platform_size[2] / 2]  # offset by 2 m to avoid off-edge or on-edge placement
        self.platform_id = self.create_box(mass=0., half_extents=[self.platform_size[0] / 2, self.platform_size[1] / 2, self.platform_size[2] / 2], position=self.platform_position, color=[0.5, 0.5, 0.5, 1.])
        self._p.changeDynamics(bodyUniqueId=self.platform_id, linkIndex=-1, lateralFriction=0.8, restitution=0.5)

        # Init door
        self.door_size = [0.5, 2., 2.]
        self.door_position_init = [self.robot_position_init[0] + 5., self.platform_position[1], self.platform_position[2] + self.platform_size[2] / 2 + self.door_size[2] / 2]
        self.door_id = self.create_box(mass=0., half_extents=[self.door_size[0] / 2, self.door_size[1] / 2, self.door_size[2] / 2], position=self.door_position_init, color=[1., 0., 0., 1.])
        self.door_open = False

        # Init wall
        self.wall_size = [self.door_size[0], (self.platform_size[1] - self.door_size[1]) / 2, self.door_size[2]]  # walls plus door span the full platform to prevent robot to go around
        self.create_box(mass=0., half_extents=[self.wall_size[0] / 2, self.wall_size[1] / 2, self.wall_size[2] / 2], position=[self.door_position_init[0], self.door_position_init[1] + self.door_size[1] / 2 + self.wall_size[1] / 2, self.platform_position[2] + self.platform_size[2] / 2 + self.wall_size[2] / 2], color=[0., 0., 1., 1.])  # left section
        self.create_box(mass=0., half_extents=[self.wall_size[0] / 2, self.wall_size[1] / 2, self.wall_size[2] / 2], position=[self.door_position_init[0], self.door_position_init[1] - self.door_size[1] / 2 - self.wall_size[1] / 2, self.platform_position[2] + self.platform_size[2] / 2 + self.wall_size[2] / 2], color=[0., 0., 1., 1.])  # right section

        # Init lever
        self.lever_radius = 0.05
        self.lever_height = 0.5
        lever_position = [self.door_position_init[0] - 2., self.door_size[1], self.platform_position[2] + self.platform_size[2] / 2 + self.lever_height / 2]  # two meters to the left of the door on the platform
        self.lever_id = self.create_cylinder(mass=0., radius=self.lever_radius, height=self.lever_height, position=lever_position, color=[0.5, 0.25, 0., 1.])

    def create_box(self, mass, half_extents, position, color):
        collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents)
        visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents, rgbaColor=color)
        return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position)

    def create_cylinder(self, mass, radius, height, position, color):
        collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_CYLINDER, radius=radius, height=height)
        visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_CYLINDER, radius=radius, length=height, rgbaColor=color)
        return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position)

    def get_object_position(self, object_id):
        return np.asarray(self._p.getBasePositionAndOrientation(object_id)[0])

    def get_distance_to_object(self, object_id):
        object_position = self.get_object_position(object_id)
        robot_position = self.robot.links["base"].position
        return np.linalg.norm(object_position[:2] - robot_position[:2])

    def reset(self):
        observation = super().reset()

        # Reset door
        self.door_open = False
        self._p.resetBasePositionAndOrientation(self.door_id, self.door_position_init, [0., 0., 0., 1.])

        # Reset robot position
        self._p.resetBasePositionAndOrientation(self.robot.robot_id, [self.robot_position_init[0], self.robot_position_init[1], self.robot_position_init[2] + self.robot.links["base"].position_init[2]], self.robot.links["base"].orientation_init)

        return observation

    def step(self, action):
        # Before taking action
        self.position = self.robot.links["base"].position
        self.distance_to_lever = self.get_distance_to_object(self.lever_id)

        observation, reward, terminated, truncated, info = super().step(action)

        contact_points = self._p.getContactPoints(bodyA=self.robot.robot_id, bodyB=self.lever_id)
        if len(contact_points) > 0 and not self.door_open:
            self.door_open = True
            self._p.resetBasePositionAndOrientation(self.door_id, [self.door_position_init[0], self.door_position_init[1] + self.door_size[1], self.door_position_init[2]], [0., 0., 0., 1.])

        return observation, reward, terminated, truncated, info

    def get_task_rewards(self, action):
        # After taking action
        new_position = self.robot.links["base"].position
        new_distance_to_lever = self.get_distance_to_object(self.lever_id)

        # Survival
        survival = 1.

        # Reach lever
        if not self.door_open and len(self._p.getContactPoints(bodyA=self.robot.robot_id, bodyB=self.lever_id)) == 0:
            reach_lever = (self.distance_to_lever - new_distance_to_lever) / self.dt
        elif not self.door_open and len(self._p.getContactPoints(bodyA=self.robot.robot_id, bodyB=self.lever_id)) > 0:
            reach_lever = 10.
        else:
            reach_lever = 0.

        # Forward velocity
        if self.door_open:
            forward_velocity = (new_position[0] - self.position[0]) / self.dt
        else:
            forward_velocity = 0.

        return {"survival": survival, "reach_lever": reach_lever, "forward_velocity": forward_velocity}

    def get_terminated(self, action):
        # Terminate if fall off
        return self.robot.links["base"].position[2] < self.platform_position[2]

    def get_success(self):
        # Success if pass through door
        return self.robot.links["base"].position[0] > 10.

</omni_epic/envs/r2d2/open_door.py>

<omni_epic/envs/r2d2/walk_on_cylinder.py>
import numpy as np
from omni_epic.envs.r2d2.base import R2D2Env


class Env(R2D2Env):
    """
    Go forward on top of a rolling cylinder.

    Description:
    - The environment consists of a large flat ground measuring 1000 x 1000 x 10 m.
    - A cylinder with a radius of 2 m and a height of 3 m is placed on the ground and can roll along the x-axis.
    - The cylinder's initial position is at the center of the ground, and it is oriented to roll along the x-axis.
    - The robot is initialized on top of the cylinder.
    - The task of the robot is to go forward while balancing on top of the rolling cylinder.

    Success:
    The task is completed if the robot rolls more than 5 m forward without falling off.

    Rewards:
    To guide the robot to complete the task:
    - The robot receives a reward for each time step it remains balanced on the cylinder.
    - The robot receives a reward for forward velocity along the x-axis.

    Termination:
    The task terminates immediately if the robot falls off the cylinder.
    """

    def __init__(self):
        super().__init__()

        # Init ground
        self.ground_size = [1000., 1000., 10.]
        self.ground_position = [0., 0., 0.]
        self.ground_id = self.create_box(mass=0., half_extents=[self.ground_size[0] / 2, self.ground_size[1] / 2, self.ground_size[2] / 2], position=self.ground_position, color=[0.5, 0.5, 0.5, 1.])
        self._p.changeDynamics(bodyUniqueId=self.ground_id, linkIndex=-1, lateralFriction=0.8, restitution=0.5)

        # Init cylinder
        self.cylinder_radius = 2.
        self.cylinder_height = 3.
        self.cylinder_position_init = [self.ground_position[0], self.ground_position[1], self.ground_position[2] + self.ground_size[2] / 2 + self.cylinder_radius]
        self.cylinder_orientation_init = self._p.getQuaternionFromEuler(eulerAngles=[np.pi / 2, 0., 0.])  # roll along x-axis
        self.cylinder_id = self.create_cylinder(mass=25., radius=self.cylinder_radius, height=self.cylinder_height, position=self.cylinder_position_init, orientation=self.cylinder_orientation_init, color=[0., 0., 1., 1.]) 
        self._p.changeDynamics(bodyUniqueId=self.cylinder_id, linkIndex=-1, lateralFriction=0.8, restitution=0.5)

    def create_box(self, mass, half_extents, position, color):
        collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents)
        visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_BOX, halfExtents=half_extents, rgbaColor=color)
        return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position)

    def create_cylinder(self, mass, radius, height, position, orientation, color):
        collision_shape_id = self._p.createCollisionShape(shapeType=self._p.GEOM_CYLINDER, radius=radius, height=height)
        visual_shape_id = self._p.createVisualShape(shapeType=self._p.GEOM_CYLINDER, radius=radius, length=height, rgbaColor=color)
        return self._p.createMultiBody(baseMass=mass, baseCollisionShapeIndex=collision_shape_id, baseVisualShapeIndex=visual_shape_id, basePosition=position, baseOrientation=orientation)

    def reset(self):
        observation = super().reset()

        # Reset cylinder position
        self._p.resetBasePositionAndOrientation(self.cylinder_id, self.cylinder_position_init, self.cylinder_orientation_init)

        # Reset robot position on the top of cylinder
        self._p.resetBasePositionAndOrientation(self.robot.robot_id, [self.cylinder_position_init[0], self.cylinder_position_init[1], self.cylinder_position_init[2] + self.cylinder_radius + self.robot.links["base"].position_init[2]], self.robot.links["base"].orientation_init)

        return observation

    def step(self, action):
        # Before taking action
        self.position = self.robot.links["base"].position

        observation, reward, terminated, truncated, info = super().step(action)

        return observation, reward, terminated, truncated, info

    def get_task_rewards(self, action):
        # After taking action
        new_position = self.robot.links["base"].position

        # Survival
        survival = 1.

        # Forward velocity
        forward_velocity = (new_position[0] - self.position[0]) / self.dt

        return {"survival": survival, "forward_velocity": forward_velocity}

    def get_terminated(self, action):
        # Terminate if not on cylinder
        is_on_cylinder = self.robot.links["base"].position[2] > self.cylinder_position_init[2] + self.cylinder_radius
        return not is_on_cylinder

    def get_success(self):
        # Success if rolled on cylinder
        return self.robot.links["base"].position[0] > 5.

</omni_epic/envs/r2d2/walk_on_cylinder.py>

<omni_epic/envs/wrappers/vision.py>
import gym


class VisionWrapper(gym.Wrapper):

	def __init__(self, env, height=64, width=64, use_depth=True, fov=90.):
		super().__init__(env)
		self._height = height
		self._width = width
		self._use_depth = use_depth
		self._fov = fov

	def vision(self):
		return self.robot.vision(self._height, self._width, self._use_depth, self._fov)

</omni_epic/envs/wrappers/vision.py>

<omni_epic/envs/wrappers/__init__.py>


</omni_epic/envs/wrappers/__init__.py>

<omni_epic/envs/__init__.py>
import multiprocessing
import numpy as np


# Task descriptions
task_dict = {
	"go_up_stairs_0.05m": """
Go up the stairs.

The stairs have 10 steps going up. The steps are 1.0 meters in length, 5.0 meters in width, and 0.05 meters in height. The robot starts on the ground, 2.0 meters away from the bottom of the stairs.
The task of the robot is to walk up the stairs, ensuring that it maintains its balance and does not fall.
""".strip(),

	"go_up_stairs_0.1m": """
Go up the stairs.

The stairs have 10 steps going up. The steps are 1.0 meters in length, 5.0 meters in width, and 0.1 meters in height. The robot starts on the ground, 2.0 meters away from the bottom of the stairs.
The task of the robot is to walk up the stairs, ensuring that it maintains its balance and does not fall.
""".strip(),

	"hurdle_0.05m": """
Run forward over one hurdle.

A hurdle is placed 2.0 meters ahead of the robot. The hurdle measures 0.1 meters in length, 5.0 meters in width, and 0.05 meters in height.
The task of the robot is to run forward, leaping over the hurdle without touching or sidestepping it.
""".strip(),

	"hurdles_0.05m": """
Run forward over a series of 5 hurdles.

A series of 5 hurdles spaced 2.0 meters apart, is placed 2.0 meters ahead of the robot. Each hurdle measures 0.1 meters in length, 5.0 meters in width, and 0.05 meters in height.
The task of the robot is to run forward, leaping over the hurdles without touching or sidestepping it.
""".strip(),

	"kick_ball_to_goal": """
Kick the ball towards the goal.

A red ball is placed 2.0 meters from the robot. The goal is represented by a green box and is placed 5.0 meters from the robot.
The task of the robot is to reach the ball as quickly as possible and kick the ball to push it towards the goal.
""".strip(),

	"kick_ball_to_goalposts": """
Kick the ball towards the goal.

A red ball is placed 2.0 meters away from the robot. The goal is represented by two green posts and is placed 5.0 meters from the robot. The goalposts are spaced at least twice the ball's diameter apart.
The task of the robot is to reach the ball as quickly as possible and kick the ball to push it towards the goal between the two goalposts.
""".strip(),

	"walk_backward_on_cylinder": """
Walk backward on a cylinder.

The robot is standing on a 2-meter-radius cylinder that can roll on the floor on the x axis.
The task of the robot is to walk backward on the cylinder while not falling off.
""".strip(),

	"dance_on_platform": """
Dance on a platform.

The robot is standing on a yellow platform that is 4.0 meters in length and width, and 0.1 meters in height above the ground.
The task of the robot is to move its body, to dance to a periodic rhythm.
""".strip(),

	"cross_bridge_gap_0.05m": """
Cross a pride-colored bridge with tiny gaps.

A 6-meter-long bridge with pride colors links the start platform to the end platform. The bridge has tiny gaps of 0.05 meters between each segment.
The task of the robot is to cross the bridge as quickly as possible.
""".strip(),

	"cross_bridge_gap_0.1m": """
Cross a pride-colored bridge with tiny gaps.

A 6-meter-long bridge with pride colors links the start platform to the end platform. The bridge has tiny gaps of 0.1 meters between each segment.
The task of the robot is to cross the bridge as quickly as possible.
""".strip(),
}


# Test Environment
terminated_error = """
The method Env.get_terminated returns True immediately following Env.reset, leading the episode to terminate prematurely.

Possible causes:
- The method Env.get_terminated might not be implemented correctly.
- The method Env.reset might not be implemented correctly, causing the termination condition to be met immediately after reset.

To fix:
- Check the implementation of Env.get_terminated and ensure that the logic is correct.
- Check the implementation of Env.reset and make sure that the termination condition is not met immediately after reset. For example, ensure that the initial state of the robot does not meet the termination condition after reset.
""".strip()

success_error = """
The method Env.get_success returns True immediately following Env.reset, leading to completing the task prematurely.

Possible causes:
- The method Env.get_success might not be implemented correctly.
- The method Env.reset might not be implemented correctly, causing the success condition to be met immediately after reset.

To fix:
- Check the implementation of Env.get_success and ensure that the logic is correct.
- Check the implementation of Env.reset and make sure that the success condition is not met immediately after reset.
	- Ensure that the initial state of the robot does not meet the success condition after reset.
""".strip()

robot_colliding_error = """
A collision has been detected between the robot and another body, immediately following Env.reset. This issue typically indicates a problem with the initial position of the robot relative to its environment, leading to overlaps.

Possible causes:
- The initial position of the robot might be set incorrectly during Env.reset.
- The initial position or orientation of at least one object might be set incorrectly during Env.reset.

To fix:
- Ensure that the robot's initial position is set relative to the platform it starts on, as demonstrated in the provided environment code examples. For example, if the robot starts on a platform, its initial position should be set to [self.platform_position[0], self.platform_position[1], self.platform_position[2] + self.platform_size[2] / 2 + self.robot.links["base"].position_init[2]].
- Check Env.reset and make sure that the initial position of the robot is set correctly.
	- Ensure that the initial x and y coordinates of the robot are set to the designated starting point of the supporting ground or platform to avoid off-edge placements.
	- Ensure that the initial z coordinate of the robot is set to a height that allows for safe clearance above the supporting ground or platform, avoiding any unintended collision with the surface.
- Check Env.reset and make sure that the initial position of the objects are set correctly.
	- Ensure that the initial position of each object is spaced far enough from the robot, taking into account the size and shape of each object to prevent overlapping.
	- Ensure that the initial orientation of each object is appropriate, and that any directional aspects of the objects do not interfere with the robot's starting position.
""".strip()

object_colliding_error = """
A collision has been detected between at least two bodies, immediately following Env.reset. This issue typically indicates a problem with the initial position or orientation of the different bodies, leading to overlaps.

To fix:
- Check Env.reset and make sure that the initial position and orientation of each object are set correctly.
	- If an object is supposed to be initialized on a supporting ground or platform, ensure that the initial x and y coordinates of the object are set to the designated starting point of the supporting ground or platform to avoid off-edge placements.
	- If an object is supposed to be initialized on a supporting ground or platform, ensure that the initial z coordinate of the object is set to a height that allows for safe clearance above the supporting ground or platform, avoiding any unintended collision with the surface.
- Ensure that objects are spaced far enough from each other, taking into account the size and shape of each object to prevent overlapping.
- Ensure that the initial orientation of each object is appropriate, and that any directional aspects of objects do not interfere with each other.
""".strip()

robot_falling_error = """
The robot is falling immediately following Env.reset.

Possible causes:
- The initial position of the robot might be set incorrectly during Env.reset, causing it to start off the edge of a platform or unsupported area.
- No supporting ground or platform for the robot to stand on has been created during Env.reset, causing the robot to free fall.
- A supporting ground of platform for the robot to stand on exists, but it might not be large enough or its initial position might be set incorrectly, leading to inadequate support.

To fix:
- Check Env.reset and make sure that the initial position of the robot is set correctly.
	- Verify that the robot is initialized at a safe and central position on the platform or ground. Check the x and y coordinates to ensure they center the robot adequately on the available space.
	- Ensure the z coordinate positions the robot firmly on the surface, without any part suspended in air.
- Confirm the existence and adequacy of the platform or ground:
	- Check that a platform or ground is created to support the robot.
	- Ensure that the platform or ground is of appropriate dimensions to accommodate the robot's size.
	- Adjust the initial position of the platform or ground, making sure it aligns correctly with the initial position of the robot.
	- Make sure that the platform or ground is steady and stable, providing a secure foundation for the robot.
""".strip()

timeout_error = """
A method in class Env exceeded the time limit while running.

Possible causes:
- A method might contain an infinite loop.
- A method might take an excessive amount of time to complete.

To fix:
Check the implementation of Env and ensure that all methods including Env.__init__ have proper termination conditions and don't contain infinite loops.
""".strip()

class EnvironmentError(Exception):
	pass

def test_env(env_path):
	# Test Env.__init__
	from embodied.envs.pybullet import PyBullet
	env = PyBullet(env_path=env_path, vision=False)._env

	try:
		# Test Env.reset
		observation = env.reset()
		if not isinstance(observation, np.ndarray):
			raise EnvironmentError(
				f"Expected observation from Env.reset to be a numpy.ndarray, but received type '{type(observation).__name__}'. "
				"Please ensure that observation from Env.reset returns a numpy.ndarray."
			)

		# Test robot collision after Env.reset
		if env.is_robot_colliding():
			raise EnvironmentError(robot_colliding_error)

		# Test Env.step
		observation, reward, terminated, truncated, info = env.step(0. * env.action_space.sample())

		if not isinstance(observation, np.ndarray):
			raise EnvironmentError(
				f"Expected observation from Env.step to be a numpy.ndarray, but received type '{type(observation).__name__}'. "
				"Please ensure that observation from Env.step returns a numpy.ndarray."
			)

		if not isinstance(terminated, bool) and not isinstance(terminated, np.bool_) and not (isinstance(terminated, np.ndarray) and terminated.dtype == bool):
			raise EnvironmentError(
				f"Expected terminated from Env.step to be a boolean, but received type '{type(terminated).__name__}'. "
				"Please ensure that terminated from Env.step returns a boolean."
			)

		# Test Env.get_success
		success = env.get_success()
		if not isinstance(success, bool) and not isinstance(success, np.bool_) and not (isinstance(success, np.ndarray) and success.dtype == bool):
			raise EnvironmentError(
				f"Expected success from Env.get_success to be a boolean, but received type '{type(success).__name__}'. "
				"Please ensure that success from Env.get_success returns a boolean."
			)

		# Test robot collision after one Env.step call
		if env.is_robot_colliding():
			raise EnvironmentError(robot_colliding_error)

		# Test terminated after one Env.step call
		if terminated:
			raise EnvironmentError(terminated_error)

		# Test success after one Env.step call
		if success:
			raise EnvironmentError(success_error)

		for _ in range(100):
			env.step(0. * env.action_space.sample())
			if env.is_object_colliding():
				raise EnvironmentError(object_colliding_error)
			if env.is_robot_falling():
				raise EnvironmentError(robot_falling_error)
	except Exception as e:
		raise e
	finally:
		env.close()

def env_run_all(env_path):
	# Test Env.__init__
	from embodied.envs.pybullet import PyBullet
	env = PyBullet(env_path=env_path, vision=False)._env

	try:
		# Test Env.reset
		env.reset()

		# Test Env.step
		env.step(env.action_space.sample())

		# Test Env.get_success
		env.get_success()
	except:
		pass
	finally:
		env.close()

def test_env_halts(env_path, timeout=10.):
	process = multiprocessing.Process(target=env_run_all, args=(env_path,))
	process.start()

	process.join(timeout)
	if process.is_alive():
		process.terminate()
		process.join()
		raise EnvironmentError(timeout_error)


if __name__ == "__main__":
	env_path = "/workspace/src/env_not_halting.py"
	# env_path = "/workspace/src/env_error.py"
	# env_path = "/workspace/src/env_good.py"

	test_env_halts(env_path)

</omni_epic/envs/__init__.py>

<omni_epic/robots/ant.py>
import os
import functools

import numpy as np
from scipy.spatial.transform import Rotation
import gym.spaces
import pybullet
import pybullet_data

from omni_epic.robots.base import MJCFRobot


class AntRobot(MJCFRobot):

	electricity_penalty_weight = 0.2
	stall_torque_penalty_weight = 0.1
	joints_at_limit_penalty_weight = 0.1

	foot_list = ["front_left_foot", "front_right_foot", "left_back_foot", "right_back_foot"]
	joints_torque_max = {
		"hip_1": 250., "ankle_1": 250.,
		"hip_2": 250., "ankle_2": 250.,
		"hip_3": 250., "ankle_3": 250.,
		"hip_4": 250., "ankle_4": 250.,
	}

	def __init__(self, bullet_client):
		mjcf = os.path.join(pybullet_data.getDataPath(), "mjcf", "ant.xml")
		super().__init__(bullet_client, mjcf, self_collision=True, joints_torque_max=self.joints_torque_max)

	@functools.cached_property
	def action_space(self):
		high = np.ones((8,), dtype=np.float32)
		return gym.spaces.Box(-high, high, dtype=np.float32)

	@functools.cached_property
	def observation_space(self):
		high = np.inf * np.ones((30,), dtype=np.float32)
		return gym.spaces.Box(-high, high, dtype=np.float32)

	def reset(self, seed=None):
		super().reset(seed=seed)

		self.links["base"].set_position_and_orientation(
			self.links["base"].position_init,
			self.links["base"].orientation_init,
		)
		self.links["base"].set_linear_velocity_and_angular_velocity(
			self.links["base"].linear_velocity_init,
			self.links["base"].angular_velocity_init,
		)
		for joint in self.joints.values():
			joint.reset_position_and_velocity(self.np_random.uniform(low=-0.01, high=0.01), 0.)
		self.update()

	def apply_action(self, action):
		torque = self._action_to_torque(action)
		self._p.setJointMotorControlArray(
			bodyIndex=self.robot_id,
			jointIndices=self._joints_index,
			controlMode=pybullet.TORQUE_CONTROL,
			forces=torque,
		)

	def _action_to_torque(self, action):
		return self._joints_torque_max * np.clip(action, -1., +1.)

	def get_observation(self):
		qpos = np.concatenate([self.links["base"].orientation] + [joint.position_norm for joint in self.joints.values()])  # (12,)
		qvel = np.concatenate([self.links["base"].linear_velocity, self.links["base"].angular_velocity] + [joint.velocity for joint in self.joints.values()])  # (14,)
		feet_contact = self._get_feet_contact()  # (4,)
		return np.concatenate([qpos, qvel, feet_contact])

	def get_rewards(self, action):
		# Energy penalty
		joints_velocity = np.array([joint.velocity[0] for joint in self.joints.values()])
		electricity_penalty = self.electricity_penalty_weight * float(np.abs(action * joints_velocity).mean())
		stall_torque_penalty = self.stall_torque_penalty_weight * float(np.square(action).mean())

		# Joints at limit penalty
		joints_position_norm = np.array([joint.position_norm[0] for joint in self.joints.values()])
		joints_at_limit = np.count_nonzero(np.abs(joints_position_norm) > 0.99)
		joints_at_limit_penalty = self.joints_at_limit_penalty_weight * float(joints_at_limit)

		return {"electricity_penalty": -electricity_penalty, "stall_torque_penalty": -stall_torque_penalty, "joints_at_limit_penalty": -joints_at_limit_penalty}

	def _get_feet_contact(self):
		return np.asarray([len(self._p.getContactPoints(bodyA=self.robot_id, linkIndexA=self.links[foot].index)) > 0 for foot in self.foot_list], dtype=np.float32)

	def _get_contact_force(self):
		forces = []
		for foot in self.foot_list:
			contact_points = self._p.getContactPoints(bodyA=self.robot_id, linkIndexA=self.links[foot].index)
			if contact_points:
				contact_normal = np.sum(np.asarray([contact_point[9] * np.asarray(contact_point[7]) for contact_point in contact_points], dtype=np.float32), axis=0)
				lateral_friction_1 = np.sum(np.asarray([contact_point[10] * np.asarray(contact_point[11]) for contact_point in contact_points], dtype=np.float32), axis=0)
				lateral_friction_2 = np.sum(np.asarray([contact_point[12] * np.asarray(contact_point[13]) for contact_point in contact_points], dtype=np.float32), axis=0)
				force = contact_normal + lateral_friction_1 + lateral_friction_2
			else:
				force = np.zeros(3, dtype=np.float32)
			forces.append(force)
		return np.concatenate(forces, axis=0)

	def _get_eye_target_up(self):
		head_rotation = Rotation.from_quat(self.links["base"].orientation)

		# Eye position
		eye_position = self.links["base"].position + head_rotation.apply(np.array([0.25, 0., 0.]))  # head is 0.25m in front of the torso

		# Target position
		target_position = eye_position + 10. * head_rotation.apply(np.array([1., 0., 0.]))

		# Up vector
		up_vector = head_rotation.apply(np.array([0., 0., 1.]))

		return eye_position, target_position, up_vector

</omni_epic/robots/ant.py>

<omni_epic/robots/base.py>
import logging

import numpy as np
from gym.utils import seeding
import pybullet
logger = logging.getLogger(__name__)


class Robot:
	"""
	Abstract class for robots.
	"""

	action_space: ...
	observation_space: ...

	_np_random = None

	@property
	def np_random(self):
		if self._np_random is None:
			self._np_random, seed = seeding.np_random()
		return self._np_random

	@np_random.setter
	def np_random(self, value: np.random.Generator):
		self._np_random = value

	def reset(self, seed=None):
		if seed is not None:
			self._np_random, seed = seeding.np_random(seed)

	def apply_action(self, action):
		raise NotImplementedError

	def get_observation(self):
		raise NotImplementedError

	def get_rewards(self, action):
		raise NotImplementedError

	def vision(self, height, width, use_depth, fov):
		near = 0.01
		far = 100.
		eye_position, target_position, up_vector = self._get_eye_target_up()
		view_matrix = self._p.computeViewMatrix(
			cameraEyePosition=eye_position,
			cameraTargetPosition=target_position,
			cameraUpVector=up_vector,
		)
		proj_matrix = self._p.computeProjectionMatrixFOV(
			fov=fov,
			aspect=width / height,
			nearVal=near,
			farVal=far,
		)
		(_, _, rgba, zbuffer, _) = self._p.getCameraImage(
			width=width,
			height=height,
			viewMatrix=view_matrix,
			projectionMatrix=proj_matrix,
			renderer=pybullet.ER_BULLET_HARDWARE_OPENGL,
			flags=pybullet.ER_NO_SEGMENTATION_MASK,
		)
		if use_depth:
			def zbuffer_to_depth(zbuffer):
				return far * near / (far - (far - near) * zbuffer)

			depth = (zbuffer_to_depth(zbuffer) - near) / far
			return np.concatenate([rgba[..., :3] / 255., depth[..., None]], axis=-1, dtype=np.float32)
		else:
			return (rgba[..., :3] / 255.).astype(np.float32)

class XMLRobot(Robot):
	"""
	Abstract class for XML based robots.
	"""

	def __init__(self, bullet_client):
		self._p = bullet_client

	def _init(self, robot_id):
		links, joints = {}, {}
		links["base"] = Base(self._p, robot_id)
		for joint_index in range(self._p.getNumJoints(bodyUniqueId=robot_id)):
			self._p.setJointMotorControl2(
				bodyUniqueId=robot_id,
				jointIndex=joint_index,
				controlMode=pybullet.POSITION_CONTROL,
				force=0,
				positionGain=0.1,
				velocityGain=0.1,
			)  # TODO: is it possible to use disable method of Joint class?
			joint_info = self._p.getJointInfo(bodyUniqueId=robot_id, jointIndex=joint_index)
			joint_name = joint_info[1].decode("utf8")
			link_name = joint_info[12].decode("utf8")

			assert link_name not in links, f"Link {link_name} already exists in links dictionary."
			links[link_name] = Link(self._p, robot_id, joint_index, link_name)

			if joint_name.startswith("ignore"):
				logger.info(f"Ignore joint {joint_name}.")
				Joint(self._p, robot_id, joint_index, joint_name).disable()
				continue
			elif joint_name.startswith("jointfix"):
				logger.info(f"Ignore joint {joint_name}.")
			elif joint_info[2] == pybullet.JOINT_FIXED:
				logger.info(f"Ignore joint {joint_name}.")
			else:
				assert joint_name not in joints, f"Joint {joint_name} already exists in joints dictionary."
				assert joint_info[2] == pybullet.JOINT_REVOLUTE, f"Joint {joint_name} is not supported."
				joints[joint_name] = Joint(self._p, robot_id, joint_index, joint_name)
		return links, joints


class URDFRobot(XMLRobot):
	"""
	Base class for URDF based robots.
	"""

	def __init__(self, bullet_client, urdf, base_position=[0., 0., 0.], base_orientation=[0., 0., 0., 1.], fixed_base=False, self_collision=True):
		super().__init__(bullet_client)
		self.base_position = base_position
		self.base_orientation = base_orientation
		self.fixed_base = fixed_base
		self.self_collision = self_collision

		# Load URDF
		if self_collision:
			flags = pybullet.URDF_USE_SELF_COLLISION | pybullet.URDF_GOOGLEY_UNDEFINED_COLORS
		else:
			flags = pybullet.URDF_GOOGLEY_UNDEFINED_COLORS
		self.robot_id = self._p.loadURDF(
			fileName=urdf,
			basePosition=self.base_position,
			baseOrientation=self.base_orientation,
			useFixedBase=self.fixed_base,
			flags=flags,
		)
		self.links, self.joints = self._init(self.robot_id)

		# Mass
		self.mass = np.asarray([link.mass for link in self.links.values()]).sum()

		# Links
		self._link_index = np.asarray([link.index for link in self.links.values()], dtype=np.int32)

		# Joints
		self._joints_index = np.asarray([joint.index for joint in self.joints.values()], dtype=np.int32)

	def _update_links(self):
		base, *links_list = self.links.values()

		# Update base
		base.position, base.orientation = base._get_position_and_orientation()
		base.linear_velocity, base.angular_velocity = base._get_linear_velocity_and_angular_velocity()

		# Update links
		links_state = self._p.getLinkStates(bodyUniqueId=self.robot_id, linkIndices=self._link_index[1:], computeLinkVelocity=1)
		for link, link_state in zip(links_list, links_state):
			link.position, link.orientation = np.asarray(link_state[0], dtype=np.float32), np.asarray(link_state[1], dtype=np.float32)
			link.linear_velocity, link.angular_velocity = np.asarray(link_state[6], dtype=np.float32), np.asarray(link_state[7], dtype=np.float32)

	def _update_joints(self):
		if len(self.joints) > 0:
			joints_state = self._p.getJointStates(bodyUniqueId=self.robot_id, jointIndex=self._joints_index)
			for joint, joint_state in zip(self.joints.values(), joints_state):
				joint.position, joint.velocity = np.asarray([joint_state[0]], dtype=np.float32), np.asarray([joint_state[1]], dtype=np.float32)

	def update(self):
		self._update_links()
		self._update_joints()


class MJCFRobot(XMLRobot):
	"""
	Base class for MJCF based robots.
	"""

	def __init__(self, bullet_client, mjcf, self_collision=True, joints_torque_max=None):
		super().__init__(bullet_client)
		self.self_collision = self_collision

		# Load MJCF
		if self_collision:
			self.flags = pybullet.URDF_USE_SELF_COLLISION | pybullet.URDF_USE_SELF_COLLISION_EXCLUDE_ALL_PARENTS | pybullet.URDF_GOOGLEY_UNDEFINED_COLORS
		else:
			self.flags = pybullet.URDF_GOOGLEY_UNDEFINED_COLORS
		(self.robot_id,) = self._p.loadMJCF(mjcfFileName=mjcf, flags=self.flags)
		self.links, self.joints = self._init(self.robot_id)

		# Mass
		self.mass = np.asarray([link.mass for link in self.links.values()]).sum()

		# Links
		self._link_index = np.asarray([link.index for link in self.links.values()], dtype=np.int32)

		# Joints
		self._joints_index = np.asarray([joint.index for joint in self.joints.values()], dtype=np.int32)
		if joints_torque_max is not None:
			assert joints_torque_max.keys() == self.joints.keys(), "joints_max_torque keys must match self.joints keys."
			for joint_name, joint in self.joints.items():
				joint.torque_max = joints_torque_max[joint_name]
			self._joints_torque_max = np.asarray([joint.torque_max for joint in self.joints.values()], dtype=np.float32)

	def _update_links(self):
		base, *links_list = self.links.values()

		# Update base
		base.position, base.orientation = base._get_position_and_orientation()
		base.linear_velocity, base.angular_velocity = base._get_linear_velocity_and_angular_velocity()

		# Update links
		links_state = self._p.getLinkStates(bodyUniqueId=self.robot_id, linkIndices=self._link_index[1:], computeLinkVelocity=1)
		for link, link_state in zip(links_list, links_state):
			link.position, link.orientation = np.asarray(link_state[0], dtype=np.float32), np.asarray(link_state[1], dtype=np.float32)
			link.linear_velocity, link.angular_velocity = np.asarray(link_state[6], dtype=np.float32), np.asarray(link_state[7], dtype=np.float32)

	def _update_joints(self):
		joints_state = self._p.getJointStates(bodyUniqueId=self.robot_id, jointIndices=self._joints_index)
		if joints_state is None:
			return
		for joint, joint_state in zip(self.joints.values(), joints_state):
			joint.position, joint.velocity = np.asarray([joint_state[0]], dtype=np.float32), np.asarray([joint_state[1]], dtype=np.float32)

	def update(self):
		self._update_links()
		self._update_joints()


class Link:

	def __init__(self, bullet_client, robot_id, link_index, link_name):
		self._p = bullet_client
		self.robot_id = robot_id
		self.index = link_index
		self.name = link_name
		self.mass = self._p.getDynamicsInfo(bodyUniqueId=self.robot_id, linkIndex=self.index)[0]

		self.position_init, self.orientation_init = self._get_position_and_orientation()
		self.linear_velocity_init, self.angular_velocity_init = self._get_linear_velocity_and_angular_velocity()

		self.position, self.orientation = self.position_init, self.orientation_init
		self.linear_velocity, self.angular_velocity = self.linear_velocity_init, self.angular_velocity_init

	def _get_position_and_orientation(self):
		position, orientation, _, _, _, _ = self._p.getLinkState(bodyUniqueId=self.robot_id, linkIndex=self.index)
		return np.asarray(position, dtype=np.float32), np.asarray(orientation, dtype=np.float32)  # return position and orientation in world frame

	def _get_linear_velocity_and_angular_velocity(self):
		_, _, _, _, _, _, linear_velocity, angular_velocity = self._p.getLinkState(bodyUniqueId=self.robot_id, linkIndex=self.index, computeLinkVelocity=1)
		return np.asarray(linear_velocity, dtype=np.float32), np.asarray(angular_velocity, dtype=np.float32)  # return velocity in world frame


class Base(Link):

	def __init__(self, bullet_client, robot_id):
		super().__init__(bullet_client, robot_id, -1, "base")

		self.position_init, self.orientation_init = self._get_position_and_orientation()
		self.linear_velocity_init, self.angular_velocity_init = self._get_linear_velocity_and_angular_velocity()

		self.position, self.orientation = self.position_init, self.orientation_init
		self.linear_velocity, self.angular_velocity = self.linear_velocity_init, self.angular_velocity_init

	def _get_position_and_orientation(self):
		position, orientation = self._p.getBasePositionAndOrientation(bodyUniqueId=self.robot_id)
		return np.asarray(position, dtype=np.float32), np.asarray(orientation, dtype=np.float32)  # return position and orientation in world frame

	def set_position_and_orientation(self, position, orientation):
		self._p.resetBasePositionAndOrientation(bodyUniqueId=self.robot_id, posObj=position, ornObj=orientation)
		self.position, self.orientation = position, orientation

	def _get_linear_velocity_and_angular_velocity(self):
		linear_velocity, angular_velocity = self._p.getBaseVelocity(bodyUniqueId=self.robot_id)
		return np.asarray(linear_velocity, dtype=np.float32), np.asarray(angular_velocity, dtype=np.float32)  # return velocity in world frame

	def set_linear_velocity_and_angular_velocity(self, linear_velocity, angular_velocity):
		self._p.resetBaseVelocity(objectUniqueId=self.robot_id, linearVelocity=linear_velocity, angularVelocity=angular_velocity)
		self.linear_velocity, self.angular_velocity = linear_velocity, angular_velocity


class Joint:

	def __init__(self, bullet_client, robot_id, joint_index, joint_name):
		self._p = bullet_client
		self.robot_id = robot_id
		self.index = joint_index
		self.name = joint_name

		joint_info = self._p.getJointInfo(bodyUniqueId=self.robot_id, jointIndex=self.index)
		self.lower_limit = joint_info[8]
		self.upper_limit = joint_info[9]
		self.torque_max = None

		self.position, self.velocity = self._get_position_and_velocity()

	def _get_position_and_velocity(self):
		position, velocity, _, _ = self._p.getJointState(bodyUniqueId=self.robot_id, jointIndex=self.index)
		return np.asarray([position], dtype=np.float32), np.asarray([velocity], dtype=np.float32)

	def set_position_and_velocity(self, position, velocity):
		self._p.resetJointState(bodyUniqueId=self.robot_id, jointIndex=self.index, targetValue=position, targetVelocity=velocity)
		self.position, self.velocity = position, velocity

	def reset_position_and_velocity(self, position, velocity):
		self.set_position_and_velocity(position, velocity)
		self.disable()

	@property
	def position_norm(self):
		# Normalize joint position to [-1., 1.]
		pos_mid = 0.5 * (self.lower_limit + self.upper_limit)
		return  2 * (self.position - pos_mid) / (self.upper_limit - self.lower_limit)

	def set_position(self, position):
		self._p.setJointMotorControl2(
			bodyUniqueId=self.robot_id,
			jointIndex=self.index,
			controlMode=pybullet.POSITION_CONTROL,
			targetPosition=position,
		)

	def set_velocity(self, velocity):
		self._p.setJointMotorControl2(
			bodyUniqueId=self.robot_id,
			jointIndex=self.index,
			controlMode=pybullet.VELOCITY_CONTROL,
			targetVelocity=velocity,
		)

	def set_torque(self, torque):
		self._p.setJointMotorControl2(
			bodyUniqueId=self.robot_id,
			jointIndex=self.index,
			controlMode=pybullet.TORQUE_CONTROL,
			force=torque,
		)

	def disable(self):
		self._p.setJointMotorControl2(
			bodyUniqueId=self.robot_id,
			jointIndex=self.index,
			controlMode=pybullet.POSITION_CONTROL,
			targetPosition=0.,
			targetVelocity=0.,
			force=0.,
			positionGain=0.1,  # TODO: is it needed?
			velocityGain=0.1,  # TODO: is it needed?
		)


def angle_between_vectors_2d(v_1, v_2):
	return np.arctan2(np.cross(v_1, v_2), np.dot(v_1, v_2))

def angle_between_vectors_3d(v_1, v_2):
	return np.arctan2(np.linalg.norm(np.cross(v_1, v_2)), np.dot(v_1, v_2))

</omni_epic/robots/base.py>

<omni_epic/robots/humanoid.py>
import os
import functools

import numpy as np
from scipy.spatial.transform import Rotation
import gym.spaces
import pybullet
import pybullet_data

from omni_epic.robots.base import MJCFRobot, angle_between_vectors_3d


class HumanoidRobot(MJCFRobot):

	electricity_penalty_weight = 0.85
	stall_torque_penalty_weight = 0.425
	joints_at_limit_penalty_weight = 0.1

	foot_list = ["left_foot", "right_foot"]
	joints_torque_max = {
		"abdomen_z": 41., "abdomen_y": 41., "abdomen_x": 41.,
		"right_hip_x": 41., "right_hip_z": 41., "right_hip_y": 123., "right_knee": 82.,
		"left_hip_x":  41., "left_hip_z": 41., "left_hip_y": 123., "left_knee": 82.,
		"right_shoulder1": 30.75, "right_shoulder2": 30.75, "right_elbow": 30.75,
		"left_shoulder1": 30.75, "left_shoulder2": 30.75, "left_elbow": 30.75,
	}

	def __init__(self, bullet_client):
		mjcf = os.path.join(pybullet_data.getDataPath(), "mjcf", "humanoid_symmetric.xml")
		super().__init__(bullet_client, mjcf, self_collision=True, joints_torque_max=self.joints_torque_max)

	@functools.cached_property
	def action_space(self):
		high = np.ones((17,), dtype=np.float32)
		return gym.spaces.Box(-high, high, dtype=np.float32)

	@functools.cached_property
	def observation_space(self):
		high = np.inf * np.ones((46,), dtype=np.float32)
		return gym.spaces.Box(-high, high, dtype=np.float32)

	def reset(self, seed=None):
		super().reset(seed=seed)

		self.links["base"].set_position_and_orientation(
			self.links["base"].position_init,
			self.links["base"].orientation_init,
		)
		self.links["base"].set_linear_velocity_and_angular_velocity(
			self.links["base"].linear_velocity_init,
			self.links["base"].angular_velocity_init,
		)
		for joint in self.joints.values():
			joint.reset_position_and_velocity(self.np_random.uniform(low=-0.01, high=0.01), 0.)
		self.update()

	def apply_action(self, action):
		torque = self._action_to_torque(action)
		self._p.setJointMotorControlArray(
			bodyIndex=self.robot_id,
			jointIndices=self._joints_index,
			controlMode=pybullet.TORQUE_CONTROL,
			forces=torque,
		)

	def _action_to_torque(self, action):
		return self._joints_torque_max * np.clip(action, -1., +1.)

	def get_observation(self):
		qpos = np.concatenate([self.links["base"].orientation] + [joint.position_norm for joint in self.joints.values()])  # (21,)
		qvel = np.concatenate([self.links["base"].linear_velocity, self.links["base"].angular_velocity] + [joint.velocity for joint in self.joints.values()])  # (23,)
		feet_contact = self._get_feet_contact()  # (2,)
		return np.concatenate([qpos, qvel, feet_contact])

	def get_rewards(self, action):
		# Energy penalty
		joints_velocity = np.array([joint.velocity[0] for joint in self.joints.values()])
		electricity_penalty = self.electricity_penalty_weight * float(np.abs(action * joints_velocity).mean())
		stall_torque_penalty = self.stall_torque_penalty_weight * float(np.square(action).mean())

		# Joints at limit penalty
		joints_position_norm = np.array([joint.position_norm[0] for joint in self.joints.values()])
		joints_at_limit = np.count_nonzero(np.abs(joints_position_norm) > 0.99)
		joints_at_limit_penalty = self.joints_at_limit_penalty_weight * float(joints_at_limit)

		return {"electricity_penalty": -electricity_penalty, "stall_torque_penalty": -stall_torque_penalty, "joints_at_limit_penalty": -joints_at_limit_penalty}

	def _get_feet_contact(self):
		return np.asarray([len(self._p.getContactPoints(bodyA=self.robot_id, linkIndexA=self.links[foot].index)) > 0 for foot in self.foot_list], dtype=np.float32)

	def _get_contact_force(self):
		forces = []
		for foot in self.foot_list:
			contact_points = self._p.getContactPoints(bodyA=self.robot_id, linkIndexA=self.links[foot].index)
			if contact_points:
				contact_normal = np.sum(np.asarray([contact_point[9] * np.asarray(contact_point[7]) for contact_point in contact_points], dtype=np.float32), axis=0)
				lateral_friction_1 = np.sum(np.asarray([contact_point[10] * np.asarray(contact_point[11]) for contact_point in contact_points], dtype=np.float32), axis=0)
				lateral_friction_2 = np.sum(np.asarray([contact_point[12] * np.asarray(contact_point[13]) for contact_point in contact_points], dtype=np.float32), axis=0)
				force = contact_normal + lateral_friction_1 + lateral_friction_2
			else:
				force = np.zeros(3, dtype=np.float32)
			forces.append(force)
		return np.concatenate(forces, axis=0)

	def _get_eye_target_up(self):
		head_rotation = Rotation.from_quat(self.links["base"].orientation)

		# Eye position
		eye_position = self.links["base"].position + head_rotation.apply(np.array([0.09, 0., 0.19]))  # head is 0.19m above the torso

		# Target position
		target_position = eye_position + 10. * head_rotation.apply(np.array([1., 0., 0.]))

		# Up vector
		up_vector = head_rotation.apply(np.array([0., 0., 1.]))

		return eye_position, target_position, up_vector

</omni_epic/robots/humanoid.py>

<omni_epic/robots/r2d2.py>
import functools

import numpy as np
from scipy.spatial.transform import Rotation
import gym.spaces

from omni_epic.robots.base import URDFRobot, angle_between_vectors_3d


class R2D2Robot(URDFRobot):

	wheel_list = ["right_front_wheel", "left_front_wheel", "right_back_wheel", "left_back_wheel"]

	angular_velocity_gain = 200.

	linear_velocity_delta = 0.2
	linear_velocity_max = 10.0

	angular_velocity_delta = 1.
	angular_velocity_max = 2 * 2 * np.pi

	jump_velocity = 5.0

	def __init__(self, bullet_client):
		urdf = "/workspace/src/omni_epic/robots/assets/r2d2.urdf"
		super().__init__(bullet_client, urdf, base_position=[0., 0., 0.5], base_orientation=[0., 0., np.sqrt(2)/2, -np.sqrt(2)/2], self_collision=False)

	@functools.cached_property
	def action_space(self):
		# Four actions: do nothing, move forward, move backward, rotate clockwise, rotate counterclockwise, jump
		return gym.spaces.Discrete(6)

	@functools.cached_property
	def observation_space(self):
		high = np.inf * np.ones((5,), dtype=np.float32)
		return gym.spaces.Box(-high, high, dtype=np.float32)

	def reset(self, seed=None):
		super().reset(seed=seed)

		self.links["base"].set_position_and_orientation(
			self.links["base"].position_init,
			self.links["base"].orientation_init,
		)
		self.links["base"].set_linear_velocity_and_angular_velocity(
			self.links["base"].linear_velocity_init,
			self.links["base"].angular_velocity_init,
		)
		for joint in self.joints.values():
			joint.reset_position_and_velocity(self.np_random.uniform(low=-0.01, high=0.01), 0.)
		self.update()

	def apply_action(self, action):
		base_rotation_init = Rotation.from_quat(self.links["base"].orientation_init)
		base_rotation = Rotation.from_quat(self.links["base"].orientation)
		base_rotation_relative = base_rotation * base_rotation_init.inv()
		up_vector = base_rotation_relative.apply(np.array([0., 0., 1.]))
		cross_vector = np.cross(up_vector, np.array([0., 0., 1.]))
		angle = angle_between_vectors_3d(up_vector, np.array([0., 0., 1.]))

		if action == 0:
			# Do nothing
			new_angular_velocity = np.clip([0., 0., self.links["base"].angular_velocity[2]] + self.angular_velocity_gain * angle * cross_vector, -self.angular_velocity_max, self.angular_velocity_max)
			self._p.resetBaseVelocity(self.robot_id, angularVelocity=new_angular_velocity)
		if action == 1:
			# Go forward - up arrow
			forward_direction = base_rotation_relative.apply(np.array([1., 0., 0.]))
			new_linear_velocity = self.links["base"].linear_velocity + self.linear_velocity_delta * forward_direction
			normalize = min(self.linear_velocity_max / np.linalg.norm(new_linear_velocity), 1.)
			new_angular_velocity = np.clip([0., 0., self.links["base"].angular_velocity[2]] + self.angular_velocity_gain * angle * cross_vector, -self.angular_velocity_max, self.angular_velocity_max)
			self._p.resetBaseVelocity(self.robot_id, linearVelocity=normalize * new_linear_velocity, angularVelocity=new_angular_velocity)
		if action == 2:
			# Go backward - down arrow
			forward_direction = base_rotation_relative.apply(np.array([1., 0., 0.]))
			new_linear_velocity = self.links["base"].linear_velocity - self.linear_velocity_delta * forward_direction
			normalize = min(self.linear_velocity_max / np.linalg.norm(new_linear_velocity), 1.)
			new_angular_velocity = np.clip([0., 0., self.links["base"].angular_velocity[2]] + self.angular_velocity_gain * angle * cross_vector, -self.angular_velocity_max, self.angular_velocity_max)
			self._p.resetBaseVelocity(self.robot_id, linearVelocity=normalize * new_linear_velocity, angularVelocity=new_angular_velocity)
		if action == 3:
			# Rotate clockwise - right arrow
			new_angular_velocity = np.clip([0., 0., self.links["base"].angular_velocity[2]] - self.angular_velocity_delta * up_vector + self.angular_velocity_gain * angle * cross_vector, -self.angular_velocity_max, self.angular_velocity_max)
			self._p.resetBaseVelocity(self.robot_id, angularVelocity=new_angular_velocity)
		if action == 4:
			# Rotate counterclockwise - left arrow
			new_angular_velocity = np.clip([0., 0., self.links["base"].angular_velocity[2]] + self.angular_velocity_delta * up_vector + self.angular_velocity_gain * angle * cross_vector, -self.angular_velocity_max, self.angular_velocity_max)
			self._p.resetBaseVelocity(self.robot_id, angularVelocity=new_angular_velocity)
		if action == 5:
			# Jump - space
			wheel_contact = self._get_wheel_contact()
			is_standing = np.any(wheel_contact, keepdims=True).astype(np.float32)
			if not is_standing:
				new_angular_velocity = np.clip([0., 0., self.links["base"].angular_velocity[2]] + self.angular_velocity_gain * angle * cross_vector, -self.angular_velocity_max, self.angular_velocity_max)
				self._p.resetBaseVelocity(self.robot_id, angularVelocity=new_angular_velocity)
			else:
				new_linear_velocity = np.array([self.links["base"].linear_velocity[0], self.links["base"].linear_velocity[1], self.jump_velocity])  # no clipping
				new_angular_velocity = np.clip([0., 0., self.links["base"].angular_velocity[2]] + self.angular_velocity_gain * angle * cross_vector, -self.angular_velocity_max, self.angular_velocity_max)
				self._p.resetBaseVelocity(self.robot_id, linearVelocity=new_linear_velocity)

	def get_observation(self):
		qvel = np.concatenate([self.links["base"].linear_velocity, self.links["base"].angular_velocity[2:]])  # (4,)
		wheel_contact = self._get_wheel_contact()
		is_standing = np.any(wheel_contact, keepdims=True).astype(np.float32)  # (1,)
		return np.concatenate([qvel, is_standing])

	def get_rewards(self, action):
		if action == 0:
			return {"energy_penalty": 0.}
		elif action == 1 or action == 2:
			return {"energy_penalty": -0.2}
		elif action == 3 or action == 4:
			return {"energy_penalty": -0.1}
		elif action == 5:
			return {"energy_penalty": -0.5}

	def _get_wheel_contact(self):
		return np.asarray([len(self._p.getContactPoints(bodyA=self.robot_id, linkIndexA=self.links[wheel].index)) > 0 for wheel in self.wheel_list], dtype=np.float32)

	def _get_eye_target_up(self):
		head_rotation = Rotation.from_quat(self.links["base"].orientation)

		# Eye position
		eye_position = self.links["base"].position + head_rotation.apply(np.array([0., 0., 0.3]) + np.array([0., 0.1214, 0.1214]))  # head is 0.25m in front of the torso

		# Target position
		target_position = eye_position + 10. * head_rotation.apply(np.array([0., 1., 0.]))

		# Up vector
		up_vector = head_rotation.apply(np.array([0., 0., 1.]))

		return eye_position, target_position, up_vector

</omni_epic/robots/r2d2.py>

<omni_epic/robots/__init__.py>
from textwrap import dedent


robot_dict = {
	"ant": {
		"robot_desc": dedent("""
			Quadruped robot consisting of a base and four articulated legs.
			- The links of the robot, given by `robot.links.keys()`, include but are not limited to `['base', 'front_left_leg', 'front_left_foot', 'front_right_leg', 'front_right_foot', 'left_back_leg', 'left_back_foot', 'right_back_leg', 'right_back_foot']`.
			- The robot measures 2 m in width and 1 m in height.
			- The initial position of the robot is given by `robot.links["base"].position_init`, and is appropriate to position the robot on a platform whose surface is at z = 0.
			- The initial orientation of the robot is given by `robot.links["base"].orientation_init`, which aligns the robot to face toward the positive x-axis.
			""").strip(),
		"env_paths_example": [
			"/workspace/src/omni_epic/envs/ant/balance_board.py",
			"/workspace/src/omni_epic/envs/ant/cross_bridge.py",
			"/workspace/src/omni_epic/envs/ant/cross_lava.py",
			"/workspace/src/omni_epic/envs/ant/go_down_stairs.py",
			"/workspace/src/omni_epic/envs/ant/go_to_box.py",
			"/workspace/src/omni_epic/envs/ant/kick_ball.py",
			# "/workspace/src/omni_epic/envs/ant/maze.py",
			"/workspace/src/omni_epic/envs/ant/open_door.py",
			# "/workspace/src/omni_epic/envs/ant/go_forward.py",
			"/workspace/src/omni_epic/envs/ant/walk_on_cylinder.py",
		],
		"task_descs_init": [
			dedent("""
			Cross a pride-colored bridge with gaps to reach a platform.

			Description:
			- A start platform and an end platform (each 3 m in size and 0.5 m in thickness) are placed 30 m apart.
			- The two platforms are connected by a bridge (2 m wide) divided in multiple segments. Each segment has a different color corresponding to the pride colors.
			- The segments are separated by gaps measuring 0.1 m.
			The robot is initialized on the start platform.
			The task of the robot is to cross the bridge to reach the end platform as fast as possible.

			Success:
			The task is successfully completed when the robot reaches the end platform.

			Rewards:
			To help the robot complete the task:
			- The robot receives a reward for each time step it remains standing on the bridge or platforms, encouraging steady progress.
			- The robot is rewarded based on how much it reduces the distance to the end platform, incentivizing swift movement towards the goal.

			Termination:
			The task terminates immediately if the robot falls off the start platform, any segment of the bridge, or the end platform.
			""").strip(),
			dedent("""
			Go backward on top of a rolling cylinder.

			Description:
			- The environment consists of a large flat ground measuring 1000 x 1000 x 10 m.
			- A cylinder with a radius of 2 m and a height of 3 m is placed on the ground and can roll along the x-axis.
			- The cylinder's initial position is at the center of the ground, and it is oriented to roll along the x-axis.
			- The robot is initialized on top of the cylinder.
			- The task of the robot is to go backward while balancing on top of the rolling cylinder.

			Success:
			The task is completed if the robot rolls more than 5 m backward without falling off.

			Rewards:
			To guide the robot to complete the task:
			- The robot receives a reward for each time step it remains balanced on the cylinder.
			- The robot receives a reward for backward velocity along the x-axis.

			Termination:
			The task terminates immediately if the is not standing on the cylinder or if the robot falls off the cylinder.
			""").strip(),
			dedent("""
			Dodge flying balls.

			Description:
			- The environment is a square arena measuring 20 x 20 x 5 m.
			- The robot is initialized at the center of the arena.
			- Every second a ball is launched toward the robot at varying speeds from random positions around the arena.
			- The task of the robot is to avoid being hit by the balls while remaining within the arena boundaries.

			Success:
			The task is successfully completed if the robot dodges all the balls.

			Rewards:
			To help the robot complete the task:
			- The robot is rewarded for standing at each time step.

			Termination:
			The task terminates immediately if the robot is hit by a ball or if the robot falls off the arena.
			""").strip()
		]
	},

	"humanoid": {
		"robot_desc": dedent("""
			Humanoid robot consisting of a base with two legs, two arms and a head.
			- The links of the robot, given by `robot.links.keys()`, include but are not limited to `['base', 'lwaist', 'pelvis', 'right_thigh', 'right_shin', 'right_foot', 'left_thigh', 'left_shin', 'left_foot', 'right_upper_arm', 'right_lower_arm', 'left_upper_arm', 'left_lower_arm']`.
			- The robot measures 0.5 m in width and 1.8 m in height.
			- The initial position of the robot is given by `robot.links["base"].position_init`, and is appropriate to position the robot on a platform whose surface is at z = 0.
			- The initial orientation of the robot is given by `robot.links["base"].orientation_init`, which aligns the robot to face toward the positive x-axis.
			""").strip(),
		"env_paths_example": [
			"/workspace/src/omni_epic/envs/humanoid/balance_board.py",
			"/workspace/src/omni_epic/envs/humanoid/cross_bridge.py",
			"/workspace/src/omni_epic/envs/humanoid/cross_lava.py",
			"/workspace/src/omni_epic/envs/humanoid/go_down_stairs.py",
			"/workspace/src/omni_epic/envs/humanoid/go_to_box.py",
			"/workspace/src/omni_epic/envs/humanoid/kick_ball.py",
			# "/workspace/src/omni_epic/envs/humanoid/maze.py",
			"/workspace/src/omni_epic/envs/humanoid/open_door.py",
			# "/workspace/src/omni_epic/envs/humanoid/go_forward.py",
			"/workspace/src/omni_epic/envs/humanoid/walk_on_cylinder.py",
		],
		"task_descs_init": [
			dedent("""
			Cross a pride-colored bridge with gaps to reach a platform.

			Description:
			- A start platform and an end platform (each 3 m in size and 0.5 m in thickness) are placed 30 m apart.
			- The two platforms are connected by a bridge (2 m wide) divided in multiple segments. Each segment has a different color corresponding to the pride colors.
			- The segments are separated by gaps measuring 0.1 m.
			The robot is initialized on the start platform.
			The task of the robot is to cross the bridge to reach the end platform as fast as possible.

			Success:
			The task is successfully completed when the robot reaches the end platform.

			Rewards:
			To help the robot complete the task:
			- The robot receives a reward for each time step it remains standing on the bridge or platforms, encouraging steady progress.
			- The robot is rewarded based on how much it reduces the distance to the end platform, incentivizing swift movement towards the goal.

			Termination:
			The task terminates immediately if the robot falls off the start platform, any segment of the bridge, or the end platform.
			""").strip(),
			dedent("""
			Go backward on top of a rolling cylinder.

			Description:
			- The environment consists of a large flat ground measuring 1000 x 1000 x 10 m.
			- A cylinder with a radius of 2 m and a height of 3 m is placed on the ground and can roll along the x-axis.
			- The cylinder's initial position is at the center of the ground, and it is oriented to roll along the x-axis.
			- The robot is initialized on top of the cylinder.
			- The task of the robot is to go backward while balancing on top of the rolling cylinder.

			Success:
			The task is completed if the robot rolls more than 5 m backward without falling off.

			Rewards:
			To guide the robot to complete the task:
			- The robot receives a reward for each time step it remains balanced on the cylinder.
			- The robot receives a reward for backward velocity along the x-axis.

			Termination:
			The task terminates immediately if the is not standing on the cylinder or if the robot falls off the cylinder.
			""").strip(),
			dedent("""
			Dodge flying balls.

			Description:
			- The environment is a square arena measuring 20 x 20 x 5 m.
			- The robot is initialized at the center of the arena.
			- Every second a ball is launched toward the robot at varying speeds from random positions around the arena.
			- The task of the robot is to avoid being hit by the balls while remaining within the arena boundaries.

			Success:
			The task is successfully completed if the robot dodges all the balls.

			Rewards:
			To help the robot complete the task:
			- The robot is rewarded for standing at each time step.

			Termination:
			The task terminates immediately if the robot is hit by a ball or if the robot falls off the arena.
			""").strip()
		]
	},

	"r2d2": {
		"robot_desc": dedent("""
			R2D2 robot that can roll on wheels up to 10 m/s and jump 1 m high.
			- The robot measures 0.5 m in width and 1 m in height.
			- The initial position of the robot is given by `robot.links["base"].position_init`, and is appropriate to position the robot on a platform whose surface is at z = 0.
			- The initial orientation of the robot is given by `robot.links["base"].orientation_init`, which aligns the robot to face toward the positive x-axis.
			""").strip(),
		"env_paths_example": [
			"/workspace/src/omni_epic/envs/r2d2/balance_board.py",
			"/workspace/src/omni_epic/envs/r2d2/cross_bridge.py",
			"/workspace/src/omni_epic/envs/r2d2/cross_lava.py",
			"/workspace/src/omni_epic/envs/r2d2/go_down_stairs.py",
			"/workspace/src/omni_epic/envs/r2d2/go_to_box.py",
			"/workspace/src/omni_epic/envs/r2d2/kick_ball.py",
			# "/workspace/src/omni_epic/envs/r2d2/maze.py",
			"/workspace/src/omni_epic/envs/r2d2/open_door.py",
			# "/workspace/src/omni_epic/envs/r2d2/go_forward.py",
			"/workspace/src/omni_epic/envs/r2d2/walk_on_cylinder.py",
		],
		"task_descs_init": [
			dedent("""
			Cross a pride-colored bridge with gaps to reach a platform.

			Description:
			- A start platform and an end platform (each 3 m in size and 0.5 m in thickness) are placed 50 m apart.
			- The two platforms are connected by a bridge (2 m wide) divided in multiple segments. Each segment has a different color corresponding to the pride colors.
			- The segments are separated by gaps measuring 2 m.
			The robot is initialized on the start platform.
			The task of the robot is to cross the bridge to reach the end platform as fast as possible.

			Success:
			The task is successfully completed when the robot reaches the end platform.

			Rewards:
			To help the robot complete the task:
			- The robot receives a reward for each time step it remains standing on the bridge or platforms, encouraging steady progress.
			- The robot is rewarded based on how much it reduces the distance to the end platform, incentivizing swift movement towards the goal.

			Termination:
			The task terminates immediately if the robot falls off the start platform, any segment of the bridge, or the end platform.
			""").strip(),
			dedent("""
			Ascend a series of stairs to reach a platform.

			Description:
			- The environment consists of a ground platform (1000 m x 10 m x 10 m) and a set of 10 steps.
			- Each step has dimensions of 1 m in length, 10 m in width, and 0.2 m in height.
			- The steps are positioned to form an ascending staircase, with each subsequent step higher than the previous one.
			The robot is initialized on the ground at the bottom of the stairs.

			Success:
			The task is completed when the robot successfully ascends the stairs and reaches the top platform.

			Rewards:
			To help the robot complete the task:
			- The robot is rewarded for survival at each time step.
			- The robot is rewarded for forward velocity, incentivizing it to move up the stairs.

			Termination:
			The task terminates immediately if the robot falls off the stairs or the top platform.
			""").strip(),
			dedent("""
			Kick a ball into a goal.

			Description:
			- The environment consists of a large flat ground measuring 1000 x 1000 x 10 meters.
			- A ball with a radius of 0.5 meters is placed randomly on the ground.
			- The goal is defined by two goal posts, each 2 meters high and placed 3 meters apart, forming a goal area.
			- The robot is initialized at a fixed position on the ground.
			- The task of the robot is to move across the ground, reach the ball, and kick it into the goal.

			Success:
			The task is successfully completed if the robot kicks the ball so that it passes between the two goal posts.

			Rewards:
			To help the robot complete the task:
			- The robot is rewarded for survival at each time step.
			- The robot is rewarded for decreasing its distance to the ball.
			- The robot is rewarded for kicking the ball towards the goal, with additional rewards for successfully kicking the ball into the goal.

			Termination:
			The task does not have a specific termination condition.
			""").strip()
		]
	},
}

</omni_epic/robots/__init__.py>

<rag_utils.py>
import numpy as np
from scipy import spatial


def read_file(file_path):
	with open(file_path, 'r') as file:
		return file.read()

def distances_from_embeddings(
	query_embedding,
	embeddings,
	distance_metric="cosine",
):
	"""Return the distances between a query embedding and a list of embeddings."""
	distance_metrics = {
		"cosine": spatial.distance.cosine,
		"L1": spatial.distance.cityblock,
		"L2": spatial.distance.euclidean,
		"Linf": spatial.distance.chebyshev,
	}
	distances = [
		distance_metrics[distance_metric](query_embedding, embedding)
		for embedding in embeddings
	]
	return distances

def get_openai_embeddings(texts):
	from openai import OpenAI

	client = OpenAI()
	assert len(texts) <= 2048, "The batch size should not be larger than 2048."
	# replace newlines, which can negatively affect performance.
	texts = [text.replace("\n", " ") for text in texts]
	data = client.embeddings.create(input=texts, model='text-embedding-3-small').data
	return [d.embedding for d in data]

def get_codet5_embeddings(texts):
	import torch
	from transformers import AutoModel, AutoTokenizer

	checkpoint = "Salesforce/codet5p-110m-embedding"
	device = "cuda" if torch.cuda.is_available() else "cpu"
	tokenizer = AutoTokenizer.from_pretrained(checkpoint)
	model = AutoModel.from_pretrained(checkpoint, trust_remote_code=True).to(device)
	embeddings = []
	for text in texts:
		inputs = tokenizer.encode(text, return_tensors="pt").to(device)
		embedding = model(inputs)[0].detach().cpu().numpy()
		embeddings.append(embedding)
	return embeddings

def get_mxbai_embeddings(texts):
	from sentence_transformers import SentenceTransformer

	model = SentenceTransformer("mixedbread-ai/mxbai-embed-large-v1")
	embeddings = model.encode(texts)
	return embeddings

def get_bert_embeddings(texts):
	from transformers import BertTokenizer, BertModel

	tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
	model = BertModel.from_pretrained('bert-base-uncased')
	inputs = tokenizer(texts, return_tensors='pt', padding=True, truncation=True, max_length=512)
	outputs = model(**inputs)
	# Use the average of the last hidden state as the sentence embedding
	embeddings = outputs.last_hidden_state.mean(dim=1).detach().numpy()
	return embeddings

def get_nomic_embeddings(texts):
	# import torch.nn.functional as F
	from sentence_transformers import SentenceTransformer

	model = SentenceTransformer("nomic-ai/nomic-embed-text-v1.5", trust_remote_code=True)
	texts = [f'search_document: {xs}' for xs in texts]
	embeddings = model.encode(texts)
	return embeddings

def get_mistral_embeddings(texts):
	import torch
	import torch.nn.functional as F
	from torch import Tensor
	from transformers import AutoTokenizer, AutoModel, BitsAndBytesConfig

	def last_token_pool(last_hidden_states: Tensor,
					attention_mask: Tensor) -> Tensor:
		left_padding = (attention_mask[:, -1].sum() == attention_mask.shape[0])
		if left_padding:
			return last_hidden_states[:, -1]
		else:
			sequence_lengths = attention_mask.sum(dim=1) - 1
			batch_size = last_hidden_states.shape[0]
			return last_hidden_states[torch.arange(batch_size, device=last_hidden_states.device), sequence_lengths]

	quantization_config = BitsAndBytesConfig(
		load_in_4bit=True,
		bnb_4bit_quant_type="nf4",
		bnb_4bit_compute_dtype=torch.float16,
	)
	tokenizer = AutoTokenizer.from_pretrained('intfloat/e5-mistral-7b-instruct')
	model = AutoModel.from_pretrained(
		'intfloat/e5-mistral-7b-instruct',
		torch_dtype=torch.float16,
		attn_implementation="flash_attention_2",
		device_map="cuda",
		quantization_config=quantization_config,
	)

	batch_dict = tokenizer(texts, padding=True, return_tensors='pt')
	outputs = model(**batch_dict)
	embeddings = last_token_pool(outputs.last_hidden_state, batch_dict['attention_mask'])
	embeddings = F.normalize(embeddings, p=2, dim=1).detach().cpu().numpy()
	return embeddings

def get_embeddings(codepath, embedding_method="codet5"):
	""" Get the embedding of a code snippet.

	Args:
		codepath (str): The path to the code snippet.
		embedding_method (str): The method to use for embedding the code snippet.

	Returns:
		list: The embedding of the code snippet.
	"""
	# Read the content of the code snippet
	content = read_file(codepath)

	# Map embedding methods to their respective functions
	embedding_methods = {
		"openai": get_openai_embeddings,
		"codet5": get_codet5_embeddings,
		"mxbai": get_mxbai_embeddings,
		"bert": get_bert_embeddings,
		"nomic": get_nomic_embeddings,
		"mistral": get_mistral_embeddings,
	}

	# Use the specified embedding method
	if embedding_method in embedding_methods:
		embeddings = embedding_methods[embedding_method]([content])
	else:
		raise ValueError(f"Invalid embedding method: {embedding_method}")

	return embeddings[0]

def get_similar_codepaths(chosen_codepath, other_codepaths, num_returns=5, embedding_method="codet5"):
	# TODO: reembedding the tasks everytime, can save it to a cache or smth
	""" Get codepaths that have similar content to that of the chosen codepath.

	Args:
		chosen_codepath (str): The path to the chosen code snippet.
		other_codepaths (list): List of paths to other code snippets.
		num_returns (int): Number of code snippets to return.
		embedding_method (str): The method to use for embedding the code snippets.

	Returns:
		list: Paths to the most similar code snippets.
	"""
	# Read contents of codepaths
	chosen_content = read_file(chosen_codepath)
	other_contents = [read_file(codepath) for codepath in other_codepaths]

	# Map embedding methods to their respective functions
	embedding_methods = {
		"openai": get_openai_embeddings,
		"codet5": get_codet5_embeddings,
		"mxbai": get_mxbai_embeddings,
		"bert": get_bert_embeddings,
		"nomic": get_nomic_embeddings,
		"mistral": get_mistral_embeddings,
	}

	# Use the specified embedding method
	if embedding_method in embedding_methods:
		embeddings = embedding_methods[embedding_method]([chosen_content] + other_contents)
	else:
		raise ValueError(f"Invalid embedding method: {embedding_method}")

	# Get the chosen vector and other vectors
	chosen_vector = embeddings[0]
	other_vectors = embeddings[1:]

	# Calculate distances between emebddings
	similarities = distances_from_embeddings(chosen_vector, other_vectors, distance_metric="cosine")
	sorted_indices = np.array(similarities).argsort()

	# Return the most similar codepaths
	similar_indices = sorted_indices[:num_returns]
	return [other_codepaths[i] for i in similar_indices], similar_indices


if __name__ == "__main__":
	chosen_codepath = "/workspace/src/omni_epic/envs/ant/cross_bridge.py"
	other_codepaths = [
			"/workspace/src/omni_epic/envs/ant/cross_bridge.py",
			"/workspace/src/omni_epic/envs/ant/go_to_box.py",
			"/workspace/src/omni_epic/envs/ant/kick_ball.py",
			"/workspace/src/omni_epic/envs/ant/maze.py",
			"/workspace/src/omni_epic/envs/ant/go_forward.py",
			"/workspace/src/omni_epic/envs/ant/walk_on_cylinder.py",
			"/workspace/src/omni_epic/envs/ant/go_down_stairs.py",
			"/workspace/src/omni_epic/envs/ant/cross_lava.py",
			"/workspace/src/omni_epic/envs/ant/balance_board.py",
		]
	similar_codepaths, similar_indices = get_similar_codepaths(chosen_codepath, other_codepaths, embedding_method="mistral")
	print(similar_codepaths)

</rag_utils.py>

<README.md>
<h1 align="center">
  <b>OMNI-EPIC:<br/>Open-endedness via Models of human Notions of Interestingness with Environments Programmed in Code</b><br>
</h1>

<p align="center">
  <a href="https://github.com/maxencefaldor/omni-epic/blob/main/LICENSE"><img src="https://img.shields.io/badge/License-Apache%202.0-blue.svg?style=for-the-badge"></a>
  <a href="https://arxiv.org/abs/2405.15568"><img src="https://img.shields.io/badge/arXiv-2405.15568-b31b1b.svg?logo=arxiv&style=for-the-badge"></a>
  <a href="https://omni-epic.vercel.app/"><img src="https://img.shields.io/badge/-Website-%238D6748?style=for-the-badge&logo=Website&logoColor=white"></a>
  <a href="https://x.com/jeffclune/status/1795787632435212732"><img src="https://img.shields.io/badge/twitter-%230077B5.svg?&style=for-the-badge&logo=twitter&logoColor=white&color=00acee"></a>
</p>

<p align="center">
  <img src="misc/render_0.gif" width="23%" height="auto" />
  <img src="misc/render3p_3.gif" width="23%" height="auto" />
  <img src="misc/render_2.gif" width="23%" height="auto" />
  <img src="misc/render3p_2.gif" width="23%" height="auto" />
</p>

Repository for **O**pen-endedness via **M**odels of human **N**otions of **I**nterestingness (**OMNI**) with **E**nvironments **P**rogrammed **i**n **C**ode (**EPIC**), that *endlessly* create learnable and interesting environments, further propelling the development of self-improving AI systems and AI-Generating Algorithms.

<p align="center">
<img src="misc/algo.svg"/></a><br>
</p>

## Setup - Apptainer

### Step 0: update your environment

Update your `.bashrc` with

```bash
# Add foundation model API keys to your environment
export OPENAI_API_KEY='...'
export ANTHROPIC_API_KEY='...'

# Optionally
export CUDA_VISIBLE_DEVICES=...
export WANDB_API_KEY='...'
```

### Step 1: clone the repository

Clone the repository with `git clone https://github.com/maxencefaldor/omni-epic.git`.

### Step 2: build the container

Go at the root of the cloned repository with `cd omni-epic/` and run:

```bash
apptainer build \
	--fakeroot \
	--force \
	apptainer/container.sif \
	apptainer/container.def
```

### Step 3: shell into the container

Go at the root of the cloned repository with `cd omni-epic/` and run

```bash
apptainer shell \
	--bind $(pwd):/workspace/src/ \
	--cleanenv \
	--containall \
	--env "CUDA_VISIBLE_DEVICES=$CUDA_VISIBLE_DEVICES" \
	--env "WANDB_API_KEY=$WANDB_API_KEY" \
	--env "OPENAI_API_KEY=$OPENAI_API_KEY" \
	--env "ANTHROPIC_API_KEY=$ANTHROPIC_API_KEY" \
	--home /tmp/ \
	--no-home \
	--nv \
	--pwd /workspace/src/ \
	--workdir apptainer/ \
	apptainer/container.sif
```

## Running Instructions

### Running OMNI-EPIC

```bash
python main_omni_epic.py
```

### Human Playable Game

```bash
python -m game.backend.app
```

For prettier frontend, on another terminal
```bash
cd game/frontend/
npm i
npm run dev
```

See more detailed readme for this in `game/frontend/README.md`

### File structure

- `analysis/` scripts used for plotting and analysis
- `apptainer/` for setting up apptainer, easier reproducability
- `configs/` configuration files used in training and analysis
- `dreamerv3/` code for DreamerV3, RL algorithm used to train the agents
- `game/` code for human playable game
- `omni_epic/` code for robots, example environments, and foundation model calls

## Citation

If you find this project useful, please consider citing:
```
@article{faldor2024omni,
	title={OMNI-EPIC: Open-endedness via Models of human Notions of Interestingness with Environments Programmed in Code},
	author={Faldor, Maxence and Zhang, Jenny and Cully, Antoine and Clune, Jeff},
	journal={arXiv preprint arXiv:2405.15568},
	year={2024}
}
```

</README.md>

<repo_structure_omni.yaml>
  - path: /analysis
    type: directory
    contents:
    - path: /analysis/icons
      type: directory
      contents:
      - path: /analysis/icons/cross.png
        type: file
      - path: /analysis/icons/sleep.png
        type: file
      - path: /analysis/icons/tick.png
        type: file
    - path: /analysis/plot_annecs.py
      type: file
    - path: /analysis/plot_diversity.py
      type: file
    - path: /analysis/plot_envgen_success.py
      type: file
    - path: /analysis/plot_percentlearned.py
      type: file
    - path: /analysis/run_scratch.py
      type: file
    - path: /analysis/visualize_blockbuster.py
      type: file
    - path: /analysis/visualize_dreamer.py
      type: file
    - path: /analysis/visualize_taskgen.py
      type: file
  - path: /apptainer
    type: directory
    contents:
    - path: /apptainer/10_nvidia.json
      type: file
    - path: /apptainer/container.def
      type: file
  - path: /configs
    type: directory
    contents:
    - path: /configs/dreamer
      type: directory
      contents:
      - path: /configs/dreamer/dreamer_xs.yaml
        type: file
      - path: /configs/dreamer/dreamer_xxs.yaml
        type: file
    - path: /configs/omni_epic.yaml
      type: file
    - path: /configs/plot_annecs.yaml
      type: file
    - path: /configs/plot_diversity.yaml
      type: file
  - path: /dreamerv3
    type: directory
    contents:
    - path: /dreamerv3/agent.py
      type: file
    - path: /dreamerv3/configs.yaml
      type: file
    - path: /dreamerv3/Dockerfile
      type: file
    - path: /dreamerv3/jaxagent.py
      type: file
    - path: /dreamerv3/jaxutils.py
      type: file
    - path: /dreamerv3/main.py
      type: file
    - path: /dreamerv3/nets.py
      type: file
    - path: /dreamerv3/ninjax.py
      type: file
    - path: /dreamerv3/requirements.txt
      type: file
    - path: /dreamerv3/__init__.py
      type: file
  - path: /embodied
    type: directory
    contents:
    - path: /embodied/core
      type: directory
      contents:
      - path: /embodied/core/agg.py
        type: file
      - path: /embodied/core/base.py
        type: file
      - path: /embodied/core/checkpoint.py
        type: file
      - path: /embodied/core/config.py
        type: file
      - path: /embodied/core/counter.py
        type: file
      - path: /embodied/core/driver.py
        type: file
      - path: /embodied/core/flags.py
        type: file
      - path: /embodied/core/fps.py
        type: file
      - path: /embodied/core/logger.py
        type: file
      - path: /embodied/core/path.py
        type: file
      - path: /embodied/core/prefetch.py
        type: file
      - path: /embodied/core/printing.py
        type: file
      - path: /embodied/core/random_agent.py
        type: file
      - path: /embodied/core/rwlock.py
        type: file
      - path: /embodied/core/space.py
        type: file
      - path: /embodied/core/timer.py
        type: file
      - path: /embodied/core/tree.py
        type: file
      - path: /embodied/core/usage.py
        type: file
      - path: /embodied/core/utils.py
        type: file
      - path: /embodied/core/uuid.py
        type: file
      - path: /embodied/core/when.py
        type: file
      - path: /embodied/core/wrappers.py
        type: file
      - path: /embodied/core/__init__.py
        type: file
    - path: /embodied/distr
      type: directory
      contents:
      - path: /embodied/distr/client.py
        type: file
      - path: /embodied/distr/pool.py
        type: file
      - path: /embodied/distr/process.py
        type: file
      - path: /embodied/distr/proc_server.py
        type: file
      - path: /embodied/distr/server.py
        type: file
      - path: /embodied/distr/sockets.py
        type: file
      - path: /embodied/distr/thread.py
        type: file
      - path: /embodied/distr/utils.py
        type: file
      - path: /embodied/distr/__init__.py
        type: file
    - path: /embodied/envs
      type: directory
      contents:
      - path: /embodied/envs/atari.py
        type: file
      - path: /embodied/envs/bsuite.py
        type: file
      - path: /embodied/envs/crafter.py
        type: file
      - path: /embodied/envs/dmc.py
        type: file
      - path: /embodied/envs/dmlab.py
        type: file
      - path: /embodied/envs/dummy.py
        type: file
      - path: /embodied/envs/from_dm.py
        type: file
      - path: /embodied/envs/from_gym.py
        type: file
      - path: /embodied/envs/loconav.py
        type: file
      - path: /embodied/envs/loconav_quadruped.py
        type: file
      - path: /embodied/envs/loconav_quadruped.xml
        type: file
      - path: /embodied/envs/minecraft.py
        type: file
      - path: /embodied/envs/minecraft_base.py
        type: file
      - path: /embodied/envs/minecraft_minerl.py
        type: file
      - path: /embodied/envs/pinpad.py
        type: file
      - path: /embodied/envs/procgen.py
        type: file
      - path: /embodied/envs/pybullet.py
        type: file
    - path: /embodied/replay
      type: directory
      contents:
      - path: /embodied/replay/chunk.py
        type: file
      - path: /embodied/replay/indexdict.py
        type: file
      - path: /embodied/replay/limiters.py
        type: file
      - path: /embodied/replay/replay.py
        type: file
      - path: /embodied/replay/sampletree.py
        type: file
      - path: /embodied/replay/selectors.py
        type: file
      - path: /embodied/replay/__init__.py
        type: file
    - path: /embodied/requirements.txt
      type: file
    - path: /embodied/run
      type: directory
      contents:
      - path: /embodied/run/eval.py
        type: file
      - path: /embodied/run/eval_only.py
        type: file
      - path: /embodied/run/parallel.py
        type: file
      - path: /embodied/run/parallel_with_eval.py
        type: file
      - path: /embodied/run/train.py
        type: file
      - path: /embodied/run/train_eval.py
        type: file
      - path: /embodied/run/train_holdout.py
        type: file
      - path: /embodied/run/__init__.py
        type: file
    - path: /embodied/scripts
      type: directory
      contents:
      - path: /embodied/scripts/install-dmlab.sh
        type: file
      - path: /embodied/scripts/install-minecraft.sh
        type: file
      - path: /embodied/scripts/print.py
        type: file
      - path: /embodied/scripts/xvfb_run.sh
        type: file
    - path: /embodied/tests
      type: directory
      contents:
      - path: /embodied/tests/distr
        type: directory
        contents:
        - path: /embodied/tests/distr/test_process.py
          type: file
        - path: /embodied/tests/distr/test_server.py
          type: file
        - path: /embodied/tests/distr/test_thread.py
          type: file
      - path: /embodied/tests/run
        type: directory
        contents:
        - path: /embodied/tests/run/test_parallel.py
          type: file
        - path: /embodied/tests/run/test_train.py
          type: file
        - path: /embodied/tests/run/utils.py
          type: file
      - path: /embodied/tests/test_driver.py
        type: file
      - path: /embodied/tests/test_path.py
        type: file

</repo_structure_omni.yaml>

<requirements.txt>
--find-links https://storage.googleapis.com/jax-releases/jax_cuda_releases.html

numpy==1.26.4
scipy
jax[cuda12_pip]
flax
torch
tensorflow_probability
scikit-learn
pybullet
gym
statsmodels
seaborn
ipython
ipykernel
opencv-python
moviepy
imageio
mediapy
hydra-core
wandb
openai
anthropic
google-generativeai
memory_profiler

# DreamerV3
ruamel.yaml
einops
colored

# Website
flask
flask-cors
flask-socketio
eventlet

# Visualization
pyvis
manim

</requirements.txt>

<run_utils.py>
import cv2
import base64
import numpy as np
import os
import re
import json
import hydra
from omegaconf import DictConfig
from omegaconf import OmegaConf
from textwrap import dedent

from embodied.envs.pybullet import PyBullet
from omni_epic.robots import robot_dict
from omni_epic.core.fm import FM


# Function to get images at specified intervals from a video file
def get_images_from_video(video_file, interval=62):
	# Open the video file
	cap = cv2.VideoCapture(video_file)
	if not cap.isOpened():
		print("Error: Could not open video.")
		return None
	# Calculate the interval between each image to be captured
	total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
	# Skip the first 10 frames to get to the interesting parts
	frames_to_capture = range(10, total_frames, interval)
	images = []
	for frame_id in frames_to_capture:
		# Read the current frame position of the video file
		cap.set(cv2.CAP_PROP_POS_FRAMES, frame_id)
		ret, frame = cap.read()
		if ret:
			images.append(frame)
		else:
			print(f"Error: Could not read frame {frame_id}")
			break
	# Release the video capture object
	cap.release()
	return images

# Save images into output directory
def save_images(images, output_dir):
	os.makedirs(output_dir, exist_ok=True)
	# Save individual images
	for i, image in enumerate(images):
		cv2.imwrite(f'{output_dir}/image_{i}.png', image)

	# Label image number on the top left corner of each image
	for i, image in enumerate(images):
		cv2.putText(image, f'{i+1}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2, cv2.LINE_AA)

	n_per_row = 8
	# Calculate the number of images to be padded
	padded_images = images.copy()
	remainder = len(padded_images) % n_per_row
	if remainder != 0:
		padding = n_per_row - remainder
		# Create a dummy image with the same shape as the last image in the list
		dummy_image = np.zeros_like(padded_images[-1])
		# Add the dummy image to the list of images
		padded_images.extend([dummy_image] * padding)

	# Save concated images, only have N images per row
	concat_image = np.concatenate([
		 np.concatenate(padded_images[i:i+n_per_row], axis=1) \
			for i in range(0, len(padded_images), n_per_row)], axis=0)
	cv2.imwrite(f'{output_dir}/concat_image.png', concat_image)

	return concat_image

# Function to encode the image
def encode_image(image_path):
	with open(image_path, "rb") as image_file:
		return base64.b64encode(image_file.read()).decode('utf-8')

def get_envcode_path(run_folder):
	input_config = OmegaConf.load(os.path.join(run_folder, "./.hydra/config.yaml"))
	return input_config['env']['path']

def parse_task_desc_from_env_code(env_code):
	# Only search after class definition
	task_desc = re.search(r'class Env.*?:\s*\"\"\"(.+?)\"\"\"', env_code, re.DOTALL).group(1)
	# For each line in taskdesc, remove leading and trailing whitespaces
	task_desc = '\n'.join([line.strip() for line in task_desc.split('\n')]).strip()
	return task_desc

def get_task_desc_from_env_path(env_path):
	env = PyBullet(env_path=env_path, vision=False)._env
	task_desc = dedent(env.__doc__).strip()
	return task_desc

def get_task_success_from_file(success_file):
	# Read file
	with open(success_file, "r") as f:
		text = f.read().strip()
		step_successes = text.split('\n')
		step_successes = [x == 'True' for x in step_successes]
	# Determine final task success
	success = any(step_successes)
	return success

def get_task_success_from_folder(run_folder, voting='majority'):
	# Get task success from saved files
	success_files = [f for f in os.listdir(run_folder) if f.endswith('.txt') and f.startswith('success')]
	success_files = [os.path.join(run_folder, f) for f in success_files]
	# Process overall task success
	task_successes = [get_task_success_from_file(f) for f in success_files]
	if voting == 'majority':
		task_success = sum(task_successes) >= len(task_successes) / 2
	elif voting == 'all':
		task_success = all(task_successes)
	else:
		task_success = any(task_successes)
	return task_success

def get_task_success_file_from_folder(run_folder):
	# Get task success from saved files
	success_files = [f for f in os.listdir(run_folder) if f.endswith('.txt') and f.startswith('success')]
	success_files = [os.path.join(run_folder, f) for f in success_files]
	# Process overall task success
	task_successes = [get_task_success_from_file(f) for f in success_files]
	# Return the first successful file
	for i, task_success in enumerate(task_successes):
		if task_success:
			return success_files[i]
	return None

</run_utils.py>

