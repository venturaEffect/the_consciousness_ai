# configs/reinforcement.yaml

reinforcement:
  # Emotional reward scaling
  emotional_scale: 2.0 # Weight for emotional rewards

  # DreamerV3 World Model Configuration
  dreamer_config:
    hidden_size: 256
    learning_rate: 0.0001
    gamma: 0.99 # Discount factor
    lambda_gae: 0.95 # GAE parameter
    horizon: 333 # Planning horizon
    imag_steps: 15 # Imagination steps for planning

  # Memory Configuration
  memory_config:
    capacity: 100000 # Size of experience buffer
    batch_size: 64
    emotion_embedding_size: 128
    context_length: 32

  # Narrative Configuration
  narrative_config:
    model: "llama-3.3"
    max_length: 128

  # Meta-Learning
  meta_config:
    enabled: true
    adaptation_steps: 5
    inner_learning_rate: 0.01
    meta_batch_size: 16
    context_length: 32

  # Pavilion Integration
  pavilion:
    enabled: true
    face_recognition:
      model: "pavilion_face_rec_v1"
      emotion_threshold: 0.7
    environment:
      render_quality: "epic"
      physics_substeps: 2
      emotion_feedback_rate: 10 # Hz
    interaction:
      max_distance: 2.0
      emotion_memory_length: 100

# Configuration for ACM reinforcement learning and adaptation

narrator_model:
  name: "llama-3.3"
  weights_path: "/models/llama3_3/base"
  lora:
    enabled: true
    rank: 8
    alpha: 32
    # Dynamic adaptation of LoRA weights
    adaptation_rate: 0.01
    min_update_weight: 0.1

meta_memory:
  # Controls for memory reinforcement
  stability:
    threshold: 0.75 # Minimum stability score for pattern reinforcement
    decay_rate: 0.995 # Memory stability decay over time

  # Novel experience handling
  novelty:
    initial_weight: 0.1 # Starting weight for new experiences
    min_reinforcement: 0.05 # Minimum reinforcement value
    max_reinforcement: 0.95 # Maximum reinforcement ceiling

  # Pattern reinforcement
  reinforcement:
    base_rate: 0.1
    scale_factor: 2.0 # Multiplier for repeated patterns
    emotional_bonus: 0.5 # Additional weight for emotional coherence

imagination:
  # Constraints for imagination module
  sampling:
    temperature: 0.8
    top_p: 0.95
    max_tokens: 1024

  # Safety bounds for imagined scenarios
  constraints:
    min_coherence: 0.6
    max_deviation: 0.3
    reality_check_interval: 100

emotional_development:
  # Parameters for emotional learning
  learning_rate: 0.001
  batch_size: 32
  update_interval: 50

  # Stability controls
  min_confidence: 0.7
  max_adaptation_rate: 0.2
  emotional_decay: 0.99

feedback_mechanisms:
  # Predictive feedback controls
  prediction:
    horizon: 100
    confidence_threshold: 0.8
    error_tolerance: 0.15

  # Integration feedback
  integration:
    coherence_weight: 0.6
    stability_weight: 0.4
    minimum_consensus: 0.7
