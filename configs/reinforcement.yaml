# configs/reinforcement.yaml

reinforcement:
  # Emotional reward scaling
  emotional_scale: 2.0

  # DreamerV3 World Model Configuration
  dreamerV3:
    hidden_size: 256
    learning_rate: 0.0001
    gamma: 0.99
    lambda_gae: 0.95
    horizon: 333
    imag_steps: 15

  # Memory Configuration
  memory_config:
    capacity: 100000
    batch_size: 64
    emotion_embedding_size: 128
    context_length: 32

  # Narrative Configuration
  narrative_config:
    model: "llama-3.3"
    max_length: 128

  # Meta-Learning
  meta_config:
    enabled: true
    adaptation_steps: 5
    inner_learning_rate: 0.01
    meta_batch_size: 16
    context_length: 32

  # Pavilion Integration
  pavilion:
    enabled: true
    face_recognition:
      model: "pavilion_face_rec_v1"
      emotion_threshold: 0.7
    environment:
      render_quality: "epic"
      physics_substeps: 2
      emotion_feedback_rate: 10
    interaction:
      max_distance: 2.0
      emotion_memory_length: 100

# Configuration for ACM reinforcement learning and adaptation
narrator_model:
  name: "llama-3.3"
  weights_path: "/models/language/llama-3.3"
  lora:
    enabled: true
    rank: 8
    alpha: 32
    adaptation_rate: 0.01
    min_update_weight: 0.1

meta_memory:
  stability:
    threshold: 0.75
    decay_rate: 0.995

  novelty:
    initial_weight: 0.1
    min_reinforcement: 0.05
    max_reinforcement: 0.95

  reinforcement:
    base_rate: 0.1
    scale_factor: 2.0
    emotional_bonus: 0.5

imagination:
  sampling:
    temperature: 0.8
    top_p: 0.95
    max_tokens: 1024

  constraints:
    min_coherence: 0.6
    max_deviation: 0.3
    reality_check_interval: 100

emotional_development:
  learning_rate: 0.001
  batch_size: 32
  update_interval: 50
  min_confidence: 0.7
  max_adaptation_rate: 0.2
  emotional_decay: 0.99

feedback_mechanisms:
  prediction:
    horizon: 100
    confidence_threshold: 0.8
    error_tolerance: 0.15

  integration:
    coherence_weight: 0.6
    stability_weight: 0.4
    minimum_consensus: 0.7
