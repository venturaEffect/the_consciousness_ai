  - path: /ACKNOWLEDGEMENT.md
    type: file
  - path: /assets
    type: directory
    contents:
    - path: /assets/cat_and_chicken.mp4
      type: file
    - path: /assets/desert.jpg
      type: file
    - path: /assets/logo.png
      type: file
    - path: /assets/performance.png
      type: file
    - path: /assets/pipeline.jpg
      type: file
    - path: /assets/results_image_2b.png
      type: file
    - path: /assets/results_image_7b.png
      type: file
    - path: /assets/results_video_2b.png
      type: file
    - path: /assets/results_video_7b.png
      type: file
    - path: /assets/sora.png
      type: file
  - path: /evaluation
    type: directory
    contents:
    - path: /evaluation/evaluate.py
      type: file
    - path: /evaluation/image
      type: directory
      contents:
      - path: /evaluation/image/AI2D
        type: directory
        contents:
        - path: /evaluation/image/AI2D/evaluate_image_AI2D.py
          type: file
        - path: /evaluation/image/AI2D/inference_image_AI2D.py
          type: file
      - path: /evaluation/image/BLINK
        type: directory
        contents:
        - path: /evaluation/image/BLINK/evaluate_image_BLINK.py
          type: file
        - path: /evaluation/image/BLINK/inference_image_BLINK.py
          type: file
        - path: /evaluation/image/BLINK/multiple_choice.py
          type: file
      - path: /evaluation/image/ChartQA
        type: directory
        contents:
        - path: /evaluation/image/ChartQA/evaluate_image_ChartQA.py
          type: file
        - path: /evaluation/image/ChartQA/inference_image_ChartQA.py
          type: file
      - path: /evaluation/image/DocVQA
        type: directory
        contents:
        - path: /evaluation/image/DocVQA/convert_json.py
          type: file
        - path: /evaluation/image/DocVQA/evaluate_image_DocVQA.py
          type: file
        - path: /evaluation/image/DocVQA/inference_image_DocVQA.py
          type: file
      - path: /evaluation/image/GQA
        type: directory
        contents:
        - path: /evaluation/image/GQA/evaluate_image_GQA.py
          type: file
        - path: /evaluation/image/GQA/inference_image_GQA.py
          type: file
      - path: /evaluation/image/InfoVQA
        type: directory
        contents:
        - path: /evaluation/image/InfoVQA/convert_json.py
          type: file
        - path: /evaluation/image/InfoVQA/evaluate_image_InfoVQA.py
          type: file
        - path: /evaluation/image/InfoVQA/inference_image_InfoVQA.py
          type: file
      - path: /evaluation/image/MathVista
        type: directory
        contents:
        - path: /evaluation/image/MathVista/evaluate_image_MathVista.py
          type: file
        - path: /evaluation/image/MathVista/ext_ans.py
          type: file
        - path: /evaluation/image/MathVista/inference_image_MathVista.py
          type: file
      - path: /evaluation/image/MME
        type: directory
        contents:
        - path: /evaluation/image/MME/evaluate_image_MME.py
          type: file
        - path: /evaluation/image/MME/inference_image_MME.py
          type: file
      - path: /evaluation/image/MMMU
        type: directory
        contents:
        - path: /evaluation/image/MMMU/config_file.yaml
          type: file
        - path: /evaluation/image/MMMU/data_utils.py
          type: file
        - path: /evaluation/image/MMMU/evaluate_image_MMMU.py
          type: file
        - path: /evaluation/image/MMMU/eval_utils.py
          type: file
        - path: /evaluation/image/MMMU/inference_image_MMMU.py
          type: file
      - path: /evaluation/image/MMMU-Pro
        type: directory
        contents:
        - path: /evaluation/image/MMMU-Pro/evaluate_image_MMMU_Pro.py
          type: file
        - path: /evaluation/image/MMMU-Pro/inference_image_MMMU_Pro.py
          type: file
        - path: /evaluation/image/MMMU-Pro/prompts.yaml
          type: file
      - path: /evaluation/image/OCRBench
        type: directory
        contents:
        - path: /evaluation/image/OCRBench/evaluate_image_OCRBench.py
          type: file
        - path: /evaluation/image/OCRBench/inference_image_OCRBench.py
          type: file
      - path: /evaluation/image/RealWorldQA
        type: directory
        contents:
        - path: /evaluation/image/RealWorldQA/evaluate_image_RealWorldQA.py
          type: file
        - path: /evaluation/image/RealWorldQA/inference_image_RealWorldQA.py
          type: file
    - path: /evaluation/register.py
      type: file
    - path: /evaluation/video
      type: directory
      contents:
      - path: /evaluation/video/cap_msvc
        type: directory
        contents:
        - path: /evaluation/video/cap_msvc/eval_video_cap_msvc_correctness.py
          type: file
        - path: /evaluation/video/cap_msvc/eval_video_cap_msvc_detailedness.py
          type: file
        - path: /evaluation/video/cap_msvc/inference_video_cap_msvc.py
          type: file
      - path: /evaluation/video/mcqa
        type: directory
        contents:
        - path: /evaluation/video/mcqa/eval_video_mcqa_mlvu.py
          type: file
        - path: /evaluation/video/mcqa/eval_video_mcqa_mvbench.py
          type: file
        - path: /evaluation/video/mcqa/eval_video_mcqa_videomme.py
          type: file
        - path: /evaluation/video/mcqa/inference_video_mcqa_egoschema.py
          type: file
        - path: /evaluation/video/mcqa/inference_video_mcqa_longvideobench.py
          type: file
        - path: /evaluation/video/mcqa/inference_video_mcqa_mlvu.py
          type: file
        - path: /evaluation/video/mcqa/inference_video_mcqa_mvbench.py
          type: file
        - path: /evaluation/video/mcqa/inference_video_mcqa_perception_test_mcqa.py
          type: file
        - path: /evaluation/video/mcqa/inference_video_mcqa_videomme.py
          type: file
      - path: /evaluation/video/video_oqa
        type: directory
        contents:
        - path: /evaluation/video/video_oqa/eval_video_oqa_activitynet.py
          type: file
        - path: /evaluation/video/video_oqa/eval_video_oqa_vcgpt_1_correctness.py
          type: file
        - path: /evaluation/video/video_oqa/eval_video_oqa_vcgpt_2_detailed_orientation.py
          type: file
        - path: /evaluation/video/video_oqa/eval_video_oqa_vcgpt_3_context.py
          type: file
        - path: /evaluation/video/video_oqa/eval_video_oqa_vcgpt_4_temporal.py
          type: file
        - path: /evaluation/video/video_oqa/eval_video_oqa_vcgpt_5_consistency.py
          type: file
        - path: /evaluation/video/video_oqa/inference_video_oqa_activitynet.py
          type: file
        - path: /evaluation/video/video_oqa/inference_video_oqa_vcgpt_consistency.py
          type: file
        - path: /evaluation/video/video_oqa/inference_video_oqa_vcgpt_general.py
          type: file
  - path: /inference
    type: directory
    contents:
    - path: /inference/example_videollama3.py
      type: file
    - path: /inference/interface
      type: directory
      contents:
      - path: /inference/interface/gradio_interface.py
        type: file
      - path: /inference/interface/__init__.py
        type: file
    - path: /inference/launch_gradio_demo.py
      type: file
    - path: /inference/notebooks
      type: directory
      contents:
      - path: /inference/notebooks/01_single_image_understanding.ipynb
        type: file
      - path: /inference/notebooks/02_multi_image_understanding.ipynb
        type: file
      - path: /inference/notebooks/03_visual_referring_and_grounding.ipynb
        type: file
      - path: /inference/notebooks/04_video_understanding.ipynb
        type: file
      - path: /inference/notebooks/visuals
        type: directory
        contents:
        - path: /inference/notebooks/visuals/algorithm.jpg
          type: file
        - path: /inference/notebooks/visuals/basketball.mp4
          type: file
        - path: /inference/notebooks/visuals/cars.jpg
          type: file
        - path: /inference/notebooks/visuals/cat.jpg
          type: file
        - path: /inference/notebooks/visuals/chart.jpg
          type: file
        - path: /inference/notebooks/visuals/city1.jpg
          type: file
        - path: /inference/notebooks/visuals/city2.jpg
          type: file
        - path: /inference/notebooks/visuals/cola.mp4
          type: file
        - path: /inference/notebooks/visuals/doc.jpg
          type: file
        - path: /inference/notebooks/visuals/long.mp4
          type: file
        - path: /inference/notebooks/visuals/math.jpg
          type: file
        - path: /inference/notebooks/visuals/table.jpg
          type: file
    - path: /inference/server
      type: directory
      contents:
      - path: /inference/server/plain_server.py
        type: file
      - path: /inference/server/__init__.py
        type: file
    - path: /inference/transformers_api
      type: directory
      contents:
      - path: /inference/transformers_api/configuration_videollama3.py
        type: file
      - path: /inference/transformers_api/configuration_videollama3_encoder.py
        type: file
      - path: /inference/transformers_api/image_processing_videollama3.py
        type: file
      - path: /inference/transformers_api/modeling_videollama3.py
        type: file
      - path: /inference/transformers_api/modeling_videollama3_encoder.py
        type: file
      - path: /inference/transformers_api/processing_videollama3.py
        type: file
      - path: /inference/transformers_api/__init__.py
        type: file
  - path: /LICENSE
    type: file
  - path: /pyproject.toml
    type: file
  - path: /README.md
    type: file
  - path: /requirements.txt
    type: file
  - path: /scripts
    type: directory
    contents:
    - path: /scripts/zero1.json
      type: file
    - path: /scripts/zero2.json
      type: file
    - path: /scripts/zero3.json
      type: file
  - path: /videollama3
    type: directory
    contents:
    - path: /videollama3/constants.py
      type: file
    - path: /videollama3/infer.py
      type: file
    - path: /videollama3/mm_utils.py
      type: file
    - path: /videollama3/model
      type: directory
      contents:
      - path: /videollama3/model/encoder.py
        type: file
      - path: /videollama3/model/processor.py
        type: file
      - path: /videollama3/model/projector.py
        type: file
      - path: /videollama3/model/videollama3_arch.py
        type: file
      - path: /videollama3/model/videollama3_encoder
        type: directory
        contents:
        - path: /videollama3/model/videollama3_encoder/configuration_videollama3_encoder.py
          type: file
        - path: /videollama3/model/videollama3_encoder/image_processing_videollama3.py
          type: file
        - path: /videollama3/model/videollama3_encoder/modeling_videollama3_encoder.py
          type: file
        - path: /videollama3/model/videollama3_encoder/__init__.py
          type: file
      - path: /videollama3/model/videollama3_qwen2.py
        type: file
      - path: /videollama3/model/__init__.py
        type: file
    - path: /videollama3/train.py
      type: file
    - path: /videollama3/videollama3_trainer.py
      type: file
    - path: /videollama3/__init__.py
      type: file
